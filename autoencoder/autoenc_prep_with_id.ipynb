{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoenc_prep_with_id.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TapasKumarDutta1/IEEE-CIS-Fraud/blob/master/autoenc_prep_with_id.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, concatenate\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.utils import Sequence, get_custom_objects\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from math import ceil, floor\n",
        "import gc"
      ],
      "metadata": {
        "id": "slRoVeKJiyav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYtsrH0G_GC3"
      },
      "source": [
        "Loading the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "6ec9cd90-9356-41d0-ac4b-94f5eeee5253"
      },
      "source": [
        "\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo-8vK5m_NrM"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3CLKiyk_VTC"
      },
      "source": [
        "np.random.seed(42) # NumPy\n",
        "random.seed(42) # Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFkVLjyg_Io5"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJem4-mp8otc"
      },
      "source": [
        "# Read the training and test data from CSV files and set the first column as the index\n",
        "trn = pd.read_csv(\"/content/gdrive/My Drive/fraud/train_id.csv\", index_col=[0])\n",
        "tst = pd.read_csv(\"/content/gdrive/My Drive/fraud/test_id.csv\", index_col=[0])\n",
        "\n",
        "# Define the list of categorical columns as strings from 0 to 443\n",
        "categorical = [str(i) for i in range(444)]\n",
        "\n",
        "# Convert the categorical columns in the training DataFrame to uint8 data type\n",
        "trn[categorical] = trn[categorical].astype(\"uint8\")\n",
        "\n",
        "# Convert the categorical columns in the test DataFrame to uint8 data type\n",
        "tst[categorical] = tst[categorical].astype(\"uint8\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk57wdug_Kuq"
      },
      "source": [
        "Drop  isFraud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiE3LbOCCgku",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e90041c0-2733-484a-f408-33818f2c4dca"
      },
      "source": [
        "trn = trn.drop([\"isFraud\"], 1)\n",
        "trn.shape, tst.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((590540, 617), (506691, 617))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaSRatVa_Qlr"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKYcx1CSuEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "ead108e0-05cf-4604-8a7d-480853426027"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\"\n",
        "    Reduce the memory usage of a DataFrame by downcasting the numeric columns to smaller data types.\n",
        "\n",
        "    Parameters:\n",
        "        df (DataFrame): The DataFrame to be optimized.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: The DataFrame with reduced memory usage.\n",
        "\n",
        "    Example:\n",
        "        trn = reduce_mem_usage(trn)\n",
        "        tst = reduce_mem_usage(tst)\n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if (\n",
        "                    c_min > np.finfo(np.float16).min\n",
        "                    and c_max < np.finfo(np.float16).max\n",
        "                ):\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif (\n",
        "                    c_min > np.finfo(np.float32).min\n",
        "                    and c_max < np.finfo(np.float32).max\n",
        "                ):\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype(\"category\")\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
        "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Reduce memory usage for training and test DataFrames\n",
        "trn = reduce_mem_usage(trn)\n",
        "tst = reduce_mem_usage(tst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1034.00 MB\n",
            "Memory usage after optimization is: 663.43 MB\n",
            "Decreased by 35.8%\n",
            "Memory usage of dataframe is 887.19 MB\n",
            "Memory usage after optimization is: 566.33 MB\n",
            "Decreased by 36.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYYe5k4-_aBP"
      },
      "source": [
        "Concatenate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha_HXo738T8S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5b93af53-4280-4ac6-ac39-abce4200e611"
      },
      "source": [
        "# Concatenate trn and tst DataFrames and reset index\n",
        "X = pd.concat([trn, tst]).reset_index(drop=True)\n",
        "\n",
        "# Delete trn and tst DataFrames to free up memory\n",
        "del trn, tst\n",
        "\n",
        "# Convert categorical columns to uint8 data type to optimize memory usage\n",
        "categorical = [str(i) for i in range(444)]\n",
        "X[categorical] = X[categorical].astype(\"uint8\")\n",
        "\n",
        "# Perform garbage collection to release unused memory\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGUnUEl_dAz"
      },
      "source": [
        "Divide data into categorical and numerical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIcL-BDLW9T"
      },
      "source": [
        "\n",
        "# Define the categorical columns as a list of strings from 0 to 443\n",
        "cat = [str(i) for i in range(444)]\n",
        "\n",
        "# Convert the categorical columns to uint8 data type to optimize memory usage\n",
        "X[cat] = X[cat].astype('uint8')\n",
        "\n",
        "# Find columns that are not categorical (numerical columns)\n",
        "no_dum = [i for i in X.columns if i not in cat]\n",
        "\n",
        "# Get the number of numerical and categorical features\n",
        "num_shape = len(no_dum)\n",
        "cat_shape = len(cat)\n",
        "\n",
        "# Perform garbage collection to release unused memory\n",
        "gc.collect()\n",
        "\n",
        "def custom_gelu(x):\n",
        "    \"\"\"\n",
        "    Custom Gaussian Error Linear Unit (GELU) activation function.\n",
        "\n",
        "    Parameters:\n",
        "        x (Tensor): The input tensor.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: The output tensor after applying the custom GELU activation.\n",
        "\n",
        "    Example:\n",
        "        x = custom_gelu(x)\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "def create_model():\n",
        "    \"\"\"\n",
        "    Create a custom neural network model.\n",
        "\n",
        "    Returns:\n",
        "        Model: The compiled neural network model.\n",
        "\n",
        "    Example:\n",
        "        model = create_model()\n",
        "    \"\"\"\n",
        "    K.clear_session()\n",
        "    num_inp = Input(shape=(num_shape,))\n",
        "    cat_inp = Input(shape=(cat_shape,))\n",
        "    inps = concatenate([num_inp, cat_inp])\n",
        "    x = Dense(512, activation=custom_gelu)(inps)\n",
        "    x = Dense(256, activation=custom_gelu)(x)\n",
        "    x = Dense(512, activation=custom_gelu)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    cat_out = Dense(cat_shape, activation=\"linear\")(x)\n",
        "    num_out = Dense(num_shape, activation=\"linear\")(x)\n",
        "    model = Model(inputs=[num_inp, cat_inp], outputs=[num_out, cat_out])\n",
        "    model.compile(optimizer=Adam(0.05, clipnorm=1, clipvalue=1), loss=[\"mse\", \"mse\"])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWNV_5Kl_y46"
      },
      "source": [
        "Warmup learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf25ibJI8T5-"
      },
      "source": [
        "\n",
        "class WarmUpLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Custom Callback to implement a warm-up learning rate scheduler.\n",
        "\n",
        "    Parameters:\n",
        "        warmup_batches (int): The number of batches for the warm-up phase.\n",
        "        init_lr (float): The initial learning rate before warm-up.\n",
        "        verbose (int): Whether to print messages about learning rate changes.\n",
        "\n",
        "    Example:\n",
        "        warmup_lr_scheduler = WarmUpLearningRateScheduler(warmup_batches=100, init_lr=0.01, verbose=1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup_batches, init_lr, verbose=0):\n",
        "        super(WarmUpLearningRateScheduler, self).__init__()\n",
        "        self.warmup_batches = warmup_batches\n",
        "        self.init_lr = init_lr\n",
        "        self.verbose = verbose\n",
        "        self.batch_count = 0\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        \"\"\"\n",
        "        Callback function executed at the end of each batch.\n",
        "\n",
        "        Parameters:\n",
        "            batch (int): The current batch index.\n",
        "            logs (dict): Dictionary containing the training metrics for the current batch.\n",
        "        \"\"\"\n",
        "        self.batch_count += 1\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"\n",
        "        Callback function executed at the beginning of each batch.\n",
        "\n",
        "        Parameters:\n",
        "            batch (int): The current batch index.\n",
        "            logs (dict): Dictionary containing the training metrics for the current batch.\n",
        "        \"\"\"\n",
        "        if self.batch_count <= self.warmup_batches:\n",
        "            lr = self.batch_count * self.init_lr / self.warmup_batches\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "            if self.verbose > 0:\n",
        "                print(\"\\nBatch %05d: WarmUpLearningRateScheduler setting learning rate to %s.\" % (self.batch_count + 1, lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMkvG-As_4Pb"
      },
      "source": [
        "Data generator for denoising autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyjXsW3U8Txj"
      },
      "source": [
        "class DAESequence(Sequence):\n",
        "    \"\"\"\n",
        "    Custom Sequence generator for Denoising Autoencoder (DAE) training.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The input dataframe containing the data for the DAE.\n",
        "        no_dum (list): List of numerical column names.\n",
        "        frac (float): Fraction of data to be corrupted (default is 0.15).\n",
        "        dumm (range): Range of column indices for dummy/categorical columns (default is range(911)).\n",
        "        batch_size (int): Batch size for training (default is 2048).\n",
        "\n",
        "    Example:\n",
        "        dae_seq = DAESequence(df, no_dum=['col1', 'col2', 'col3'], batch_size=1024)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, no_dum, frac=0.15, dumm=range(911), batch_size=2048):\n",
        "        self.batch_size = batch_size\n",
        "        self.frac = frac\n",
        "        self.dumm = dumm\n",
        "        self.df = df\n",
        "        self.cat_data = df[dumm].values\n",
        "        self.num_data = df[no_dum].values\n",
        "        self.no_dumm = no_dum\n",
        "        self.len_data = df.shape[0]\n",
        "        self.columns = df.shape[1]\n",
        "        self.data = df\n",
        "        self.idx = []\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of batches in the Sequence.\n",
        "\n",
        "        Returns:\n",
        "            int: The number of batches.\n",
        "        \"\"\"\n",
        "        return int(ceil(self.len_data / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Generates one batch of data for training.\n",
        "\n",
        "        Parameters:\n",
        "            idx (int): The index of the batch.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing input and output data for the DAE.\n",
        "        \"\"\"\n",
        "        self.idx.append(idx)\n",
        "        last = min((idx + 1) * self.batch_size, self.len_data)\n",
        "        idx = idx * self.batch_size\n",
        "        size = last - idx\n",
        "\n",
        "        inps = []\n",
        "        outs = []\n",
        "        output_x = self.data.iloc[idx:last]\n",
        "\n",
        "        # Generate noise for numerical columns\n",
        "        data = output_x[self.no_dumm].values\n",
        "        noise_x = data.copy()\n",
        "        for i in range(len(self.no_dumm)):\n",
        "            to = np.random.randint(0, size, int(size * self.frac))\n",
        "            frm = np.random.randint(0, size, int(size * self.frac))\n",
        "            noise_x[to, i] = noise_x[frm, i]\n",
        "\n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "\n",
        "        # Generate noise for categorical columns\n",
        "        data = output_x[self.dumm].values\n",
        "        noise_x = data.copy()\n",
        "        for i in range(len(self.dumm)):\n",
        "            to = np.random.randint(0, size, int(size * self.frac))\n",
        "            frm = np.random.randint(0, size, int(size * self.frac))\n",
        "            noise_x[to, i] = noise_x[frm, i]\n",
        "\n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "\n",
        "        return inps, outs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acDwaLOGACcP"
      },
      "source": [
        "Fill nan by mean then by 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ryHot0g1BwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a47894b2-e179-498b-c7fd-f5de224c63aa"
      },
      "source": [
        "# Fill missing values with the column mean for columns with missing values\n",
        "a = X.isna().sum()\n",
        "a = a[a > 0]\n",
        "cls = list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "    if col in cls:\n",
        "        X[col] = X[col].fillna(X[col].mean())\n",
        "\n",
        "# Fill remaining missing values with 0 for columns with missing values\n",
        "a = X.isna().sum()\n",
        "a = a[a > 0]\n",
        "cls = list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "    if col in cls:\n",
        "        X[col] = X[col].fillna(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 53.29it/s]\n",
            "0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXdXM2kpNXgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "497a34bb-8ca9-4c34-96aa-73e5f46de318"
      },
      "source": [
        "# Create the model\n",
        "model_mse = create_model()\n",
        "\n",
        "# Initialize the learning rate warm-up scheduler\n",
        "warm_up_lr = WarmUpLearningRateScheduler(warmup_batches=400, init_lr=0.0005)\n",
        "\n",
        "# Free up memory\n",
        "gc.collect()\n",
        "\n",
        "# Define the number of epochs and batch size\n",
        "epochs = 100\n",
        "batch_size = 2048\n",
        "\n",
        "# Create the data generator using DAESequence\n",
        "train_gen = DAESequence(X, no_dum, batch_size=batch_size, dumm=cat)\n",
        "\n",
        "# Train the model\n",
        "hist = model_mse.fit_generator(\n",
        "    train_gen,\n",
        "    steps_per_epoch=len(X) // batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    workers=-1,\n",
        "    use_multiprocessing=True,\n",
        "    callbacks=[warm_up_lr],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.2250 - dense_4_loss: 0.1935 - dense_3_loss: 0.0315\n",
            "Epoch 2/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0810 - dense_4_loss: 0.0670 - dense_3_loss: 0.0140\n",
            "Epoch 3/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0670 - dense_4_loss: 0.0559 - dense_3_loss: 0.0111\n",
            "Epoch 4/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0627 - dense_4_loss: 0.0527 - dense_3_loss: 0.0100\n",
            "Epoch 5/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0613 - dense_4_loss: 0.0518 - dense_3_loss: 0.0094\n",
            "Epoch 6/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0570 - dense_4_loss: 0.0477 - dense_3_loss: 0.0093\n",
            "Epoch 7/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0587 - dense_4_loss: 0.0495 - dense_3_loss: 0.0092\n",
            "Epoch 8/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0554 - dense_4_loss: 0.0467 - dense_3_loss: 0.0087\n",
            "Epoch 9/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0528 - dense_4_loss: 0.0442 - dense_3_loss: 0.0086\n",
            "Epoch 10/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0508 - dense_4_loss: 0.0423 - dense_3_loss: 0.0085\n",
            "Epoch 11/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0507 - dense_4_loss: 0.0422 - dense_3_loss: 0.0084\n",
            "Epoch 12/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0490 - dense_4_loss: 0.0409 - dense_3_loss: 0.0082\n",
            "Epoch 13/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0481 - dense_4_loss: 0.0399 - dense_3_loss: 0.0081\n",
            "Epoch 14/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0488 - dense_4_loss: 0.0406 - dense_3_loss: 0.0082\n",
            "Epoch 15/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0462 - dense_4_loss: 0.0383 - dense_3_loss: 0.0080\n",
            "Epoch 16/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0467 - dense_4_loss: 0.0387 - dense_3_loss: 0.0079\n",
            "Epoch 17/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0467 - dense_4_loss: 0.0388 - dense_3_loss: 0.0079\n",
            "Epoch 18/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0447 - dense_4_loss: 0.0370 - dense_3_loss: 0.0078\n",
            "Epoch 19/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0468 - dense_4_loss: 0.0389 - dense_3_loss: 0.0078\n",
            "Epoch 20/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0444 - dense_4_loss: 0.0366 - dense_3_loss: 0.0078\n",
            "Epoch 21/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0437 - dense_4_loss: 0.0361 - dense_3_loss: 0.0076\n",
            "Epoch 22/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0428 - dense_4_loss: 0.0352 - dense_3_loss: 0.0076\n",
            "Epoch 23/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0424 - dense_4_loss: 0.0349 - dense_3_loss: 0.0076\n",
            "Epoch 24/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0433 - dense_4_loss: 0.0358 - dense_3_loss: 0.0075\n",
            "Epoch 25/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0426 - dense_4_loss: 0.0351 - dense_3_loss: 0.0075\n",
            "Epoch 26/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0436 - dense_4_loss: 0.0361 - dense_3_loss: 0.0075\n",
            "Epoch 27/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0424 - dense_4_loss: 0.0349 - dense_3_loss: 0.0074\n",
            "Epoch 28/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0413 - dense_4_loss: 0.0340 - dense_3_loss: 0.0074\n",
            "Epoch 29/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0419 - dense_4_loss: 0.0345 - dense_3_loss: 0.0075\n",
            "Epoch 30/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0407 - dense_4_loss: 0.0334 - dense_3_loss: 0.0073\n",
            "Epoch 31/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0400 - dense_4_loss: 0.0327 - dense_3_loss: 0.0073\n",
            "Epoch 32/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0412 - dense_4_loss: 0.0339 - dense_3_loss: 0.0073\n",
            "Epoch 33/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0408 - dense_4_loss: 0.0336 - dense_3_loss: 0.0072\n",
            "Epoch 34/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0415 - dense_4_loss: 0.0343 - dense_3_loss: 0.0072\n",
            "Epoch 35/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0405 - dense_4_loss: 0.0334 - dense_3_loss: 0.0072\n",
            "Epoch 36/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0390 - dense_4_loss: 0.0318 - dense_3_loss: 0.0072\n",
            "Epoch 37/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0387 - dense_4_loss: 0.0316 - dense_3_loss: 0.0071\n",
            "Epoch 38/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0383 - dense_4_loss: 0.0312 - dense_3_loss: 0.0071\n",
            "Epoch 39/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0387 - dense_4_loss: 0.0316 - dense_3_loss: 0.0070\n",
            "Epoch 40/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0384 - dense_4_loss: 0.0314 - dense_3_loss: 0.0070\n",
            "Epoch 41/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0384 - dense_4_loss: 0.0313 - dense_3_loss: 0.0070\n",
            "Epoch 42/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0399 - dense_4_loss: 0.0329 - dense_3_loss: 0.0070\n",
            "Epoch 43/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0374 - dense_4_loss: 0.0304 - dense_3_loss: 0.0070\n",
            "Epoch 44/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0395 - dense_4_loss: 0.0326 - dense_3_loss: 0.0069\n",
            "Epoch 45/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0382 - dense_4_loss: 0.0312 - dense_3_loss: 0.0069\n",
            "Epoch 46/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0373 - dense_4_loss: 0.0303 - dense_3_loss: 0.0070\n",
            "Epoch 47/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0373 - dense_4_loss: 0.0304 - dense_3_loss: 0.0070\n",
            "Epoch 48/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0388 - dense_4_loss: 0.0319 - dense_3_loss: 0.0069\n",
            "Epoch 49/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0366 - dense_4_loss: 0.0298 - dense_3_loss: 0.0068\n",
            "Epoch 50/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0375 - dense_4_loss: 0.0307 - dense_3_loss: 0.0068\n",
            "Epoch 51/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0389 - dense_4_loss: 0.0321 - dense_3_loss: 0.0068\n",
            "Epoch 52/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0366 - dense_4_loss: 0.0299 - dense_3_loss: 0.0067\n",
            "Epoch 53/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0367 - dense_4_loss: 0.0299 - dense_3_loss: 0.0068\n",
            "Epoch 54/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0402 - dense_4_loss: 0.0335 - dense_3_loss: 0.0067\n",
            "Epoch 55/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0361 - dense_4_loss: 0.0295 - dense_3_loss: 0.0067\n",
            "Epoch 56/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0396 - dense_4_loss: 0.0329 - dense_3_loss: 0.0067\n",
            "Epoch 57/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0403 - dense_4_loss: 0.0336 - dense_3_loss: 0.0066\n",
            "Epoch 58/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0362 - dense_4_loss: 0.0295 - dense_3_loss: 0.0067\n",
            "Epoch 59/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0374 - dense_4_loss: 0.0307 - dense_3_loss: 0.0067\n",
            "Epoch 60/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0407 - dense_4_loss: 0.0340 - dense_3_loss: 0.0066\n",
            "Epoch 61/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0365 - dense_4_loss: 0.0299 - dense_3_loss: 0.0066\n",
            "Epoch 62/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0351 - dense_4_loss: 0.0286 - dense_3_loss: 0.0066\n",
            "Epoch 63/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0353 - dense_4_loss: 0.0288 - dense_3_loss: 0.0065\n",
            "Epoch 64/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0357 - dense_4_loss: 0.0292 - dense_3_loss: 0.0065\n",
            "Epoch 65/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0366 - dense_4_loss: 0.0299 - dense_3_loss: 0.0067\n",
            "Epoch 66/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0357 - dense_4_loss: 0.0292 - dense_3_loss: 0.0065\n",
            "Epoch 67/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0351 - dense_4_loss: 0.0286 - dense_3_loss: 0.0064\n",
            "Epoch 68/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0348 - dense_4_loss: 0.0283 - dense_3_loss: 0.0064\n",
            "Epoch 69/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0354 - dense_4_loss: 0.0289 - dense_3_loss: 0.0065\n",
            "Epoch 70/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0353 - dense_4_loss: 0.0288 - dense_3_loss: 0.0065\n",
            "Epoch 71/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0353 - dense_4_loss: 0.0289 - dense_3_loss: 0.0064\n",
            "Epoch 72/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0370 - dense_4_loss: 0.0306 - dense_3_loss: 0.0064\n",
            "Epoch 73/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0351 - dense_4_loss: 0.0287 - dense_3_loss: 0.0064\n",
            "Epoch 74/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0353 - dense_4_loss: 0.0289 - dense_3_loss: 0.0064\n",
            "Epoch 75/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0350 - dense_4_loss: 0.0286 - dense_3_loss: 0.0064\n",
            "Epoch 76/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0360 - dense_4_loss: 0.0296 - dense_3_loss: 0.0064\n",
            "Epoch 77/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0355 - dense_4_loss: 0.0291 - dense_3_loss: 0.0064\n",
            "Epoch 78/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0348 - dense_4_loss: 0.0285 - dense_3_loss: 0.0064\n",
            "Epoch 79/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0358 - dense_4_loss: 0.0295 - dense_3_loss: 0.0063\n",
            "Epoch 80/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0343 - dense_4_loss: 0.0279 - dense_3_loss: 0.0063\n",
            "Epoch 81/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0352 - dense_4_loss: 0.0289 - dense_3_loss: 0.0063\n",
            "Epoch 82/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0342 - dense_4_loss: 0.0279 - dense_3_loss: 0.0063\n",
            "Epoch 83/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0355 - dense_4_loss: 0.0292 - dense_3_loss: 0.0063\n",
            "Epoch 84/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0343 - dense_4_loss: 0.0280 - dense_3_loss: 0.0063\n",
            "Epoch 85/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0337 - dense_4_loss: 0.0274 - dense_3_loss: 0.0063\n",
            "Epoch 86/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0361 - dense_4_loss: 0.0298 - dense_3_loss: 0.0063\n",
            "Epoch 87/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0339 - dense_4_loss: 0.0276 - dense_3_loss: 0.0063\n",
            "Epoch 88/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0336 - dense_4_loss: 0.0273 - dense_3_loss: 0.0063\n",
            "Epoch 89/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0342 - dense_4_loss: 0.0279 - dense_3_loss: 0.0063\n",
            "Epoch 90/100\n",
            "535/535 [==============================] - 20s 38ms/step - loss: 0.0336 - dense_4_loss: 0.0274 - dense_3_loss: 0.0062\n",
            "Epoch 91/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0339 - dense_4_loss: 0.0276 - dense_3_loss: 0.0063\n",
            "Epoch 92/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0336 - dense_4_loss: 0.0274 - dense_3_loss: 0.0062\n",
            "Epoch 93/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0338 - dense_4_loss: 0.0276 - dense_3_loss: 0.0062\n",
            "Epoch 94/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0358 - dense_4_loss: 0.0295 - dense_3_loss: 0.0063\n",
            "Epoch 95/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0330 - dense_4_loss: 0.0268 - dense_3_loss: 0.0062\n",
            "Epoch 96/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0349 - dense_4_loss: 0.0287 - dense_3_loss: 0.0062\n",
            "Epoch 97/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0340 - dense_4_loss: 0.0278 - dense_3_loss: 0.0062\n",
            "Epoch 98/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0337 - dense_4_loss: 0.0275 - dense_3_loss: 0.0062\n",
            "Epoch 99/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0372 - dense_4_loss: 0.0309 - dense_3_loss: 0.0062\n",
            "Epoch 100/100\n",
            "535/535 [==============================] - 20s 37ms/step - loss: 0.0347 - dense_4_loss: 0.0285 - dense_3_loss: 0.0062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNx0SXIhhb0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "f64cfa3d-c192-45b7-c2ab-9638fada5233"
      },
      "source": [
        "mod=Model(inputs=model_mse.inputs,outputs=model_mse.layers[4].output)\n",
        "mod.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 173)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 444)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 617)          0           input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          316416      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 447,744\n",
            "Trainable params: 447,744\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdaDfCWm8pDt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "fda4a6ff-4162-4b63-dcea-74a4f26952c2"
      },
      "source": [
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f70703f4630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU9Z3/8ddnZjIJ95AL14AgIBRBUQNeqq6X2kKtl7pqobZq665tXdv9/exua9et/tbt5de6vblr/YlVq/VWS2ulLUqt1WqrIkGRiwgEkJBwSUhCuOQ6yef3x5yESUjMAIFIzvv5eMyDme85Z+Z7HsNj3vlezveYuyMiIuET6e0KiIhI71AAiIiElAJARCSkFAAiIiGlABARCalYb1fgYOTl5fm4ceN6uxoiIseUZcuW7XT3/I7lx1QAjBs3jqKiot6uhojIMcXMNndWri4gEZGQUgCIiISUAkBEJKQUACIiIaUAEBEJqbQCwMxmm9laMys2s1s72X6Lmb1jZivM7AUzOy4on2Fmr5nZ6mDbp1KO+bmZbTKz5cFjRs+dloiIdKfbADCzKHAPMAeYCswzs6kddnsLKHT3k4AFwPeD8lrgWnc/EZgN/NjMslOO+1d3nxE8lh/muYiIyEFIpwUwCyh2943u3gg8CVyWuoO7v+jutcHL14GCoHydu68Pnm8FyoEDLkY40n7zZimPvt7pNFgRkdBKJwBGA1tSXpcGZV25AXi2Y6GZzQLiwIaU4m8HXUM/MrPMzt7MzG40syIzK6qoqEijugf63dtb+eXSLd3vKCISIj06CGxmnwEKgbs6lI8EfgF8zt1bguJvAFOAmUAO8PXO3tPd57t7obsX5ucfWuMhIxqhqbml+x1FREIknQAoA8akvC4Iytoxs48AtwGXuntDSvlg4A/Abe7+emu5u2/zpAbgIZJdTUeEAkBE5EDpBMBSYJKZjTezODAXWJi6g5mdAtxH8se/PKU8DjwNPOLuCzocMzL414DLgVWHcyLvJxY1Ei269aWISKpuF4Nz94SZ3QwsBqLAg+6+2szuBIrcfSHJLp+BwK+Sv+eUuPulwNXAuUCumV0fvOX1wYyfx8wsHzBgOfDFnj21/TKiEZoSagGIiKRKazVQd18ELOpQdnvK8490cdyjwKNdbLsg/Woenoyo0aQWgIhIO6G4EjgWiZDQGICISDuhCICMaIREs1oAIiKpQhIARqNaACIi7YQiADQLSETkQKEIgIxohOYWp0UhICLSJjQBANDUom4gEZFWoQiAWMQANBAsIpIiHAEQtAAUACIi+4UiAOLRZAtAM4FERPYLRQC0tQA0BiAi0iYcAaAxABGRA4QiAOKx5GmqC0hEZL9QBEAsokFgEZGOwhEAwSCwbgojIrJfKAIg3nohmAJARKRNKAKgtQWg9YBERPYLRwBE1AIQEekorQAws9lmttbMis3s1k6232Jm75jZCjN7wcyOS9l2nZmtDx7XpZSfZmYrg/e8O7g38BERj2kaqIhIR90GgJlFgXuAOcBUYJ6ZTe2w21tAobufBCwAvh8cmwPcAZwOzALuMLOhwTH3Av8ITAoesw/7bLqgFoCIyIHSaQHMAordfaO7NwJPApel7uDuL7p7bfDydaAgeP4x4Hl3r3L3auB5YLaZjQQGu/vr7u7AI8DlPXA+ndo/C0gtABGRVukEwGhgS8rr0qCsKzcAz3Zz7OjgebfvaWY3mlmRmRVVVFSkUd0DZWgpCBGRA/ToILCZfQYoBO7qqfd09/nuXujuhfn5+Yf0HhmaBioicoB0AqAMGJPyuiAoa8fMPgLcBlzq7g3dHFvG/m6iLt+zp7SuBaQuIBGR/dIJgKXAJDMbb2ZxYC6wMHUHMzsFuI/kj395yqbFwEfNbGgw+PtRYLG7bwN2m9kZweyfa4FneuB8OpWh+wGIiBwg1t0O7p4ws5tJ/phHgQfdfbWZ3QkUuftCkl0+A4FfBbM5S9z9UnevMrP/JBkiAHe6e1Xw/Cbg50A/kmMGz3KEZGgpCBGRA3QbAADuvghY1KHs9pTnH3mfYx8EHuykvAiYlnZND0NMYwAiIgcIxZXAGVoKQkTkACEJgKAFkFALQESkVSgCoG0WkFoAIiJtQhEAZkYsYiQ0BiAi0iYUAQDJbiANAouI7BeaAIhFTReCiYikCE0AZEQjWgtIRCRFaAIgOQagFoCISKvQBEBGNEKjxgBERNqEKADUAhARSRWaAIhpDEBEpJ3QBEBGNEJjQi0AEZFWIQoAUwtARCRFaAJAs4BERNoLTQBoFpCISHuhCgCtBSQisl9oAiAWNd0PQEQkRVoBYGazzWytmRWb2a2dbD/XzN40s4SZXZlSfr6ZLU951JvZ5cG2n5vZppRtM3rutA6UnAWkFoCISKtubwlpZlHgHuAioBRYamYL3f2dlN1KgOuBf0k91t1fBGYE75MDFAN/TNnlX919weGcQLoy1AIQEWknnXsCzwKK3X0jgJk9CVwGtAWAu78XbHu/P7GvBJ5199pDru1hiEU0BiAikiqdLqDRwJaU16VB2cGaCzzRoezbZrbCzH5kZpmdHWRmN5pZkZkVVVRUHMLHJmk5aBGR9o7KILCZjQSmA4tTir8BTAFmAjnA1zs71t3nu3uhuxfm5+cfch3iuiGMiEg76QRAGTAm5XVBUHYwrgaedvem1gJ33+ZJDcBDJLuajhjNAhIRaS+dAFgKTDKz8WYWJ9mVs/AgP2ceHbp/glYBZmbA5cCqg3zPgxKLqAUgIpKq2wBw9wRwM8numzXAU+6+2szuNLNLAcxsppmVAlcB95nZ6tbjzWwcyRbEXzq89WNmthJYCeQB3zr80+laPKYAEBFJlc4sINx9EbCoQ9ntKc+Xkuwa6uzY9+hk0NjdLziYih4urQUkItJeiK4EjpBocdwVAiIiEKIAiEcNQFNBRUQCoQmAWDR5qrongIhIUngCIKIWgIhIqtAEQDyWPFXNBBIRSQpNAMQiQReQWgAiIkCYAqBtEFgtABERCFEAxKPqAhIRSRWaAGhtAWg9IBGRpPAEQEQtABGRVKEJgIzWFoAGgUVEgFAFgFoAIiKpQhMAMS0FISLSTmgCIENLQYiItBO6AFAXkIhIUmgCQGsBiYi0l1YAmNlsM1trZsVmdmsn2881szfNLGFmV3bY1mxmy4PHwpTy8Wa2JHjPXwa3mzxi2rqAFAAiIkAaAWBmUeAeYA4wFZhnZlM77FYCXA883slb1Ln7jOBxaUr594AfuftEoBq44RDqn7YMLQUhItJOOi2AWUCxu29090bgSeCy1B3c/T13XwGk9esa3Aj+AmBBUPQwyRvDHzEaAxARaS+dABgNbEl5XUon9/h9H1lmVmRmr5tZ6498LrAruOH8+76nmd0YHF9UUVFxEB/bnpaCEBFpL62bwh+m49y9zMyOB/5sZiuBmnQPdvf5wHyAwsLCQ/71VgtARKS9dFoAZcCYlNcFQVla3L0s+Hcj8BJwClAJZJtZawAd1Hseioy2tYDUAhARgfQCYCkwKZi1EwfmAgu7OQYAMxtqZpnB8zzgw8A77u7Ai0DrjKHrgGcOtvIHo60LSC0AEREgjQAI+ulvBhYDa4Cn3H21md1pZpcCmNlMMysFrgLuM7PVweEfAorM7G2SP/j/193fCbZ9HbjFzIpJjgk80JMn1pFuCCMi0l5aYwDuvghY1KHs9pTnS0l243Q87lVgehfvuZHkDKOjQl1AIiLtheZK4EjEiEZMawGJiARCEwCQXA5CVwKLiCSFKgDi0QiNGgMQEQFCFgCxqFoAIiKtQhYAEY0BiIgEQhUA8WiExoRaACIiELIAiEU1C0hEpFW4AkCzgERE2oQqADI0C0hEpE3oAkBrAYmIJIUqAJJjAOoCEhGBkAVARiRCY0ItABERCFsAxNQCEBFpFaoAiEU0BiAi0ipUAZARNRo1DVREBAhdAKgFICLSKlQBkFwLSC0AERFIMwDMbLaZrTWzYjO7tZPt55rZm2aWMLMrU8pnmNlrZrbazFaY2adStv3czDaZ2fLgMaNnTqlrGRHTLSFFRALd3hLSzKLAPcBFQCmw1MwWptzbF6AEuB74lw6H1wLXuvt6MxsFLDOzxe6+K9j+r+6+4HBPIl0Z0YgCQEQkkM49gWcBxcE9fDGzJ4HLgLYAcPf3gm3tfl3dfV3K861mVg7kA7voBbofgIjIful0AY0GtqS8Lg3KDoqZzQLiwIaU4m8HXUM/MrPMLo670cyKzKyooqLiYD+2HbUARET2OyqDwGY2EvgF8Dl3b/0F/gYwBZgJ5ABf7+xYd5/v7oXuXpifn39Y9ciIGk1qAYiIAOkFQBkwJuV1QVCWFjMbDPwBuM3dX28td/dtntQAPESyq+mI0h3BRET2SycAlgKTzGy8mcWBucDCdN482P9p4JGOg71BqwAzM+ByYNXBVPxQJGcBOe5qBYiIdBsA7p4AbgYWA2uAp9x9tZndaWaXApjZTDMrBa4C7jOz1cHhVwPnAtd3Mt3zMTNbCawE8oBv9eiZdSIjmjxdXQsgIpLeLCDcfRGwqEPZ7SnPl5LsGup43KPAo1285wUHVdMeEGsNgGYnI3q0P11E5IMlVFcCZ0QNgCaNA4iIhCsAYpEgAHRPABGRcAVARkxjACIircIVAJHk6epiMBGRkAVArHUMQBeDiYiEKwDapoGqBSAiErYAUAtARKRVqAIgFmkdBFYLQEQkVAHQOgtIg8AiImELgIi6gEREWoUqAFKXghARCbtQBcD+QWB1AYmIhCwANAYgItIqVAHQeiGYloIQEQlbAGgpCBGRNqEKgHhbF5BaACIioQqAti4gtQBERNILADObbWZrzazYzG7tZPu5ZvammSXM7MoO264zs/XB47qU8tPMbGXwnncH9wY+omKaBSQi0qbbADCzKHAPMAeYCswzs6kddisBrgce73BsDnAHcDowC7jDzIYGm+8F/hGYFDxmH/JZpEldQCIi+6XTApgFFLv7RndvBJ4ELkvdwd3fc/cVQMc/rT8GPO/uVe5eDTwPzDazkcBgd3/d3R14BLj8cE+mO20XgmktIBGRtAJgNLAl5XVpUJaOro4dHTzv9j3N7EYzKzKzooqKijQ/tnMxLQUhItLmAz8I7O7z3b3Q3Qvz8/MP6710IZiIyH7pBEAZMCbldUFQlo6uji0Lnh/Kex6yaMSImNYCEhGB9AJgKTDJzMabWRyYCyxM8/0XAx81s6HB4O9HgcXuvg3YbWZnBLN/rgWeOYT6H7RYNEKTxgBERLoPAHdPADeT/DFfAzzl7qvN7E4zuxTAzGaaWSlwFXCfma0Ojq0C/pNkiCwF7gzKAG4CfgYUAxuAZ3v0zLoQj0ZoSqgFICISS2cnd18ELOpQdnvK86W079JJ3e9B4MFOyouAaQdT2Z4Qi5pmAYmIcAwMAve0WCSiWUAiIoQwADKipllAIiKEMgAiWgtIRIQQBkAsajTpfgAiIuELgIxIhKaEWgAiIuELgJjpjmAiIoQwAJKzgNQCEBEJXQBoFpCISFIIAyCitYBERAhhACTXAlIAiIiELgAyIqbrAERECGMARDUILCICIQyAWNQ0BiAiQggDoF9GlN31id6uhohIrwtdAEwZOZidexvYXlPf21UREelVoQuAGWOyAVi+ZVcv10REpHeFLgBOHDWYWMQUACISemkFgJnNNrO1ZlZsZrd2sj3TzH4ZbF9iZuOC8mvMbHnKo8XMZgTbXgres3XbsJ48sa5kZUT50MjBvK0AEJGQ6zYAzCwK3APMAaYC88xsaofdbgCq3X0i8CPgewDu/pi7z3D3GcBngU3uvjzluGtat7t7eQ+cT1pmjMlmRekumnVBmIiEWDotgFlAsbtvdPdG4Engsg77XAY8HDxfAFxoZtZhn3nBsb1uxphs9jU2U1y+t7erIiLSa9IJgNHAlpTXpUFZp/u4ewKoAXI77PMp4IkOZQ8F3T/f7CQwADCzG82syMyKKioq0qhu904OBoLVDSQiYXZUBoHN7HSg1t1XpRRf4+7TgXOCx2c7O9bd57t7obsX5ufn90h9js8bwKCsGG8pAEQkxNIJgDJgTMrrgqCs033MLAYMASpTts+lw1//7l4W/LsHeJxkV9NREYkYM8ZkqwUgIqGWTgAsBSaZ2Xgzi5P8MV/YYZ+FwHXB8yuBP7u7A5hZBLialP5/M4uZWV7wPAP4BLCKo+jkgmzW7thDXWPz0fxYEZEPjG4DIOjTvxlYDKwBnnL31WZ2p5ldGuz2AJBrZsXALUDqVNFzgS3uvjGlLBNYbGYrgOUkWxD3H/bZHIQZY7JpbnFWltUczY8VEfnAiKWzk7svAhZ1KLs95Xk9cFUXx74EnNGhbB9w2kHWtUelDgTPGp/Tm1UREekVobsSuFX+oExGZ/fTFcEiElqhDQCAGWOzWfpeFQ0JjQOISPiEOgCuPK2A8j0N/PhP63u7KiIiR12oA+D8ycOYO3MM9/1lA0XvVfV2dUREjqpQBwDAv39iKqOH9uOWp95mX4NuFCMi4RH6ABiYGeMHV81gS3UtdyxcrfsFi0hohD4AAGaNz+GLfzeBBctKOf+/XuKxJZs1MCwifZ4CIPC1j03mwesLyR2YyW1Pr+IjP/wL5bt120gR6bsUAAEz44Ipw/ntTWfx0PUzKd/dwNd/vYJgRQsRkT5HAdCBmXH+lGF8Y84UXlxbweNvlLRtc3c2VuxVKIhIn6AA6MK1Z47jnEl5fOv3a9i0cx9vllTzyZ++ygU/+Av//efi3q6eiMhhUwB0IRIx7rryZOKxCFfe+ypX/PRVtu6q45xJefzw+XU8kdIyEBE5FikA3seIIVl87++n0+zOly+YyIv/ch4PXj+T8ybnc9vTK/nj6u29XUURkUNmx1J/dmFhoRcVFfV2NahtTDDv/iW8u2039332NM6bPKy3qyQi0iUzW+buhR3L1QI4BP3jMR66fiYT8gdyw8NFPL5E3UEicuxRAByinAFxnvrimZw9MY9/e3ol33vuXVpajp3WlIhIWgFgZrPNbK2ZFZvZrZ1szzSzXwbbl5jZuKB8nJnVmdny4PH/Uo45zcxWBsfcbWbWUyd1tAzMjPHAdYXMmzWWe1/awLUPvkFpdW1vV0tEJC3dBoCZRYF7gDnAVGCemU3tsNsNQLW7TwR+BHwvZdsGd58RPL6YUn4v8I/ApOAx+9BPo/fEohG+88lpfOeT03mrpJrZP36Fx5eUUL2vkdrGBM1qFYjIB1Q6t4ScBRS33tPXzJ4ELgPeSdnnMuD/BM8XAP/zfn/Rm9lIYLC7vx68fgS4HHj2YE/gg8DM+PTpYzlnUh5f//UK/u3plfzb0yvbtp83OZ9b50xhyojBvVhLEZH20gmA0cCWlNelwOld7ePuCTOrAXKDbePN7C1gN/Dv7v5KsH9ph/cc3dmHm9mNwI0AY8eOTaO6vWdMTn8eveF0nl+zg2276qhPtFC9r5En3ihhzk9e4cpTC/jSeRM4Pn9gu+MaEy1kRI1jsBdMRI5had0U/jBsA8a6e6WZnQb81sxOPJg3cPf5wHxITgM9AnXsUZGI8bETR7Qr+9J5E7jnxWIefnUzv1pWypQRg5g9bQRRM17bWMmyzdUUDO3Hg9fP5LjcAb1UcxEJm3QGgcuAMSmvC4KyTvcxsxgwBKh09wZ3rwRw92XABuCEYP+Cbt6zz8juH+e2i6fyytfP5/ZPTGVwVgY/eWE9P3h+Hbtqm5g7cwxV+xr55E9f5c2S6t6uroiERLcXggU/6OuAC0n+SC8FPu3uq1P2+Sdgurt/0czmAle4+9Vmlg9UuXuzmR0PvBLsV2VmbwBfAZYAi4D/dvdF71eXD8qFYD1h594GomYMHRAHYNPOfVz/0Btsr6nnmtOPY8eeejaU72Xn3kbcHQeGD87ijkumcsbxyd61+qZmvv/cWha+vZVvXT6N2dNGvM8nikhYdXUhWFpXApvZx4EfA1HgQXf/tpndCRS5+0IzywJ+AZwCVAFz3X2jmf09cCfQBLQAd7j774L3LAR+DvQjOfj7Ze+mMn0pADpTubeBLz32JkXvVTEmpz/H5w1gxJAsImaYwcvrdlJSVcs1p4/l49NH8s1nVrGxYh8FQ/tRWl3HVy6cxP+6cBKRiMYSRGS/wwqAD4q+HgCtmppbyIge2DtX25jgB39cx4N/24Q7jBqSxV1Xncxpxw3lm79dxa+WlXL+5HzmzhrLKWOzGTYoqxdqLyIfNAqAPuTNkmr+un4n1394HIOzMoDkvQoeeW0z31m0hoZE8r7GBUP7cf7kYcyeNoJZ43MOCJXy3fW8trGSof3jnDwmmyH9MtjXkOCFd8v54+rt5A6I89kzxzFx2MAD6iAixw4FQEjUNzWzeutu3iqpZsmmKl5ZX0F9UwuDs2KMzx/IyMFZDB0Q5+0tu3hn2+6248xgfO4AynbV0ZBoIW9gJrvrmmhsbuGcSXlcc/pYzps8jKyMaC+enYgcCgVASNU1NvOXdRX8ZV05W6rq2L67np17Gzhh+CDOm5zPORPz2V3fxJubq3m7tIbR2VlcfNIoCo8bSlVtI0++UcIvXt/Mjt0NDMqMcdGJwykY2p9VZTWsLKshYvCpwjHMO30sI4f0O+Dz9zYkWFVWw6gh/RiVnUU0YpRW11G0uYr1O/Yyc1wOH56YRzymZalEjhQFgByyRHMLr22s5Hdvb+XZVdvZ15Bg4rCBTBs9hOp9jby0rgIDzpmUz5kTcpk1PoesWJQn3ijhN2+Wsq+xGYBYxBiUFaO6tqnd+w/KinHRh4bz+bPHM230kF44w6Nnb0MCAwZkdn4Jjruzaec+HJiQ33XX24aKvTz86nvcctEJZPePH5nKSp+hAJAe0ZhoobnF6Rff3xW0paqWx98oYfGq7Wzcua+tPB6LcMlJo/j49BFU7mtkc+U+Kvc2cuKowRSOy2F83gBe3bCTZ1du57nV29lTn+ATJ43kqx+dzPi8w7sgbvXWGv77hWIaEs3cddXJ5A3MbNu2qqyGt7bs4uLpI8kZcPR+PMt31/PJn75KZkaE3918drsQeHldBfe/spG3t+xid32CeDTCb246q9NA3LqrjivvfZWtNfXMPnEE937mVF1FLu9LASBHRcWeBoreq6KqtpGPTxvZdp1Dd2rqmrj/5Y088NdNNCSayR+UydD+cbL7ZzBqSD/G5PRnTE5/GhMt7NhdT/meeiJm5AyIkzMgzoB4jGjEiEWN51Zt59lV2xmUFaMxGM+4/9pCJo8YxL0vFfPjP60n0eL0y4jyqZljuOHs8YzJ6d9pvRLNLSx8eyvPv7ODebPGcu4J+Qfs05ho4ZnlZSxYVsqZE3L58gWTiHaYilvbmGDu/NdZt2MPjYkWLj9lND+8egYAb5VUM3f+6+QPyuScSflMHz2Eu19YT1ZGhN9/5RwGpgRF9b5GrrrvNXbU1HPJjFE8vqSE714xnXmzPtjLpEjvUgDIMaFiTwOPLymhbFctu2qbqK5tpKy6jm2762n9r2oGuQPiuEN1bSMdF1wdmBnj82eP54azx7O5ch83PrKMmromJg0fyIrSGi45eRSf+/A4Hl9SwjPLy2hqdk4cNZgLpwzjjONziUaMpmZnU+U+7n95IyVVtfTLiFLX1MwX/u54vnrRZOKxCJt27uPZVdt45NXNbN9dz8ghWWyrqefM43P5ybwZbdNwm1ucmx5bxvPv7GD+ZwtZWVaTvBL8qpOZNT6HT/70b/SPx3j6prPIDVoqSzZWMu/+17nk5FH8+FMzMDMq9zZww8NFvLNtN498fhazxuVw3UNvsPS9Kn7/5bOZOGzQ0fyq5AhrSDSTGeuZSRcKADmmNSSa2bqrnsxYhPxBmW1TWptbnJq6JmobEySanUSLM3xwJoOC6bGQ7Hr5wqPLWL9jL/95+YlcPmN0W5fJtpo6nn6rjBffLWfZ5uoDwuSkgiF8+YJJfHhiLt/6wxoeX1LClBGDaEy0tHV3nTUhly/83QTOnZTHgmWlfPOZVQzMzODi6SNoanG2VNXyyvqd3HHJVD734fE0tzifvv91VpbVMGJwFpX7GvnNTWcd0Od/9wvr+eHz67jpvAlsrqrlj6u309zi3PuZ09rWmyrfXc/sn7zC8MFZPHrDrLYA6Yq7s6FiH69trCR/YCZnT8pr18I4VJV7G/jh8+t4dUMlX/vYZOZMH3nY7xlmdy1+l5+9sonvXjGdK04t6P6AbigAJNSaW5z6puYuB18h2b2ysqyGaMTIiEYYlBVjyohB7frXn1u1je8/t5aCnP5cOGUYF0wZdkD30drte/jqr5ZTUllLPBYlHjWuPK2AWz46uW2f7TX1zPnJy+xtSPDI50/nzAm5dNTc4nz2gSW8uqGSIf0yuOLU0Xx61lgmDW//l/6f393BPzxcREY0wtWFY/iHc8aT3S9OTV2yBbWlupbNlbVsqNjLko1VlO2qazs2I2rMHJfDWRNyOWXsUE4qGNIuPFvrsWnnXsp3N5ARixCPRtp1cb22oZK7X1hPbVMzBUP7sbmyljnTRvAfl53I4KwMqvY1srchQXb/DHIHJAPqjU1VPLtqG6+s30newDhTRw7mQyMHM230ECaPGERGNEJ9UzMvr6vgxbXlHJ83kM+ccVy7saem5pbgHNrPIFtZWkPF3nrOnpjf6eyylhbnf14s5qmiLfz7xR9i9rSeD6uGRDMP/HUTeQMyuXrmmO4PSPHkGyXc+puV5A3MZOfeBr5w7vF8bfaUA7oVD4YCQOQDZt2OPeypT3DacUO73Kemromi96r48MS8970Go7h8D/Nf3sjTbyW7tDqTPyiTU8dmc+4J+Zw9MY9tNfW8uLacl96tYO2OPUCye23UkH7kDYyTPyiT3fUJVpfVtM3k6sr5k/O57eIPcVzuAOa/vJGfvLCeRHPLAS2qiEFmLNmdlpUR4awJedTUNfHutt1tnxGPRThh+EA2VuyjtrGZ/vEotY3N5A3M5ObzJ5A3KJPnVm3nxXfLiZjxkanDmTNtBI3NLTz41028WbILSHYTXllYwBWnFDBp2EAiEaOmrolbfrmcF94tJ39QJhV7GvjMGWP594un9tg1Lm+VVPO1BStYX74XgJvPn8hXP3oCZj3ekU0AAAhBSURBVEZtY4L/+XMxxeV7OeeEfC6cMoxR2funT/+teCfXPfgGZ07I5f5rC/nOojU88tpmzpucz93zTmm78PNgKQBEQmDH7np+9/ZWzIwh/TIY0i+DgqH9GJvT/31bPzW1TbxduovlW3axubKWir0NVOxpICsjwkmjhzC9IJvR2f1ItLTQ1NxCU7PT+vdo/qBMThnbPsSKy/fy9Ful9I/HyBkQZ2BmjF21jVTsaWB3fYJZ43M4b3I+/ePJOrW0OCVVtawoq2FFcJHicbkDmDNtBGdOyGX5ll381+K1LNlUBUDewDgXTR1Oc4uzePUOauqSU4uPy+3PdWeO47jc/jxVtIU/rSmnucUZlBXj5IJsSqpq2bqrjtsvmcrcmWP5wR/Xct/LGxmfN4AZY7LJHRBnQGaMTTv3sXb7Ht6r3Meo7H58aOQgThie7PrbubeByr2N9ItHyR+USf6gTJqbneraJrbvruO5VdsZPjiLb10+jT+t2cETb2zh06eP5aKpw7n9mVVsqaprGy8COD5vAAU5/Rk1JIs/rNzGyCFZLPjSWW0/9o8t2cxdi9ey4ItnHvI4jwJARI5p7s6bJclxmlPHDm3rEmlqbuG1DZU4cPbEvHZdJeW7k62ct0trWFG6i4amFr57xXQKx+W07fPyugrufmE9O/bUs3NPI3VNzYzO7sfkEYMYlzuArbvqWLN9N5sra4lFjNyBcXIGZFLf1EzFngb2NiQAGBCPkt0/zgVThvG12ZMZlJWBu3PX4rX89KUNQPLH/rtXTGfW+Bw2VOzlT2vKeXvLLrbuqqNsVz2D+8V45POzKBjavltxT33TAV1zB0MBICKShq4WY6xvaiYejRyw2m5dYzPRiL3v1exPvlFC5b5Gbjh7fK8sp9JVABzpO4KJiBxTOvvxB7r84U4dmO7K3A/odRpagEVEJKQUACIiIaUAEBEJqbQCwMxmm9laMys2s1s72Z5pZr8Mti8xs3FB+UVmtszMVgb/XpByzEvBey4PHsN66qRERKR73Q4Cm1kUuAe4CCgFlprZQnd/J2W3G4Bqd58Y3BT+e8CngJ3AJe6+1cymAYuB0SnHXePumtYjItIL0mkBzAKK3X2juzcCTwKXddjnMuDh4PkC4EIzM3d/y923BuWrgX5m9v6LlYiIyFGRTgCMBrakvC6l/V/x7fZx9wRQA3Rc3OTvgTfdvSGl7KGg++eb1sWC5mZ2o5kVmVlRRUVFGtUVEZF0HJVBYDM7kWS30BdSiq9x9+nAOcHjs50d6+7z3b3Q3Qvz8w9ci11ERA5NOheClQGpy9kVBGWd7VNqZjFgCFAJYGYFwNPAte6+ofUAdy8L/t1jZo+T7Gp65P0qsmzZsp1mtjmNOncmj+SYRNiE8bzDeM4QzvPWOafnuM4K0wmApcAkMxtP8od+LvDpDvssBK4DXgOuBP7s7m5m2cAfgFvd/W+tOwchke3uO80sA/gE8KfuKuLuh9wEMLOizi6F7uvCeN5hPGcI53nrnA9Pt11AQZ/+zSRn8KwBnnL31WZ2p5ldGuz2AJBrZsXALUDrVNGbgYnA7R2me2YCi81sBbCcZLDc3xMnJCIi6TmmFoM7HGH8SwHCed5hPGcI53nrnA9PmK4Ent/bFeglYTzvMJ4zhPO8dc6HITQtABERaS9MLQAREUmhABARCalQBEB3i9n1BWY2xsxeNLN3zGy1mf1zUJ5jZs+b2frg367vQH6MMrOomb1lZr8PXo8PFiUsDhYpjPd2HXuamWWb2QIze9fM1pjZmX39uzaz/x38315lZk+YWVZf/K7N7EEzKzezVSllnX63lnR3cP4rzOzUg/msPh8AKYvZzQGmAvPMbGrv1uqISABfdfepwBnAPwXneSvwgrtPAl5g/xTdvuSfSU5RbvU94EfuPhGoJrlYYV/zE+A5d58CnEzy/Pvsd21mo4GvAIXuPg2IkrwmqS9+1z8HZnco6+q7nQNMCh43AvcezAf1+QAgvcXsjnnuvs3d3wye7yH5gzCa9gv1PQxc3js1PDKCK80vBn4WvDbgApKLEkLfPOchwLkkr7/B3RvdfRd9/LsmeeFqv+BC0v7ANvrgd+3uLwNVHYq7+m4vAx7xpNeBbDMbme5nhSEA0lnMrk8J7sdwCrAEGO7u24JN24HhvVStI+XHwNeAluB1LrAruIAR+ub3PR6oILmY4ltm9jMzG0Af/q6DpWP+Cygh+cNfAyyj73/Xrbr6bg/r9y0MARAqZjYQ+DXwv9x9d+o2T8757TPzfs3sE0C5uy/r7bocZTHgVOBedz8F2EeH7p4++F0PJfnX7nhgFDCAA7tJQqEnv9swBEA6i9n1CcG6Sr8GHnP33wTFO1qbhMG/5b1VvyPgw8ClZvYeya69C0j2jWcH3QTQN7/vUqDU3ZcErxeQDIS+/F1/BNjk7hXu3gT8huT339e/61ZdfbeH9fsWhgBoW8wumCEwl+TidX1K0Pf9ALDG3X+Ysql1oT6Cf5852nU7Utz9G+5e4O7jSH6vf3b3a4AXSS5KCH3snAHcfTuwxcwmB0UXAu/Qh79rkl0/Z5hZ/+D/eus59+nvOkVX3+1C4NpgNtAZQE1KV1H33L3PP4CPA+uADcBtvV2fI3SOZ5NsFrYusLc8OO9ckrMG1pNccTWnt+t6hM7/POD3wfPjgTeAYuBXQGZv1+8InO8MoCj4vn8LDO3r3zXwH8C7wCrgFyQXlexz3zXwBMlxjiaSrb0buvpuASM5y3EDsJLkLKm0P0tLQYiIhFQYuoBERKQTCgARkZBSAIiIhJQCQEQkpBQAIiIhpQAQEQkpBYCISEj9f/dYPfP0gGiZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcTepLPKl3uE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "acf3e388-fab2-4122-eba9-0c72332ff844"
      },
      "source": [
        "pre=mod.predict([X[no_dum],X[cat]])\n",
        "pre.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1097231, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB8qLYW28Rg6"
      },
      "source": [
        "pd.DataFrame(pre).to_csv('/content/gdrive/My Drive/fraud/with_id.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7kGh-p9H_e"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
