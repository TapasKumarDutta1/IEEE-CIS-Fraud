{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoenc_prep_without_id.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TapasKumarDutta1/IEEE-CIS-Fraud/blob/master/autoenc_prep_without_id.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from math import *\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization, Activation, concatenate\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import gc\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from keras.utils import Sequence\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "OaecDJtSj4QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYtsrH0G_GC3"
      },
      "source": [
        "Loading the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "67291fce-8615-4281-fffd-9fdca896ee5b"
      },
      "source": [
        "\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3CLKiyk_VTC"
      },
      "source": [
        "\n",
        "np.random.seed(42) # NumPy\n",
        "random.seed(42) # Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFkVLjyg_Io5"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJem4-mp8otc"
      },
      "source": [
        "\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv',index_col=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk57wdug_Kuq"
      },
      "source": [
        "Drop id and isFraud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiE3LbOCCgku"
      },
      "source": [
        "trn=trn.drop(['isFraud','id'],1)\n",
        "tst=tst.drop(['id'],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaSRatVa_Qlr"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKYcx1CSuEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "a1988576-51f4-481a-c34c-2b8e535d1f6c"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\"\n",
        "    Reduce memory usage of a DataFrame by converting data types to lower memory equivalents.\n",
        "\n",
        "    Parameters:\n",
        "        df (pandas.DataFrame): The DataFrame to be optimized.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: The DataFrame with optimized memory usage.\n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage of the DataFrame is {:.2f} MB\".format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if (\n",
        "                    c_min > np.finfo(np.float16).min\n",
        "                    and c_max < np.finfo(np.float16).max\n",
        "                ):\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif (\n",
        "                    c_min > np.finfo(np.float32).min\n",
        "                    and c_max < np.finfo(np.float32).max\n",
        "                ):\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype(\"category\")\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
        "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Example usage\n",
        "trn = reduce_mem_usage(trn)\n",
        "tst = reduce_mem_usage(tst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2243.72 MB\n",
            "Memory usage after optimization is: 554.17 MB\n",
            "Decreased by 75.3%\n",
            "Memory usage of dataframe is 1925.14 MB\n",
            "Memory usage after optimization is: 475.49 MB\n",
            "Decreased by 75.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYYe5k4-_aBP"
      },
      "source": [
        "Concatenate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha_HXo738T8S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f60761e2-9dc2-42a0-d293-7cc1046bde70"
      },
      "source": [
        "# Concatenate the DataFrames trn and tst into a new DataFrame X\n",
        "X = pd.concat([trn, tst]).reset_index(drop=True)\n",
        "\n",
        "# Delete the original DataFrames trn and tst to free up memory\n",
        "del [trn, tst]\n",
        "\n",
        "# Perform garbage collection to release memory used by deleted objects\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGUnUEl_dAz"
      },
      "source": [
        "Divide data into categorical and numerical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLml17V2_dJe"
      },
      "source": [
        "# Convert categorical columns to uint8 data type\n",
        "cat = [str(i) for i in range(444)]\n",
        "X[cat] = X[cat].astype(\"uint8\")\n",
        "\n",
        "# Find numeric columns that are not in the categorical columns\n",
        "no_dum = [i for i in X.columns if i not in cat]\n",
        "\n",
        "# Get the number of numeric and categorical features\n",
        "num_shape = len(no_dum)\n",
        "cat_shape = len(cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIcL-BDLW9T"
      },
      "source": [
        "\n",
        "def custom_gelu(x):\n",
        "    \"\"\"\n",
        "    Custom gelu activation function.\n",
        "\n",
        "    Parameters:\n",
        "    x (tensor): Input tensor.\n",
        "\n",
        "    Returns:\n",
        "    tensor: Output tensor after applying custom gelu activation.\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "\n",
        "def create_model():\n",
        "    \"\"\"\n",
        "    Create a neural network model with custom gelu activation.\n",
        "\n",
        "    Returns:\n",
        "    keras.models.Model: Neural network model with inputs and outputs.\n",
        "    \"\"\"\n",
        "    # Collect garbage to free up memory\n",
        "    gc.collect()\n",
        "\n",
        "    # Clear any existing Keras session\n",
        "    K.clear_session()\n",
        "\n",
        "    # Define input layers for numeric and categorical features\n",
        "    num_inp = Input(shape=(num_shape,))\n",
        "    cat_inp = Input(shape=(cat_shape,))\n",
        "\n",
        "    # Concatenate the numeric and categorical inputs\n",
        "    inps = concatenate([num_inp, cat_inp])\n",
        "\n",
        "    # Create dense layers with custom gelu activation\n",
        "    x = Dense(512, activation=custom_gelu)(inps)\n",
        "    x = Dense(256, activation=custom_gelu)(x)\n",
        "    x = Dense(512, activation=custom_gelu)(x)\n",
        "\n",
        "    # Add dropout layer for regularization\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Output layers for numeric and categorical features\n",
        "    cat_out = Dense(cat_shape, activation=\"linear\")(x)\n",
        "    num_out = Dense(num_shape, activation=\"linear\")(x)\n",
        "\n",
        "    # Create the model with inputs and outputs\n",
        "    model = Model(inputs=[num_inp, cat_inp], outputs=[num_out, cat_out])\n",
        "\n",
        "    # Compile the model with Adam optimizer and mse loss for both outputs\n",
        "    model.compile(optimizer=Adam(0.05, clipnorm=1, clipvalue=1), loss=[\"mse\", \"mse\"])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWNV_5Kl_y46"
      },
      "source": [
        "Warmup learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf25ibJI8T5-"
      },
      "source": [
        "\n",
        "class WarmUpLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Custom Callback to implement a warm-up learning rate scheduler.\n",
        "\n",
        "    Parameters:\n",
        "        warmup_batches (int): The number of batches for the warm-up phase.\n",
        "        init_lr (float): The initial learning rate before warm-up.\n",
        "        verbose (int): Whether to print messages about learning rate changes.\n",
        "\n",
        "    Example:\n",
        "        warmup_lr_scheduler = WarmUpLearningRateScheduler(warmup_batches=100, init_lr=0.01, verbose=1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup_batches, init_lr, verbose=0):\n",
        "        super(WarmUpLearningRateScheduler, self).__init__()\n",
        "        self.warmup_batches = warmup_batches\n",
        "        self.init_lr = init_lr\n",
        "        self.verbose = verbose\n",
        "        self.batch_count = 0\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        \"\"\"\n",
        "        Callback function executed at the end of each batch.\n",
        "\n",
        "        Parameters:\n",
        "            batch (int): The current batch index.\n",
        "            logs (dict): Dictionary containing the training metrics for the current batch.\n",
        "        \"\"\"\n",
        "        self.batch_count += 1\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        \"\"\"\n",
        "        Callback function executed at the beginning of each batch.\n",
        "\n",
        "        Parameters:\n",
        "            batch (int): The current batch index.\n",
        "            logs (dict): Dictionary containing the training metrics for the current batch.\n",
        "        \"\"\"\n",
        "        if self.batch_count <= self.warmup_batches:\n",
        "            lr = self.batch_count * self.init_lr / self.warmup_batches\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "            if self.verbose > 0:\n",
        "                print(\"\\nBatch %05d: WarmUpLearningRateScheduler setting learning rate to %s.\" % (self.batch_count + 1, lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMkvG-As_4Pb"
      },
      "source": [
        "Data generator for denoising autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyjXsW3U8Txj"
      },
      "source": [
        "class DAESequence(Sequence):\n",
        "    \"\"\"\n",
        "    Custom Sequence generator for Denoising Autoencoder (DAE) training.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The input dataframe containing the data for the DAE.\n",
        "        no_dum (list): List of numerical column names.\n",
        "        frac (float): Fraction of data to be corrupted (default is 0.15).\n",
        "        dumm (range): Range of column indices for dummy/categorical columns (default is range(911)).\n",
        "        batch_size (int): Batch size for training (default is 2048).\n",
        "\n",
        "    Example:\n",
        "        dae_seq = DAESequence(df, no_dum=['col1', 'col2', 'col3'], batch_size=1024)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, no_dum, frac=0.15, dumm=range(911), batch_size=2048):\n",
        "        self.batch_size = batch_size\n",
        "        self.frac = frac\n",
        "        self.dumm = dumm\n",
        "        self.df = df\n",
        "        self.cat_data = df[dumm].values\n",
        "        self.num_data = df[no_dum].values\n",
        "        self.no_dumm = no_dum\n",
        "        self.len_data = df.shape[0]\n",
        "        self.columns = df.shape[1]\n",
        "        self.data = df\n",
        "        self.idx = []\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of batches in the Sequence.\n",
        "\n",
        "        Returns:\n",
        "            int: The number of batches.\n",
        "        \"\"\"\n",
        "        return int(ceil(self.len_data / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Generates one batch of data for training.\n",
        "\n",
        "        Parameters:\n",
        "            idx (int): The index of the batch.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing input and output data for the DAE.\n",
        "        \"\"\"\n",
        "        self.idx.append(idx)\n",
        "        last = min((idx + 1) * self.batch_size, self.len_data)\n",
        "        idx = idx * self.batch_size\n",
        "        size = last - idx\n",
        "\n",
        "        inps = []\n",
        "        outs = []\n",
        "        output_x = self.data.iloc[idx:last]\n",
        "\n",
        "        # Generate noise for numerical columns\n",
        "        data = output_x[self.no_dumm].values\n",
        "        noise_x = data.copy()\n",
        "        for i in range(len(self.no_dumm)):\n",
        "            to = np.random.randint(0, size, int(size * self.frac))\n",
        "            frm = np.random.randint(0, size, int(size * self.frac))\n",
        "            noise_x[to, i] = noise_x[frm, i]\n",
        "\n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "\n",
        "        # Generate noise for categorical columns\n",
        "        data = output_x[self.dumm].values\n",
        "        noise_x = data.copy()\n",
        "        for i in range(len(self.dumm)):\n",
        "            to = np.random.randint(0, size, int(size * self.frac))\n",
        "            frm = np.random.randint(0, size, int(size * self.frac))\n",
        "            noise_x[to, i] = noise_x[frm, i]\n",
        "\n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "\n",
        "        return inps, outs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acDwaLOGACcP"
      },
      "source": [
        "Fill nan by mean then by 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ryHot0g1BwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ff2e0ebf-c5aa-4285-fcd0-bd3673f52bac"
      },
      "source": [
        "# Fill missing values with the column mean for columns with missing values\n",
        "a = X.isna().sum()\n",
        "a = a[a > 0]\n",
        "cls = list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "    if col in cls:\n",
        "        X[col] = X[col].fillna(X[col].mean())\n",
        "\n",
        "# Fill remaining missing values with 0 for columns with missing values\n",
        "a = X.isna().sum()\n",
        "a = a[a > 0]\n",
        "cls = list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "    if col in cls:\n",
        "        X[col] = X[col].fillna(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXdXM2kpNXgw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "234ea244-b3f7-4c2a-c2a2-69784b57f8ec"
      },
      "source": [
        "# Create the model\n",
        "model_mse = create_model()\n",
        "\n",
        "# Initialize the learning rate warm-up scheduler\n",
        "warm_up_lr = WarmUpLearningRateScheduler(warmup_batches=400, init_lr=0.0005)\n",
        "\n",
        "# Free up memory\n",
        "gc.collect()\n",
        "\n",
        "# Define the number of epochs and batch size\n",
        "epochs = 100\n",
        "batch_size = 2048\n",
        "\n",
        "# Create the data generator using DAESequence\n",
        "train_gen = DAESequence(X, no_dum, batch_size=batch_size, dumm=cat)\n",
        "\n",
        "# Train the model\n",
        "hist = model_mse.fit_generator(\n",
        "    train_gen,\n",
        "    steps_per_epoch=len(X) // batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    workers=-1,\n",
        "    use_multiprocessing=True,\n",
        "    callbacks=[warm_up_lr],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-6159992651dc>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.2237 - dense_4_loss: 0.1960 - dense_3_loss: 0.0277\n",
            "Epoch 2/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0842 - dense_4_loss: 0.0711 - dense_3_loss: 0.0131\n",
            "Epoch 3/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0748 - dense_4_loss: 0.0643 - dense_3_loss: 0.0105\n",
            "Epoch 4/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0680 - dense_4_loss: 0.0585 - dense_3_loss: 0.0095\n",
            "Epoch 5/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0643 - dense_4_loss: 0.0553 - dense_3_loss: 0.0090\n",
            "Epoch 6/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0644 - dense_4_loss: 0.0557 - dense_3_loss: 0.0087\n",
            "Epoch 7/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0603 - dense_4_loss: 0.0519 - dense_3_loss: 0.0084\n",
            "Epoch 8/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0608 - dense_4_loss: 0.0526 - dense_3_loss: 0.0082\n",
            "Epoch 9/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0609 - dense_4_loss: 0.0529 - dense_3_loss: 0.0080\n",
            "Epoch 10/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0612 - dense_4_loss: 0.0531 - dense_3_loss: 0.0081\n",
            "Epoch 11/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0534 - dense_4_loss: 0.0455 - dense_3_loss: 0.0079\n",
            "Epoch 12/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0585 - dense_4_loss: 0.0506 - dense_3_loss: 0.0079\n",
            "Epoch 13/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0506 - dense_4_loss: 0.0430 - dense_3_loss: 0.0076\n",
            "Epoch 14/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0492 - dense_4_loss: 0.0417 - dense_3_loss: 0.0075\n",
            "Epoch 15/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0503 - dense_4_loss: 0.0428 - dense_3_loss: 0.0074\n",
            "Epoch 16/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0496 - dense_4_loss: 0.0423 - dense_3_loss: 0.0073\n",
            "Epoch 17/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0489 - dense_4_loss: 0.0417 - dense_3_loss: 0.0072\n",
            "Epoch 18/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0503 - dense_4_loss: 0.0431 - dense_3_loss: 0.0072\n",
            "Epoch 19/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0490 - dense_4_loss: 0.0419 - dense_3_loss: 0.0071\n",
            "Epoch 20/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0471 - dense_4_loss: 0.0401 - dense_3_loss: 0.0070\n",
            "Epoch 21/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0452 - dense_4_loss: 0.0382 - dense_3_loss: 0.0070\n",
            "Epoch 22/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0459 - dense_4_loss: 0.0389 - dense_3_loss: 0.0070\n",
            "Epoch 23/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0463 - dense_4_loss: 0.0394 - dense_3_loss: 0.0069\n",
            "Epoch 24/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0508 - dense_4_loss: 0.0440 - dense_3_loss: 0.0068\n",
            "Epoch 25/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0432 - dense_4_loss: 0.0364 - dense_3_loss: 0.0068\n",
            "Epoch 26/50\n",
            "535/535 [==============================] - 24s 44ms/step - loss: 0.0441 - dense_4_loss: 0.0374 - dense_3_loss: 0.0068\n",
            "Epoch 27/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0496 - dense_4_loss: 0.0430 - dense_3_loss: 0.0066\n",
            "Epoch 28/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0434 - dense_4_loss: 0.0368 - dense_3_loss: 0.0067\n",
            "Epoch 29/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0476 - dense_4_loss: 0.0410 - dense_3_loss: 0.0066\n",
            "Epoch 30/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0442 - dense_4_loss: 0.0376 - dense_3_loss: 0.0066\n",
            "Epoch 31/50\n",
            "535/535 [==============================] - 23s 42ms/step - loss: 0.0430 - dense_4_loss: 0.0365 - dense_3_loss: 0.0065\n",
            "Epoch 32/50\n",
            "535/535 [==============================] - 23s 42ms/step - loss: 0.0440 - dense_4_loss: 0.0374 - dense_3_loss: 0.0066\n",
            "Epoch 33/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0485 - dense_4_loss: 0.0421 - dense_3_loss: 0.0065\n",
            "Epoch 34/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0434 - dense_4_loss: 0.0370 - dense_3_loss: 0.0064\n",
            "Epoch 35/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0416 - dense_4_loss: 0.0352 - dense_3_loss: 0.0064\n",
            "Epoch 36/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0440 - dense_4_loss: 0.0376 - dense_3_loss: 0.0064\n",
            "Epoch 37/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0425 - dense_4_loss: 0.0362 - dense_3_loss: 0.0063\n",
            "Epoch 38/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0478 - dense_4_loss: 0.0415 - dense_3_loss: 0.0063\n",
            "Epoch 39/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0409 - dense_4_loss: 0.0345 - dense_3_loss: 0.0063\n",
            "Epoch 40/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0420 - dense_4_loss: 0.0358 - dense_3_loss: 0.0063\n",
            "Epoch 41/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0419 - dense_4_loss: 0.0357 - dense_3_loss: 0.0062\n",
            "Epoch 42/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0413 - dense_4_loss: 0.0350 - dense_3_loss: 0.0063\n",
            "Epoch 43/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0409 - dense_4_loss: 0.0347 - dense_3_loss: 0.0061\n",
            "Epoch 44/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0472 - dense_4_loss: 0.0411 - dense_3_loss: 0.0062\n",
            "Epoch 45/50\n",
            "535/535 [==============================] - 24s 44ms/step - loss: 0.0514 - dense_4_loss: 0.0453 - dense_3_loss: 0.0061\n",
            "Epoch 46/50\n",
            "535/535 [==============================] - 23s 42ms/step - loss: 0.0412 - dense_4_loss: 0.0351 - dense_3_loss: 0.0061\n",
            "Epoch 47/50\n",
            "535/535 [==============================] - 23s 43ms/step - loss: 0.0455 - dense_4_loss: 0.0394 - dense_3_loss: 0.0060\n",
            "Epoch 48/50\n",
            "535/535 [==============================] - 23s 42ms/step - loss: 0.0424 - dense_4_loss: 0.0363 - dense_3_loss: 0.0061\n",
            "Epoch 49/50\n",
            "535/535 [==============================] - 24s 44ms/step - loss: 0.0404 - dense_4_loss: 0.0343 - dense_3_loss: 0.0061\n",
            "Epoch 50/50\n",
            "535/535 [==============================] - 23s 44ms/step - loss: 0.0455 - dense_4_loss: 0.0395 - dense_3_loss: 0.0060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNx0SXIhhb0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "89040b2c-ff93-45a0-84b0-6931ec05567d"
      },
      "source": [
        "mod=Model(inputs=model_mse.inputs,outputs=model_mse.layers[4].output)\n",
        "mod.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 53)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 444)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 497)          0           input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          254976      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 386,304\n",
            "Trainable params: 386,304\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdaDfCWm8pDt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "0adb878d-c586-40a0-fd8b-f931f071a847"
      },
      "source": [
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f13f05c9f28>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcTepLPKl3uE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "57cb61ce-9411-4ca0-a0ce-9fc429e33857"
      },
      "source": [
        "pre=mod.predict([X[no_dum],X[cat]])\n",
        "pre.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1097231, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB8qLYW28Rg6"
      },
      "source": [
        "pd.DataFrame(pre).to_csv('/content/gdrive/My Drive/fraud/without_id.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7kGh-p9H_e"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
