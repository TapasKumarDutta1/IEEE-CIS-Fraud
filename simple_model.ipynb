{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "13749859-143a-44db-ab55-a6ab8e14d7c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "b5a58907-8508-4851-a507-58c608d9edc3"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 84% 49.0M/58.3M [00:02<00:00, 13.4MB/s]\n",
            "100% 58.3M/58.3M [00:02<00:00, 25.8MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 166MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 48% 25.0M/52.2M [00:01<00:01, 18.8MB/s]\n",
            "100% 52.2M/52.2M [00:01<00:00, 34.9MB/s]\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 223MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 219MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold=5\n",
        "lr=0.0001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OTCMdEiOn9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv80v8W_Ko2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b1796b0e-c24d-4e68-f8f7-6840c06b96d3"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in cols:\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4jt2pcxPije",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "ss=StandardScaler()\n",
        "frd=trn['isFraud']\n",
        "ls=list(trn)\n",
        "trn=ss.fit_transform(trn.drop(['isFraud'],1))\n",
        "trn=pd.DataFrame(trn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls.remove('isFraud')\n",
        "trn.columns=ls\n",
        "trn['isFraud']=frd\n",
        "\n",
        "ls=list(tst)\n",
        "tst=ss.fit_transform(tst)\n",
        "tst=pd.DataFrame(tst)\n",
        "tst.columns=ls"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "42735ff2-84fa-46e1-ecf8-c8d961530a6c"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1671.53 MB\n",
            "Memory usage after optimization is: 417.88 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 1430.33 MB\n",
            "Memory usage after optimization is: 357.58 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvEaxp9jhbvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a2a6b7bf-d473-4c1f-dd54-acb08a2b11e1"
      },
      "source": [
        "trn_n=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_n=pd.read_csv('test_transaction.csv.zip')\n",
        "trn['month']=trn_n['TransactionDT']//(86400*30)\n",
        "trn_n.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkB4RpFZiww2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5e571dc3-f202-492b-e270-281ec73bb55d"
      },
      "source": [
        "\n",
        "trn_ls=list(trn_n)\n",
        "tst_ls=list(tst_n)\n",
        "for col in trn:\n",
        "  if col in trn_ls:\n",
        "    trn[col+'_isna']=trn_n[col].isna().astype('uint8')\n",
        "for col in tst:\n",
        "  if col in tst_ls:\n",
        "    tst[col+'_isna']=tst_n[col].isna().astype('uint8')\n",
        "import gc\n",
        "del([trn_n,tst_n])\n",
        "gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMRiP7efPTDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.drop(['isFraud_isna'],1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08d36d16-3461-4ea1-dfa9-1a3a57e7be3a"
      },
      "source": [
        "dk={}\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        if self.ep%10==0:\n",
        "          y_pred_val = self.model.predict(self.x_val)\n",
        "          roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "          print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "  inp=Input((593,))\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=inp,outputs=x)\n",
        "  return mod\n",
        "for en,month in enumerate([(4,5),(3,4),(3,5)]):\n",
        "  train=trn.loc[trn['month']<=month[0]]\n",
        "  test=trn.loc[(trn['month']>=month[1])&(trn['month']<6)]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  roc = RocCallback(\n",
        "                  validation_data=(test.drop(['isFraud'],1), test['isFraud']))\n",
        "  mod.compile(optimizer=Adam(0.0001,decay=1e-3),loss='binary_crossentropy')\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es,roc])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  df=trn.loc[trn['month']==6].reset_index(drop=True).drop(['month'],1)\n",
        "  pre=mod.predict(df.drop(['isFraud'],1))\n",
        "  scr=roc_auc_score(df['isFraud'],pre)\n",
        "  dk[str(scr)]=mod.predict(tst)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "243/243 [==============================] - 2s 7ms/step - loss: 0.6880 - val_loss: 0.6070\n",
            "Epoch 2/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.5113 - val_loss: 0.4689\n",
            "Epoch 3/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.3887 - val_loss: 0.3299\n",
            "Epoch 4/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.3022 - val_loss: 0.2561\n",
            "Epoch 5/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.2463 - val_loss: 0.2099\n",
            "Epoch 6/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.2113 - val_loss: 0.1828\n",
            "Epoch 7/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1892 - val_loss: 0.1681\n",
            "Epoch 8/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1748 - val_loss: 0.1554\n",
            "Epoch 9/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1630 - val_loss: 0.1485\n",
            "Epoch 10/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.1553roc-auc_val: 0.8126\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1553 - val_loss: 0.1436\n",
            "Epoch 11/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1489 - val_loss: 0.1374\n",
            "Epoch 12/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1451 - val_loss: 0.1342\n",
            "Epoch 13/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1404 - val_loss: 0.1315\n",
            "Epoch 14/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1378 - val_loss: 0.1302\n",
            "Epoch 15/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1361 - val_loss: 0.1278\n",
            "Epoch 16/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1339 - val_loss: 0.1272\n",
            "Epoch 17/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1321 - val_loss: 0.1260\n",
            "Epoch 18/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1303 - val_loss: 0.1251\n",
            "Epoch 19/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1301 - val_loss: 0.1244\n",
            "Epoch 20/1000\n",
            "242/243 [============================>.] - ETA: 0s - loss: 0.1290roc-auc_val: 0.8254\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1290 - val_loss: 0.1235\n",
            "Epoch 21/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1278 - val_loss: 0.1230\n",
            "Epoch 22/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1261 - val_loss: 0.1224\n",
            "Epoch 23/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1254 - val_loss: 0.1214\n",
            "Epoch 24/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1248 - val_loss: 0.1211\n",
            "Epoch 25/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1248 - val_loss: 0.1212\n",
            "Epoch 26/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1230 - val_loss: 0.1207\n",
            "Epoch 27/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1225 - val_loss: 0.1200\n",
            "Epoch 28/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1222 - val_loss: 0.1198\n",
            "Epoch 29/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1223 - val_loss: 0.1195\n",
            "Epoch 30/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.1220roc-auc_val: 0.834\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1221 - val_loss: 0.1194\n",
            "Epoch 31/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1217 - val_loss: 0.1191\n",
            "Epoch 32/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1202 - val_loss: 0.1186\n",
            "Epoch 33/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1201 - val_loss: 0.1184\n",
            "Epoch 34/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1200 - val_loss: 0.1182\n",
            "Epoch 35/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1193 - val_loss: 0.1181\n",
            "Epoch 36/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1193 - val_loss: 0.1181\n",
            "Epoch 37/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1186 - val_loss: 0.1180\n",
            "Epoch 38/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1181 - val_loss: 0.1176\n",
            "Epoch 39/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1181 - val_loss: 0.1175\n",
            "Epoch 40/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.1183roc-auc_val: 0.8401\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1182 - val_loss: 0.1170\n",
            "Epoch 41/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1178 - val_loss: 0.1172\n",
            "Epoch 42/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1176 - val_loss: 0.1169\n",
            "Epoch 43/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1176 - val_loss: 0.1167\n",
            "Epoch 44/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1167 - val_loss: 0.1167\n",
            "Epoch 45/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1161 - val_loss: 0.1167\n",
            "Epoch 46/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1165 - val_loss: 0.1165\n",
            "Epoch 47/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1162 - val_loss: 0.1164\n",
            "Epoch 48/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1156 - val_loss: 0.1161\n",
            "Epoch 49/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1151 - val_loss: 0.1160\n",
            "Epoch 50/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.1152roc-auc_val: 0.8436\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1153 - val_loss: 0.1160\n",
            "Epoch 51/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1146 - val_loss: 0.1158\n",
            "Epoch 52/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1143 - val_loss: 0.1158\n",
            "Epoch 53/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1151 - val_loss: 0.1156\n",
            "Epoch 54/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1140 - val_loss: 0.1156\n",
            "Epoch 55/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1148 - val_loss: 0.1155\n",
            "Epoch 56/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1146 - val_loss: 0.1154\n",
            "Epoch 57/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1137 - val_loss: 0.1154\n",
            "Epoch 58/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1140 - val_loss: 0.1153\n",
            "Epoch 59/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1136 - val_loss: 0.1150\n",
            "Epoch 60/1000\n",
            "241/243 [============================>.] - ETA: 0s - loss: 0.1129roc-auc_val: 0.8466\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1130 - val_loss: 0.1149\n",
            "Epoch 61/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1134 - val_loss: 0.1149\n",
            "Epoch 62/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1134 - val_loss: 0.1149\n",
            "Epoch 63/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1130 - val_loss: 0.1149\n",
            "Epoch 64/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1128 - val_loss: 0.1147\n",
            "Epoch 65/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1134 - val_loss: 0.1147\n",
            "Epoch 66/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1126 - val_loss: 0.1147\n",
            "Epoch 67/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1124 - val_loss: 0.1146\n",
            "Epoch 68/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1127 - val_loss: 0.1146\n",
            "Epoch 69/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1127 - val_loss: 0.1145\n",
            "Epoch 70/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.1116roc-auc_val: 0.8479\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1115 - val_loss: 0.1144\n",
            "Epoch 71/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1119 - val_loss: 0.1144\n",
            "Epoch 72/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1119 - val_loss: 0.1144\n",
            "Epoch 73/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1115 - val_loss: 0.1144\n",
            "Epoch 74/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1106 - val_loss: 0.1145\n",
            "Epoch 75/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1114 - val_loss: 0.1141\n",
            "Epoch 76/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1106 - val_loss: 0.1140\n",
            "Epoch 77/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1112 - val_loss: 0.1140\n",
            "Epoch 78/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1104 - val_loss: 0.1140\n",
            "Epoch 79/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1104 - val_loss: 0.1141\n",
            "Epoch 80/1000\n",
            "233/243 [===========================>..] - ETA: 0s - loss: 0.1105roc-auc_val: 0.8492\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1104 - val_loss: 0.1140\n",
            "Epoch 81/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1102 - val_loss: 0.1140\n",
            "Epoch 82/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1107 - val_loss: 0.1138\n",
            "Epoch 83/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1097 - val_loss: 0.1139\n",
            "Epoch 84/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1096 - val_loss: 0.1139\n",
            "Epoch 85/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1101 - val_loss: 0.1137\n",
            "Epoch 86/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1102 - val_loss: 0.1137\n",
            "Epoch 87/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1095 - val_loss: 0.1136\n",
            "Epoch 88/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1094 - val_loss: 0.1137\n",
            "Epoch 89/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1093 - val_loss: 0.1135\n",
            "Epoch 90/1000\n",
            "233/243 [===========================>..] - ETA: 0s - loss: 0.1096roc-auc_val: 0.8506\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1095 - val_loss: 0.1134\n",
            "Epoch 91/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1096 - val_loss: 0.1135\n",
            "Epoch 92/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1094 - val_loss: 0.1134\n",
            "Epoch 93/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1098 - val_loss: 0.1135\n",
            "Epoch 94/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1133\n",
            "Epoch 95/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1090 - val_loss: 0.1135\n",
            "Epoch 96/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1133\n",
            "Epoch 97/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1084 - val_loss: 0.1132\n",
            "Epoch 98/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1131\n",
            "Epoch 99/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1086 - val_loss: 0.1130\n",
            "Epoch 100/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.1086roc-auc_val: 0.8518\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1086 - val_loss: 0.1130\n",
            "Epoch 101/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1084 - val_loss: 0.1131\n",
            "Epoch 102/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.1131\n",
            "Epoch 103/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1085 - val_loss: 0.1130\n",
            "Epoch 104/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.1129\n",
            "Epoch 105/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1085 - val_loss: 0.1128\n",
            "Epoch 106/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.1130\n",
            "Epoch 107/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1076 - val_loss: 0.1129\n",
            "Epoch 108/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1076 - val_loss: 0.1128\n",
            "Epoch 109/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1078 - val_loss: 0.1128\n",
            "Epoch 110/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.1077roc-auc_val: 0.8522\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1079 - val_loss: 0.1128\n",
            "Epoch 111/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1128\n",
            "Epoch 112/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1129\n",
            "Epoch 113/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1076 - val_loss: 0.1126\n",
            "Epoch 114/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1072 - val_loss: 0.1126\n",
            "Epoch 115/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1072 - val_loss: 0.1125\n",
            "Epoch 116/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1081 - val_loss: 0.1126\n",
            "Epoch 117/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1073 - val_loss: 0.1127\n",
            "Epoch 118/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1071 - val_loss: 0.1126\n",
            "Epoch 119/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1071 - val_loss: 0.1127\n",
            "Epoch 120/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.1069roc-auc_val: 0.853\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1070 - val_loss: 0.1126\n",
            "Epoch 121/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1066 - val_loss: 0.1126\n",
            "Epoch 122/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1070 - val_loss: 0.1126\n",
            "Epoch 123/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1068 - val_loss: 0.1127\n",
            "Epoch 124/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1069 - val_loss: 0.1126\n",
            "Epoch 125/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1069 - val_loss: 0.1124\n",
            "Epoch 126/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1066 - val_loss: 0.1124\n",
            "Epoch 127/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1066 - val_loss: 0.1124\n",
            "Epoch 128/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1064 - val_loss: 0.1124\n",
            "Epoch 129/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1065 - val_loss: 0.1123\n",
            "Epoch 130/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.1069roc-auc_val: 0.854\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1069 - val_loss: 0.1123\n",
            "Epoch 131/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1063 - val_loss: 0.1123\n",
            "Epoch 132/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1057 - val_loss: 0.1123\n",
            "Epoch 133/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1058 - val_loss: 0.1122\n",
            "Epoch 134/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1054 - val_loss: 0.1123\n",
            "Epoch 135/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1063 - val_loss: 0.1124\n",
            "Epoch 136/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.1122\n",
            "Epoch 137/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1057 - val_loss: 0.1122\n",
            "Epoch 138/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1058 - val_loss: 0.1121\n",
            "Epoch 139/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1060 - val_loss: 0.1121\n",
            "Epoch 140/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.1054roc-auc_val: 0.8545\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1054 - val_loss: 0.1121\n",
            "Epoch 141/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1063 - val_loss: 0.1120\n",
            "Epoch 142/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1054 - val_loss: 0.1121\n",
            "Epoch 143/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1057 - val_loss: 0.1121\n",
            "Epoch 144/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1054 - val_loss: 0.1120\n",
            "Epoch 145/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1058 - val_loss: 0.1121\n",
            "Epoch 146/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1051 - val_loss: 0.1119\n",
            "Epoch 147/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1050 - val_loss: 0.1120\n",
            "Epoch 148/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1050 - val_loss: 0.1119\n",
            "Epoch 149/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1054 - val_loss: 0.1120\n",
            "Epoch 150/1000\n",
            "236/243 [============================>.] - ETA: 0s - loss: 0.1056roc-auc_val: 0.8556\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1055 - val_loss: 0.1119\n",
            "Epoch 151/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1049 - val_loss: 0.1120\n",
            "Epoch 152/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1048 - val_loss: 0.1119\n",
            "Epoch 153/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1050 - val_loss: 0.1119\n",
            "Epoch 154/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1045 - val_loss: 0.1118\n",
            "Epoch 155/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1053 - val_loss: 0.1118\n",
            "Epoch 156/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1050 - val_loss: 0.1118\n",
            "Epoch 157/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1047 - val_loss: 0.1118\n",
            "Epoch 158/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1048 - val_loss: 0.1116\n",
            "Epoch 159/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1048 - val_loss: 0.1118\n",
            "Epoch 160/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.1041roc-auc_val: 0.8558\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1041 - val_loss: 0.1118\n",
            "Epoch 161/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1046 - val_loss: 0.1118\n",
            "Epoch 162/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1046 - val_loss: 0.1117\n",
            "Epoch 163/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1045 - val_loss: 0.1116\n",
            "Epoch 164/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1116\n",
            "Epoch 165/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.1117\n",
            "Epoch 166/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1050 - val_loss: 0.1116\n",
            "Epoch 167/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1045 - val_loss: 0.1116\n",
            "Epoch 168/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1045 - val_loss: 0.1117\n",
            "Epoch 169/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1043 - val_loss: 0.1117\n",
            "Epoch 170/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.1052roc-auc_val: 0.8563\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1052 - val_loss: 0.1117\n",
            "Epoch 171/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1041 - val_loss: 0.1117\n",
            "Epoch 172/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1042 - val_loss: 0.1117\n",
            "Epoch 173/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1037 - val_loss: 0.1116\n",
            "Epoch 174/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.1116\n",
            "Epoch 175/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1037 - val_loss: 0.1117\n",
            "Epoch 176/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1043 - val_loss: 0.1115\n",
            "Epoch 177/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1034 - val_loss: 0.1114\n",
            "Epoch 178/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1039 - val_loss: 0.1115\n",
            "Epoch 179/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1035 - val_loss: 0.1114\n",
            "Epoch 180/1000\n",
            "235/243 [============================>.] - ETA: 0s - loss: 0.1040roc-auc_val: 0.857\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1038 - val_loss: 0.1114\n",
            "Epoch 181/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.1114\n",
            "Epoch 182/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1040 - val_loss: 0.1115\n",
            "Epoch 183/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1039 - val_loss: 0.1115\n",
            "Epoch 184/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1035 - val_loss: 0.1114\n",
            "Epoch 185/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1040 - val_loss: 0.1113\n",
            "Epoch 186/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1034 - val_loss: 0.1112\n",
            "Epoch 187/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1035 - val_loss: 0.1113\n",
            "Epoch 188/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1034 - val_loss: 0.1113\n",
            "Epoch 189/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1034 - val_loss: 0.1113\n",
            "Epoch 190/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.1031roc-auc_val: 0.8577\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1031 - val_loss: 0.1112\n",
            "Epoch 191/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1035 - val_loss: 0.1113\n",
            "Epoch 192/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1111\n",
            "Epoch 193/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1113\n",
            "Epoch 194/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1035 - val_loss: 0.1111\n",
            "Epoch 195/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.1112\n",
            "Epoch 196/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1112\n",
            "Epoch 197/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1111\n",
            "Epoch 198/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.1112\n",
            "Epoch 199/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1028 - val_loss: 0.1110\n",
            "Epoch 200/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.1025roc-auc_val: 0.8582\n",
            "243/243 [==============================] - 4s 16ms/step - loss: 0.1025 - val_loss: 0.1110\n",
            "Epoch 201/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1110\n",
            "Epoch 202/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1029 - val_loss: 0.1111\n",
            "Epoch 203/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1029 - val_loss: 0.1110\n",
            "Epoch 204/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1111\n",
            "Epoch 205/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1110\n",
            "Epoch 206/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1024 - val_loss: 0.1110\n",
            "Epoch 207/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1111\n",
            "Epoch 208/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1025 - val_loss: 0.1109\n",
            "Epoch 209/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1110\n",
            "Epoch 210/1000\n",
            "234/243 [===========================>..] - ETA: 0s - loss: 0.1027roc-auc_val: 0.8584\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1025 - val_loss: 0.1110\n",
            "Epoch 211/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1109\n",
            "Epoch 212/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1109\n",
            "Epoch 213/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1110\n",
            "Epoch 214/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1110\n",
            "Epoch 215/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1110\n",
            "Epoch 216/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1024 - val_loss: 0.1109\n",
            "Epoch 217/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1029 - val_loss: 0.1108\n",
            "Epoch 218/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1108\n",
            "Epoch 219/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1025 - val_loss: 0.1108\n",
            "Epoch 220/1000\n",
            "243/243 [==============================] - ETA: 0s - loss: 0.1015roc-auc_val: 0.8588\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1015 - val_loss: 0.1108\n",
            "Epoch 221/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1108\n",
            "Epoch 222/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1108\n",
            "Epoch 223/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.1108\n",
            "Epoch 224/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1108\n",
            "Epoch 225/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1108\n",
            "Epoch 226/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1108\n",
            "Epoch 227/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1019 - val_loss: 0.1108\n",
            "Epoch 228/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1107\n",
            "Epoch 229/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1015 - val_loss: 0.1107\n",
            "Epoch 230/1000\n",
            "233/243 [===========================>..] - ETA: 0s - loss: 0.1024roc-auc_val: 0.8593\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1023 - val_loss: 0.1107\n",
            "Epoch 231/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1106\n",
            "Epoch 232/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1107\n",
            "Epoch 233/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1106\n",
            "Epoch 234/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1106\n",
            "Epoch 235/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1106\n",
            "Epoch 236/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1108\n",
            "Epoch 237/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1106\n",
            "Epoch 238/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1011 - val_loss: 0.1106\n",
            "Epoch 239/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1106\n",
            "Epoch 240/1000\n",
            "235/243 [============================>.] - ETA: 0s - loss: 0.1015roc-auc_val: 0.8596\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1016 - val_loss: 0.1106\n",
            "Epoch 241/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.1107\n",
            "Epoch 242/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.1105\n",
            "Epoch 243/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.1106\n",
            "Epoch 244/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1105\n",
            "Epoch 245/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1105\n",
            "Epoch 246/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1104\n",
            "Epoch 247/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1105\n",
            "Epoch 248/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1011 - val_loss: 0.1104\n",
            "Epoch 249/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.1105\n",
            "Epoch 250/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.1013roc-auc_val: 0.8602\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1014 - val_loss: 0.1104\n",
            "Epoch 251/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1104\n",
            "Epoch 252/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1104\n",
            "Epoch 253/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 0.1104\n",
            "Epoch 254/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1104\n",
            "Epoch 255/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1105\n",
            "Epoch 256/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.1105\n",
            "Epoch 257/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1104\n",
            "Epoch 258/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1105\n",
            "Epoch 259/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1105\n",
            "Epoch 260/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.1007roc-auc_val: 0.8602\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1008 - val_loss: 0.1105\n",
            "Epoch 261/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1104\n",
            "Epoch 262/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1103\n",
            "Epoch 263/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1009 - val_loss: 0.1104\n",
            "Epoch 264/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1104\n",
            "Epoch 265/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1009 - val_loss: 0.1103\n",
            "Epoch 266/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1103\n",
            "Epoch 267/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1104\n",
            "Epoch 268/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1103\n",
            "Epoch 269/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1104\n",
            "Epoch 270/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.1008roc-auc_val: 0.8605\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1007 - val_loss: 0.1104\n",
            "Epoch 271/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1006 - val_loss: 0.1104\n",
            "Epoch 272/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1103\n",
            "Epoch 273/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1104\n",
            "Epoch 274/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1103\n",
            "Epoch 275/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1102\n",
            "Epoch 276/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1103\n",
            "Epoch 277/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1103\n",
            "Epoch 278/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1102\n",
            "Epoch 279/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1006 - val_loss: 0.1102\n",
            "Epoch 280/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.1007roc-auc_val: 0.8608\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1007 - val_loss: 0.1103\n",
            "Epoch 281/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1101\n",
            "Epoch 282/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1103\n",
            "Epoch 283/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1102\n",
            "Epoch 284/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1102\n",
            "Epoch 285/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0999 - val_loss: 0.1101\n",
            "Epoch 286/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1101\n",
            "Epoch 287/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1102\n",
            "Epoch 288/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1101\n",
            "Epoch 289/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.1101\n",
            "Epoch 290/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.0995roc-auc_val: 0.8611\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0996 - val_loss: 0.1101\n",
            "Epoch 291/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1101\n",
            "Epoch 292/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1101\n",
            "Epoch 293/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1006 - val_loss: 0.1100\n",
            "Epoch 294/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.1101\n",
            "Epoch 295/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1101\n",
            "Epoch 296/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1001 - val_loss: 0.1101\n",
            "Epoch 297/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0999 - val_loss: 0.1101\n",
            "Epoch 298/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1101\n",
            "Epoch 299/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1100\n",
            "Epoch 300/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.1001roc-auc_val: 0.8615\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.1001 - val_loss: 0.1100\n",
            "Epoch 301/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.1102\n",
            "Epoch 302/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1101\n",
            "Epoch 303/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1100\n",
            "Epoch 304/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.1100\n",
            "Epoch 305/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1101\n",
            "Epoch 306/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1101\n",
            "Epoch 307/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.1101\n",
            "Epoch 308/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.1100\n",
            "Epoch 309/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1101\n",
            "Epoch 310/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.0997roc-auc_val: 0.8615\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0997 - val_loss: 0.1100\n",
            "Epoch 311/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.1100\n",
            "Epoch 312/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1101\n",
            "Epoch 313/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1101\n",
            "Epoch 314/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1100\n",
            "Epoch 315/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1099\n",
            "Epoch 316/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.1099\n",
            "Epoch 317/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0991 - val_loss: 0.1100\n",
            "Epoch 318/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0991 - val_loss: 0.1100\n",
            "Epoch 319/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1098\n",
            "Epoch 320/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.0994roc-auc_val: 0.8619\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0993 - val_loss: 0.1099\n",
            "Epoch 321/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1099\n",
            "Epoch 322/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1099\n",
            "Epoch 323/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1099\n",
            "Epoch 324/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.1100\n",
            "Epoch 325/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.1100\n",
            "Epoch 326/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1099\n",
            "Epoch 327/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1099\n",
            "Epoch 328/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1099\n",
            "Epoch 329/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1099\n",
            "Epoch 330/1000\n",
            "234/243 [===========================>..] - ETA: 0s - loss: 0.0996roc-auc_val: 0.862\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0996 - val_loss: 0.1098\n",
            "Epoch 331/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1099\n",
            "Epoch 332/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0991 - val_loss: 0.1099\n",
            "Epoch 333/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1098\n",
            "Epoch 334/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1099\n",
            "Epoch 335/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1098\n",
            "Epoch 336/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1098\n",
            "Epoch 337/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1098\n",
            "Epoch 338/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1098\n",
            "Epoch 339/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1098\n",
            "Epoch 340/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.0988roc-auc_val: 0.8622\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0989 - val_loss: 0.1098\n",
            "Epoch 341/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1097\n",
            "Epoch 342/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1098\n",
            "Epoch 343/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1097\n",
            "Epoch 344/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1098\n",
            "Epoch 345/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1098\n",
            "Epoch 346/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0991 - val_loss: 0.1097\n",
            "Epoch 347/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1098\n",
            "Epoch 348/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1098\n",
            "Epoch 349/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1097\n",
            "Epoch 350/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.0986roc-auc_val: 0.8621\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0987 - val_loss: 0.1098\n",
            "Epoch 351/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1098\n",
            "Epoch 352/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1098\n",
            "Epoch 353/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1098\n",
            "Epoch 354/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1098\n",
            "Epoch 355/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1098\n",
            "Epoch 356/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1097\n",
            "Epoch 357/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1097\n",
            "Epoch 358/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1097\n",
            "Epoch 359/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1097\n",
            "Epoch 360/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.0983roc-auc_val: 0.8629\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0984 - val_loss: 0.1095\n",
            "Epoch 361/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1097\n",
            "Epoch 362/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1096\n",
            "Epoch 363/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1097\n",
            "Epoch 364/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1097\n",
            "Epoch 365/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1098\n",
            "Epoch 366/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1096\n",
            "Epoch 367/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1097\n",
            "Epoch 368/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1098\n",
            "Epoch 369/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1097\n",
            "Epoch 370/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.0985roc-auc_val: 0.8626\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0986 - val_loss: 0.1097\n",
            "Epoch 371/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1097\n",
            "Epoch 372/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1097\n",
            "Epoch 373/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1096\n",
            "Epoch 374/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1097\n",
            "Epoch 375/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1097\n",
            "Epoch 376/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1096\n",
            "Epoch 377/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1096\n",
            "Epoch 378/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1096\n",
            "Epoch 379/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1096\n",
            "Epoch 380/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.0983roc-auc_val: 0.8629\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0983 - val_loss: 0.1096\n",
            "Epoch 381/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1095\n",
            "Epoch 382/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1095\n",
            "Epoch 383/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1096\n",
            "Epoch 384/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1095\n",
            "Epoch 385/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1096\n",
            "Epoch 386/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1095\n",
            "Epoch 387/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1096\n",
            "Epoch 388/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1095\n",
            "Epoch 389/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.1096\n",
            "Epoch 390/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.0978roc-auc_val: 0.863\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0978 - val_loss: 0.1095\n",
            "Epoch 391/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1095\n",
            "Epoch 392/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1095\n",
            "Epoch 393/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1096\n",
            "Epoch 394/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1096\n",
            "Epoch 395/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0977 - val_loss: 0.1095\n",
            "Epoch 396/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1096\n",
            "Epoch 397/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1095\n",
            "Epoch 398/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1096\n",
            "Epoch 399/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1095\n",
            "Epoch 400/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.0976roc-auc_val: 0.8632\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0977 - val_loss: 0.1095\n",
            "Epoch 401/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1095\n",
            "Epoch 402/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1096\n",
            "Epoch 403/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1096\n",
            "Epoch 404/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1095\n",
            "Epoch 405/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1096\n",
            "Epoch 406/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1095\n",
            "Epoch 407/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.1093\n",
            "Epoch 408/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1094\n",
            "Epoch 409/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1096\n",
            "Epoch 410/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.0979roc-auc_val: 0.8634\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0979 - val_loss: 0.1094\n",
            "Epoch 411/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1095\n",
            "Epoch 412/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1094\n",
            "Epoch 413/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1095\n",
            "Epoch 414/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0977 - val_loss: 0.1093\n",
            "Epoch 415/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0977 - val_loss: 0.1095\n",
            "Epoch 416/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1095\n",
            "Epoch 417/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1095\n",
            "Epoch 418/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1094\n",
            "Epoch 419/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1094\n",
            "Epoch 420/1000\n",
            "241/243 [============================>.] - ETA: 0s - loss: 0.0980roc-auc_val: 0.8633\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0980 - val_loss: 0.1095\n",
            "Epoch 421/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1093\n",
            "Epoch 422/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1094\n",
            "Epoch 423/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1095\n",
            "Epoch 424/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1093\n",
            "Epoch 425/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1094\n",
            "Epoch 426/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1094\n",
            "Epoch 427/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.1094\n",
            "Epoch 428/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1093\n",
            "Epoch 429/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1095\n",
            "Epoch 430/1000\n",
            "241/243 [============================>.] - ETA: 0s - loss: 0.0974roc-auc_val: 0.8634\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0973 - val_loss: 0.1094\n",
            "Epoch 431/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1094\n",
            "Epoch 432/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1094\n",
            "Epoch 433/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1094\n",
            "Epoch 434/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1094\n",
            "Epoch 435/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1095\n",
            "Epoch 436/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1093\n",
            "Epoch 437/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1093\n",
            "Epoch 438/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1094\n",
            "Epoch 439/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1094\n",
            "Epoch 440/1000\n",
            "236/243 [============================>.] - ETA: 0s - loss: 0.0973roc-auc_val: 0.8636\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0972 - val_loss: 0.1093\n",
            "Epoch 441/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1094\n",
            "Epoch 442/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1093\n",
            "Epoch 443/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1095\n",
            "Epoch 444/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1093\n",
            "Epoch 445/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1094\n",
            "Epoch 446/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1094\n",
            "Epoch 447/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1094\n",
            "Epoch 448/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1094\n",
            "Epoch 449/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1093\n",
            "Epoch 450/1000\n",
            "236/243 [============================>.] - ETA: 0s - loss: 0.0971roc-auc_val: 0.8635\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0971 - val_loss: 0.1094\n",
            "Epoch 451/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1092\n",
            "Epoch 452/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1093\n",
            "Epoch 453/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1093\n",
            "Epoch 454/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1092\n",
            "Epoch 455/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1093\n",
            "Epoch 456/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1093\n",
            "Epoch 457/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1092\n",
            "Epoch 458/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1092\n",
            "Epoch 459/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1093\n",
            "Epoch 460/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.0972roc-auc_val: 0.8638\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0970 - val_loss: 0.1093\n",
            "Epoch 461/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1092\n",
            "Epoch 462/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1093\n",
            "Epoch 463/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1092\n",
            "Epoch 464/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1092\n",
            "Epoch 465/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1093\n",
            "Epoch 466/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1093\n",
            "Epoch 467/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1093\n",
            "Epoch 468/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1092\n",
            "Epoch 469/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1092\n",
            "Epoch 470/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.0970roc-auc_val: 0.8641\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0969 - val_loss: 0.1092\n",
            "Epoch 471/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1092\n",
            "Epoch 472/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1092\n",
            "Epoch 473/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1093\n",
            "Epoch 474/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1093\n",
            "Epoch 475/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1092\n",
            "Epoch 476/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1093\n",
            "Epoch 477/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1092\n",
            "Epoch 478/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1091\n",
            "Epoch 479/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1091\n",
            "Epoch 480/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.0969roc-auc_val: 0.8641\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0968 - val_loss: 0.1092\n",
            "Epoch 481/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1093\n",
            "Epoch 482/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1091\n",
            "Epoch 483/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1093\n",
            "Epoch 484/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1093\n",
            "Epoch 485/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1092\n",
            "Epoch 486/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1092\n",
            "Epoch 487/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1091\n",
            "Epoch 488/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1092\n",
            "Epoch 489/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1091\n",
            "Epoch 490/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.0964roc-auc_val: 0.8641\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0963 - val_loss: 0.1092\n",
            "Epoch 491/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1092\n",
            "Epoch 492/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1092\n",
            "Epoch 493/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1091\n",
            "Epoch 494/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1091\n",
            "Epoch 495/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1092\n",
            "Epoch 496/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1092\n",
            "Epoch 497/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1090\n",
            "Epoch 498/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1092\n",
            "Epoch 499/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1092\n",
            "Epoch 500/1000\n",
            "235/243 [============================>.] - ETA: 0s - loss: 0.0968roc-auc_val: 0.8641\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0968 - val_loss: 0.1091\n",
            "Epoch 501/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1091\n",
            "Epoch 502/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1091\n",
            "Epoch 503/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1091\n",
            "Epoch 504/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1091\n",
            "Epoch 505/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1090\n",
            "Epoch 506/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1090\n",
            "Epoch 507/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1091\n",
            "Epoch 508/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1091\n",
            "Epoch 509/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1093\n",
            "Epoch 510/1000\n",
            "236/243 [============================>.] - ETA: 0s - loss: 0.0962roc-auc_val: 0.8645\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0962 - val_loss: 0.1090\n",
            "Epoch 511/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1091\n",
            "Epoch 512/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1091\n",
            "Epoch 513/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1091\n",
            "Epoch 514/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1092\n",
            "Epoch 515/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1091\n",
            "Epoch 516/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1092\n",
            "Epoch 517/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1092\n",
            "Epoch 518/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1092\n",
            "Epoch 519/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1090\n",
            "Epoch 520/1000\n",
            "240/243 [============================>.] - ETA: 0s - loss: 0.0965roc-auc_val: 0.8642\n",
            "243/243 [==============================] - 4s 16ms/step - loss: 0.0964 - val_loss: 0.1091\n",
            "Epoch 521/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1091\n",
            "Epoch 522/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1092\n",
            "Epoch 523/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1091\n",
            "Epoch 524/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1089\n",
            "Epoch 525/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1090\n",
            "Epoch 526/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1090\n",
            "Epoch 527/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1090\n",
            "Epoch 528/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1090\n",
            "Epoch 529/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1090\n",
            "Epoch 530/1000\n",
            "238/243 [============================>.] - ETA: 0s - loss: 0.0962roc-auc_val: 0.8647\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0962 - val_loss: 0.1090\n",
            "Epoch 531/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1090\n",
            "Epoch 532/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1091\n",
            "Epoch 533/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1091\n",
            "Epoch 534/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1091\n",
            "Epoch 535/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1090\n",
            "Epoch 536/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1090\n",
            "Epoch 537/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1090\n",
            "Epoch 538/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1091\n",
            "Epoch 539/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1089\n",
            "Epoch 540/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.0958roc-auc_val: 0.8644\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0958 - val_loss: 0.1090\n",
            "Epoch 541/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1090\n",
            "Epoch 542/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1090\n",
            "Epoch 543/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1091\n",
            "Epoch 544/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1090\n",
            "Epoch 545/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1090\n",
            "Epoch 546/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1090\n",
            "Epoch 547/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1091\n",
            "Epoch 548/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1090\n",
            "Epoch 549/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1090\n",
            "Epoch 550/1000\n",
            "235/243 [============================>.] - ETA: 0s - loss: 0.0960roc-auc_val: 0.8643\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0960 - val_loss: 0.1091\n",
            "Epoch 551/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1091\n",
            "Epoch 552/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1090\n",
            "Epoch 553/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1090\n",
            "Epoch 554/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1090\n",
            "Epoch 555/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1090\n",
            "Epoch 556/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1089\n",
            "Epoch 557/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1090\n",
            "Epoch 558/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1090\n",
            "Epoch 559/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1090\n",
            "Epoch 560/1000\n",
            "234/243 [===========================>..] - ETA: 0s - loss: 0.0959roc-auc_val: 0.8645\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0959 - val_loss: 0.1090\n",
            "Epoch 561/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1090\n",
            "Epoch 562/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1089\n",
            "Epoch 563/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1089\n",
            "Epoch 564/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1089\n",
            "Epoch 565/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1089\n",
            "Epoch 566/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1090\n",
            "Epoch 567/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1090\n",
            "Epoch 568/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1090\n",
            "Epoch 569/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1090\n",
            "Epoch 570/1000\n",
            "233/243 [===========================>..] - ETA: 0s - loss: 0.0958roc-auc_val: 0.8647\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0958 - val_loss: 0.1090\n",
            "Epoch 571/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1089\n",
            "Epoch 572/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1091\n",
            "Epoch 573/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1089\n",
            "Epoch 574/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0950 - val_loss: 0.1088\n",
            "Epoch 575/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0953 - val_loss: 0.1090\n",
            "Epoch 576/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.1089\n",
            "Epoch 577/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1090\n",
            "Epoch 578/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.1088\n",
            "Epoch 579/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0953 - val_loss: 0.1090\n",
            "Epoch 580/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.0955roc-auc_val: 0.8649\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0955 - val_loss: 0.1089\n",
            "Epoch 581/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1089\n",
            "Epoch 582/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1089\n",
            "Epoch 583/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1089\n",
            "Epoch 584/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1090\n",
            "Epoch 585/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1087\n",
            "Epoch 586/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1088\n",
            "Epoch 587/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1090\n",
            "Epoch 588/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1090\n",
            "Epoch 589/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1090\n",
            "Epoch 590/1000\n",
            "237/243 [============================>.] - ETA: 0s - loss: 0.0956roc-auc_val: 0.8647\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0956 - val_loss: 0.1089\n",
            "Epoch 591/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1089\n",
            "Epoch 592/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1090\n",
            "Epoch 593/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1090\n",
            "Epoch 594/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1089\n",
            "Epoch 595/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1089\n",
            "Epoch 596/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1089\n",
            "Epoch 597/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1089\n",
            "Epoch 598/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1089\n",
            "Epoch 599/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0951 - val_loss: 0.1090\n",
            "Epoch 600/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.0955roc-auc_val: 0.8653\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0955 - val_loss: 0.1088\n",
            "Epoch 601/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0951 - val_loss: 0.1089\n",
            "Epoch 602/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1090\n",
            "Epoch 603/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.1089\n",
            "Epoch 604/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0953 - val_loss: 0.1089\n",
            "Epoch 605/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1090\n",
            "Epoch 606/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1089\n",
            "Epoch 607/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0953 - val_loss: 0.1088\n",
            "Epoch 608/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0949 - val_loss: 0.1088\n",
            "Epoch 609/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1089\n",
            "Epoch 610/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.0954roc-auc_val: 0.8652\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0954 - val_loss: 0.1088\n",
            "Epoch 611/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1089\n",
            "Epoch 612/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0951 - val_loss: 0.1089\n",
            "Epoch 613/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.1089\n",
            "Epoch 614/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1089\n",
            "Epoch 615/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0951 - val_loss: 0.1089\n",
            "Epoch 616/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1089\n",
            "Epoch 617/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0950 - val_loss: 0.1089\n",
            "Epoch 618/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0950 - val_loss: 0.1089\n",
            "Epoch 619/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.1088\n",
            "Epoch 620/1000\n",
            "239/243 [============================>.] - ETA: 0s - loss: 0.0957roc-auc_val: 0.8651\n",
            "243/243 [==============================] - 4s 15ms/step - loss: 0.0956 - val_loss: 0.1089\n",
            "Epoch 621/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0950 - val_loss: 0.1089\n",
            "Epoch 622/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1087\n",
            "Epoch 623/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0953 - val_loss: 0.1088\n",
            "Epoch 624/1000\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1090\n",
            "Epoch 1/1000\n",
            "201/201 [==============================] - 2s 9ms/step - loss: 0.7085 - val_loss: 0.4478\n",
            "Epoch 2/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.5420 - val_loss: 0.3681\n",
            "Epoch 3/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.4289 - val_loss: 0.2930\n",
            "Epoch 4/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.3438 - val_loss: 0.2408\n",
            "Epoch 5/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.2832 - val_loss: 0.2028\n",
            "Epoch 6/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.2423 - val_loss: 0.1795\n",
            "Epoch 7/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.2138 - val_loss: 0.1629\n",
            "Epoch 8/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1941 - val_loss: 0.1525\n",
            "Epoch 9/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1797 - val_loss: 0.1452\n",
            "Epoch 10/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1694roc-auc_val: 0.7897\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1690 - val_loss: 0.1400\n",
            "Epoch 11/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1616 - val_loss: 0.1371\n",
            "Epoch 12/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1551 - val_loss: 0.1341\n",
            "Epoch 13/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1512 - val_loss: 0.1318\n",
            "Epoch 14/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1468 - val_loss: 0.1299\n",
            "Epoch 15/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1433 - val_loss: 0.1286\n",
            "Epoch 16/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1404 - val_loss: 0.1279\n",
            "Epoch 17/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1395 - val_loss: 0.1267\n",
            "Epoch 18/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1371 - val_loss: 0.1256\n",
            "Epoch 19/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1347 - val_loss: 0.1255\n",
            "Epoch 20/1000\n",
            "200/201 [============================>.] - ETA: 0s - loss: 0.1325roc-auc_val: 0.8158\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1326 - val_loss: 0.1249\n",
            "Epoch 21/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1325 - val_loss: 0.1251\n",
            "Epoch 22/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1307 - val_loss: 0.1246\n",
            "Epoch 23/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1301 - val_loss: 0.1241\n",
            "Epoch 24/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1291 - val_loss: 0.1238\n",
            "Epoch 25/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1273 - val_loss: 0.1235\n",
            "Epoch 26/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1270 - val_loss: 0.1236\n",
            "Epoch 27/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1258 - val_loss: 0.1233\n",
            "Epoch 28/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1263 - val_loss: 0.1234\n",
            "Epoch 29/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1255 - val_loss: 0.1228\n",
            "Epoch 30/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1238roc-auc_val: 0.8239\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1238 - val_loss: 0.1227\n",
            "Epoch 31/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1236 - val_loss: 0.1225\n",
            "Epoch 32/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1233 - val_loss: 0.1223\n",
            "Epoch 33/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1237 - val_loss: 0.1224\n",
            "Epoch 34/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1211 - val_loss: 0.1224\n",
            "Epoch 35/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1215 - val_loss: 0.1223\n",
            "Epoch 36/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1215 - val_loss: 0.1222\n",
            "Epoch 37/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1206 - val_loss: 0.1220\n",
            "Epoch 38/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1203 - val_loss: 0.1218\n",
            "Epoch 39/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1203 - val_loss: 0.1216\n",
            "Epoch 40/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1203roc-auc_val: 0.8287\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1203 - val_loss: 0.1217\n",
            "Epoch 41/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1192 - val_loss: 0.1218\n",
            "Epoch 42/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1189 - val_loss: 0.1212\n",
            "Epoch 43/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1198 - val_loss: 0.1213\n",
            "Epoch 44/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1187 - val_loss: 0.1213\n",
            "Epoch 45/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1184 - val_loss: 0.1210\n",
            "Epoch 46/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1187 - val_loss: 0.1210\n",
            "Epoch 47/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1189 - val_loss: 0.1207\n",
            "Epoch 48/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1184 - val_loss: 0.1205\n",
            "Epoch 49/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1180 - val_loss: 0.1206\n",
            "Epoch 50/1000\n",
            "198/201 [============================>.] - ETA: 0s - loss: 0.1174roc-auc_val: 0.8322\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1171 - val_loss: 0.1204\n",
            "Epoch 51/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1179 - val_loss: 0.1205\n",
            "Epoch 52/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1167 - val_loss: 0.1203\n",
            "Epoch 53/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1170 - val_loss: 0.1205\n",
            "Epoch 54/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1163 - val_loss: 0.1201\n",
            "Epoch 55/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1161 - val_loss: 0.1200\n",
            "Epoch 56/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1161 - val_loss: 0.1201\n",
            "Epoch 57/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1163 - val_loss: 0.1199\n",
            "Epoch 58/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1155 - val_loss: 0.1198\n",
            "Epoch 59/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1160 - val_loss: 0.1198\n",
            "Epoch 60/1000\n",
            "200/201 [============================>.] - ETA: 0s - loss: 0.1143roc-auc_val: 0.8346\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1143 - val_loss: 0.1196\n",
            "Epoch 61/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1151 - val_loss: 0.1196\n",
            "Epoch 62/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1151 - val_loss: 0.1195\n",
            "Epoch 63/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1148 - val_loss: 0.1194\n",
            "Epoch 64/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1146 - val_loss: 0.1195\n",
            "Epoch 65/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1139 - val_loss: 0.1194\n",
            "Epoch 66/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1151 - val_loss: 0.1195\n",
            "Epoch 67/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1138 - val_loss: 0.1193\n",
            "Epoch 68/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1135 - val_loss: 0.1192\n",
            "Epoch 69/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1136 - val_loss: 0.1192\n",
            "Epoch 70/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.1145roc-auc_val: 0.8367\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1147 - val_loss: 0.1192\n",
            "Epoch 71/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1133 - val_loss: 0.1191\n",
            "Epoch 72/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1135 - val_loss: 0.1190\n",
            "Epoch 73/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1128 - val_loss: 0.1190\n",
            "Epoch 74/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1122 - val_loss: 0.1190\n",
            "Epoch 75/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1126 - val_loss: 0.1189\n",
            "Epoch 76/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1120 - val_loss: 0.1187\n",
            "Epoch 77/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1131 - val_loss: 0.1189\n",
            "Epoch 78/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1125 - val_loss: 0.1187\n",
            "Epoch 79/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1127 - val_loss: 0.1189\n",
            "Epoch 80/1000\n",
            "194/201 [===========================>..] - ETA: 0s - loss: 0.1126roc-auc_val: 0.8381\n",
            "201/201 [==============================] - 6s 28ms/step - loss: 0.1126 - val_loss: 0.1187\n",
            "Epoch 81/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1117 - val_loss: 0.1187\n",
            "Epoch 82/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1122 - val_loss: 0.1186\n",
            "Epoch 83/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1118 - val_loss: 0.1185\n",
            "Epoch 84/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1125 - val_loss: 0.1188\n",
            "Epoch 85/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1123 - val_loss: 0.1185\n",
            "Epoch 86/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1111 - val_loss: 0.1185\n",
            "Epoch 87/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1104 - val_loss: 0.1185\n",
            "Epoch 88/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1110 - val_loss: 0.1184\n",
            "Epoch 89/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1105 - val_loss: 0.1184\n",
            "Epoch 90/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.1118roc-auc_val: 0.839\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1119 - val_loss: 0.1185\n",
            "Epoch 91/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1104 - val_loss: 0.1184\n",
            "Epoch 92/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1101 - val_loss: 0.1184\n",
            "Epoch 93/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1098 - val_loss: 0.1183\n",
            "Epoch 94/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1106 - val_loss: 0.1183\n",
            "Epoch 95/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1106 - val_loss: 0.1184\n",
            "Epoch 96/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1100 - val_loss: 0.1184\n",
            "Epoch 97/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1097 - val_loss: 0.1183\n",
            "Epoch 98/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1098 - val_loss: 0.1181\n",
            "Epoch 99/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1100 - val_loss: 0.1181\n",
            "Epoch 100/1000\n",
            "199/201 [============================>.] - ETA: 0s - loss: 0.1098roc-auc_val: 0.84\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1098 - val_loss: 0.1182\n",
            "Epoch 101/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1093 - val_loss: 0.1179\n",
            "Epoch 102/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1086 - val_loss: 0.1180\n",
            "Epoch 103/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1097 - val_loss: 0.1181\n",
            "Epoch 104/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1093 - val_loss: 0.1181\n",
            "Epoch 105/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1097 - val_loss: 0.1180\n",
            "Epoch 106/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1093 - val_loss: 0.1181\n",
            "Epoch 107/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1093 - val_loss: 0.1180\n",
            "Epoch 108/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1092 - val_loss: 0.1179\n",
            "Epoch 109/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1086 - val_loss: 0.1180\n",
            "Epoch 110/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1090roc-auc_val: 0.8412\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1090 - val_loss: 0.1179\n",
            "Epoch 111/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1179\n",
            "Epoch 112/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1089 - val_loss: 0.1178\n",
            "Epoch 113/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1178\n",
            "Epoch 114/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1088 - val_loss: 0.1177\n",
            "Epoch 115/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1178\n",
            "Epoch 116/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1089 - val_loss: 0.1177\n",
            "Epoch 117/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1084 - val_loss: 0.1178\n",
            "Epoch 118/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1094 - val_loss: 0.1177\n",
            "Epoch 119/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1080 - val_loss: 0.1176\n",
            "Epoch 120/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1080roc-auc_val: 0.8419\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1080 - val_loss: 0.1176\n",
            "Epoch 121/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1177\n",
            "Epoch 122/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1075 - val_loss: 0.1177\n",
            "Epoch 123/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1084 - val_loss: 0.1176\n",
            "Epoch 124/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1080 - val_loss: 0.1175\n",
            "Epoch 125/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1076 - val_loss: 0.1175\n",
            "Epoch 126/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1080 - val_loss: 0.1175\n",
            "Epoch 127/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1072 - val_loss: 0.1176\n",
            "Epoch 128/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1077 - val_loss: 0.1176\n",
            "Epoch 129/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1176\n",
            "Epoch 130/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.1075roc-auc_val: 0.8423\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1076 - val_loss: 0.1175\n",
            "Epoch 131/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1070 - val_loss: 0.1175\n",
            "Epoch 132/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1078 - val_loss: 0.1175\n",
            "Epoch 133/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1068 - val_loss: 0.1175\n",
            "Epoch 134/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1080 - val_loss: 0.1174\n",
            "Epoch 135/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1174\n",
            "Epoch 136/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1072 - val_loss: 0.1174\n",
            "Epoch 137/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1066 - val_loss: 0.1174\n",
            "Epoch 138/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1078 - val_loss: 0.1175\n",
            "Epoch 139/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1069 - val_loss: 0.1174\n",
            "Epoch 140/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1069roc-auc_val: 0.8431\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1070 - val_loss: 0.1173\n",
            "Epoch 141/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1063 - val_loss: 0.1173\n",
            "Epoch 142/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1071 - val_loss: 0.1172\n",
            "Epoch 143/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1069 - val_loss: 0.1172\n",
            "Epoch 144/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1063 - val_loss: 0.1173\n",
            "Epoch 145/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1068 - val_loss: 0.1172\n",
            "Epoch 146/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.1173\n",
            "Epoch 147/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1067 - val_loss: 0.1172\n",
            "Epoch 148/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1067 - val_loss: 0.1172\n",
            "Epoch 149/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1065 - val_loss: 0.1171\n",
            "Epoch 150/1000\n",
            "200/201 [============================>.] - ETA: 0s - loss: 0.1065roc-auc_val: 0.8434\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1066 - val_loss: 0.1171\n",
            "Epoch 151/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1070 - val_loss: 0.1171\n",
            "Epoch 152/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.1172\n",
            "Epoch 153/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1059 - val_loss: 0.1171\n",
            "Epoch 154/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1060 - val_loss: 0.1172\n",
            "Epoch 155/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1068 - val_loss: 0.1171\n",
            "Epoch 156/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1058 - val_loss: 0.1171\n",
            "Epoch 157/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.1171\n",
            "Epoch 158/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1060 - val_loss: 0.1172\n",
            "Epoch 159/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1054 - val_loss: 0.1172\n",
            "Epoch 160/1000\n",
            "200/201 [============================>.] - ETA: 0s - loss: 0.1055roc-auc_val: 0.8437\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1055 - val_loss: 0.1171\n",
            "Epoch 161/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1054 - val_loss: 0.1171\n",
            "Epoch 162/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1062 - val_loss: 0.1172\n",
            "Epoch 163/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1043 - val_loss: 0.1171\n",
            "Epoch 164/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1052 - val_loss: 0.1171\n",
            "Epoch 165/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1050 - val_loss: 0.1171\n",
            "Epoch 166/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1051 - val_loss: 0.1171\n",
            "Epoch 167/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1049 - val_loss: 0.1171\n",
            "Epoch 168/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1050 - val_loss: 0.1171\n",
            "Epoch 169/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1045 - val_loss: 0.1171\n",
            "Epoch 170/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.1050roc-auc_val: 0.8445\n",
            "201/201 [==============================] - 6s 28ms/step - loss: 0.1049 - val_loss: 0.1171\n",
            "Epoch 171/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1049 - val_loss: 0.1171\n",
            "Epoch 172/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1171\n",
            "Epoch 173/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1058 - val_loss: 0.1171\n",
            "Epoch 174/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1039 - val_loss: 0.1170\n",
            "Epoch 175/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1041 - val_loss: 0.1172\n",
            "Epoch 176/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1046 - val_loss: 0.1170\n",
            "Epoch 177/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1046 - val_loss: 0.1170\n",
            "Epoch 178/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1047 - val_loss: 0.1171\n",
            "Epoch 179/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1051 - val_loss: 0.1170\n",
            "Epoch 180/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1044roc-auc_val: 0.8444\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1044 - val_loss: 0.1170\n",
            "Epoch 181/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1041 - val_loss: 0.1170\n",
            "Epoch 182/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1169\n",
            "Epoch 183/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1169\n",
            "Epoch 184/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1170\n",
            "Epoch 185/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1170\n",
            "Epoch 186/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1040 - val_loss: 0.1170\n",
            "Epoch 187/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1041 - val_loss: 0.1170\n",
            "Epoch 188/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1170\n",
            "Epoch 189/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1045 - val_loss: 0.1169\n",
            "Epoch 190/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.1040roc-auc_val: 0.8449\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1041 - val_loss: 0.1169\n",
            "Epoch 191/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1043 - val_loss: 0.1171\n",
            "Epoch 192/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1047 - val_loss: 0.1169\n",
            "Epoch 193/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1037 - val_loss: 0.1170\n",
            "Epoch 194/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.1169\n",
            "Epoch 195/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1041 - val_loss: 0.1168\n",
            "Epoch 196/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1033 - val_loss: 0.1169\n",
            "Epoch 197/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1041 - val_loss: 0.1168\n",
            "Epoch 198/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1036 - val_loss: 0.1168\n",
            "Epoch 199/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1035 - val_loss: 0.1168\n",
            "Epoch 200/1000\n",
            "198/201 [============================>.] - ETA: 0s - loss: 0.1033roc-auc_val: 0.8454\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1034 - val_loss: 0.1168\n",
            "Epoch 201/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1037 - val_loss: 0.1168\n",
            "Epoch 202/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1033 - val_loss: 0.1169\n",
            "Epoch 203/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1033 - val_loss: 0.1168\n",
            "Epoch 204/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1036 - val_loss: 0.1168\n",
            "Epoch 205/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1169\n",
            "Epoch 206/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1028 - val_loss: 0.1169\n",
            "Epoch 207/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1034 - val_loss: 0.1167\n",
            "Epoch 208/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1167\n",
            "Epoch 209/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1037 - val_loss: 0.1167\n",
            "Epoch 210/1000\n",
            "199/201 [============================>.] - ETA: 0s - loss: 0.1040roc-auc_val: 0.8458\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1039 - val_loss: 0.1167\n",
            "Epoch 211/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.1167\n",
            "Epoch 212/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1167\n",
            "Epoch 213/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1026 - val_loss: 0.1167\n",
            "Epoch 214/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.1167\n",
            "Epoch 215/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1166\n",
            "Epoch 216/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1036 - val_loss: 0.1166\n",
            "Epoch 217/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1030 - val_loss: 0.1166\n",
            "Epoch 218/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1028 - val_loss: 0.1167\n",
            "Epoch 219/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1030 - val_loss: 0.1166\n",
            "Epoch 220/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1028roc-auc_val: 0.8458\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1028 - val_loss: 0.1167\n",
            "Epoch 221/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1167\n",
            "Epoch 222/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.1167\n",
            "Epoch 223/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1166\n",
            "Epoch 224/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.1166\n",
            "Epoch 225/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.1166\n",
            "Epoch 226/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1166\n",
            "Epoch 227/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1167\n",
            "Epoch 228/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1019 - val_loss: 0.1167\n",
            "Epoch 229/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1166\n",
            "Epoch 230/1000\n",
            "199/201 [============================>.] - ETA: 0s - loss: 0.1025roc-auc_val: 0.8462\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1024 - val_loss: 0.1166\n",
            "Epoch 231/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1167\n",
            "Epoch 232/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1024 - val_loss: 0.1166\n",
            "Epoch 233/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1167\n",
            "Epoch 234/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1015 - val_loss: 0.1165\n",
            "Epoch 235/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1017 - val_loss: 0.1167\n",
            "Epoch 236/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1166\n",
            "Epoch 237/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1166\n",
            "Epoch 238/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1165\n",
            "Epoch 239/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1167\n",
            "Epoch 240/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1024roc-auc_val: 0.8464\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1024 - val_loss: 0.1166\n",
            "Epoch 241/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1166\n",
            "Epoch 242/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1165\n",
            "Epoch 243/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1166\n",
            "Epoch 244/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1017 - val_loss: 0.1165\n",
            "Epoch 245/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1165\n",
            "Epoch 246/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1165\n",
            "Epoch 247/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1015 - val_loss: 0.1166\n",
            "Epoch 248/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1166\n",
            "Epoch 249/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1019 - val_loss: 0.1164\n",
            "Epoch 250/1000\n",
            "200/201 [============================>.] - ETA: 0s - loss: 0.1017roc-auc_val: 0.8467\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1017 - val_loss: 0.1165\n",
            "Epoch 251/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1165\n",
            "Epoch 252/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1016 - val_loss: 0.1165\n",
            "Epoch 253/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1019 - val_loss: 0.1165\n",
            "Epoch 254/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1165\n",
            "Epoch 255/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1017 - val_loss: 0.1165\n",
            "Epoch 256/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.1164\n",
            "Epoch 257/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1013 - val_loss: 0.1165\n",
            "Epoch 258/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1165\n",
            "Epoch 259/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1164\n",
            "Epoch 260/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.1018roc-auc_val: 0.8471\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1019 - val_loss: 0.1165\n",
            "Epoch 261/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1164\n",
            "Epoch 262/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1009 - val_loss: 0.1165\n",
            "Epoch 263/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1164\n",
            "Epoch 264/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1019 - val_loss: 0.1165\n",
            "Epoch 265/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1009 - val_loss: 0.1165\n",
            "Epoch 266/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1017 - val_loss: 0.1165\n",
            "Epoch 267/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1165\n",
            "Epoch 268/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1164\n",
            "Epoch 269/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1011 - val_loss: 0.1165\n",
            "Epoch 270/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1010roc-auc_val: 0.8473\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1010 - val_loss: 0.1165\n",
            "Epoch 271/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1164\n",
            "Epoch 272/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 0.1164\n",
            "Epoch 273/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.1164\n",
            "Epoch 274/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1009 - val_loss: 0.1164\n",
            "Epoch 275/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1016 - val_loss: 0.1164\n",
            "Epoch 276/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1164\n",
            "Epoch 277/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1009 - val_loss: 0.1163\n",
            "Epoch 278/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1009 - val_loss: 0.1163\n",
            "Epoch 279/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 0.1163\n",
            "Epoch 280/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1007roc-auc_val: 0.8476\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1007 - val_loss: 0.1163\n",
            "Epoch 281/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1164\n",
            "Epoch 282/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1164\n",
            "Epoch 283/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1163\n",
            "Epoch 284/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1006 - val_loss: 0.1163\n",
            "Epoch 285/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1001 - val_loss: 0.1163\n",
            "Epoch 286/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 0.1163\n",
            "Epoch 287/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1001 - val_loss: 0.1163\n",
            "Epoch 288/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1163\n",
            "Epoch 289/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1163\n",
            "Epoch 290/1000\n",
            "200/201 [============================>.] - ETA: 0s - loss: 0.1003roc-auc_val: 0.8477\n",
            "201/201 [==============================] - 6s 30ms/step - loss: 0.1003 - val_loss: 0.1163\n",
            "Epoch 291/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1003 - val_loss: 0.1162\n",
            "Epoch 292/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1003 - val_loss: 0.1163\n",
            "Epoch 293/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1005 - val_loss: 0.1163\n",
            "Epoch 294/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1001 - val_loss: 0.1163\n",
            "Epoch 295/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1000 - val_loss: 0.1162\n",
            "Epoch 296/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1002 - val_loss: 0.1163\n",
            "Epoch 297/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.1002 - val_loss: 0.1163\n",
            "Epoch 298/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.0998 - val_loss: 0.1163\n",
            "Epoch 299/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1163\n",
            "Epoch 300/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1006roc-auc_val: 0.8479\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.1006 - val_loss: 0.1163\n",
            "Epoch 301/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1161\n",
            "Epoch 302/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.1162\n",
            "Epoch 303/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1162\n",
            "Epoch 304/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.1163\n",
            "Epoch 305/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1163\n",
            "Epoch 306/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0999 - val_loss: 0.1162\n",
            "Epoch 307/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1162\n",
            "Epoch 308/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.1163\n",
            "Epoch 309/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1163\n",
            "Epoch 310/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.0993roc-auc_val: 0.8484\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.0997 - val_loss: 0.1163\n",
            "Epoch 311/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1162\n",
            "Epoch 312/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.1162\n",
            "Epoch 313/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1162\n",
            "Epoch 314/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1162\n",
            "Epoch 315/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1162\n",
            "Epoch 316/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.1162\n",
            "Epoch 317/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1162\n",
            "Epoch 318/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1162\n",
            "Epoch 319/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1162\n",
            "Epoch 320/1000\n",
            "200/201 [============================>.] - ETA: 0s - loss: 0.0999roc-auc_val: 0.8484\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.0998 - val_loss: 0.1162\n",
            "Epoch 321/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1163\n",
            "Epoch 322/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1162\n",
            "Epoch 323/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1162\n",
            "Epoch 324/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1162\n",
            "Epoch 325/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1161\n",
            "Epoch 326/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1162\n",
            "Epoch 327/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1162\n",
            "Epoch 328/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1162\n",
            "Epoch 329/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0995 - val_loss: 0.1162\n",
            "Epoch 330/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.0990roc-auc_val: 0.8487\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.0991 - val_loss: 0.1161\n",
            "Epoch 331/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1160\n",
            "Epoch 332/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1161\n",
            "Epoch 333/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1161\n",
            "Epoch 334/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.1161\n",
            "Epoch 335/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1161\n",
            "Epoch 336/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1161\n",
            "Epoch 337/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1160\n",
            "Epoch 338/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1161\n",
            "Epoch 339/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1161\n",
            "Epoch 340/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.0994roc-auc_val: 0.8485\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.0994 - val_loss: 0.1162\n",
            "Epoch 341/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1161\n",
            "Epoch 342/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1161\n",
            "Epoch 343/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1161\n",
            "Epoch 344/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1161\n",
            "Epoch 345/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1161\n",
            "Epoch 346/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1161\n",
            "Epoch 347/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1162\n",
            "Epoch 348/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1162\n",
            "Epoch 349/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.1161\n",
            "Epoch 350/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.0988roc-auc_val: 0.8488\n",
            "201/201 [==============================] - 6s 28ms/step - loss: 0.0989 - val_loss: 0.1161\n",
            "Epoch 351/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1160\n",
            "Epoch 352/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1160\n",
            "Epoch 353/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1160\n",
            "Epoch 354/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1161\n",
            "Epoch 355/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1160\n",
            "Epoch 356/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1161\n",
            "Epoch 357/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1161\n",
            "Epoch 358/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1160\n",
            "Epoch 359/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1160\n",
            "Epoch 360/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.0990roc-auc_val: 0.8492\n",
            "201/201 [==============================] - 6s 28ms/step - loss: 0.0988 - val_loss: 0.1160\n",
            "Epoch 361/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1160\n",
            "Epoch 362/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1160\n",
            "Epoch 363/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1160\n",
            "Epoch 364/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0991 - val_loss: 0.1160\n",
            "Epoch 365/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1160\n",
            "Epoch 366/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1159\n",
            "Epoch 367/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1160\n",
            "Epoch 368/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1159\n",
            "Epoch 369/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1160\n",
            "Epoch 370/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.0980roc-auc_val: 0.8493\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.0981 - val_loss: 0.1159\n",
            "Epoch 371/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1160\n",
            "Epoch 372/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1160\n",
            "Epoch 373/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1160\n",
            "Epoch 374/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1160\n",
            "Epoch 375/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1160\n",
            "Epoch 376/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1160\n",
            "Epoch 377/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1160\n",
            "Epoch 378/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1160\n",
            "Epoch 379/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1160\n",
            "Epoch 380/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.0985roc-auc_val: 0.8493\n",
            "201/201 [==============================] - 6s 28ms/step - loss: 0.0984 - val_loss: 0.1159\n",
            "Epoch 381/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1160\n",
            "Epoch 382/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1160\n",
            "Epoch 383/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1159\n",
            "Epoch 384/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1159\n",
            "Epoch 385/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1159\n",
            "Epoch 386/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1160\n",
            "Epoch 387/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0977 - val_loss: 0.1159\n",
            "Epoch 388/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.1160\n",
            "Epoch 389/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1159\n",
            "Epoch 390/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.0970roc-auc_val: 0.8494\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.0972 - val_loss: 0.1160\n",
            "Epoch 391/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.0975 - val_loss: 0.1159\n",
            "Epoch 392/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.0978 - val_loss: 0.1159\n",
            "Epoch 393/1000\n",
            "201/201 [==============================] - 1s 6ms/step - loss: 0.0979 - val_loss: 0.1160\n",
            "Epoch 394/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1160\n",
            "Epoch 395/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1159\n",
            "Epoch 396/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1159\n",
            "Epoch 397/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1159\n",
            "Epoch 398/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1159\n",
            "Epoch 399/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1158\n",
            "Epoch 400/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.0975roc-auc_val: 0.8498\n",
            "201/201 [==============================] - 6s 29ms/step - loss: 0.0975 - val_loss: 0.1159\n",
            "Epoch 401/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1159\n",
            "Epoch 402/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1159\n",
            "Epoch 403/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1159\n",
            "Epoch 404/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1159\n",
            "Epoch 405/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1159\n",
            "Epoch 406/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.1159\n",
            "Epoch 407/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0977 - val_loss: 0.1159\n",
            "Epoch 408/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1159\n",
            "Epoch 409/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1159\n",
            "Epoch 410/1000\n",
            "194/201 [===========================>..] - ETA: 0s - loss: 0.0973roc-auc_val: 0.8496\n",
            "201/201 [==============================] - 6s 28ms/step - loss: 0.0974 - val_loss: 0.1160\n",
            "Epoch 411/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1159\n",
            "Epoch 412/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1159\n",
            "Epoch 413/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1158\n",
            "Epoch 414/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1158\n",
            "Epoch 415/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1159\n",
            "Epoch 416/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1158\n",
            "Epoch 417/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1158\n",
            "Epoch 418/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1159\n",
            "Epoch 1/1000\n",
            "201/201 [==============================] - 1s 7ms/step - loss: 0.7025 - val_loss: 0.5874\n",
            "Epoch 2/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.5462 - val_loss: 0.4945\n",
            "Epoch 3/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.4342 - val_loss: 0.4060\n",
            "Epoch 4/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.3460 - val_loss: 0.3081\n",
            "Epoch 5/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.2835 - val_loss: 0.2463\n",
            "Epoch 6/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.2414 - val_loss: 0.2104\n",
            "Epoch 7/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.2132 - val_loss: 0.1874\n",
            "Epoch 8/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1925 - val_loss: 0.1721\n",
            "Epoch 9/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1782 - val_loss: 0.1626\n",
            "Epoch 10/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.1667roc-auc_val: 0.7904\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1665 - val_loss: 0.1561\n",
            "Epoch 11/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1603 - val_loss: 0.1498\n",
            "Epoch 12/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1528 - val_loss: 0.1443\n",
            "Epoch 13/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1485 - val_loss: 0.1415\n",
            "Epoch 14/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1451 - val_loss: 0.1392\n",
            "Epoch 15/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1418 - val_loss: 0.1376\n",
            "Epoch 16/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1393 - val_loss: 0.1366\n",
            "Epoch 17/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1372 - val_loss: 0.1336\n",
            "Epoch 18/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1356 - val_loss: 0.1341\n",
            "Epoch 19/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1333 - val_loss: 0.1326\n",
            "Epoch 20/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.1317roc-auc_val: 0.811\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1315 - val_loss: 0.1326\n",
            "Epoch 21/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1307 - val_loss: 0.1312\n",
            "Epoch 22/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1288 - val_loss: 0.1307\n",
            "Epoch 23/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1276 - val_loss: 0.1297\n",
            "Epoch 24/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1273 - val_loss: 0.1283\n",
            "Epoch 25/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1259 - val_loss: 0.1285\n",
            "Epoch 26/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1249 - val_loss: 0.1277\n",
            "Epoch 27/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1239 - val_loss: 0.1279\n",
            "Epoch 28/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1241 - val_loss: 0.1272\n",
            "Epoch 29/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1229 - val_loss: 0.1266\n",
            "Epoch 30/1000\n",
            "195/201 [============================>.] - ETA: 0s - loss: 0.1225roc-auc_val: 0.8191\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1225 - val_loss: 0.1264\n",
            "Epoch 31/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1222 - val_loss: 0.1266\n",
            "Epoch 32/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1217 - val_loss: 0.1256\n",
            "Epoch 33/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1211 - val_loss: 0.1258\n",
            "Epoch 34/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1210 - val_loss: 0.1254\n",
            "Epoch 35/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1211 - val_loss: 0.1254\n",
            "Epoch 36/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1202 - val_loss: 0.1246\n",
            "Epoch 37/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1199 - val_loss: 0.1245\n",
            "Epoch 38/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1188 - val_loss: 0.1237\n",
            "Epoch 39/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1189 - val_loss: 0.1237\n",
            "Epoch 40/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.1191roc-auc_val: 0.825\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1189 - val_loss: 0.1235\n",
            "Epoch 41/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1185 - val_loss: 0.1232\n",
            "Epoch 42/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1176 - val_loss: 0.1237\n",
            "Epoch 43/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1178 - val_loss: 0.1228\n",
            "Epoch 44/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1179 - val_loss: 0.1230\n",
            "Epoch 45/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1169 - val_loss: 0.1231\n",
            "Epoch 46/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1174 - val_loss: 0.1227\n",
            "Epoch 47/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1161 - val_loss: 0.1226\n",
            "Epoch 48/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1164 - val_loss: 0.1223\n",
            "Epoch 49/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1158 - val_loss: 0.1225\n",
            "Epoch 50/1000\n",
            "194/201 [===========================>..] - ETA: 0s - loss: 0.1151roc-auc_val: 0.829\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1148 - val_loss: 0.1216\n",
            "Epoch 51/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1149 - val_loss: 0.1216\n",
            "Epoch 52/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1151 - val_loss: 0.1219\n",
            "Epoch 53/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1157 - val_loss: 0.1214\n",
            "Epoch 54/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1155 - val_loss: 0.1215\n",
            "Epoch 55/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1145 - val_loss: 0.1214\n",
            "Epoch 56/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1144 - val_loss: 0.1206\n",
            "Epoch 57/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1138 - val_loss: 0.1209\n",
            "Epoch 58/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1139 - val_loss: 0.1208\n",
            "Epoch 59/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1154 - val_loss: 0.1207\n",
            "Epoch 60/1000\n",
            "194/201 [===========================>..] - ETA: 0s - loss: 0.1134roc-auc_val: 0.8313\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1133 - val_loss: 0.1209\n",
            "Epoch 61/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1134 - val_loss: 0.1210\n",
            "Epoch 62/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1139 - val_loss: 0.1208\n",
            "Epoch 63/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1129 - val_loss: 0.1209\n",
            "Epoch 64/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1129 - val_loss: 0.1208\n",
            "Epoch 65/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1130 - val_loss: 0.1205\n",
            "Epoch 66/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1128 - val_loss: 0.1204\n",
            "Epoch 67/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1122 - val_loss: 0.1199\n",
            "Epoch 68/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1127 - val_loss: 0.1204\n",
            "Epoch 69/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1124 - val_loss: 0.1198\n",
            "Epoch 70/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1129roc-auc_val: 0.8328\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1130 - val_loss: 0.1200\n",
            "Epoch 71/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1129 - val_loss: 0.1203\n",
            "Epoch 72/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1115 - val_loss: 0.1200\n",
            "Epoch 73/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1123 - val_loss: 0.1194\n",
            "Epoch 74/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1110 - val_loss: 0.1195\n",
            "Epoch 75/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1116 - val_loss: 0.1195\n",
            "Epoch 76/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1122 - val_loss: 0.1197\n",
            "Epoch 77/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1115 - val_loss: 0.1194\n",
            "Epoch 78/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1117 - val_loss: 0.1195\n",
            "Epoch 79/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1112 - val_loss: 0.1193\n",
            "Epoch 80/1000\n",
            "199/201 [============================>.] - ETA: 0s - loss: 0.1108roc-auc_val: 0.8343\n",
            "201/201 [==============================] - 4s 18ms/step - loss: 0.1109 - val_loss: 0.1191\n",
            "Epoch 81/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1099 - val_loss: 0.1191\n",
            "Epoch 82/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1106 - val_loss: 0.1193\n",
            "Epoch 83/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1111 - val_loss: 0.1196\n",
            "Epoch 84/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1099 - val_loss: 0.1195\n",
            "Epoch 85/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1102 - val_loss: 0.1194\n",
            "Epoch 86/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1102 - val_loss: 0.1193\n",
            "Epoch 87/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1114 - val_loss: 0.1189\n",
            "Epoch 88/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1100 - val_loss: 0.1191\n",
            "Epoch 89/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1103 - val_loss: 0.1190\n",
            "Epoch 90/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1099roc-auc_val: 0.8353\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1102 - val_loss: 0.1187\n",
            "Epoch 91/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1099 - val_loss: 0.1187\n",
            "Epoch 92/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1190\n",
            "Epoch 93/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1091 - val_loss: 0.1188\n",
            "Epoch 94/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1087 - val_loss: 0.1189\n",
            "Epoch 95/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1095 - val_loss: 0.1187\n",
            "Epoch 96/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1088 - val_loss: 0.1190\n",
            "Epoch 97/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1090 - val_loss: 0.1189\n",
            "Epoch 98/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1093 - val_loss: 0.1187\n",
            "Epoch 99/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1089 - val_loss: 0.1185\n",
            "Epoch 100/1000\n",
            "200/201 [============================>.] - ETA: 0s - loss: 0.1095roc-auc_val: 0.8372\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1095 - val_loss: 0.1183\n",
            "Epoch 101/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.1184\n",
            "Epoch 102/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1082 - val_loss: 0.1183\n",
            "Epoch 103/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1080 - val_loss: 0.1183\n",
            "Epoch 104/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1084 - val_loss: 0.1186\n",
            "Epoch 105/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1075 - val_loss: 0.1183\n",
            "Epoch 106/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1184\n",
            "Epoch 107/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1071 - val_loss: 0.1184\n",
            "Epoch 108/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1087 - val_loss: 0.1180\n",
            "Epoch 109/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1085 - val_loss: 0.1183\n",
            "Epoch 110/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.1076roc-auc_val: 0.8371\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1075 - val_loss: 0.1181\n",
            "Epoch 111/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1179\n",
            "Epoch 112/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1075 - val_loss: 0.1178\n",
            "Epoch 113/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1071 - val_loss: 0.1180\n",
            "Epoch 114/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1073 - val_loss: 0.1183\n",
            "Epoch 115/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1069 - val_loss: 0.1180\n",
            "Epoch 116/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1063 - val_loss: 0.1182\n",
            "Epoch 117/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1068 - val_loss: 0.1179\n",
            "Epoch 118/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1070 - val_loss: 0.1180\n",
            "Epoch 119/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1072 - val_loss: 0.1179\n",
            "Epoch 120/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1058roc-auc_val: 0.8379\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1060 - val_loss: 0.1179\n",
            "Epoch 121/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1075 - val_loss: 0.1180\n",
            "Epoch 122/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1062 - val_loss: 0.1176\n",
            "Epoch 123/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1074 - val_loss: 0.1177\n",
            "Epoch 124/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1069 - val_loss: 0.1179\n",
            "Epoch 125/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1065 - val_loss: 0.1177\n",
            "Epoch 126/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1062 - val_loss: 0.1177\n",
            "Epoch 127/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1066 - val_loss: 0.1179\n",
            "Epoch 128/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1069 - val_loss: 0.1180\n",
            "Epoch 129/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1063 - val_loss: 0.1178\n",
            "Epoch 130/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.1053roc-auc_val: 0.8383\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1054 - val_loss: 0.1179\n",
            "Epoch 131/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1059 - val_loss: 0.1178\n",
            "Epoch 132/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1053 - val_loss: 0.1175\n",
            "Epoch 133/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1061 - val_loss: 0.1178\n",
            "Epoch 134/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.1176\n",
            "Epoch 135/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1060 - val_loss: 0.1178\n",
            "Epoch 136/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1053 - val_loss: 0.1180\n",
            "Epoch 137/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1060 - val_loss: 0.1178\n",
            "Epoch 138/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.1174\n",
            "Epoch 139/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1051 - val_loss: 0.1175\n",
            "Epoch 140/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.1060roc-auc_val: 0.8394\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1058 - val_loss: 0.1173\n",
            "Epoch 141/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1050 - val_loss: 0.1172\n",
            "Epoch 142/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1054 - val_loss: 0.1172\n",
            "Epoch 143/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1055 - val_loss: 0.1174\n",
            "Epoch 144/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1054 - val_loss: 0.1175\n",
            "Epoch 145/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1058 - val_loss: 0.1174\n",
            "Epoch 146/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.1174\n",
            "Epoch 147/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1051 - val_loss: 0.1175\n",
            "Epoch 148/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1053 - val_loss: 0.1173\n",
            "Epoch 149/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1047 - val_loss: 0.1176\n",
            "Epoch 150/1000\n",
            "194/201 [===========================>..] - ETA: 0s - loss: 0.1045roc-auc_val: 0.8404\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1046 - val_loss: 0.1177\n",
            "Epoch 151/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1050 - val_loss: 0.1174\n",
            "Epoch 152/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1043 - val_loss: 0.1171\n",
            "Epoch 153/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1172\n",
            "Epoch 154/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1171\n",
            "Epoch 155/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1036 - val_loss: 0.1169\n",
            "Epoch 156/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1046 - val_loss: 0.1172\n",
            "Epoch 157/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1172\n",
            "Epoch 158/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.1173\n",
            "Epoch 159/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1043 - val_loss: 0.1171\n",
            "Epoch 160/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.1047roc-auc_val: 0.8404\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1049 - val_loss: 0.1172\n",
            "Epoch 161/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1042 - val_loss: 0.1168\n",
            "Epoch 162/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1037 - val_loss: 0.1169\n",
            "Epoch 163/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1049 - val_loss: 0.1170\n",
            "Epoch 164/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1041 - val_loss: 0.1167\n",
            "Epoch 165/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1037 - val_loss: 0.1172\n",
            "Epoch 166/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1039 - val_loss: 0.1170\n",
            "Epoch 167/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.1172\n",
            "Epoch 168/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1037 - val_loss: 0.1171\n",
            "Epoch 169/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1039 - val_loss: 0.1169\n",
            "Epoch 170/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1043roc-auc_val: 0.8408\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1042 - val_loss: 0.1169\n",
            "Epoch 171/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1033 - val_loss: 0.1170\n",
            "Epoch 172/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1035 - val_loss: 0.1169\n",
            "Epoch 173/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1035 - val_loss: 0.1169\n",
            "Epoch 174/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1034 - val_loss: 0.1170\n",
            "Epoch 175/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1169\n",
            "Epoch 176/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1033 - val_loss: 0.1170\n",
            "Epoch 177/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.1166\n",
            "Epoch 178/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1029 - val_loss: 0.1168\n",
            "Epoch 179/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1030 - val_loss: 0.1166\n",
            "Epoch 180/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.1031roc-auc_val: 0.8411\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1031 - val_loss: 0.1168\n",
            "Epoch 181/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1166\n",
            "Epoch 182/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1025 - val_loss: 0.1169\n",
            "Epoch 183/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1166\n",
            "Epoch 184/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1030 - val_loss: 0.1168\n",
            "Epoch 185/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1033 - val_loss: 0.1167\n",
            "Epoch 186/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1030 - val_loss: 0.1169\n",
            "Epoch 187/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1167\n",
            "Epoch 188/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.1167\n",
            "Epoch 189/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1168\n",
            "Epoch 190/1000\n",
            "199/201 [============================>.] - ETA: 0s - loss: 0.1017roc-auc_val: 0.8415\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1019 - val_loss: 0.1166\n",
            "Epoch 191/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1028 - val_loss: 0.1167\n",
            "Epoch 192/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1162\n",
            "Epoch 193/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.1164\n",
            "Epoch 194/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1167\n",
            "Epoch 195/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1026 - val_loss: 0.1164\n",
            "Epoch 196/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.1165\n",
            "Epoch 197/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1029 - val_loss: 0.1166\n",
            "Epoch 198/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1164\n",
            "Epoch 199/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1166\n",
            "Epoch 200/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.1025roc-auc_val: 0.8421\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1027 - val_loss: 0.1163\n",
            "Epoch 201/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1025 - val_loss: 0.1166\n",
            "Epoch 202/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1024 - val_loss: 0.1165\n",
            "Epoch 203/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1015 - val_loss: 0.1166\n",
            "Epoch 204/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.1168\n",
            "Epoch 205/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1167\n",
            "Epoch 206/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.1166\n",
            "Epoch 207/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1017 - val_loss: 0.1164\n",
            "Epoch 208/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1024 - val_loss: 0.1162\n",
            "Epoch 209/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1162\n",
            "Epoch 210/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1016roc-auc_val: 0.8425\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1016 - val_loss: 0.1167\n",
            "Epoch 211/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.1165\n",
            "Epoch 212/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.1163\n",
            "Epoch 213/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1021 - val_loss: 0.1165\n",
            "Epoch 214/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1165\n",
            "Epoch 215/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.1161\n",
            "Epoch 216/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1017 - val_loss: 0.1162\n",
            "Epoch 217/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1023 - val_loss: 0.1164\n",
            "Epoch 218/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1016 - val_loss: 0.1163\n",
            "Epoch 219/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1165\n",
            "Epoch 220/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1012roc-auc_val: 0.8425\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1012 - val_loss: 0.1164\n",
            "Epoch 221/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1160\n",
            "Epoch 222/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1018 - val_loss: 0.1162\n",
            "Epoch 223/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1164\n",
            "Epoch 224/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1011 - val_loss: 0.1160\n",
            "Epoch 225/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1016 - val_loss: 0.1161\n",
            "Epoch 226/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1160\n",
            "Epoch 227/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1163\n",
            "Epoch 228/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1161\n",
            "Epoch 229/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1163\n",
            "Epoch 230/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.1009roc-auc_val: 0.8433\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1010 - val_loss: 0.1162\n",
            "Epoch 231/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1162\n",
            "Epoch 232/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1016 - val_loss: 0.1158\n",
            "Epoch 233/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1158\n",
            "Epoch 234/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1159\n",
            "Epoch 235/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1161\n",
            "Epoch 236/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1161\n",
            "Epoch 237/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1160\n",
            "Epoch 238/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1160\n",
            "Epoch 239/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1162\n",
            "Epoch 240/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.1005roc-auc_val: 0.8438\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1007 - val_loss: 0.1159\n",
            "Epoch 241/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.1160\n",
            "Epoch 242/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1159\n",
            "Epoch 243/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1162\n",
            "Epoch 244/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1161\n",
            "Epoch 245/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1159\n",
            "Epoch 246/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1162\n",
            "Epoch 247/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1159\n",
            "Epoch 248/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1161\n",
            "Epoch 249/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1006 - val_loss: 0.1160\n",
            "Epoch 250/1000\n",
            "201/201 [==============================] - ETA: 0s - loss: 0.1006roc-auc_val: 0.8437\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1006 - val_loss: 0.1161\n",
            "Epoch 251/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1158\n",
            "Epoch 252/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1157\n",
            "Epoch 253/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1006 - val_loss: 0.1157\n",
            "Epoch 254/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1159\n",
            "Epoch 255/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0999 - val_loss: 0.1158\n",
            "Epoch 256/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1158\n",
            "Epoch 257/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1161\n",
            "Epoch 258/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.1161\n",
            "Epoch 259/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1005 - val_loss: 0.1155\n",
            "Epoch 260/1000\n",
            "194/201 [===========================>..] - ETA: 0s - loss: 0.1006roc-auc_val: 0.8442\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1005 - val_loss: 0.1159\n",
            "Epoch 261/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1155\n",
            "Epoch 262/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1001 - val_loss: 0.1158\n",
            "Epoch 263/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.1157\n",
            "Epoch 264/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1003 - val_loss: 0.1157\n",
            "Epoch 265/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 0.1155\n",
            "Epoch 266/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1156\n",
            "Epoch 267/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0991 - val_loss: 0.1157\n",
            "Epoch 268/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1158\n",
            "Epoch 269/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0999 - val_loss: 0.1156\n",
            "Epoch 270/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.1005roc-auc_val: 0.8441\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.1005 - val_loss: 0.1157\n",
            "Epoch 271/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1156\n",
            "Epoch 272/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.1000 - val_loss: 0.1158\n",
            "Epoch 273/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1156\n",
            "Epoch 274/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.1159\n",
            "Epoch 275/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.1157\n",
            "Epoch 276/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1154\n",
            "Epoch 277/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.1157\n",
            "Epoch 278/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0996 - val_loss: 0.1159\n",
            "Epoch 279/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1157\n",
            "Epoch 280/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.0991roc-auc_val: 0.845\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0989 - val_loss: 0.1155\n",
            "Epoch 281/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.1157\n",
            "Epoch 282/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1159\n",
            "Epoch 283/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1157\n",
            "Epoch 284/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1158\n",
            "Epoch 285/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1156\n",
            "Epoch 286/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1156\n",
            "Epoch 287/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1159\n",
            "Epoch 288/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1158\n",
            "Epoch 289/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1157\n",
            "Epoch 290/1000\n",
            "194/201 [===========================>..] - ETA: 0s - loss: 0.0996roc-auc_val: 0.8445\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0996 - val_loss: 0.1157\n",
            "Epoch 291/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1158\n",
            "Epoch 292/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1155\n",
            "Epoch 293/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1157\n",
            "Epoch 294/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.1154\n",
            "Epoch 295/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1159\n",
            "Epoch 296/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1159\n",
            "Epoch 297/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1158\n",
            "Epoch 298/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1155\n",
            "Epoch 299/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.1156\n",
            "Epoch 300/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.0987roc-auc_val: 0.8448\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0986 - val_loss: 0.1157\n",
            "Epoch 301/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1156\n",
            "Epoch 302/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.1155\n",
            "Epoch 303/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1156\n",
            "Epoch 304/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1157\n",
            "Epoch 305/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1154\n",
            "Epoch 306/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1153\n",
            "Epoch 307/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1153\n",
            "Epoch 308/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1156\n",
            "Epoch 309/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.1154\n",
            "Epoch 310/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.0988roc-auc_val: 0.8452\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0987 - val_loss: 0.1155\n",
            "Epoch 311/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1155\n",
            "Epoch 312/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1155\n",
            "Epoch 313/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.1154\n",
            "Epoch 314/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1153\n",
            "Epoch 315/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1151\n",
            "Epoch 316/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.1154\n",
            "Epoch 317/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1153\n",
            "Epoch 318/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1154\n",
            "Epoch 319/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.1155\n",
            "Epoch 320/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.0989roc-auc_val: 0.8457\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0985 - val_loss: 0.1152\n",
            "Epoch 321/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1152\n",
            "Epoch 322/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1153\n",
            "Epoch 323/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1152\n",
            "Epoch 324/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1151\n",
            "Epoch 325/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1152\n",
            "Epoch 326/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1152\n",
            "Epoch 327/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1152\n",
            "Epoch 328/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1153\n",
            "Epoch 329/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1152\n",
            "Epoch 330/1000\n",
            "190/201 [===========================>..] - ETA: 0s - loss: 0.0976roc-auc_val: 0.8455\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0976 - val_loss: 0.1152\n",
            "Epoch 331/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.1151\n",
            "Epoch 332/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1153\n",
            "Epoch 333/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1152\n",
            "Epoch 334/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1150\n",
            "Epoch 335/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1150\n",
            "Epoch 336/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.1151\n",
            "Epoch 337/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1155\n",
            "Epoch 338/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.1153\n",
            "Epoch 339/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1153\n",
            "Epoch 340/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.0978roc-auc_val: 0.8453\n",
            "201/201 [==============================] - 4s 18ms/step - loss: 0.0977 - val_loss: 0.1151\n",
            "Epoch 341/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1151\n",
            "Epoch 342/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0977 - val_loss: 0.1151\n",
            "Epoch 343/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1153\n",
            "Epoch 344/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1153\n",
            "Epoch 345/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.1155\n",
            "Epoch 346/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1153\n",
            "Epoch 347/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1152\n",
            "Epoch 348/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1151\n",
            "Epoch 349/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1148\n",
            "Epoch 350/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.0975roc-auc_val: 0.8458\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0974 - val_loss: 0.1149\n",
            "Epoch 351/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1150\n",
            "Epoch 352/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1152\n",
            "Epoch 353/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1152\n",
            "Epoch 354/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.1153\n",
            "Epoch 355/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1151\n",
            "Epoch 356/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1149\n",
            "Epoch 357/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1151\n",
            "Epoch 358/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.1153\n",
            "Epoch 359/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1150\n",
            "Epoch 360/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.0975roc-auc_val: 0.8456\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0974 - val_loss: 0.1150\n",
            "Epoch 361/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.1151\n",
            "Epoch 362/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1151\n",
            "Epoch 363/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1150\n",
            "Epoch 364/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1151\n",
            "Epoch 365/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.1151\n",
            "Epoch 366/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1151\n",
            "Epoch 367/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1150\n",
            "Epoch 368/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1152\n",
            "Epoch 369/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1151\n",
            "Epoch 370/1000\n",
            "192/201 [===========================>..] - ETA: 0s - loss: 0.0971roc-auc_val: 0.8457\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0972 - val_loss: 0.1149\n",
            "Epoch 371/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1150\n",
            "Epoch 372/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1147\n",
            "Epoch 373/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.1150\n",
            "Epoch 374/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1147\n",
            "Epoch 375/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1149\n",
            "Epoch 376/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.1151\n",
            "Epoch 377/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1151\n",
            "Epoch 378/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.1150\n",
            "Epoch 379/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1152\n",
            "Epoch 380/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.0969roc-auc_val: 0.846\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0969 - val_loss: 0.1151\n",
            "Epoch 381/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1149\n",
            "Epoch 382/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1148\n",
            "Epoch 383/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1148\n",
            "Epoch 384/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1149\n",
            "Epoch 385/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1149\n",
            "Epoch 386/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1150\n",
            "Epoch 387/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1150\n",
            "Epoch 388/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.1149\n",
            "Epoch 389/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1151\n",
            "Epoch 390/1000\n",
            "191/201 [===========================>..] - ETA: 0s - loss: 0.0966roc-auc_val: 0.846\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0968 - val_loss: 0.1149\n",
            "Epoch 391/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1148\n",
            "Epoch 392/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.1150\n",
            "Epoch 393/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1151\n",
            "Epoch 394/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1149\n",
            "Epoch 395/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.1150\n",
            "Epoch 396/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1149\n",
            "Epoch 397/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1149\n",
            "Epoch 398/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1147\n",
            "Epoch 399/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1149\n",
            "Epoch 400/1000\n",
            "196/201 [============================>.] - ETA: 0s - loss: 0.0970roc-auc_val: 0.8462\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0968 - val_loss: 0.1150\n",
            "Epoch 401/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1149\n",
            "Epoch 402/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1148\n",
            "Epoch 403/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1146\n",
            "Epoch 404/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1149\n",
            "Epoch 405/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1151\n",
            "Epoch 406/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1150\n",
            "Epoch 407/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1149\n",
            "Epoch 408/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1147\n",
            "Epoch 409/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1150\n",
            "Epoch 410/1000\n",
            "195/201 [============================>.] - ETA: 0s - loss: 0.0962roc-auc_val: 0.8463\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0962 - val_loss: 0.1146\n",
            "Epoch 411/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1148\n",
            "Epoch 412/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.1148\n",
            "Epoch 413/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1149\n",
            "Epoch 414/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1148\n",
            "Epoch 415/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1148\n",
            "Epoch 416/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1147\n",
            "Epoch 417/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1147\n",
            "Epoch 418/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.1149\n",
            "Epoch 419/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1151\n",
            "Epoch 420/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.0964roc-auc_val: 0.8463\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0963 - val_loss: 0.1148\n",
            "Epoch 421/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1147\n",
            "Epoch 422/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1145\n",
            "Epoch 423/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1148\n",
            "Epoch 424/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0961 - val_loss: 0.1149\n",
            "Epoch 425/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1149\n",
            "Epoch 426/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1148\n",
            "Epoch 427/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1149\n",
            "Epoch 428/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0963 - val_loss: 0.1148\n",
            "Epoch 429/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1146\n",
            "Epoch 430/1000\n",
            "194/201 [===========================>..] - ETA: 0s - loss: 0.0960roc-auc_val: 0.8467\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0961 - val_loss: 0.1146\n",
            "Epoch 431/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1149\n",
            "Epoch 432/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.1148\n",
            "Epoch 433/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1146\n",
            "Epoch 434/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1146\n",
            "Epoch 435/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1146\n",
            "Epoch 436/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1146\n",
            "Epoch 437/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1146\n",
            "Epoch 438/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1148\n",
            "Epoch 439/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1147\n",
            "Epoch 440/1000\n",
            "195/201 [============================>.] - ETA: 0s - loss: 0.0958roc-auc_val: 0.847\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0957 - val_loss: 0.1144\n",
            "Epoch 441/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1146\n",
            "Epoch 442/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.1148\n",
            "Epoch 443/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0962 - val_loss: 0.1148\n",
            "Epoch 444/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1147\n",
            "Epoch 445/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.1147\n",
            "Epoch 446/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1147\n",
            "Epoch 447/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1146\n",
            "Epoch 448/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1149\n",
            "Epoch 449/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1147\n",
            "Epoch 450/1000\n",
            "199/201 [============================>.] - ETA: 0s - loss: 0.0956roc-auc_val: 0.8466\n",
            "201/201 [==============================] - 4s 18ms/step - loss: 0.0955 - val_loss: 0.1148\n",
            "Epoch 451/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1148\n",
            "Epoch 452/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1145\n",
            "Epoch 453/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1147\n",
            "Epoch 454/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1147\n",
            "Epoch 455/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1147\n",
            "Epoch 456/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.1147\n",
            "Epoch 457/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1146\n",
            "Epoch 458/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.1146\n",
            "Epoch 459/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0951 - val_loss: 0.1146\n",
            "Epoch 460/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.0956roc-auc_val: 0.8468\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0954 - val_loss: 0.1145\n",
            "Epoch 461/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.1146\n",
            "Epoch 462/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.1146\n",
            "Epoch 463/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0957 - val_loss: 0.1146\n",
            "Epoch 464/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0949 - val_loss: 0.1147\n",
            "Epoch 465/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0947 - val_loss: 0.1145\n",
            "Epoch 466/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0950 - val_loss: 0.1146\n",
            "Epoch 467/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.1146\n",
            "Epoch 468/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.1145\n",
            "Epoch 469/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0949 - val_loss: 0.1146\n",
            "Epoch 470/1000\n",
            "193/201 [===========================>..] - ETA: 0s - loss: 0.0958roc-auc_val: 0.8469\n",
            "201/201 [==============================] - 3s 17ms/step - loss: 0.0959 - val_loss: 0.1147\n",
            "Epoch 471/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1146\n",
            "Epoch 472/1000\n",
            "201/201 [==============================] - 1s 5ms/step - loss: 0.0955 - val_loss: 0.1145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw5PePWLxWIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "911bbf65-b5e4-4a80-f418-3021723a283a"
      },
      "source": [
        "dk.keys()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['0.8779500422817255', '0.870236284248577', '0.8662341329665374'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-QgHQLLd6Fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('sub',dk)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Oa58sCVd9Sb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "aa2b5ff2-62b7-462b-fd52-5b5af8d1854c"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(dk['0.8779500422817255'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fee769360f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDP4fwsDfm4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d7a9b369-8cf0-49b9-c55b-47dc10cfb077"
      },
      "source": [
        "\n",
        "sns.distplot(dk['0.870236284248577'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fee768861d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CsAQEHdfpZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "57af37c3-ec7d-4e28-8112-b3bff283f3f0"
      },
      "source": [
        "\n",
        "sns.distplot(dk['0.8662341329665374'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fee75b929b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0gL1ZONfsBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}