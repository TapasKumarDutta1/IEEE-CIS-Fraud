{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9602a147-49be-456f-faf0-0c04a313ff07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f33919e6-40c0-4dc7-dcff-3e9813f9b24f"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "train_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold=5\n",
        "lr=0.0001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OTCMdEiOn9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv80v8W_Ko2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1c68354f-2139-4c99-9056-3edee2e3da11"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in cols:\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4jt2pcxPije",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "ss=StandardScaler()\n",
        "frd=trn['isFraud']\n",
        "ls=list(trn)\n",
        "trn=ss.fit_transform(trn.drop(['isFraud'],1))\n",
        "trn=pd.DataFrame(trn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls.remove('isFraud')\n",
        "trn.columns=ls\n",
        "trn['isFraud']=frd\n",
        "\n",
        "ls=list(tst)\n",
        "tst=ss.fit_transform(tst)\n",
        "tst=pd.DataFrame(tst)\n",
        "tst.columns=ls"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ESyOnm5Prsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym1ua9V-PnyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "910d3d4b-253f-4b99-ffb5-86e72d62db85"
      },
      "source": [
        "tst.shape,trn.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((506691, 370), (590540, 371))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "defdc14f-dd88-4365-b59d-661d080b1836"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1671.53 MB\n",
            "Memory usage after optimization is: 417.88 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 1430.33 MB\n",
            "Memory usage after optimization is: 357.58 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10c29f31-2975-4e18-ab69-252b5fd460b4"
      },
      "source": [
        "trn_n=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_n=pd.read_csv('test_transaction.csv.zip')\n",
        "trn_ls=list(trn_n)\n",
        "tst_ls=list(tst_n)\n",
        "for col in trn:\n",
        "  if col in trn_ls:\n",
        "    trn[col+'_isna']=trn_n[col].isna().astype('uint8')\n",
        "for col in tst:\n",
        "  if col in tst_ls:\n",
        "    tst[col+'_isna']=tst_n[col].isna().astype('uint8')\n",
        "import gc\n",
        "del([trn_n,tst_n])\n",
        "gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOcyf3LcXiPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd886ecc-b77e-4961-9c01-0579212c9ea7"
      },
      "source": [
        "trn=trn.drop(['isFraud_isna'],1)\n",
        "trn.shape,tst.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((590540, 594), (506691, 593))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6gnpm4CjDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7925cd18-f9a5-4aec-f7a6-600e0cb40f53"
      },
      "source": [
        "\n",
        "from keras.utils import *\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "  inp=Input((593,))\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=inp,outputs=x)\n",
        "  return mod\n",
        "kf = KFold(n_splits=n_fold)\n",
        "for en,(train_index, test_index) in enumerate(kf.split(trn)):\n",
        "  train=trn.loc[train_index].reset_index(drop=True)\n",
        "  test=trn.loc[test_index].reset_index(drop=True)\n",
        "  mod=load_model()\n",
        "  mod.compile(optimizer=Adam(0.0001,decay=1e-5),loss='binary_crossentropy',metrics='accuracy')\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=5)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  if en==0:\n",
        "    pre=mod.predict(tst)/n_fold\n",
        "  else:\n",
        "    pre+=mod.predict(tst)/n_fold"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "231/231 [==============================] - 2s 10ms/step - loss: 0.6715 - accuracy: 0.6614 - val_loss: 0.5512 - val_accuracy: 0.9158\n",
            "Epoch 2/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.4646 - accuracy: 0.8856 - val_loss: 0.3909 - val_accuracy: 0.9593\n",
            "Epoch 3/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.3091 - accuracy: 0.9495 - val_loss: 0.2806 - val_accuracy: 0.9669\n",
            "Epoch 4/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.2126 - accuracy: 0.9613 - val_loss: 0.2499 - val_accuracy: 0.9681\n",
            "Epoch 5/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1669 - accuracy: 0.9645 - val_loss: 0.2565 - val_accuracy: 0.9685\n",
            "Epoch 6/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1453 - accuracy: 0.9655 - val_loss: 0.2458 - val_accuracy: 0.9692\n",
            "Epoch 7/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1335 - accuracy: 0.9662 - val_loss: 0.2804 - val_accuracy: 0.9689\n",
            "Epoch 8/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1268 - accuracy: 0.9666 - val_loss: 0.3132 - val_accuracy: 0.9690\n",
            "Epoch 9/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1222 - accuracy: 0.9671 - val_loss: 0.3291 - val_accuracy: 0.9690\n",
            "Epoch 10/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1192 - accuracy: 0.9673 - val_loss: 0.3483 - val_accuracy: 0.9690\n",
            "Epoch 11/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1166 - accuracy: 0.9677 - val_loss: 0.3699 - val_accuracy: 0.9690\n",
            "Epoch 1/1000\n",
            "231/231 [==============================] - 2s 10ms/step - loss: 0.6796 - accuracy: 0.6411 - val_loss: 0.5176 - val_accuracy: 0.9445\n",
            "Epoch 2/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.4723 - accuracy: 0.8751 - val_loss: 0.3593 - val_accuracy: 0.9615\n",
            "Epoch 3/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.3122 - accuracy: 0.9520 - val_loss: 0.2312 - val_accuracy: 0.9647\n",
            "Epoch 4/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.2117 - accuracy: 0.9641 - val_loss: 0.1686 - val_accuracy: 0.9655\n",
            "Epoch 5/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1650 - accuracy: 0.9671 - val_loss: 0.1465 - val_accuracy: 0.9657\n",
            "Epoch 6/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1409 - accuracy: 0.9683 - val_loss: 0.1364 - val_accuracy: 0.9656\n",
            "Epoch 7/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1296 - accuracy: 0.9690 - val_loss: 0.1312 - val_accuracy: 0.9657\n",
            "Epoch 8/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1225 - accuracy: 0.9692 - val_loss: 0.1296 - val_accuracy: 0.9656\n",
            "Epoch 9/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1184 - accuracy: 0.9694 - val_loss: 0.1281 - val_accuracy: 0.9658\n",
            "Epoch 10/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1146 - accuracy: 0.9697 - val_loss: 0.1290 - val_accuracy: 0.9654\n",
            "Epoch 11/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1121 - accuracy: 0.9701 - val_loss: 0.1286 - val_accuracy: 0.9655\n",
            "Epoch 12/1000\n",
            "231/231 [==============================] - 2s 6ms/step - loss: 0.1103 - accuracy: 0.9703 - val_loss: 0.1288 - val_accuracy: 0.9653\n",
            "Epoch 13/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1080 - accuracy: 0.9706 - val_loss: 0.1286 - val_accuracy: 0.9655\n",
            "Epoch 14/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1064 - accuracy: 0.9710 - val_loss: 0.1284 - val_accuracy: 0.9653\n",
            "Epoch 1/1000\n",
            "231/231 [==============================] - 2s 9ms/step - loss: 0.6742 - accuracy: 0.6609 - val_loss: 0.4684 - val_accuracy: 0.9528\n",
            "Epoch 2/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.4634 - accuracy: 0.8906 - val_loss: 0.3148 - val_accuracy: 0.9629\n",
            "Epoch 3/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.3072 - accuracy: 0.9529 - val_loss: 0.2146 - val_accuracy: 0.9662\n",
            "Epoch 4/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.2107 - accuracy: 0.9641 - val_loss: 0.1616 - val_accuracy: 0.9668\n",
            "Epoch 5/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1644 - accuracy: 0.9669 - val_loss: 0.1405 - val_accuracy: 0.9671\n",
            "Epoch 6/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1408 - accuracy: 0.9679 - val_loss: 0.1319 - val_accuracy: 0.9672\n",
            "Epoch 7/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1294 - accuracy: 0.9687 - val_loss: 0.1284 - val_accuracy: 0.9671\n",
            "Epoch 8/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1228 - accuracy: 0.9689 - val_loss: 0.1269 - val_accuracy: 0.9672\n",
            "Epoch 9/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1178 - accuracy: 0.9694 - val_loss: 0.1263 - val_accuracy: 0.9671\n",
            "Epoch 10/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1152 - accuracy: 0.9695 - val_loss: 0.1264 - val_accuracy: 0.9668\n",
            "Epoch 11/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1117 - accuracy: 0.9699 - val_loss: 0.1259 - val_accuracy: 0.9669\n",
            "Epoch 12/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1098 - accuracy: 0.9702 - val_loss: 0.1243 - val_accuracy: 0.9673\n",
            "Epoch 13/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1080 - accuracy: 0.9706 - val_loss: 0.1247 - val_accuracy: 0.9670\n",
            "Epoch 14/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1060 - accuracy: 0.9707 - val_loss: 0.1243 - val_accuracy: 0.9671\n",
            "Epoch 15/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1052 - accuracy: 0.9709 - val_loss: 0.1237 - val_accuracy: 0.9671\n",
            "Epoch 16/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1033 - accuracy: 0.9714 - val_loss: 0.1239 - val_accuracy: 0.9672\n",
            "Epoch 17/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1016 - accuracy: 0.9716 - val_loss: 0.1208 - val_accuracy: 0.9675\n",
            "Epoch 18/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1007 - accuracy: 0.9717 - val_loss: 0.1204 - val_accuracy: 0.9678\n",
            "Epoch 19/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0988 - accuracy: 0.9723 - val_loss: 0.1205 - val_accuracy: 0.9677\n",
            "Epoch 20/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0977 - accuracy: 0.9725 - val_loss: 0.1199 - val_accuracy: 0.9678\n",
            "Epoch 21/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0962 - accuracy: 0.9729 - val_loss: 0.1197 - val_accuracy: 0.9677\n",
            "Epoch 22/1000\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.0952 - accuracy: 0.9732 - val_loss: 0.1219 - val_accuracy: 0.9677\n",
            "Epoch 23/1000\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.0940 - accuracy: 0.9735 - val_loss: 0.1180 - val_accuracy: 0.9681\n",
            "Epoch 24/1000\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.0925 - accuracy: 0.9737 - val_loss: 0.1169 - val_accuracy: 0.9694\n",
            "Epoch 25/1000\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.0917 - accuracy: 0.9741 - val_loss: 0.1210 - val_accuracy: 0.9679\n",
            "Epoch 26/1000\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.0902 - accuracy: 0.9745 - val_loss: 0.1192 - val_accuracy: 0.9692\n",
            "Epoch 27/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0891 - accuracy: 0.9747 - val_loss: 0.1178 - val_accuracy: 0.9694\n",
            "Epoch 28/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0886 - accuracy: 0.9748 - val_loss: 0.1182 - val_accuracy: 0.9691\n",
            "Epoch 29/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0882 - accuracy: 0.9750 - val_loss: 0.1183 - val_accuracy: 0.9693\n",
            "Epoch 1/1000\n",
            "231/231 [==============================] - 2s 10ms/step - loss: 0.6809 - accuracy: 0.6460 - val_loss: 0.5230 - val_accuracy: 0.9406\n",
            "Epoch 2/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.4739 - accuracy: 0.8792 - val_loss: 0.3629 - val_accuracy: 0.9622\n",
            "Epoch 3/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.3144 - accuracy: 0.9506 - val_loss: 0.2313 - val_accuracy: 0.9652\n",
            "Epoch 4/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.2145 - accuracy: 0.9631 - val_loss: 0.1725 - val_accuracy: 0.9665\n",
            "Epoch 5/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1653 - accuracy: 0.9665 - val_loss: 0.1438 - val_accuracy: 0.9669\n",
            "Epoch 6/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1422 - accuracy: 0.9679 - val_loss: 0.1321 - val_accuracy: 0.9671\n",
            "Epoch 7/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1306 - accuracy: 0.9684 - val_loss: 0.1257 - val_accuracy: 0.9672\n",
            "Epoch 8/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1234 - accuracy: 0.9689 - val_loss: 0.1230 - val_accuracy: 0.9670\n",
            "Epoch 9/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1194 - accuracy: 0.9692 - val_loss: 0.1220 - val_accuracy: 0.9669\n",
            "Epoch 10/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1166 - accuracy: 0.9693 - val_loss: 0.1220 - val_accuracy: 0.9667\n",
            "Epoch 11/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1137 - accuracy: 0.9697 - val_loss: 0.1203 - val_accuracy: 0.9669\n",
            "Epoch 12/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1110 - accuracy: 0.9700 - val_loss: 0.1194 - val_accuracy: 0.9669\n",
            "Epoch 13/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1097 - accuracy: 0.9703 - val_loss: 0.1192 - val_accuracy: 0.9670\n",
            "Epoch 14/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1077 - accuracy: 0.9706 - val_loss: 0.1176 - val_accuracy: 0.9672\n",
            "Epoch 15/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1061 - accuracy: 0.9709 - val_loss: 0.1186 - val_accuracy: 0.9669\n",
            "Epoch 16/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1041 - accuracy: 0.9714 - val_loss: 0.1163 - val_accuracy: 0.9674\n",
            "Epoch 17/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1026 - accuracy: 0.9717 - val_loss: 0.1163 - val_accuracy: 0.9674\n",
            "Epoch 18/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1015 - accuracy: 0.9719 - val_loss: 0.1154 - val_accuracy: 0.9678\n",
            "Epoch 19/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1000 - accuracy: 0.9722 - val_loss: 0.1164 - val_accuracy: 0.9677\n",
            "Epoch 20/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0983 - accuracy: 0.9727 - val_loss: 0.1160 - val_accuracy: 0.9677\n",
            "Epoch 21/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0972 - accuracy: 0.9729 - val_loss: 0.1153 - val_accuracy: 0.9678\n",
            "Epoch 22/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0967 - accuracy: 0.9729 - val_loss: 0.1156 - val_accuracy: 0.9677\n",
            "Epoch 23/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0950 - accuracy: 0.9735 - val_loss: 0.1147 - val_accuracy: 0.9677\n",
            "Epoch 24/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0937 - accuracy: 0.9737 - val_loss: 0.1134 - val_accuracy: 0.9683\n",
            "Epoch 25/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0926 - accuracy: 0.9740 - val_loss: 0.1135 - val_accuracy: 0.9682\n",
            "Epoch 26/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0917 - accuracy: 0.9743 - val_loss: 0.1132 - val_accuracy: 0.9683\n",
            "Epoch 27/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0906 - accuracy: 0.9745 - val_loss: 0.1119 - val_accuracy: 0.9682\n",
            "Epoch 28/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0898 - accuracy: 0.9748 - val_loss: 0.1149 - val_accuracy: 0.9681\n",
            "Epoch 29/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0885 - accuracy: 0.9749 - val_loss: 0.1123 - val_accuracy: 0.9683\n",
            "Epoch 30/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0879 - accuracy: 0.9753 - val_loss: 0.1119 - val_accuracy: 0.9685\n",
            "Epoch 31/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0869 - accuracy: 0.9752 - val_loss: 0.1123 - val_accuracy: 0.9683\n",
            "Epoch 32/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0860 - accuracy: 0.9756 - val_loss: 0.1124 - val_accuracy: 0.9686\n",
            "Epoch 1/1000\n",
            "231/231 [==============================] - 2s 10ms/step - loss: 0.6867 - accuracy: 0.6402 - val_loss: 0.5111 - val_accuracy: 0.9395\n",
            "Epoch 2/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.4748 - accuracy: 0.8663 - val_loss: 0.3411 - val_accuracy: 0.9571\n",
            "Epoch 3/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.3200 - accuracy: 0.9448 - val_loss: 0.2270 - val_accuracy: 0.9689\n",
            "Epoch 4/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.2240 - accuracy: 0.9610 - val_loss: 0.1686 - val_accuracy: 0.9692\n",
            "Epoch 5/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1767 - accuracy: 0.9651 - val_loss: 0.1459 - val_accuracy: 0.9692\n",
            "Epoch 6/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1532 - accuracy: 0.9669 - val_loss: 0.1353 - val_accuracy: 0.9693\n",
            "Epoch 7/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1412 - accuracy: 0.9677 - val_loss: 0.1294 - val_accuracy: 0.9695\n",
            "Epoch 8/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1345 - accuracy: 0.9681 - val_loss: 0.1269 - val_accuracy: 0.9691\n",
            "Epoch 9/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1280 - accuracy: 0.9686 - val_loss: 0.1248 - val_accuracy: 0.9691\n",
            "Epoch 10/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1252 - accuracy: 0.9692 - val_loss: 0.1233 - val_accuracy: 0.9690\n",
            "Epoch 11/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1219 - accuracy: 0.9694 - val_loss: 0.1219 - val_accuracy: 0.9688\n",
            "Epoch 12/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1189 - accuracy: 0.9698 - val_loss: 0.1207 - val_accuracy: 0.9688\n",
            "Epoch 13/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1164 - accuracy: 0.9699 - val_loss: 0.1203 - val_accuracy: 0.9689\n",
            "Epoch 14/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1137 - accuracy: 0.9704 - val_loss: 0.1182 - val_accuracy: 0.9688\n",
            "Epoch 15/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1110 - accuracy: 0.9708 - val_loss: 0.1184 - val_accuracy: 0.9687\n",
            "Epoch 16/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1099 - accuracy: 0.9708 - val_loss: 0.1176 - val_accuracy: 0.9687\n",
            "Epoch 17/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1078 - accuracy: 0.9713 - val_loss: 0.1170 - val_accuracy: 0.9691\n",
            "Epoch 18/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1064 - accuracy: 0.9716 - val_loss: 0.1164 - val_accuracy: 0.9690\n",
            "Epoch 19/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1041 - accuracy: 0.9717 - val_loss: 0.1167 - val_accuracy: 0.9688\n",
            "Epoch 20/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.1020 - accuracy: 0.9722 - val_loss: 0.1160 - val_accuracy: 0.9689\n",
            "Epoch 21/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1005 - accuracy: 0.9722 - val_loss: 0.1154 - val_accuracy: 0.9693\n",
            "Epoch 22/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0988 - accuracy: 0.9727 - val_loss: 0.1158 - val_accuracy: 0.9692\n",
            "Epoch 23/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0974 - accuracy: 0.9731 - val_loss: 0.1150 - val_accuracy: 0.9693\n",
            "Epoch 24/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0964 - accuracy: 0.9732 - val_loss: 0.1148 - val_accuracy: 0.9695\n",
            "Epoch 25/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0950 - accuracy: 0.9736 - val_loss: 0.1147 - val_accuracy: 0.9696\n",
            "Epoch 26/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.1142 - val_accuracy: 0.9697\n",
            "Epoch 27/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0930 - accuracy: 0.9739 - val_loss: 0.1149 - val_accuracy: 0.9695\n",
            "Epoch 28/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0915 - accuracy: 0.9743 - val_loss: 0.1148 - val_accuracy: 0.9695\n",
            "Epoch 29/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0904 - accuracy: 0.9746 - val_loss: 0.1142 - val_accuracy: 0.9695\n",
            "Epoch 30/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0895 - accuracy: 0.9748 - val_loss: 0.1137 - val_accuracy: 0.9697\n",
            "Epoch 31/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0886 - accuracy: 0.9751 - val_loss: 0.1138 - val_accuracy: 0.9697\n",
            "Epoch 32/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0874 - accuracy: 0.9755 - val_loss: 0.1149 - val_accuracy: 0.9696\n",
            "Epoch 33/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0867 - accuracy: 0.9755 - val_loss: 0.1144 - val_accuracy: 0.9695\n",
            "Epoch 34/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0857 - accuracy: 0.9756 - val_loss: 0.1150 - val_accuracy: 0.9695\n",
            "Epoch 35/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0846 - accuracy: 0.9760 - val_loss: 0.1129 - val_accuracy: 0.9698\n",
            "Epoch 36/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0839 - accuracy: 0.9761 - val_loss: 0.1145 - val_accuracy: 0.9696\n",
            "Epoch 37/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0830 - accuracy: 0.9764 - val_loss: 0.1148 - val_accuracy: 0.9694\n",
            "Epoch 38/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0824 - accuracy: 0.9767 - val_loss: 0.1146 - val_accuracy: 0.9697\n",
            "Epoch 39/1000\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0815 - accuracy: 0.9767 - val_loss: 0.1149 - val_accuracy: 0.9696\n",
            "Epoch 40/1000\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0809 - accuracy: 0.9769 - val_loss: 0.1143 - val_accuracy: 0.9696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bzrWN4CXn3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "8e6ffb5f-3f6d-44f2-9f55-69647717257b"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(pre)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea19af44a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbJnTCvkdGSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_I6Tj5tcbli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('predictions.npy',pre)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0soz6T-zci1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aa73158c-1e9f-4b6e-a1f8-e6dca3868cb2"
      },
      "source": [
        "lbl=pd.read_csv('sample_submission.csv.zip')\n",
        "lbl.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3663549</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3663550</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3663551</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3663552</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3663553</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud\n",
              "0        3663549      0.5\n",
              "1        3663550      0.5\n",
              "2        3663551      0.5\n",
              "3        3663552      0.5\n",
              "4        3663553      0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWrnmBuPdBKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lbl['isFraud']=pre.ravel()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQgGwnzjdG_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lbl=lbl.set_index('TransactionID')\n",
        "lbl.to_csv('sub.csv')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoWTZlm-dH0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}