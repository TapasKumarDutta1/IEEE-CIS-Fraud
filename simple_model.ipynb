{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAeHxBw8EEt",
        "colab_type": "text"
      },
      "source": [
        "Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstQrkXM8Bz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IonOu6819IW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "1dadfe24-c005-408f-c02e-0597e09a1c0c"
      },
      "source": [
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 30.0MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 86% 45.0M/52.2M [00:01<00:00, 23.9MB/s]\n",
            "100% 52.2M/52.2M [00:01<00:00, 30.9MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 159MB/s]\n",
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvhOLFro71iv",
        "colab_type": "text"
      },
      "source": [
        "loading drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "cd4e0936-8acd-4baa-fa09-9344370d1032"
      },
      "source": [
        "\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZi5I0Va7-Af",
        "colab_type": "text"
      },
      "source": [
        "Loading dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6b8d2371-61e4-4624-f7b7-7deb373a943b"
      },
      "source": [
        "\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv',index_col=[0])\n",
        "trn.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>V1</th>\n",
              "      <th>isna_sum</th>\n",
              "      <th>dist1_isna</th>\n",
              "      <th>dist2_isna</th>\n",
              "      <th>D1_isna</th>\n",
              "      <th>D2_isna</th>\n",
              "      <th>D3_isna</th>\n",
              "      <th>D4_isna</th>\n",
              "      <th>D5_isna</th>\n",
              "      <th>D6_isna</th>\n",
              "      <th>D7_isna</th>\n",
              "      <th>D8_isna</th>\n",
              "      <th>D9_isna</th>\n",
              "      <th>D10_isna</th>\n",
              "      <th>D11_isna</th>\n",
              "      <th>D12_isna</th>\n",
              "      <th>D13_isna</th>\n",
              "      <th>D14_isna</th>\n",
              "      <th>D15_isna</th>\n",
              "      <th>V1_isna</th>\n",
              "      <th>id</th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.319736</td>\n",
              "      <td>-0.752856</td>\n",
              "      <td>-0.429362</td>\n",
              "      <td>0.155508</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.012922</td>\n",
              "      <td>-0.737091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.807711</td>\n",
              "      <td>0.00739</td>\n",
              "      <td>-0.167776</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.01.0nan315.013926-13.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.319736</td>\n",
              "      <td>-0.752856</td>\n",
              "      <td>-0.429362</td>\n",
              "      <td>-0.942090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.038619</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.807711</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.349188</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.01.0gmail.com325.027551.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.319736</td>\n",
              "      <td>-0.752856</td>\n",
              "      <td>-0.429362</td>\n",
              "      <td>-0.942090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.038619</td>\n",
              "      <td>1.132473</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.746105</td>\n",
              "      <td>0.00739</td>\n",
              "      <td>0.211465</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.01.0outlook.com330.046631.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.319736</td>\n",
              "      <td>1.013560</td>\n",
              "      <td>-0.429362</td>\n",
              "      <td>0.973965</td>\n",
              "      <td>0.292248</td>\n",
              "      <td>-1.335951</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.301712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.688064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.260176</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.211465</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.025.0yahoo.com476.018132-111.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.319736</td>\n",
              "      <td>-0.752856</td>\n",
              "      <td>-0.429362</td>\n",
              "      <td>-0.942090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.107669</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.01.0gmail.com420.044971.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 499 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2  ...  V1_isna                                id  isFraud\n",
              "0  1.0  0.0  0.0  ...        0          1.01.0nan315.013926-13.0        0\n",
              "1  1.0  0.0  0.0  ...        1       1.01.0gmail.com325.027551.0        0\n",
              "2  1.0  0.0  0.0  ...        0     1.01.0outlook.com330.046631.0        0\n",
              "3  1.0  0.0  0.0  ...        1  2.025.0yahoo.com476.018132-111.0        0\n",
              "4  0.0  0.0  0.0  ...        1       1.01.0gmail.com420.044971.0        0\n",
              "\n",
              "[5 rows x 499 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LEIUFVW8iAC",
        "colab_type": "text"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "4243c024-2759-4432-ee68-07c98fffd299"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2252.73 MB\n",
            "Memory usage after optimization is: 580.70 MB\n",
            "Decreased by 74.2%\n",
            "Memory usage of dataframe is 1929.01 MB\n",
            "Memory usage after optimization is: 500.58 MB\n",
            "Decreased by 74.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjn9ePhArDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.replace([np.inf,-np.inf],np.nan)\n",
        "tst=tst.replace([np.inf,-np.inf],np.nan)\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRqrD6vz8ol6",
        "colab_type": "text"
      },
      "source": [
        "Making the callbacks and loading model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dk={}\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "\n",
        "\n",
        "\n",
        "  inp=Input((497,))\n",
        "  x=Dense(256,activation=custom_gelu)(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation=custom_gelu)(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation=custom_gelu)(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=[inp],outputs=x)\n",
        "  return mod\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXKSLj3p5MY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "splits=KFold(n_splits=5)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W07F3czB7b3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cebd50cc-68a8-45ea-be30-2400fb98326e"
      },
      "source": [
        "trn=trn.drop(['id'],1)\n",
        "tst=tst.drop(['id'],1)\n",
        "gc.collect()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2821"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oor5OujA6Bz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "923f45d3-b122-4603-8022-c114b7943ad3"
      },
      "source": [
        "ln=len(trn)/10\n",
        "for i in range(6,10):\n",
        "  X_train, X_test = trn.loc[:int(ln*i)], trn.loc[int(ln*i):]\n",
        "  y_train, y_test = X_train['isFraud'], X_test['isFraud']\n",
        "  X_train=X_train.drop(['isFraud'],1)\n",
        "  X_test=X_test.drop(['isFraud'],1)\n",
        "  mod=load_model()\n",
        "  roc = RocCallback(\n",
        "                  validation_data=(X_test, y_test))\n",
        "  mod.compile(optimizer=Nadam(),loss='binary_crossentropy')\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=2048,epochs=8,callbacks=[es,roc])\n",
        "  gc.collect()\n",
        "  mod.fit(X_test,y_test,epochs=2,batch_size=2048)\n",
        "  if en ==0:\n",
        "    pre=mod.predict(tst)/5\n",
        "  else:\n",
        "    pre+=mod.predict(tst)/5\n",
        "  del([X_train,X_test,y_train,y_test])\n",
        "  gc.collect()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "164/174 [===========================>..] - ETA: 0s - loss: 0.1086roc-auc_val: 0.8608\n",
            "174/174 [==============================] - 7s 42ms/step - loss: 0.1077 - val_loss: 0.2372\n",
            "Epoch 2/8\n",
            "173/174 [============================>.] - ETA: 0s - loss: 0.0866roc-auc_val: 0.8405\n",
            "174/174 [==============================] - 7s 39ms/step - loss: 0.0866 - val_loss: 0.1346\n",
            "Epoch 3/8\n",
            "166/174 [===========================>..] - ETA: 0s - loss: 0.0800roc-auc_val: 0.8732\n",
            "174/174 [==============================] - 7s 39ms/step - loss: 0.0800 - val_loss: 0.1057\n",
            "Epoch 4/8\n",
            "164/174 [===========================>..] - ETA: 0s - loss: 0.0740roc-auc_val: 0.8892\n",
            "174/174 [==============================] - 7s 39ms/step - loss: 0.0736 - val_loss: 0.1069\n",
            "Epoch 5/8\n",
            "165/174 [===========================>..] - ETA: 0s - loss: 0.0687roc-auc_val: 0.8627\n",
            "174/174 [==============================] - 7s 39ms/step - loss: 0.0687 - val_loss: 0.1133\n",
            "Epoch 6/8\n",
            "164/174 [===========================>..] - ETA: 0s - loss: 0.0656roc-auc_val: 0.8903\n",
            "174/174 [==============================] - 7s 39ms/step - loss: 0.0653 - val_loss: 0.1062\n",
            "Epoch 7/8\n",
            "165/174 [===========================>..] - ETA: 0s - loss: 0.0609roc-auc_val: 0.8828\n",
            "174/174 [==============================] - 7s 40ms/step - loss: 0.0608 - val_loss: 0.1588\n",
            "Epoch 8/8\n",
            "174/174 [==============================] - ETA: 0s - loss: 0.0585roc-auc_val: 0.8581\n",
            "174/174 [==============================] - 7s 40ms/step - loss: 0.0585 - val_loss: 0.1550\n",
            "Epoch 1/2\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0894\n",
            "Epoch 2/2\n",
            "116/116 [==============================] - 1s 5ms/step - loss: 0.0729\n",
            "Epoch 1/8\n",
            "196/202 [============================>.] - ETA: 0s - loss: 0.1108roc-auc_val: 0.8699\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.1103 - val_loss: 0.2182\n",
            "Epoch 2/8\n",
            "195/202 [===========================>..] - ETA: 0s - loss: 0.0883roc-auc_val: 0.8785\n",
            "202/202 [==============================] - 6s 29ms/step - loss: 0.0883 - val_loss: 0.1052\n",
            "Epoch 3/8\n",
            "195/202 [===========================>..] - ETA: 0s - loss: 0.0807roc-auc_val: 0.8925\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.0806 - val_loss: 0.0981\n",
            "Epoch 4/8\n",
            "196/202 [============================>.] - ETA: 0s - loss: 0.0747roc-auc_val: 0.8933\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.0748 - val_loss: 0.1002\n",
            "Epoch 5/8\n",
            "197/202 [============================>.] - ETA: 0s - loss: 0.0700roc-auc_val: 0.899\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.0700 - val_loss: 0.0984\n",
            "Epoch 6/8\n",
            "197/202 [============================>.] - ETA: 0s - loss: 0.0657roc-auc_val: 0.8923\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.0658 - val_loss: 0.0995\n",
            "Epoch 7/8\n",
            "199/202 [============================>.] - ETA: 0s - loss: 0.0622roc-auc_val: 0.8975\n",
            "202/202 [==============================] - 6s 27ms/step - loss: 0.0622 - val_loss: 0.0998\n",
            "Epoch 8/8\n",
            "196/202 [============================>.] - ETA: 0s - loss: 0.0593roc-auc_val: 0.8979\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 0.0592 - val_loss: 0.1021\n",
            "Epoch 1/2\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 0.0832\n",
            "Epoch 2/2\n",
            "87/87 [==============================] - 0s 5ms/step - loss: 0.0667\n",
            "Epoch 1/8\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.1080roc-auc_val: 0.8789\n",
            "231/231 [==============================] - 5s 20ms/step - loss: 0.1076 - val_loss: 0.1640\n",
            "Epoch 2/8\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0870roc-auc_val: 0.8826\n",
            "231/231 [==============================] - 4s 18ms/step - loss: 0.0870 - val_loss: 0.0998\n",
            "Epoch 3/8\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0799roc-auc_val: 0.8939\n",
            "231/231 [==============================] - 4s 18ms/step - loss: 0.0798 - val_loss: 0.0979\n",
            "Epoch 4/8\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0734roc-auc_val: 0.9001\n",
            "231/231 [==============================] - 4s 18ms/step - loss: 0.0734 - val_loss: 0.0957\n",
            "Epoch 5/8\n",
            "221/231 [===========================>..] - ETA: 0s - loss: 0.0685roc-auc_val: 0.8982\n",
            "231/231 [==============================] - 4s 18ms/step - loss: 0.0687 - val_loss: 0.0945\n",
            "Epoch 6/8\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0646roc-auc_val: 0.9\n",
            "231/231 [==============================] - 4s 18ms/step - loss: 0.0646 - val_loss: 0.0980\n",
            "Epoch 7/8\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0609roc-auc_val: 0.8933\n",
            "231/231 [==============================] - 4s 18ms/step - loss: 0.0608 - val_loss: 0.1017\n",
            "Epoch 8/8\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0574roc-auc_val: 0.9026\n",
            "231/231 [==============================] - 5s 20ms/step - loss: 0.0574 - val_loss: 0.0994\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0836\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0649\n",
            "Epoch 1/8\n",
            "251/260 [===========================>..] - ETA: 0s - loss: 0.1089roc-auc_val: 0.8833\n",
            "260/260 [==============================] - 3s 13ms/step - loss: 0.1088 - val_loss: 0.1702\n",
            "Epoch 2/8\n",
            "260/260 [==============================] - ETA: 0s - loss: 0.0869roc-auc_val: 0.8972\n",
            "260/260 [==============================] - 3s 11ms/step - loss: 0.0869 - val_loss: 0.0997\n",
            "Epoch 3/8\n",
            "251/260 [===========================>..] - ETA: 0s - loss: 0.0795roc-auc_val: 0.8949\n",
            "260/260 [==============================] - 3s 11ms/step - loss: 0.0796 - val_loss: 0.1020\n",
            "Epoch 4/8\n",
            "252/260 [============================>.] - ETA: 0s - loss: 0.0740roc-auc_val: 0.9092\n",
            "260/260 [==============================] - 3s 11ms/step - loss: 0.0739 - val_loss: 0.0987\n",
            "Epoch 5/8\n",
            "253/260 [============================>.] - ETA: 0s - loss: 0.0687roc-auc_val: 0.9126\n",
            "260/260 [==============================] - 3s 11ms/step - loss: 0.0687 - val_loss: 0.0970\n",
            "Epoch 6/8\n",
            "260/260 [==============================] - ETA: 0s - loss: 0.0647roc-auc_val: 0.9091\n",
            "260/260 [==============================] - 3s 11ms/step - loss: 0.0647 - val_loss: 0.0994\n",
            "Epoch 7/8\n",
            "251/260 [===========================>..] - ETA: 0s - loss: 0.0609roc-auc_val: 0.9105\n",
            "260/260 [==============================] - 3s 11ms/step - loss: 0.0609 - val_loss: 0.1030\n",
            "Epoch 8/8\n",
            "254/260 [============================>.] - ETA: 0s - loss: 0.0575roc-auc_val: 0.9131\n",
            "260/260 [==============================] - 3s 11ms/step - loss: 0.0574 - val_loss: 0.0993\n",
            "Epoch 1/2\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0870\n",
            "Epoch 2/2\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.0657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYgkVd5_NVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "c552baf2-cad9-4f97-ba32-764f918119c3"
      },
      "source": [
        "sub=pd.read_csv('sample_submission.csv.zip')\n",
        "sub['isFraud']=pre\n",
        "sub=sub.set_index('TransactionID')\n",
        "sub.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.002347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.001571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.000397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.000376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.000041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.002347\n",
              "3663550        0.001571\n",
              "3663551        0.000397\n",
              "3663552        0.000376\n",
              "3663553        0.000041"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VZlw01oHayo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub.to_csv('sub.csv')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FeqwiR2HcSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "eabb2b69-024f-4128-b74b-6cc7cdaea12f"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(pre)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e62087320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeWMkwJIWng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}