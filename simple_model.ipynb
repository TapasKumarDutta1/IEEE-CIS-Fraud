{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "eb7264e2-94c4-47df-c2d5-679ceeb12e7a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "929e0d03-e2ce-4bbc-96c2-59ab63866145"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 79.4MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 84% 49.0M/58.3M [00:03<00:00, 11.4MB/s]\n",
            "100% 58.3M/58.3M [00:03<00:00, 17.4MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 94% 49.0M/52.2M [00:02<00:00, 11.0MB/s]\n",
            "100% 52.2M/52.2M [00:02<00:00, 21.7MB/s]\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 109MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 107MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold=5\n",
        "lr=0.0001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OTCMdEiOn9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv80v8W_Ko2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "83c38669-c633-4079-ee7e-5f9c6d462226"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in cols:\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4jt2pcxPije",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "ss=StandardScaler()\n",
        "frd=trn['isFraud']\n",
        "ls=list(trn)\n",
        "trn=ss.fit_transform(trn.drop(['isFraud'],1))\n",
        "trn=pd.DataFrame(trn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls.remove('isFraud')\n",
        "trn.columns=ls\n",
        "trn['isFraud']=frd\n",
        "\n",
        "ls=list(tst)\n",
        "tst=ss.fit_transform(tst)\n",
        "tst=pd.DataFrame(tst)\n",
        "tst.columns=ls"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f50c16d5-cf29-4506-b16f-00b750e6bdc9"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1671.53 MB\n",
            "Memory usage after optimization is: 417.88 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 1430.33 MB\n",
            "Memory usage after optimization is: 357.58 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvEaxp9jhbvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "caf8f13b-ad95-4676-b730-12334e2d6103"
      },
      "source": [
        "trn_n=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_n=pd.read_csv('test_transaction.csv.zip')\n",
        "trn['month']=trn_n['TransactionDT']//(86400*30)\n",
        "trn_n.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkB4RpFZiww2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93848309-afbf-4daa-ba8f-5bb14e4ac5c7"
      },
      "source": [
        "\n",
        "trn_ls=list(trn_n)\n",
        "tst_ls=list(tst_n)\n",
        "for col in trn:\n",
        "  if col in trn_ls:\n",
        "    trn[col+'_isna']=trn_n[col].isna().astype('uint8')\n",
        "for col in tst:\n",
        "  if col in tst_ls:\n",
        "    tst[col+'_isna']=tst_n[col].isna().astype('uint8')\n",
        "import gc\n",
        "del([trn_n,tst_n])\n",
        "gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMlOWSVMjSD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.drop(['isFraud_isna'],1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0axBeW6tkIhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7ccc0da-bdf1-48a0-b989-498e950e7fa4"
      },
      "source": [
        "set(list(trn))-set(list(tst))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'isFraud', 'month'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2B9vFvjkFw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9657df18-e596-46d4-ab32-6f66e4252f10"
      },
      "source": [
        "trn.shape,tst.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((590540, 595), (506691, 593))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1e1df6e-7314-41d8-da0c-42b5b9408cda"
      },
      "source": [
        "\n",
        "\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "  inp=Input((593,))\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=inp,outputs=x)\n",
        "  return mod\n",
        "for en,month in enumerate(range(1,5)):\n",
        "  train=trn.loc[trn['month']>=month]\n",
        "  test=trn.loc[trn['month']<month]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  mod.compile(optimizer=Adam(0.00001,decay=1e-5),loss='binary_crossentropy',metrics='accuracy')\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  if en==0:\n",
        "    pre=mod.predict(tst)/n_fold\n",
        "  else:\n",
        "    pre+=mod.predict(tst)/n_fold"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.8395 - accuracy: 0.5356 - val_loss: 0.5902 - val_accuracy: 0.8004\n",
            "Epoch 2/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.7795 - accuracy: 0.5635 - val_loss: 0.5707 - val_accuracy: 0.8462\n",
            "Epoch 3/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.7400 - accuracy: 0.5903 - val_loss: 0.5551 - val_accuracy: 0.8836\n",
            "Epoch 4/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.7078 - accuracy: 0.6169 - val_loss: 0.5457 - val_accuracy: 0.9043\n",
            "Epoch 5/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.6789 - accuracy: 0.6435 - val_loss: 0.5349 - val_accuracy: 0.9187\n",
            "Epoch 6/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.6541 - accuracy: 0.6736 - val_loss: 0.5261 - val_accuracy: 0.9291\n",
            "Epoch 7/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.6311 - accuracy: 0.7021 - val_loss: 0.5183 - val_accuracy: 0.9360\n",
            "Epoch 8/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.6099 - accuracy: 0.7297 - val_loss: 0.5052 - val_accuracy: 0.9429\n",
            "Epoch 9/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.5890 - accuracy: 0.7556 - val_loss: 0.4940 - val_accuracy: 0.9475\n",
            "Epoch 10/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.5675 - accuracy: 0.7839 - val_loss: 0.4823 - val_accuracy: 0.9506\n",
            "Epoch 11/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.5481 - accuracy: 0.8079 - val_loss: 0.4727 - val_accuracy: 0.9523\n",
            "Epoch 12/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.5288 - accuracy: 0.8309 - val_loss: 0.4597 - val_accuracy: 0.9548\n",
            "Epoch 13/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.5096 - accuracy: 0.8504 - val_loss: 0.4468 - val_accuracy: 0.9563\n",
            "Epoch 14/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.4911 - accuracy: 0.8686 - val_loss: 0.4384 - val_accuracy: 0.9572\n",
            "Epoch 15/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.4735 - accuracy: 0.8835 - val_loss: 0.4253 - val_accuracy: 0.9587\n",
            "Epoch 16/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.4553 - accuracy: 0.8964 - val_loss: 0.4120 - val_accuracy: 0.9600\n",
            "Epoch 17/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.4378 - accuracy: 0.9076 - val_loss: 0.4051 - val_accuracy: 0.9606\n",
            "Epoch 18/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.4199 - accuracy: 0.9166 - val_loss: 0.3890 - val_accuracy: 0.9618\n",
            "Epoch 19/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.4036 - accuracy: 0.9237 - val_loss: 0.3783 - val_accuracy: 0.9627\n",
            "Epoch 20/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.3876 - accuracy: 0.9301 - val_loss: 0.3699 - val_accuracy: 0.9631\n",
            "Epoch 21/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.3719 - accuracy: 0.9350 - val_loss: 0.3591 - val_accuracy: 0.9638\n",
            "Epoch 22/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.3577 - accuracy: 0.9395 - val_loss: 0.3475 - val_accuracy: 0.9643\n",
            "Epoch 23/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.3422 - accuracy: 0.9427 - val_loss: 0.3395 - val_accuracy: 0.9648\n",
            "Epoch 24/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.3286 - accuracy: 0.9460 - val_loss: 0.3303 - val_accuracy: 0.9654\n",
            "Epoch 25/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.3147 - accuracy: 0.9489 - val_loss: 0.3247 - val_accuracy: 0.9655\n",
            "Epoch 26/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.3026 - accuracy: 0.9509 - val_loss: 0.3178 - val_accuracy: 0.9659\n",
            "Epoch 27/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2901 - accuracy: 0.9531 - val_loss: 0.3093 - val_accuracy: 0.9664\n",
            "Epoch 28/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2787 - accuracy: 0.9547 - val_loss: 0.3050 - val_accuracy: 0.9665\n",
            "Epoch 29/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2674 - accuracy: 0.9559 - val_loss: 0.2991 - val_accuracy: 0.9668\n",
            "Epoch 30/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2574 - accuracy: 0.9569 - val_loss: 0.2883 - val_accuracy: 0.9672\n",
            "Epoch 31/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2475 - accuracy: 0.9580 - val_loss: 0.2871 - val_accuracy: 0.9672\n",
            "Epoch 32/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2388 - accuracy: 0.9592 - val_loss: 0.2810 - val_accuracy: 0.9674\n",
            "Epoch 33/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2305 - accuracy: 0.9598 - val_loss: 0.2762 - val_accuracy: 0.9677\n",
            "Epoch 34/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2217 - accuracy: 0.9606 - val_loss: 0.2703 - val_accuracy: 0.9678\n",
            "Epoch 35/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2151 - accuracy: 0.9612 - val_loss: 0.2660 - val_accuracy: 0.9679\n",
            "Epoch 36/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2069 - accuracy: 0.9617 - val_loss: 0.2608 - val_accuracy: 0.9681\n",
            "Epoch 37/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.2006 - accuracy: 0.9624 - val_loss: 0.2589 - val_accuracy: 0.9681\n",
            "Epoch 38/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1952 - accuracy: 0.9627 - val_loss: 0.2574 - val_accuracy: 0.9682\n",
            "Epoch 39/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1888 - accuracy: 0.9630 - val_loss: 0.2521 - val_accuracy: 0.9684\n",
            "Epoch 40/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1837 - accuracy: 0.9632 - val_loss: 0.2562 - val_accuracy: 0.9684\n",
            "Epoch 41/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1791 - accuracy: 0.9635 - val_loss: 0.2552 - val_accuracy: 0.9684\n",
            "Epoch 42/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1739 - accuracy: 0.9640 - val_loss: 0.2520 - val_accuracy: 0.9687\n",
            "Epoch 43/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1698 - accuracy: 0.9641 - val_loss: 0.2480 - val_accuracy: 0.9688\n",
            "Epoch 44/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1663 - accuracy: 0.9643 - val_loss: 0.2510 - val_accuracy: 0.9688\n",
            "Epoch 45/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1620 - accuracy: 0.9644 - val_loss: 0.2509 - val_accuracy: 0.9689\n",
            "Epoch 46/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1585 - accuracy: 0.9647 - val_loss: 0.2512 - val_accuracy: 0.9688\n",
            "Epoch 47/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.1546 - accuracy: 0.9651 - val_loss: 0.2529 - val_accuracy: 0.9688\n",
            "Epoch 48/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1536 - accuracy: 0.9648 - val_loss: 0.2547 - val_accuracy: 0.9689\n",
            "Epoch 49/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1498 - accuracy: 0.9653 - val_loss: 0.2542 - val_accuracy: 0.9689\n",
            "Epoch 50/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1477 - accuracy: 0.9652 - val_loss: 0.2531 - val_accuracy: 0.9690\n",
            "Epoch 51/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1455 - accuracy: 0.9654 - val_loss: 0.2539 - val_accuracy: 0.9690\n",
            "Epoch 52/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1428 - accuracy: 0.9655 - val_loss: 0.2520 - val_accuracy: 0.9690\n",
            "Epoch 53/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1417 - accuracy: 0.9656 - val_loss: 0.2549 - val_accuracy: 0.9690\n",
            "Epoch 54/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1399 - accuracy: 0.9656 - val_loss: 0.2555 - val_accuracy: 0.9690\n",
            "Epoch 55/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1381 - accuracy: 0.9659 - val_loss: 0.2562 - val_accuracy: 0.9691\n",
            "Epoch 56/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1366 - accuracy: 0.9658 - val_loss: 0.2601 - val_accuracy: 0.9691\n",
            "Epoch 57/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1351 - accuracy: 0.9659 - val_loss: 0.2561 - val_accuracy: 0.9692\n",
            "Epoch 58/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1340 - accuracy: 0.9658 - val_loss: 0.2610 - val_accuracy: 0.9692\n",
            "Epoch 59/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1324 - accuracy: 0.9660 - val_loss: 0.2625 - val_accuracy: 0.9692\n",
            "Epoch 60/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1311 - accuracy: 0.9661 - val_loss: 0.2616 - val_accuracy: 0.9691\n",
            "Epoch 61/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1307 - accuracy: 0.9662 - val_loss: 0.2618 - val_accuracy: 0.9692\n",
            "Epoch 62/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1299 - accuracy: 0.9663 - val_loss: 0.2625 - val_accuracy: 0.9692\n",
            "Epoch 63/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1293 - accuracy: 0.9662 - val_loss: 0.2636 - val_accuracy: 0.9692\n",
            "Epoch 64/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1278 - accuracy: 0.9663 - val_loss: 0.2624 - val_accuracy: 0.9692\n",
            "Epoch 65/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1271 - accuracy: 0.9664 - val_loss: 0.2670 - val_accuracy: 0.9693\n",
            "Epoch 66/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1263 - accuracy: 0.9665 - val_loss: 0.2668 - val_accuracy: 0.9692\n",
            "Epoch 67/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1254 - accuracy: 0.9666 - val_loss: 0.2716 - val_accuracy: 0.9692\n",
            "Epoch 68/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1249 - accuracy: 0.9666 - val_loss: 0.2736 - val_accuracy: 0.9692\n",
            "Epoch 69/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1242 - accuracy: 0.9665 - val_loss: 0.2728 - val_accuracy: 0.9692\n",
            "Epoch 70/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1241 - accuracy: 0.9664 - val_loss: 0.2765 - val_accuracy: 0.9692\n",
            "Epoch 71/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1235 - accuracy: 0.9666 - val_loss: 0.2731 - val_accuracy: 0.9692\n",
            "Epoch 72/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1230 - accuracy: 0.9667 - val_loss: 0.2758 - val_accuracy: 0.9692\n",
            "Epoch 73/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9667 - val_loss: 0.2816 - val_accuracy: 0.9692\n",
            "Epoch 74/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1225 - accuracy: 0.9668 - val_loss: 0.2821 - val_accuracy: 0.9692\n",
            "Epoch 75/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1215 - accuracy: 0.9667 - val_loss: 0.2810 - val_accuracy: 0.9692\n",
            "Epoch 76/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1214 - accuracy: 0.9669 - val_loss: 0.2802 - val_accuracy: 0.9691\n",
            "Epoch 77/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1210 - accuracy: 0.9669 - val_loss: 0.2826 - val_accuracy: 0.9691\n",
            "Epoch 78/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1204 - accuracy: 0.9669 - val_loss: 0.2840 - val_accuracy: 0.9691\n",
            "Epoch 79/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1204 - accuracy: 0.9669 - val_loss: 0.2859 - val_accuracy: 0.9691\n",
            "Epoch 80/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1200 - accuracy: 0.9668 - val_loss: 0.2858 - val_accuracy: 0.9691\n",
            "Epoch 81/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1204 - accuracy: 0.9670 - val_loss: 0.2893 - val_accuracy: 0.9691\n",
            "Epoch 82/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.9672 - val_loss: 0.2882 - val_accuracy: 0.9691\n",
            "Epoch 83/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1194 - accuracy: 0.9669 - val_loss: 0.2911 - val_accuracy: 0.9691\n",
            "Epoch 84/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1188 - accuracy: 0.9671 - val_loss: 0.2950 - val_accuracy: 0.9691\n",
            "Epoch 85/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1185 - accuracy: 0.9671 - val_loss: 0.2952 - val_accuracy: 0.9691\n",
            "Epoch 86/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1185 - accuracy: 0.9673 - val_loss: 0.2935 - val_accuracy: 0.9691\n",
            "Epoch 87/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1182 - accuracy: 0.9672 - val_loss: 0.2968 - val_accuracy: 0.9691\n",
            "Epoch 88/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.1181 - accuracy: 0.9674 - val_loss: 0.3003 - val_accuracy: 0.9691\n",
            "Epoch 89/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1177 - accuracy: 0.9673 - val_loss: 0.3018 - val_accuracy: 0.9690\n",
            "Epoch 90/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1179 - accuracy: 0.9672 - val_loss: 0.3016 - val_accuracy: 0.9690\n",
            "Epoch 91/1000\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.1171 - accuracy: 0.9675 - val_loss: 0.2985 - val_accuracy: 0.9690\n",
            "Epoch 92/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1174 - accuracy: 0.9672 - val_loss: 0.3005 - val_accuracy: 0.9690\n",
            "Epoch 93/1000\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1168 - accuracy: 0.9674 - val_loss: 0.3011 - val_accuracy: 0.9690\n",
            "Epoch 1/1000\n",
            "181/181 [==============================] - 2s 11ms/step - loss: 0.8239 - accuracy: 0.5225 - val_loss: 0.7059 - val_accuracy: 0.5186\n",
            "Epoch 2/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.7810 - accuracy: 0.5472 - val_loss: 0.6729 - val_accuracy: 0.6192\n",
            "Epoch 3/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.7491 - accuracy: 0.5670 - val_loss: 0.6601 - val_accuracy: 0.6632\n",
            "Epoch 4/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.7241 - accuracy: 0.5891 - val_loss: 0.6509 - val_accuracy: 0.6946\n",
            "Epoch 5/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.7010 - accuracy: 0.6104 - val_loss: 0.6376 - val_accuracy: 0.7399\n",
            "Epoch 6/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6816 - accuracy: 0.6307 - val_loss: 0.6235 - val_accuracy: 0.7867\n",
            "Epoch 7/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6616 - accuracy: 0.6544 - val_loss: 0.6095 - val_accuracy: 0.8273\n",
            "Epoch 8/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.6429 - accuracy: 0.6784 - val_loss: 0.6009 - val_accuracy: 0.8475\n",
            "Epoch 9/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6261 - accuracy: 0.7006 - val_loss: 0.5864 - val_accuracy: 0.8782\n",
            "Epoch 10/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6096 - accuracy: 0.7241 - val_loss: 0.5742 - val_accuracy: 0.8986\n",
            "Epoch 11/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5938 - accuracy: 0.7459 - val_loss: 0.5607 - val_accuracy: 0.9151\n",
            "Epoch 12/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5769 - accuracy: 0.7689 - val_loss: 0.5499 - val_accuracy: 0.9261\n",
            "Epoch 13/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5607 - accuracy: 0.7913 - val_loss: 0.5362 - val_accuracy: 0.9356\n",
            "Epoch 14/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5457 - accuracy: 0.8113 - val_loss: 0.5236 - val_accuracy: 0.9430\n",
            "Epoch 15/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5300 - accuracy: 0.8300 - val_loss: 0.5098 - val_accuracy: 0.9470\n",
            "Epoch 16/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5155 - accuracy: 0.8467 - val_loss: 0.4969 - val_accuracy: 0.9501\n",
            "Epoch 17/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5001 - accuracy: 0.8628 - val_loss: 0.4836 - val_accuracy: 0.9524\n",
            "Epoch 18/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4842 - accuracy: 0.8772 - val_loss: 0.4717 - val_accuracy: 0.9535\n",
            "Epoch 19/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4700 - accuracy: 0.8891 - val_loss: 0.4589 - val_accuracy: 0.9552\n",
            "Epoch 20/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4557 - accuracy: 0.8996 - val_loss: 0.4458 - val_accuracy: 0.9559\n",
            "Epoch 21/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4412 - accuracy: 0.9089 - val_loss: 0.4342 - val_accuracy: 0.9570\n",
            "Epoch 22/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4277 - accuracy: 0.9161 - val_loss: 0.4229 - val_accuracy: 0.9577\n",
            "Epoch 23/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4138 - accuracy: 0.9230 - val_loss: 0.4103 - val_accuracy: 0.9585\n",
            "Epoch 24/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3999 - accuracy: 0.9283 - val_loss: 0.3970 - val_accuracy: 0.9594\n",
            "Epoch 25/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3867 - accuracy: 0.9331 - val_loss: 0.3854 - val_accuracy: 0.9599\n",
            "Epoch 26/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3729 - accuracy: 0.9384 - val_loss: 0.3752 - val_accuracy: 0.9605\n",
            "Epoch 27/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3611 - accuracy: 0.9414 - val_loss: 0.3637 - val_accuracy: 0.9609\n",
            "Epoch 28/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3488 - accuracy: 0.9446 - val_loss: 0.3530 - val_accuracy: 0.9612\n",
            "Epoch 29/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3360 - accuracy: 0.9473 - val_loss: 0.3430 - val_accuracy: 0.9618\n",
            "Epoch 30/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3265 - accuracy: 0.9492 - val_loss: 0.3335 - val_accuracy: 0.9622\n",
            "Epoch 31/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3144 - accuracy: 0.9516 - val_loss: 0.3230 - val_accuracy: 0.9627\n",
            "Epoch 32/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3047 - accuracy: 0.9528 - val_loss: 0.3136 - val_accuracy: 0.9630\n",
            "Epoch 33/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2939 - accuracy: 0.9546 - val_loss: 0.3049 - val_accuracy: 0.9635\n",
            "Epoch 34/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2839 - accuracy: 0.9559 - val_loss: 0.2966 - val_accuracy: 0.9638\n",
            "Epoch 35/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2747 - accuracy: 0.9571 - val_loss: 0.2887 - val_accuracy: 0.9640\n",
            "Epoch 36/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2656 - accuracy: 0.9580 - val_loss: 0.2793 - val_accuracy: 0.9645\n",
            "Epoch 37/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2569 - accuracy: 0.9590 - val_loss: 0.2717 - val_accuracy: 0.9652\n",
            "Epoch 38/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2481 - accuracy: 0.9599 - val_loss: 0.2649 - val_accuracy: 0.9652\n",
            "Epoch 39/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2399 - accuracy: 0.9602 - val_loss: 0.2571 - val_accuracy: 0.9658\n",
            "Epoch 40/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2334 - accuracy: 0.9609 - val_loss: 0.2511 - val_accuracy: 0.9659\n",
            "Epoch 41/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2269 - accuracy: 0.9613 - val_loss: 0.2435 - val_accuracy: 0.9661\n",
            "Epoch 42/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2195 - accuracy: 0.9619 - val_loss: 0.2389 - val_accuracy: 0.9663\n",
            "Epoch 43/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2123 - accuracy: 0.9625 - val_loss: 0.2338 - val_accuracy: 0.9664\n",
            "Epoch 44/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2064 - accuracy: 0.9629 - val_loss: 0.2288 - val_accuracy: 0.9666\n",
            "Epoch 45/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2009 - accuracy: 0.9632 - val_loss: 0.2247 - val_accuracy: 0.9667\n",
            "Epoch 46/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1953 - accuracy: 0.9635 - val_loss: 0.2202 - val_accuracy: 0.9668\n",
            "Epoch 47/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1898 - accuracy: 0.9640 - val_loss: 0.2163 - val_accuracy: 0.9670\n",
            "Epoch 48/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1853 - accuracy: 0.9641 - val_loss: 0.2131 - val_accuracy: 0.9671\n",
            "Epoch 49/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1813 - accuracy: 0.9642 - val_loss: 0.2095 - val_accuracy: 0.9671\n",
            "Epoch 50/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1769 - accuracy: 0.9645 - val_loss: 0.2072 - val_accuracy: 0.9671\n",
            "Epoch 51/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1732 - accuracy: 0.9647 - val_loss: 0.2031 - val_accuracy: 0.9672\n",
            "Epoch 52/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1693 - accuracy: 0.9647 - val_loss: 0.2016 - val_accuracy: 0.9673\n",
            "Epoch 53/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1654 - accuracy: 0.9650 - val_loss: 0.1983 - val_accuracy: 0.9673\n",
            "Epoch 54/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1625 - accuracy: 0.9653 - val_loss: 0.1957 - val_accuracy: 0.9674\n",
            "Epoch 55/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1593 - accuracy: 0.9654 - val_loss: 0.1947 - val_accuracy: 0.9674\n",
            "Epoch 56/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1557 - accuracy: 0.9656 - val_loss: 0.1921 - val_accuracy: 0.9674\n",
            "Epoch 57/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1527 - accuracy: 0.9659 - val_loss: 0.1924 - val_accuracy: 0.9674\n",
            "Epoch 58/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1506 - accuracy: 0.9656 - val_loss: 0.1910 - val_accuracy: 0.9674\n",
            "Epoch 59/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1484 - accuracy: 0.9659 - val_loss: 0.1892 - val_accuracy: 0.9674\n",
            "Epoch 60/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1466 - accuracy: 0.9661 - val_loss: 0.1879 - val_accuracy: 0.9675\n",
            "Epoch 61/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1447 - accuracy: 0.9659 - val_loss: 0.1871 - val_accuracy: 0.9674\n",
            "Epoch 62/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1422 - accuracy: 0.9661 - val_loss: 0.1852 - val_accuracy: 0.9675\n",
            "Epoch 63/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1404 - accuracy: 0.9662 - val_loss: 0.1866 - val_accuracy: 0.9675\n",
            "Epoch 64/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1390 - accuracy: 0.9662 - val_loss: 0.1848 - val_accuracy: 0.9675\n",
            "Epoch 65/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1370 - accuracy: 0.9663 - val_loss: 0.1849 - val_accuracy: 0.9675\n",
            "Epoch 66/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1354 - accuracy: 0.9663 - val_loss: 0.1838 - val_accuracy: 0.9676\n",
            "Epoch 67/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1338 - accuracy: 0.9664 - val_loss: 0.1851 - val_accuracy: 0.9675\n",
            "Epoch 68/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1328 - accuracy: 0.9666 - val_loss: 0.1854 - val_accuracy: 0.9675\n",
            "Epoch 69/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1315 - accuracy: 0.9666 - val_loss: 0.1856 - val_accuracy: 0.9675\n",
            "Epoch 70/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1302 - accuracy: 0.9667 - val_loss: 0.1868 - val_accuracy: 0.9675\n",
            "Epoch 71/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1297 - accuracy: 0.9665 - val_loss: 0.1864 - val_accuracy: 0.9675\n",
            "Epoch 72/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1286 - accuracy: 0.9667 - val_loss: 0.1853 - val_accuracy: 0.9675\n",
            "Epoch 73/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1274 - accuracy: 0.9670 - val_loss: 0.1858 - val_accuracy: 0.9675\n",
            "Epoch 74/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1264 - accuracy: 0.9670 - val_loss: 0.1860 - val_accuracy: 0.9675\n",
            "Epoch 75/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1257 - accuracy: 0.9669 - val_loss: 0.1874 - val_accuracy: 0.9675\n",
            "Epoch 76/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1255 - accuracy: 0.9669 - val_loss: 0.1878 - val_accuracy: 0.9675\n",
            "Epoch 77/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1247 - accuracy: 0.9669 - val_loss: 0.1871 - val_accuracy: 0.9675\n",
            "Epoch 78/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1236 - accuracy: 0.9670 - val_loss: 0.1882 - val_accuracy: 0.9674\n",
            "Epoch 79/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1227 - accuracy: 0.9670 - val_loss: 0.1884 - val_accuracy: 0.9675\n",
            "Epoch 80/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9671 - val_loss: 0.1900 - val_accuracy: 0.9675\n",
            "Epoch 81/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1219 - accuracy: 0.9671 - val_loss: 0.1914 - val_accuracy: 0.9674\n",
            "Epoch 82/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1210 - accuracy: 0.9671 - val_loss: 0.1940 - val_accuracy: 0.9674\n",
            "Epoch 83/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1210 - accuracy: 0.9672 - val_loss: 0.1937 - val_accuracy: 0.9674\n",
            "Epoch 84/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9674 - val_loss: 0.1944 - val_accuracy: 0.9674\n",
            "Epoch 85/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9673 - val_loss: 0.1945 - val_accuracy: 0.9675\n",
            "Epoch 86/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1189 - accuracy: 0.9674 - val_loss: 0.1948 - val_accuracy: 0.9675\n",
            "Epoch 87/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.9674 - val_loss: 0.1953 - val_accuracy: 0.9675\n",
            "Epoch 88/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1187 - accuracy: 0.9674 - val_loss: 0.1954 - val_accuracy: 0.9675\n",
            "Epoch 89/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1186 - accuracy: 0.9675 - val_loss: 0.1971 - val_accuracy: 0.9675\n",
            "Epoch 90/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1182 - accuracy: 0.9675 - val_loss: 0.1984 - val_accuracy: 0.9675\n",
            "Epoch 91/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1184 - accuracy: 0.9674 - val_loss: 0.1995 - val_accuracy: 0.9675\n",
            "Epoch 92/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1168 - accuracy: 0.9677 - val_loss: 0.1999 - val_accuracy: 0.9675\n",
            "Epoch 93/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1179 - accuracy: 0.9675 - val_loss: 0.2002 - val_accuracy: 0.9675\n",
            "Epoch 94/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1172 - accuracy: 0.9677 - val_loss: 0.1998 - val_accuracy: 0.9675\n",
            "Epoch 95/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1171 - accuracy: 0.9675 - val_loss: 0.2005 - val_accuracy: 0.9675\n",
            "Epoch 96/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1162 - accuracy: 0.9678 - val_loss: 0.2025 - val_accuracy: 0.9675\n",
            "Epoch 97/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1163 - accuracy: 0.9678 - val_loss: 0.2014 - val_accuracy: 0.9675\n",
            "Epoch 98/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1161 - accuracy: 0.9677 - val_loss: 0.2042 - val_accuracy: 0.9675\n",
            "Epoch 99/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1158 - accuracy: 0.9679 - val_loss: 0.2039 - val_accuracy: 0.9675\n",
            "Epoch 100/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1160 - accuracy: 0.9679 - val_loss: 0.2070 - val_accuracy: 0.9675\n",
            "Epoch 101/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1151 - accuracy: 0.9680 - val_loss: 0.2073 - val_accuracy: 0.9675\n",
            "Epoch 102/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1150 - accuracy: 0.9680 - val_loss: 0.2090 - val_accuracy: 0.9675\n",
            "Epoch 103/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1150 - accuracy: 0.9679 - val_loss: 0.2094 - val_accuracy: 0.9675\n",
            "Epoch 104/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1147 - accuracy: 0.9679 - val_loss: 0.2111 - val_accuracy: 0.9675\n",
            "Epoch 105/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1146 - accuracy: 0.9681 - val_loss: 0.2123 - val_accuracy: 0.9675\n",
            "Epoch 106/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1142 - accuracy: 0.9681 - val_loss: 0.2149 - val_accuracy: 0.9675\n",
            "Epoch 107/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1133 - accuracy: 0.9684 - val_loss: 0.2156 - val_accuracy: 0.9675\n",
            "Epoch 108/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1141 - accuracy: 0.9680 - val_loss: 0.2165 - val_accuracy: 0.9675\n",
            "Epoch 109/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9683 - val_loss: 0.2150 - val_accuracy: 0.9675\n",
            "Epoch 110/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1139 - accuracy: 0.9681 - val_loss: 0.2160 - val_accuracy: 0.9675\n",
            "Epoch 111/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9681 - val_loss: 0.2170 - val_accuracy: 0.9675\n",
            "Epoch 112/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1132 - accuracy: 0.9685 - val_loss: 0.2184 - val_accuracy: 0.9674\n",
            "Epoch 113/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1129 - accuracy: 0.9683 - val_loss: 0.2186 - val_accuracy: 0.9674\n",
            "Epoch 114/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1122 - accuracy: 0.9686 - val_loss: 0.2194 - val_accuracy: 0.9674\n",
            "Epoch 115/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1123 - accuracy: 0.9684 - val_loss: 0.2203 - val_accuracy: 0.9674\n",
            "Epoch 116/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1125 - accuracy: 0.9683 - val_loss: 0.2220 - val_accuracy: 0.9674\n",
            "Epoch 1/1000\n",
            "136/136 [==============================] - 2s 16ms/step - loss: 0.8303 - accuracy: 0.5439 - val_loss: 0.6530 - val_accuracy: 0.6664\n",
            "Epoch 2/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.7922 - accuracy: 0.5465 - val_loss: 0.6062 - val_accuracy: 0.7600\n",
            "Epoch 3/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.7652 - accuracy: 0.5605 - val_loss: 0.5824 - val_accuracy: 0.8114\n",
            "Epoch 4/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.7449 - accuracy: 0.5731 - val_loss: 0.5708 - val_accuracy: 0.8389\n",
            "Epoch 5/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.7267 - accuracy: 0.5890 - val_loss: 0.5585 - val_accuracy: 0.8676\n",
            "Epoch 6/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.7096 - accuracy: 0.6044 - val_loss: 0.5479 - val_accuracy: 0.8877\n",
            "Epoch 7/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.6943 - accuracy: 0.6211 - val_loss: 0.5398 - val_accuracy: 0.9010\n",
            "Epoch 8/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.6784 - accuracy: 0.6351 - val_loss: 0.5304 - val_accuracy: 0.9121\n",
            "Epoch 9/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.6646 - accuracy: 0.6540 - val_loss: 0.5227 - val_accuracy: 0.9220\n",
            "Epoch 10/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.6516 - accuracy: 0.6688 - val_loss: 0.5151 - val_accuracy: 0.9286\n",
            "Epoch 11/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.6379 - accuracy: 0.6859 - val_loss: 0.5082 - val_accuracy: 0.9343\n",
            "Epoch 12/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.6262 - accuracy: 0.7036 - val_loss: 0.5015 - val_accuracy: 0.9397\n",
            "Epoch 13/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.6140 - accuracy: 0.7191 - val_loss: 0.4945 - val_accuracy: 0.9432\n",
            "Epoch 14/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.6005 - accuracy: 0.7366 - val_loss: 0.4850 - val_accuracy: 0.9459\n",
            "Epoch 15/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.5894 - accuracy: 0.7519 - val_loss: 0.4801 - val_accuracy: 0.9474\n",
            "Epoch 16/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.5768 - accuracy: 0.7694 - val_loss: 0.4727 - val_accuracy: 0.9495\n",
            "Epoch 17/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.5660 - accuracy: 0.7851 - val_loss: 0.4645 - val_accuracy: 0.9510\n",
            "Epoch 18/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.5543 - accuracy: 0.7991 - val_loss: 0.4599 - val_accuracy: 0.9518\n",
            "Epoch 19/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.5418 - accuracy: 0.8147 - val_loss: 0.4529 - val_accuracy: 0.9535\n",
            "Epoch 20/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.5304 - accuracy: 0.8280 - val_loss: 0.4457 - val_accuracy: 0.9543\n",
            "Epoch 21/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.5199 - accuracy: 0.8407 - val_loss: 0.4401 - val_accuracy: 0.9550\n",
            "Epoch 22/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.5095 - accuracy: 0.8528 - val_loss: 0.4327 - val_accuracy: 0.9556\n",
            "Epoch 23/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4967 - accuracy: 0.8653 - val_loss: 0.4271 - val_accuracy: 0.9563\n",
            "Epoch 24/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4853 - accuracy: 0.8750 - val_loss: 0.4192 - val_accuracy: 0.9569\n",
            "Epoch 25/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4757 - accuracy: 0.8832 - val_loss: 0.4119 - val_accuracy: 0.9575\n",
            "Epoch 26/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4641 - accuracy: 0.8929 - val_loss: 0.4037 - val_accuracy: 0.9582\n",
            "Epoch 27/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4537 - accuracy: 0.9000 - val_loss: 0.3976 - val_accuracy: 0.9584\n",
            "Epoch 28/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4434 - accuracy: 0.9071 - val_loss: 0.3894 - val_accuracy: 0.9589\n",
            "Epoch 29/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4327 - accuracy: 0.9132 - val_loss: 0.3835 - val_accuracy: 0.9593\n",
            "Epoch 30/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4214 - accuracy: 0.9184 - val_loss: 0.3764 - val_accuracy: 0.9596\n",
            "Epoch 31/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4115 - accuracy: 0.9241 - val_loss: 0.3704 - val_accuracy: 0.9600\n",
            "Epoch 32/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.4019 - accuracy: 0.9276 - val_loss: 0.3620 - val_accuracy: 0.9606\n",
            "Epoch 33/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3923 - accuracy: 0.9316 - val_loss: 0.3545 - val_accuracy: 0.9608\n",
            "Epoch 34/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 0.3827 - accuracy: 0.9349 - val_loss: 0.3494 - val_accuracy: 0.9610\n",
            "Epoch 35/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3718 - accuracy: 0.9387 - val_loss: 0.3421 - val_accuracy: 0.9614\n",
            "Epoch 36/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3632 - accuracy: 0.9412 - val_loss: 0.3358 - val_accuracy: 0.9618\n",
            "Epoch 37/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3533 - accuracy: 0.9434 - val_loss: 0.3294 - val_accuracy: 0.9620\n",
            "Epoch 38/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3445 - accuracy: 0.9464 - val_loss: 0.3227 - val_accuracy: 0.9623\n",
            "Epoch 39/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3359 - accuracy: 0.9480 - val_loss: 0.3152 - val_accuracy: 0.9628\n",
            "Epoch 40/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3278 - accuracy: 0.9498 - val_loss: 0.3112 - val_accuracy: 0.9630\n",
            "Epoch 41/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3195 - accuracy: 0.9511 - val_loss: 0.3043 - val_accuracy: 0.9633\n",
            "Epoch 42/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3108 - accuracy: 0.9526 - val_loss: 0.2986 - val_accuracy: 0.9634\n",
            "Epoch 43/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.3024 - accuracy: 0.9540 - val_loss: 0.2926 - val_accuracy: 0.9637\n",
            "Epoch 44/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2947 - accuracy: 0.9552 - val_loss: 0.2867 - val_accuracy: 0.9639\n",
            "Epoch 45/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2882 - accuracy: 0.9562 - val_loss: 0.2840 - val_accuracy: 0.9639\n",
            "Epoch 46/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2807 - accuracy: 0.9569 - val_loss: 0.2789 - val_accuracy: 0.9642\n",
            "Epoch 47/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2717 - accuracy: 0.9581 - val_loss: 0.2738 - val_accuracy: 0.9643\n",
            "Epoch 48/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2661 - accuracy: 0.9589 - val_loss: 0.2699 - val_accuracy: 0.9645\n",
            "Epoch 49/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2609 - accuracy: 0.9592 - val_loss: 0.2639 - val_accuracy: 0.9647\n",
            "Epoch 50/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2539 - accuracy: 0.9604 - val_loss: 0.2603 - val_accuracy: 0.9648\n",
            "Epoch 51/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2472 - accuracy: 0.9608 - val_loss: 0.2552 - val_accuracy: 0.9650\n",
            "Epoch 52/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2418 - accuracy: 0.9611 - val_loss: 0.2516 - val_accuracy: 0.9652\n",
            "Epoch 53/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2360 - accuracy: 0.9619 - val_loss: 0.2477 - val_accuracy: 0.9654\n",
            "Epoch 54/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2286 - accuracy: 0.9624 - val_loss: 0.2442 - val_accuracy: 0.9654\n",
            "Epoch 55/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2251 - accuracy: 0.9623 - val_loss: 0.2404 - val_accuracy: 0.9656\n",
            "Epoch 56/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2200 - accuracy: 0.9629 - val_loss: 0.2369 - val_accuracy: 0.9658\n",
            "Epoch 57/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2155 - accuracy: 0.9632 - val_loss: 0.2331 - val_accuracy: 0.9658\n",
            "Epoch 58/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2112 - accuracy: 0.9634 - val_loss: 0.2299 - val_accuracy: 0.9659\n",
            "Epoch 59/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2056 - accuracy: 0.9640 - val_loss: 0.2274 - val_accuracy: 0.9659\n",
            "Epoch 60/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.2026 - accuracy: 0.9640 - val_loss: 0.2245 - val_accuracy: 0.9659\n",
            "Epoch 61/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1980 - accuracy: 0.9643 - val_loss: 0.2214 - val_accuracy: 0.9660\n",
            "Epoch 62/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1932 - accuracy: 0.9645 - val_loss: 0.2189 - val_accuracy: 0.9661\n",
            "Epoch 63/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1894 - accuracy: 0.9647 - val_loss: 0.2170 - val_accuracy: 0.9661\n",
            "Epoch 64/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1874 - accuracy: 0.9649 - val_loss: 0.2150 - val_accuracy: 0.9662\n",
            "Epoch 65/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1828 - accuracy: 0.9651 - val_loss: 0.2135 - val_accuracy: 0.9662\n",
            "Epoch 66/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1803 - accuracy: 0.9652 - val_loss: 0.2106 - val_accuracy: 0.9663\n",
            "Epoch 67/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1761 - accuracy: 0.9653 - val_loss: 0.2083 - val_accuracy: 0.9664\n",
            "Epoch 68/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1722 - accuracy: 0.9657 - val_loss: 0.2053 - val_accuracy: 0.9664\n",
            "Epoch 69/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1708 - accuracy: 0.9656 - val_loss: 0.2039 - val_accuracy: 0.9665\n",
            "Epoch 70/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1665 - accuracy: 0.9660 - val_loss: 0.2030 - val_accuracy: 0.9665\n",
            "Epoch 71/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1645 - accuracy: 0.9660 - val_loss: 0.2006 - val_accuracy: 0.9666\n",
            "Epoch 72/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1627 - accuracy: 0.9663 - val_loss: 0.2001 - val_accuracy: 0.9666\n",
            "Epoch 73/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1588 - accuracy: 0.9664 - val_loss: 0.2000 - val_accuracy: 0.9666\n",
            "Epoch 74/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1580 - accuracy: 0.9662 - val_loss: 0.1972 - val_accuracy: 0.9666\n",
            "Epoch 75/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1539 - accuracy: 0.9668 - val_loss: 0.1970 - val_accuracy: 0.9666\n",
            "Epoch 76/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1530 - accuracy: 0.9667 - val_loss: 0.1974 - val_accuracy: 0.9667\n",
            "Epoch 77/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1505 - accuracy: 0.9669 - val_loss: 0.1947 - val_accuracy: 0.9667\n",
            "Epoch 78/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1489 - accuracy: 0.9670 - val_loss: 0.1940 - val_accuracy: 0.9667\n",
            "Epoch 79/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1474 - accuracy: 0.9671 - val_loss: 0.1929 - val_accuracy: 0.9667\n",
            "Epoch 80/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1456 - accuracy: 0.9669 - val_loss: 0.1912 - val_accuracy: 0.9667\n",
            "Epoch 81/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1433 - accuracy: 0.9672 - val_loss: 0.1913 - val_accuracy: 0.9668\n",
            "Epoch 82/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1428 - accuracy: 0.9672 - val_loss: 0.1911 - val_accuracy: 0.9668\n",
            "Epoch 83/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1401 - accuracy: 0.9675 - val_loss: 0.1891 - val_accuracy: 0.9668\n",
            "Epoch 84/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1397 - accuracy: 0.9672 - val_loss: 0.1887 - val_accuracy: 0.9668\n",
            "Epoch 85/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1377 - accuracy: 0.9674 - val_loss: 0.1892 - val_accuracy: 0.9669\n",
            "Epoch 86/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1356 - accuracy: 0.9673 - val_loss: 0.1880 - val_accuracy: 0.9669\n",
            "Epoch 87/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1341 - accuracy: 0.9675 - val_loss: 0.1879 - val_accuracy: 0.9669\n",
            "Epoch 88/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1343 - accuracy: 0.9674 - val_loss: 0.1872 - val_accuracy: 0.9669\n",
            "Epoch 89/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1332 - accuracy: 0.9675 - val_loss: 0.1876 - val_accuracy: 0.9669\n",
            "Epoch 90/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1312 - accuracy: 0.9676 - val_loss: 0.1872 - val_accuracy: 0.9669\n",
            "Epoch 91/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1305 - accuracy: 0.9678 - val_loss: 0.1874 - val_accuracy: 0.9669\n",
            "Epoch 92/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1301 - accuracy: 0.9678 - val_loss: 0.1856 - val_accuracy: 0.9669\n",
            "Epoch 93/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1292 - accuracy: 0.9677 - val_loss: 0.1866 - val_accuracy: 0.9670\n",
            "Epoch 94/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1280 - accuracy: 0.9678 - val_loss: 0.1873 - val_accuracy: 0.9670\n",
            "Epoch 95/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1269 - accuracy: 0.9679 - val_loss: 0.1866 - val_accuracy: 0.9670\n",
            "Epoch 96/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1267 - accuracy: 0.9679 - val_loss: 0.1868 - val_accuracy: 0.9670\n",
            "Epoch 97/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1248 - accuracy: 0.9681 - val_loss: 0.1874 - val_accuracy: 0.9670\n",
            "Epoch 98/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1249 - accuracy: 0.9680 - val_loss: 0.1866 - val_accuracy: 0.9670\n",
            "Epoch 99/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1246 - accuracy: 0.9680 - val_loss: 0.1882 - val_accuracy: 0.9670\n",
            "Epoch 100/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1234 - accuracy: 0.9680 - val_loss: 0.1874 - val_accuracy: 0.9670\n",
            "Epoch 101/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1232 - accuracy: 0.9681 - val_loss: 0.1891 - val_accuracy: 0.9671\n",
            "Epoch 102/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1222 - accuracy: 0.9680 - val_loss: 0.1888 - val_accuracy: 0.9670\n",
            "Epoch 103/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1216 - accuracy: 0.9684 - val_loss: 0.1878 - val_accuracy: 0.9670\n",
            "Epoch 104/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1209 - accuracy: 0.9682 - val_loss: 0.1888 - val_accuracy: 0.9670\n",
            "Epoch 105/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1210 - accuracy: 0.9682 - val_loss: 0.1891 - val_accuracy: 0.9670\n",
            "Epoch 106/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 0.1198 - accuracy: 0.9684 - val_loss: 0.1899 - val_accuracy: 0.9670\n",
            "Epoch 107/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1201 - accuracy: 0.9683 - val_loss: 0.1904 - val_accuracy: 0.9670\n",
            "Epoch 108/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1191 - accuracy: 0.9682 - val_loss: 0.1906 - val_accuracy: 0.9670\n",
            "Epoch 109/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1194 - accuracy: 0.9681 - val_loss: 0.1893 - val_accuracy: 0.9670\n",
            "Epoch 110/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1183 - accuracy: 0.9684 - val_loss: 0.1904 - val_accuracy: 0.9670\n",
            "Epoch 111/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1172 - accuracy: 0.9684 - val_loss: 0.1896 - val_accuracy: 0.9670\n",
            "Epoch 112/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9686 - val_loss: 0.1906 - val_accuracy: 0.9670\n",
            "Epoch 113/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1165 - accuracy: 0.9686 - val_loss: 0.1914 - val_accuracy: 0.9670\n",
            "Epoch 114/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9685 - val_loss: 0.1918 - val_accuracy: 0.9670\n",
            "Epoch 115/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9684 - val_loss: 0.1926 - val_accuracy: 0.9670\n",
            "Epoch 116/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1165 - accuracy: 0.9688 - val_loss: 0.1910 - val_accuracy: 0.9670\n",
            "Epoch 117/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1159 - accuracy: 0.9686 - val_loss: 0.1926 - val_accuracy: 0.9670\n",
            "Epoch 118/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1154 - accuracy: 0.9687 - val_loss: 0.1925 - val_accuracy: 0.9670\n",
            "Epoch 119/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1154 - accuracy: 0.9689 - val_loss: 0.1933 - val_accuracy: 0.9670\n",
            "Epoch 120/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1147 - accuracy: 0.9688 - val_loss: 0.1934 - val_accuracy: 0.9670\n",
            "Epoch 121/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1147 - accuracy: 0.9686 - val_loss: 0.1923 - val_accuracy: 0.9670\n",
            "Epoch 122/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1145 - accuracy: 0.9688 - val_loss: 0.1939 - val_accuracy: 0.9670\n",
            "Epoch 123/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1144 - accuracy: 0.9687 - val_loss: 0.1933 - val_accuracy: 0.9670\n",
            "Epoch 124/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1138 - accuracy: 0.9690 - val_loss: 0.1945 - val_accuracy: 0.9670\n",
            "Epoch 125/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1142 - accuracy: 0.9689 - val_loss: 0.1958 - val_accuracy: 0.9670\n",
            "Epoch 126/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1141 - accuracy: 0.9687 - val_loss: 0.1950 - val_accuracy: 0.9669\n",
            "Epoch 127/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1129 - accuracy: 0.9690 - val_loss: 0.1951 - val_accuracy: 0.9669\n",
            "Epoch 128/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1132 - accuracy: 0.9690 - val_loss: 0.1961 - val_accuracy: 0.9669\n",
            "Epoch 129/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1135 - accuracy: 0.9690 - val_loss: 0.1979 - val_accuracy: 0.9669\n",
            "Epoch 130/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1127 - accuracy: 0.9690 - val_loss: 0.1964 - val_accuracy: 0.9669\n",
            "Epoch 131/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1127 - accuracy: 0.9690 - val_loss: 0.1973 - val_accuracy: 0.9669\n",
            "Epoch 132/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1123 - accuracy: 0.9691 - val_loss: 0.1970 - val_accuracy: 0.9669\n",
            "Epoch 133/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1121 - accuracy: 0.9689 - val_loss: 0.1979 - val_accuracy: 0.9669\n",
            "Epoch 134/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1123 - accuracy: 0.9690 - val_loss: 0.1978 - val_accuracy: 0.9669\n",
            "Epoch 135/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1118 - accuracy: 0.9691 - val_loss: 0.1976 - val_accuracy: 0.9669\n",
            "Epoch 136/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1122 - accuracy: 0.9690 - val_loss: 0.1988 - val_accuracy: 0.9669\n",
            "Epoch 137/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1117 - accuracy: 0.9692 - val_loss: 0.1991 - val_accuracy: 0.9669\n",
            "Epoch 138/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1113 - accuracy: 0.9693 - val_loss: 0.1996 - val_accuracy: 0.9669\n",
            "Epoch 139/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1113 - accuracy: 0.9692 - val_loss: 0.1991 - val_accuracy: 0.9669\n",
            "Epoch 140/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1109 - accuracy: 0.9693 - val_loss: 0.2003 - val_accuracy: 0.9669\n",
            "Epoch 141/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1109 - accuracy: 0.9695 - val_loss: 0.2016 - val_accuracy: 0.9669\n",
            "Epoch 142/1000\n",
            "136/136 [==============================] - 1s 8ms/step - loss: 0.1116 - accuracy: 0.9691 - val_loss: 0.2022 - val_accuracy: 0.9669\n",
            "Epoch 1/1000\n",
            "88/88 [==============================] - 2s 26ms/step - loss: 0.8443 - accuracy: 0.5220 - val_loss: 0.6484 - val_accuracy: 0.6862\n",
            "Epoch 2/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.8159 - accuracy: 0.5345 - val_loss: 0.6314 - val_accuracy: 0.7264\n",
            "Epoch 3/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.7932 - accuracy: 0.5461 - val_loss: 0.6199 - val_accuracy: 0.7466\n",
            "Epoch 4/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.7769 - accuracy: 0.5548 - val_loss: 0.6112 - val_accuracy: 0.7633\n",
            "Epoch 5/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.7624 - accuracy: 0.5647 - val_loss: 0.6053 - val_accuracy: 0.7778\n",
            "Epoch 6/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.7481 - accuracy: 0.5744 - val_loss: 0.5941 - val_accuracy: 0.8007\n",
            "Epoch 7/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.7360 - accuracy: 0.5864 - val_loss: 0.5883 - val_accuracy: 0.8152\n",
            "Epoch 8/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.7227 - accuracy: 0.5941 - val_loss: 0.5839 - val_accuracy: 0.8276\n",
            "Epoch 9/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.7110 - accuracy: 0.6063 - val_loss: 0.5753 - val_accuracy: 0.8462\n",
            "Epoch 10/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.7018 - accuracy: 0.6157 - val_loss: 0.5658 - val_accuracy: 0.8635\n",
            "Epoch 11/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.6907 - accuracy: 0.6290 - val_loss: 0.5627 - val_accuracy: 0.8721\n",
            "Epoch 12/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.6804 - accuracy: 0.6380 - val_loss: 0.5555 - val_accuracy: 0.8832\n",
            "Epoch 13/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.6709 - accuracy: 0.6508 - val_loss: 0.5488 - val_accuracy: 0.8967\n",
            "Epoch 14/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.6613 - accuracy: 0.6631 - val_loss: 0.5460 - val_accuracy: 0.9045\n",
            "Epoch 15/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.6515 - accuracy: 0.6741 - val_loss: 0.5411 - val_accuracy: 0.9107\n",
            "Epoch 16/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.6429 - accuracy: 0.6839 - val_loss: 0.5348 - val_accuracy: 0.9176\n",
            "Epoch 17/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.6338 - accuracy: 0.6961 - val_loss: 0.5316 - val_accuracy: 0.9219\n",
            "Epoch 18/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.6257 - accuracy: 0.7080 - val_loss: 0.5272 - val_accuracy: 0.9257\n",
            "Epoch 19/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.6164 - accuracy: 0.7212 - val_loss: 0.5220 - val_accuracy: 0.9305\n",
            "Epoch 20/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.6084 - accuracy: 0.7320 - val_loss: 0.5166 - val_accuracy: 0.9334\n",
            "Epoch 21/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.6017 - accuracy: 0.7445 - val_loss: 0.5122 - val_accuracy: 0.9370\n",
            "Epoch 22/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5921 - accuracy: 0.7567 - val_loss: 0.5072 - val_accuracy: 0.9395\n",
            "Epoch 23/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5843 - accuracy: 0.7689 - val_loss: 0.5033 - val_accuracy: 0.9413\n",
            "Epoch 24/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5773 - accuracy: 0.7772 - val_loss: 0.4954 - val_accuracy: 0.9443\n",
            "Epoch 25/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5676 - accuracy: 0.7898 - val_loss: 0.4908 - val_accuracy: 0.9451\n",
            "Epoch 26/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5613 - accuracy: 0.8013 - val_loss: 0.4874 - val_accuracy: 0.9463\n",
            "Epoch 27/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5535 - accuracy: 0.8106 - val_loss: 0.4827 - val_accuracy: 0.9475\n",
            "Epoch 28/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5450 - accuracy: 0.8189 - val_loss: 0.4766 - val_accuracy: 0.9482\n",
            "Epoch 29/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5373 - accuracy: 0.8301 - val_loss: 0.4713 - val_accuracy: 0.9493\n",
            "Epoch 30/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5296 - accuracy: 0.8380 - val_loss: 0.4653 - val_accuracy: 0.9511\n",
            "Epoch 31/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5209 - accuracy: 0.8482 - val_loss: 0.4594 - val_accuracy: 0.9519\n",
            "Epoch 32/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.5153 - accuracy: 0.8557 - val_loss: 0.4562 - val_accuracy: 0.9523\n",
            "Epoch 33/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.5060 - accuracy: 0.8642 - val_loss: 0.4494 - val_accuracy: 0.9530\n",
            "Epoch 34/1000\n",
            "88/88 [==============================] - 1s 14ms/step - loss: 0.4991 - accuracy: 0.8708 - val_loss: 0.4443 - val_accuracy: 0.9541\n",
            "Epoch 35/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.4921 - accuracy: 0.8773 - val_loss: 0.4391 - val_accuracy: 0.9541\n",
            "Epoch 36/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.4837 - accuracy: 0.8841 - val_loss: 0.4335 - val_accuracy: 0.9545\n",
            "Epoch 37/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4763 - accuracy: 0.8903 - val_loss: 0.4287 - val_accuracy: 0.9549\n",
            "Epoch 38/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4697 - accuracy: 0.8949 - val_loss: 0.4228 - val_accuracy: 0.9556\n",
            "Epoch 39/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4623 - accuracy: 0.9005 - val_loss: 0.4165 - val_accuracy: 0.9560\n",
            "Epoch 40/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4557 - accuracy: 0.9056 - val_loss: 0.4120 - val_accuracy: 0.9562\n",
            "Epoch 41/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4470 - accuracy: 0.9109 - val_loss: 0.4082 - val_accuracy: 0.9567\n",
            "Epoch 42/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4399 - accuracy: 0.9141 - val_loss: 0.4017 - val_accuracy: 0.9570\n",
            "Epoch 43/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4345 - accuracy: 0.9178 - val_loss: 0.3955 - val_accuracy: 0.9575\n",
            "Epoch 44/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4263 - accuracy: 0.9220 - val_loss: 0.3893 - val_accuracy: 0.9577\n",
            "Epoch 45/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4207 - accuracy: 0.9249 - val_loss: 0.3854 - val_accuracy: 0.9579\n",
            "Epoch 46/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.4114 - accuracy: 0.9280 - val_loss: 0.3795 - val_accuracy: 0.9583\n",
            "Epoch 47/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.4056 - accuracy: 0.9314 - val_loss: 0.3752 - val_accuracy: 0.9583\n",
            "Epoch 48/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3990 - accuracy: 0.9321 - val_loss: 0.3681 - val_accuracy: 0.9588\n",
            "Epoch 49/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3914 - accuracy: 0.9358 - val_loss: 0.3645 - val_accuracy: 0.9589\n",
            "Epoch 50/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.3857 - accuracy: 0.9377 - val_loss: 0.3584 - val_accuracy: 0.9592\n",
            "Epoch 51/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3797 - accuracy: 0.9399 - val_loss: 0.3523 - val_accuracy: 0.9594\n",
            "Epoch 52/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3717 - accuracy: 0.9424 - val_loss: 0.3477 - val_accuracy: 0.9595\n",
            "Epoch 53/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3671 - accuracy: 0.9425 - val_loss: 0.3430 - val_accuracy: 0.9600\n",
            "Epoch 54/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3588 - accuracy: 0.9455 - val_loss: 0.3378 - val_accuracy: 0.9601\n",
            "Epoch 55/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3529 - accuracy: 0.9460 - val_loss: 0.3311 - val_accuracy: 0.9606\n",
            "Epoch 56/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3470 - accuracy: 0.9479 - val_loss: 0.3277 - val_accuracy: 0.9605\n",
            "Epoch 57/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3418 - accuracy: 0.9489 - val_loss: 0.3233 - val_accuracy: 0.9608\n",
            "Epoch 58/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.3352 - accuracy: 0.9504 - val_loss: 0.3183 - val_accuracy: 0.9610\n",
            "Epoch 59/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.3294 - accuracy: 0.9514 - val_loss: 0.3126 - val_accuracy: 0.9612\n",
            "Epoch 60/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.9523 - val_loss: 0.3078 - val_accuracy: 0.9613\n",
            "Epoch 61/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.3180 - accuracy: 0.9535 - val_loss: 0.3038 - val_accuracy: 0.9615\n",
            "Epoch 62/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.3128 - accuracy: 0.9546 - val_loss: 0.3002 - val_accuracy: 0.9617\n",
            "Epoch 63/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.3069 - accuracy: 0.9551 - val_loss: 0.2953 - val_accuracy: 0.9619\n",
            "Epoch 64/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.3011 - accuracy: 0.9564 - val_loss: 0.2899 - val_accuracy: 0.9622\n",
            "Epoch 65/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2964 - accuracy: 0.9567 - val_loss: 0.2858 - val_accuracy: 0.9622\n",
            "Epoch 66/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2912 - accuracy: 0.9570 - val_loss: 0.2805 - val_accuracy: 0.9624\n",
            "Epoch 67/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.2860 - accuracy: 0.9582 - val_loss: 0.2773 - val_accuracy: 0.9625\n",
            "Epoch 68/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.2810 - accuracy: 0.9583 - val_loss: 0.2729 - val_accuracy: 0.9627\n",
            "Epoch 69/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2768 - accuracy: 0.9592 - val_loss: 0.2683 - val_accuracy: 0.9629\n",
            "Epoch 70/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2710 - accuracy: 0.9599 - val_loss: 0.2652 - val_accuracy: 0.9630\n",
            "Epoch 71/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2664 - accuracy: 0.9601 - val_loss: 0.2607 - val_accuracy: 0.9633\n",
            "Epoch 72/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2624 - accuracy: 0.9612 - val_loss: 0.2582 - val_accuracy: 0.9633\n",
            "Epoch 73/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2578 - accuracy: 0.9610 - val_loss: 0.2543 - val_accuracy: 0.9635\n",
            "Epoch 74/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2536 - accuracy: 0.9617 - val_loss: 0.2502 - val_accuracy: 0.9636\n",
            "Epoch 75/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2492 - accuracy: 0.9624 - val_loss: 0.2458 - val_accuracy: 0.9638\n",
            "Epoch 76/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2457 - accuracy: 0.9623 - val_loss: 0.2430 - val_accuracy: 0.9638\n",
            "Epoch 77/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2417 - accuracy: 0.9626 - val_loss: 0.2392 - val_accuracy: 0.9641\n",
            "Epoch 78/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2377 - accuracy: 0.9630 - val_loss: 0.2357 - val_accuracy: 0.9643\n",
            "Epoch 79/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2335 - accuracy: 0.9632 - val_loss: 0.2321 - val_accuracy: 0.9644\n",
            "Epoch 80/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2297 - accuracy: 0.9634 - val_loss: 0.2298 - val_accuracy: 0.9644\n",
            "Epoch 81/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2248 - accuracy: 0.9641 - val_loss: 0.2265 - val_accuracy: 0.9644\n",
            "Epoch 82/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2224 - accuracy: 0.9640 - val_loss: 0.2234 - val_accuracy: 0.9646\n",
            "Epoch 83/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2194 - accuracy: 0.9643 - val_loss: 0.2204 - val_accuracy: 0.9647\n",
            "Epoch 84/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2149 - accuracy: 0.9647 - val_loss: 0.2180 - val_accuracy: 0.9647\n",
            "Epoch 85/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2119 - accuracy: 0.9647 - val_loss: 0.2147 - val_accuracy: 0.9649\n",
            "Epoch 86/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2089 - accuracy: 0.9648 - val_loss: 0.2120 - val_accuracy: 0.9650\n",
            "Epoch 87/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.2058 - accuracy: 0.9650 - val_loss: 0.2096 - val_accuracy: 0.9651\n",
            "Epoch 88/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.2020 - accuracy: 0.9657 - val_loss: 0.2072 - val_accuracy: 0.9652\n",
            "Epoch 89/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1989 - accuracy: 0.9657 - val_loss: 0.2048 - val_accuracy: 0.9652\n",
            "Epoch 90/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1960 - accuracy: 0.9659 - val_loss: 0.2021 - val_accuracy: 0.9653\n",
            "Epoch 91/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1943 - accuracy: 0.9657 - val_loss: 0.1992 - val_accuracy: 0.9655\n",
            "Epoch 92/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1922 - accuracy: 0.9659 - val_loss: 0.1972 - val_accuracy: 0.9656\n",
            "Epoch 93/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1890 - accuracy: 0.9661 - val_loss: 0.1952 - val_accuracy: 0.9656\n",
            "Epoch 94/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1857 - accuracy: 0.9662 - val_loss: 0.1932 - val_accuracy: 0.9657\n",
            "Epoch 95/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1841 - accuracy: 0.9664 - val_loss: 0.1910 - val_accuracy: 0.9657\n",
            "Epoch 96/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1803 - accuracy: 0.9662 - val_loss: 0.1889 - val_accuracy: 0.9658\n",
            "Epoch 97/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1778 - accuracy: 0.9669 - val_loss: 0.1870 - val_accuracy: 0.9658\n",
            "Epoch 98/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1759 - accuracy: 0.9669 - val_loss: 0.1856 - val_accuracy: 0.9659\n",
            "Epoch 99/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1741 - accuracy: 0.9668 - val_loss: 0.1841 - val_accuracy: 0.9659\n",
            "Epoch 100/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1709 - accuracy: 0.9672 - val_loss: 0.1821 - val_accuracy: 0.9659\n",
            "Epoch 101/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1686 - accuracy: 0.9673 - val_loss: 0.1802 - val_accuracy: 0.9660\n",
            "Epoch 102/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1675 - accuracy: 0.9671 - val_loss: 0.1787 - val_accuracy: 0.9661\n",
            "Epoch 103/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1653 - accuracy: 0.9672 - val_loss: 0.1769 - val_accuracy: 0.9661\n",
            "Epoch 104/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1623 - accuracy: 0.9675 - val_loss: 0.1755 - val_accuracy: 0.9662\n",
            "Epoch 105/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1620 - accuracy: 0.9676 - val_loss: 0.1741 - val_accuracy: 0.9663\n",
            "Epoch 106/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1590 - accuracy: 0.9677 - val_loss: 0.1733 - val_accuracy: 0.9662\n",
            "Epoch 107/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1573 - accuracy: 0.9679 - val_loss: 0.1722 - val_accuracy: 0.9663\n",
            "Epoch 108/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1557 - accuracy: 0.9680 - val_loss: 0.1707 - val_accuracy: 0.9664\n",
            "Epoch 109/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1536 - accuracy: 0.9679 - val_loss: 0.1700 - val_accuracy: 0.9664\n",
            "Epoch 110/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1534 - accuracy: 0.9678 - val_loss: 0.1686 - val_accuracy: 0.9664\n",
            "Epoch 111/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1511 - accuracy: 0.9681 - val_loss: 0.1678 - val_accuracy: 0.9664\n",
            "Epoch 112/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1501 - accuracy: 0.9678 - val_loss: 0.1669 - val_accuracy: 0.9664\n",
            "Epoch 113/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1477 - accuracy: 0.9683 - val_loss: 0.1658 - val_accuracy: 0.9665\n",
            "Epoch 114/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1461 - accuracy: 0.9681 - val_loss: 0.1647 - val_accuracy: 0.9665\n",
            "Epoch 115/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1452 - accuracy: 0.9682 - val_loss: 0.1636 - val_accuracy: 0.9666\n",
            "Epoch 116/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1444 - accuracy: 0.9683 - val_loss: 0.1628 - val_accuracy: 0.9666\n",
            "Epoch 117/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.9685 - val_loss: 0.1627 - val_accuracy: 0.9665\n",
            "Epoch 118/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1414 - accuracy: 0.9684 - val_loss: 0.1622 - val_accuracy: 0.9665\n",
            "Epoch 119/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1398 - accuracy: 0.9685 - val_loss: 0.1608 - val_accuracy: 0.9666\n",
            "Epoch 120/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1386 - accuracy: 0.9688 - val_loss: 0.1596 - val_accuracy: 0.9667\n",
            "Epoch 121/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1381 - accuracy: 0.9686 - val_loss: 0.1592 - val_accuracy: 0.9667\n",
            "Epoch 122/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1368 - accuracy: 0.9684 - val_loss: 0.1584 - val_accuracy: 0.9667\n",
            "Epoch 123/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1352 - accuracy: 0.9687 - val_loss: 0.1586 - val_accuracy: 0.9667\n",
            "Epoch 124/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1338 - accuracy: 0.9687 - val_loss: 0.1577 - val_accuracy: 0.9667\n",
            "Epoch 125/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1337 - accuracy: 0.9689 - val_loss: 0.1573 - val_accuracy: 0.9667\n",
            "Epoch 126/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1322 - accuracy: 0.9690 - val_loss: 0.1570 - val_accuracy: 0.9667\n",
            "Epoch 127/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1322 - accuracy: 0.9688 - val_loss: 0.1567 - val_accuracy: 0.9667\n",
            "Epoch 128/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1302 - accuracy: 0.9691 - val_loss: 0.1561 - val_accuracy: 0.9667\n",
            "Epoch 129/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1300 - accuracy: 0.9690 - val_loss: 0.1559 - val_accuracy: 0.9668\n",
            "Epoch 130/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1288 - accuracy: 0.9692 - val_loss: 0.1557 - val_accuracy: 0.9668\n",
            "Epoch 131/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1271 - accuracy: 0.9692 - val_loss: 0.1554 - val_accuracy: 0.9668\n",
            "Epoch 132/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1267 - accuracy: 0.9695 - val_loss: 0.1556 - val_accuracy: 0.9668\n",
            "Epoch 133/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1264 - accuracy: 0.9691 - val_loss: 0.1553 - val_accuracy: 0.9668\n",
            "Epoch 134/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1260 - accuracy: 0.9691 - val_loss: 0.1555 - val_accuracy: 0.9668\n",
            "Epoch 135/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1239 - accuracy: 0.9695 - val_loss: 0.1551 - val_accuracy: 0.9668\n",
            "Epoch 136/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1244 - accuracy: 0.9693 - val_loss: 0.1547 - val_accuracy: 0.9668\n",
            "Epoch 137/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1237 - accuracy: 0.9695 - val_loss: 0.1538 - val_accuracy: 0.9668\n",
            "Epoch 138/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1227 - accuracy: 0.9695 - val_loss: 0.1537 - val_accuracy: 0.9668\n",
            "Epoch 139/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1225 - accuracy: 0.9693 - val_loss: 0.1531 - val_accuracy: 0.9668\n",
            "Epoch 140/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1210 - accuracy: 0.9695 - val_loss: 0.1528 - val_accuracy: 0.9668\n",
            "Epoch 141/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1215 - accuracy: 0.9693 - val_loss: 0.1531 - val_accuracy: 0.9668\n",
            "Epoch 142/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1199 - accuracy: 0.9695 - val_loss: 0.1527 - val_accuracy: 0.9668\n",
            "Epoch 143/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1199 - accuracy: 0.9695 - val_loss: 0.1530 - val_accuracy: 0.9668\n",
            "Epoch 144/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1199 - accuracy: 0.9696 - val_loss: 0.1531 - val_accuracy: 0.9668\n",
            "Epoch 145/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1180 - accuracy: 0.9695 - val_loss: 0.1531 - val_accuracy: 0.9668\n",
            "Epoch 146/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1178 - accuracy: 0.9695 - val_loss: 0.1528 - val_accuracy: 0.9669\n",
            "Epoch 147/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1176 - accuracy: 0.9697 - val_loss: 0.1523 - val_accuracy: 0.9668\n",
            "Epoch 148/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1170 - accuracy: 0.9699 - val_loss: 0.1527 - val_accuracy: 0.9669\n",
            "Epoch 149/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1174 - accuracy: 0.9696 - val_loss: 0.1523 - val_accuracy: 0.9669\n",
            "Epoch 150/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1162 - accuracy: 0.9698 - val_loss: 0.1526 - val_accuracy: 0.9669\n",
            "Epoch 151/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1161 - accuracy: 0.9697 - val_loss: 0.1527 - val_accuracy: 0.9669\n",
            "Epoch 152/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1154 - accuracy: 0.9698 - val_loss: 0.1527 - val_accuracy: 0.9669\n",
            "Epoch 153/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1145 - accuracy: 0.9699 - val_loss: 0.1527 - val_accuracy: 0.9669\n",
            "Epoch 154/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1146 - accuracy: 0.9701 - val_loss: 0.1530 - val_accuracy: 0.9669\n",
            "Epoch 155/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1140 - accuracy: 0.9702 - val_loss: 0.1533 - val_accuracy: 0.9668\n",
            "Epoch 156/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1137 - accuracy: 0.9700 - val_loss: 0.1533 - val_accuracy: 0.9669\n",
            "Epoch 157/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1129 - accuracy: 0.9699 - val_loss: 0.1536 - val_accuracy: 0.9669\n",
            "Epoch 158/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1134 - accuracy: 0.9700 - val_loss: 0.1533 - val_accuracy: 0.9669\n",
            "Epoch 159/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1129 - accuracy: 0.9698 - val_loss: 0.1536 - val_accuracy: 0.9669\n",
            "Epoch 160/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1129 - accuracy: 0.9700 - val_loss: 0.1539 - val_accuracy: 0.9669\n",
            "Epoch 161/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1124 - accuracy: 0.9700 - val_loss: 0.1543 - val_accuracy: 0.9669\n",
            "Epoch 162/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1120 - accuracy: 0.9702 - val_loss: 0.1544 - val_accuracy: 0.9669\n",
            "Epoch 163/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1121 - accuracy: 0.9704 - val_loss: 0.1544 - val_accuracy: 0.9669\n",
            "Epoch 164/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1109 - accuracy: 0.9704 - val_loss: 0.1549 - val_accuracy: 0.9669\n",
            "Epoch 165/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1103 - accuracy: 0.9704 - val_loss: 0.1550 - val_accuracy: 0.9668\n",
            "Epoch 166/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1107 - accuracy: 0.9702 - val_loss: 0.1557 - val_accuracy: 0.9668\n",
            "Epoch 167/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1099 - accuracy: 0.9704 - val_loss: 0.1562 - val_accuracy: 0.9668\n",
            "Epoch 168/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1099 - accuracy: 0.9704 - val_loss: 0.1568 - val_accuracy: 0.9669\n",
            "Epoch 169/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1098 - accuracy: 0.9702 - val_loss: 0.1565 - val_accuracy: 0.9669\n",
            "Epoch 170/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1090 - accuracy: 0.9708 - val_loss: 0.1573 - val_accuracy: 0.9668\n",
            "Epoch 171/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1097 - accuracy: 0.9705 - val_loss: 0.1574 - val_accuracy: 0.9668\n",
            "Epoch 172/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1093 - accuracy: 0.9705 - val_loss: 0.1572 - val_accuracy: 0.9669\n",
            "Epoch 173/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1084 - accuracy: 0.9704 - val_loss: 0.1579 - val_accuracy: 0.9668\n",
            "Epoch 174/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1082 - accuracy: 0.9706 - val_loss: 0.1582 - val_accuracy: 0.9668\n",
            "Epoch 175/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1079 - accuracy: 0.9707 - val_loss: 0.1592 - val_accuracy: 0.9668\n",
            "Epoch 176/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1082 - accuracy: 0.9707 - val_loss: 0.1590 - val_accuracy: 0.9668\n",
            "Epoch 177/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1073 - accuracy: 0.9708 - val_loss: 0.1590 - val_accuracy: 0.9668\n",
            "Epoch 178/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1079 - accuracy: 0.9708 - val_loss: 0.1600 - val_accuracy: 0.9668\n",
            "Epoch 179/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1076 - accuracy: 0.9707 - val_loss: 0.1604 - val_accuracy: 0.9668\n",
            "Epoch 180/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1070 - accuracy: 0.9706 - val_loss: 0.1600 - val_accuracy: 0.9667\n",
            "Epoch 181/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1070 - accuracy: 0.9708 - val_loss: 0.1603 - val_accuracy: 0.9668\n",
            "Epoch 182/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1067 - accuracy: 0.9707 - val_loss: 0.1612 - val_accuracy: 0.9668\n",
            "Epoch 183/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1069 - accuracy: 0.9708 - val_loss: 0.1605 - val_accuracy: 0.9668\n",
            "Epoch 184/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1061 - accuracy: 0.9711 - val_loss: 0.1610 - val_accuracy: 0.9668\n",
            "Epoch 185/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1060 - accuracy: 0.9710 - val_loss: 0.1611 - val_accuracy: 0.9668\n",
            "Epoch 186/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1060 - accuracy: 0.9710 - val_loss: 0.1609 - val_accuracy: 0.9668\n",
            "Epoch 187/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1063 - accuracy: 0.9708 - val_loss: 0.1610 - val_accuracy: 0.9668\n",
            "Epoch 188/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1056 - accuracy: 0.9710 - val_loss: 0.1612 - val_accuracy: 0.9668\n",
            "Epoch 189/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1056 - accuracy: 0.9710 - val_loss: 0.1616 - val_accuracy: 0.9668\n",
            "Epoch 190/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1052 - accuracy: 0.9712 - val_loss: 0.1626 - val_accuracy: 0.9667\n",
            "Epoch 191/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1053 - accuracy: 0.9709 - val_loss: 0.1631 - val_accuracy: 0.9668\n",
            "Epoch 192/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1057 - accuracy: 0.9710 - val_loss: 0.1625 - val_accuracy: 0.9667\n",
            "Epoch 193/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1051 - accuracy: 0.9710 - val_loss: 0.1628 - val_accuracy: 0.9667\n",
            "Epoch 194/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1050 - accuracy: 0.9709 - val_loss: 0.1633 - val_accuracy: 0.9668\n",
            "Epoch 195/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1047 - accuracy: 0.9712 - val_loss: 0.1634 - val_accuracy: 0.9667\n",
            "Epoch 196/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1049 - accuracy: 0.9710 - val_loss: 0.1640 - val_accuracy: 0.9668\n",
            "Epoch 197/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1045 - accuracy: 0.9710 - val_loss: 0.1642 - val_accuracy: 0.9668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6gnpm4CjDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b513a3f-744d-4135-bdf0-d80ea11e3dbb"
      },
      "source": [
        "\n",
        "for en,month in enumerate(range(2,5)):\n",
        "  train=trn.loc[trn['month']>=month]\n",
        "  test=trn.loc[trn['month']<month-1]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  mod.compile(optimizer=Adam(0.00001,decay=1e-5),loss='binary_crossentropy',metrics='accuracy')\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  if en==0:\n",
        "    pre_2=mod.predict(tst)/4\n",
        "  else:\n",
        "    pre_2+=mod.predict(tst)/4"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "181/181 [==============================] - 2s 9ms/step - loss: 0.8374 - accuracy: 0.5165 - val_loss: 0.8940 - val_accuracy: 0.2299\n",
            "Epoch 2/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.7921 - accuracy: 0.5403 - val_loss: 0.8461 - val_accuracy: 0.3489\n",
            "Epoch 3/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.7583 - accuracy: 0.5599 - val_loss: 0.8078 - val_accuracy: 0.4079\n",
            "Epoch 4/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.7320 - accuracy: 0.5798 - val_loss: 0.7800 - val_accuracy: 0.4520\n",
            "Epoch 5/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.7100 - accuracy: 0.6005 - val_loss: 0.7576 - val_accuracy: 0.4933\n",
            "Epoch 6/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6882 - accuracy: 0.6207 - val_loss: 0.7345 - val_accuracy: 0.5424\n",
            "Epoch 7/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.6696 - accuracy: 0.6409 - val_loss: 0.7150 - val_accuracy: 0.5844\n",
            "Epoch 8/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6498 - accuracy: 0.6640 - val_loss: 0.6939 - val_accuracy: 0.6433\n",
            "Epoch 9/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6337 - accuracy: 0.6848 - val_loss: 0.6794 - val_accuracy: 0.6815\n",
            "Epoch 10/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.7073 - val_loss: 0.6626 - val_accuracy: 0.7284\n",
            "Epoch 11/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6004 - accuracy: 0.7286 - val_loss: 0.6442 - val_accuracy: 0.7758\n",
            "Epoch 12/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5844 - accuracy: 0.7506 - val_loss: 0.6258 - val_accuracy: 0.8308\n",
            "Epoch 13/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5695 - accuracy: 0.7708 - val_loss: 0.6086 - val_accuracy: 0.8626\n",
            "Epoch 14/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5533 - accuracy: 0.7925 - val_loss: 0.5964 - val_accuracy: 0.8844\n",
            "Epoch 15/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.8117 - val_loss: 0.5800 - val_accuracy: 0.9063\n",
            "Epoch 16/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.8295 - val_loss: 0.5647 - val_accuracy: 0.9205\n",
            "Epoch 17/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5075 - accuracy: 0.8458 - val_loss: 0.5515 - val_accuracy: 0.9302\n",
            "Epoch 18/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4921 - accuracy: 0.8611 - val_loss: 0.5385 - val_accuracy: 0.9352\n",
            "Epoch 19/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4771 - accuracy: 0.8753 - val_loss: 0.5268 - val_accuracy: 0.9395\n",
            "Epoch 20/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4632 - accuracy: 0.8855 - val_loss: 0.5164 - val_accuracy: 0.9428\n",
            "Epoch 21/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4483 - accuracy: 0.8975 - val_loss: 0.5005 - val_accuracy: 0.9460\n",
            "Epoch 22/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4339 - accuracy: 0.9068 - val_loss: 0.4856 - val_accuracy: 0.9489\n",
            "Epoch 23/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4214 - accuracy: 0.9142 - val_loss: 0.4741 - val_accuracy: 0.9504\n",
            "Epoch 24/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.9203 - val_loss: 0.4607 - val_accuracy: 0.9526\n",
            "Epoch 25/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.3948 - accuracy: 0.9266 - val_loss: 0.4517 - val_accuracy: 0.9540\n",
            "Epoch 26/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3817 - accuracy: 0.9310 - val_loss: 0.4410 - val_accuracy: 0.9553\n",
            "Epoch 27/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3681 - accuracy: 0.9358 - val_loss: 0.4304 - val_accuracy: 0.9558\n",
            "Epoch 28/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.3557 - accuracy: 0.9393 - val_loss: 0.4173 - val_accuracy: 0.9578\n",
            "Epoch 29/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.9435 - val_loss: 0.4076 - val_accuracy: 0.9588\n",
            "Epoch 30/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3329 - accuracy: 0.9456 - val_loss: 0.3974 - val_accuracy: 0.9592\n",
            "Epoch 31/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3216 - accuracy: 0.9474 - val_loss: 0.3857 - val_accuracy: 0.9606\n",
            "Epoch 32/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.3107 - accuracy: 0.9500 - val_loss: 0.3766 - val_accuracy: 0.9614\n",
            "Epoch 33/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.3000 - accuracy: 0.9519 - val_loss: 0.3676 - val_accuracy: 0.9619\n",
            "Epoch 34/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2905 - accuracy: 0.9535 - val_loss: 0.3597 - val_accuracy: 0.9625\n",
            "Epoch 35/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2802 - accuracy: 0.9550 - val_loss: 0.3496 - val_accuracy: 0.9633\n",
            "Epoch 36/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.2723 - accuracy: 0.9560 - val_loss: 0.3418 - val_accuracy: 0.9640\n",
            "Epoch 37/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2624 - accuracy: 0.9572 - val_loss: 0.3350 - val_accuracy: 0.9641\n",
            "Epoch 38/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2530 - accuracy: 0.9583 - val_loss: 0.3300 - val_accuracy: 0.9643\n",
            "Epoch 39/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2456 - accuracy: 0.9591 - val_loss: 0.3216 - val_accuracy: 0.9651\n",
            "Epoch 40/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2385 - accuracy: 0.9597 - val_loss: 0.3191 - val_accuracy: 0.9652\n",
            "Epoch 41/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2317 - accuracy: 0.9604 - val_loss: 0.3104 - val_accuracy: 0.9656\n",
            "Epoch 42/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2245 - accuracy: 0.9608 - val_loss: 0.3014 - val_accuracy: 0.9663\n",
            "Epoch 43/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2180 - accuracy: 0.9613 - val_loss: 0.2984 - val_accuracy: 0.9663\n",
            "Epoch 44/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2109 - accuracy: 0.9621 - val_loss: 0.2918 - val_accuracy: 0.9666\n",
            "Epoch 45/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2057 - accuracy: 0.9623 - val_loss: 0.2884 - val_accuracy: 0.9667\n",
            "Epoch 46/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1989 - accuracy: 0.9631 - val_loss: 0.2861 - val_accuracy: 0.9667\n",
            "Epoch 47/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1949 - accuracy: 0.9631 - val_loss: 0.2793 - val_accuracy: 0.9670\n",
            "Epoch 48/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1907 - accuracy: 0.9633 - val_loss: 0.2794 - val_accuracy: 0.9670\n",
            "Epoch 49/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1843 - accuracy: 0.9639 - val_loss: 0.2753 - val_accuracy: 0.9672\n",
            "Epoch 50/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1807 - accuracy: 0.9639 - val_loss: 0.2718 - val_accuracy: 0.9673\n",
            "Epoch 51/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1770 - accuracy: 0.9641 - val_loss: 0.2647 - val_accuracy: 0.9676\n",
            "Epoch 52/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1730 - accuracy: 0.9645 - val_loss: 0.2645 - val_accuracy: 0.9676\n",
            "Epoch 53/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9645 - val_loss: 0.2627 - val_accuracy: 0.9677\n",
            "Epoch 54/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1651 - accuracy: 0.9649 - val_loss: 0.2602 - val_accuracy: 0.9677\n",
            "Epoch 55/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1627 - accuracy: 0.9647 - val_loss: 0.2560 - val_accuracy: 0.9680\n",
            "Epoch 56/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1587 - accuracy: 0.9652 - val_loss: 0.2583 - val_accuracy: 0.9679\n",
            "Epoch 57/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1564 - accuracy: 0.9655 - val_loss: 0.2546 - val_accuracy: 0.9681\n",
            "Epoch 58/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1537 - accuracy: 0.9654 - val_loss: 0.2535 - val_accuracy: 0.9680\n",
            "Epoch 59/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1510 - accuracy: 0.9656 - val_loss: 0.2535 - val_accuracy: 0.9681\n",
            "Epoch 60/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1495 - accuracy: 0.9656 - val_loss: 0.2544 - val_accuracy: 0.9681\n",
            "Epoch 61/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1458 - accuracy: 0.9658 - val_loss: 0.2546 - val_accuracy: 0.9681\n",
            "Epoch 62/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1442 - accuracy: 0.9659 - val_loss: 0.2519 - val_accuracy: 0.9682\n",
            "Epoch 63/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1428 - accuracy: 0.9660 - val_loss: 0.2512 - val_accuracy: 0.9682\n",
            "Epoch 64/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1401 - accuracy: 0.9663 - val_loss: 0.2500 - val_accuracy: 0.9682\n",
            "Epoch 65/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1393 - accuracy: 0.9661 - val_loss: 0.2508 - val_accuracy: 0.9681\n",
            "Epoch 66/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1374 - accuracy: 0.9662 - val_loss: 0.2525 - val_accuracy: 0.9682\n",
            "Epoch 67/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1362 - accuracy: 0.9663 - val_loss: 0.2541 - val_accuracy: 0.9682\n",
            "Epoch 68/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1347 - accuracy: 0.9661 - val_loss: 0.2516 - val_accuracy: 0.9682\n",
            "Epoch 69/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1340 - accuracy: 0.9662 - val_loss: 0.2537 - val_accuracy: 0.9683\n",
            "Epoch 70/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1322 - accuracy: 0.9666 - val_loss: 0.2518 - val_accuracy: 0.9684\n",
            "Epoch 71/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1305 - accuracy: 0.9666 - val_loss: 0.2539 - val_accuracy: 0.9683\n",
            "Epoch 72/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.9667 - val_loss: 0.2565 - val_accuracy: 0.9683\n",
            "Epoch 73/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1291 - accuracy: 0.9666 - val_loss: 0.2551 - val_accuracy: 0.9684\n",
            "Epoch 74/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1276 - accuracy: 0.9670 - val_loss: 0.2545 - val_accuracy: 0.9684\n",
            "Epoch 75/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1274 - accuracy: 0.9667 - val_loss: 0.2602 - val_accuracy: 0.9683\n",
            "Epoch 76/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1262 - accuracy: 0.9671 - val_loss: 0.2605 - val_accuracy: 0.9684\n",
            "Epoch 77/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1255 - accuracy: 0.9669 - val_loss: 0.2580 - val_accuracy: 0.9684\n",
            "Epoch 78/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1252 - accuracy: 0.9669 - val_loss: 0.2612 - val_accuracy: 0.9684\n",
            "Epoch 79/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1248 - accuracy: 0.9669 - val_loss: 0.2598 - val_accuracy: 0.9684\n",
            "Epoch 80/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1238 - accuracy: 0.9669 - val_loss: 0.2610 - val_accuracy: 0.9684\n",
            "Epoch 81/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1229 - accuracy: 0.9671 - val_loss: 0.2634 - val_accuracy: 0.9684\n",
            "Epoch 82/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1233 - accuracy: 0.9670 - val_loss: 0.2635 - val_accuracy: 0.9685\n",
            "Epoch 83/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9671 - val_loss: 0.2636 - val_accuracy: 0.9684\n",
            "Epoch 84/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9668 - val_loss: 0.2651 - val_accuracy: 0.9685\n",
            "Epoch 85/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1209 - accuracy: 0.9674 - val_loss: 0.2673 - val_accuracy: 0.9684\n",
            "Epoch 86/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1205 - accuracy: 0.9672 - val_loss: 0.2682 - val_accuracy: 0.9684\n",
            "Epoch 87/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1205 - accuracy: 0.9673 - val_loss: 0.2683 - val_accuracy: 0.9685\n",
            "Epoch 88/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1200 - accuracy: 0.9672 - val_loss: 0.2703 - val_accuracy: 0.9684\n",
            "Epoch 89/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.9674 - val_loss: 0.2703 - val_accuracy: 0.9684\n",
            "Epoch 90/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1189 - accuracy: 0.9675 - val_loss: 0.2692 - val_accuracy: 0.9684\n",
            "Epoch 91/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1188 - accuracy: 0.9674 - val_loss: 0.2719 - val_accuracy: 0.9684\n",
            "Epoch 92/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1181 - accuracy: 0.9675 - val_loss: 0.2762 - val_accuracy: 0.9683\n",
            "Epoch 93/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1178 - accuracy: 0.9675 - val_loss: 0.2744 - val_accuracy: 0.9684\n",
            "Epoch 94/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1179 - accuracy: 0.9676 - val_loss: 0.2747 - val_accuracy: 0.9685\n",
            "Epoch 95/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1175 - accuracy: 0.9676 - val_loss: 0.2743 - val_accuracy: 0.9685\n",
            "Epoch 96/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1165 - accuracy: 0.9679 - val_loss: 0.2757 - val_accuracy: 0.9685\n",
            "Epoch 97/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.9679 - val_loss: 0.2773 - val_accuracy: 0.9685\n",
            "Epoch 98/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1168 - accuracy: 0.9676 - val_loss: 0.2805 - val_accuracy: 0.9684\n",
            "Epoch 99/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1159 - accuracy: 0.9679 - val_loss: 0.2799 - val_accuracy: 0.9685\n",
            "Epoch 100/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1156 - accuracy: 0.9681 - val_loss: 0.2798 - val_accuracy: 0.9685\n",
            "Epoch 101/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1161 - accuracy: 0.9677 - val_loss: 0.2799 - val_accuracy: 0.9685\n",
            "Epoch 102/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1155 - accuracy: 0.9678 - val_loss: 0.2827 - val_accuracy: 0.9684\n",
            "Epoch 103/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9679 - val_loss: 0.2817 - val_accuracy: 0.9685\n",
            "Epoch 104/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1147 - accuracy: 0.9681 - val_loss: 0.2825 - val_accuracy: 0.9685\n",
            "Epoch 105/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9680 - val_loss: 0.2824 - val_accuracy: 0.9685\n",
            "Epoch 106/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1147 - accuracy: 0.9681 - val_loss: 0.2843 - val_accuracy: 0.9685\n",
            "Epoch 107/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1145 - accuracy: 0.9681 - val_loss: 0.2875 - val_accuracy: 0.9685\n",
            "Epoch 108/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1141 - accuracy: 0.9681 - val_loss: 0.2853 - val_accuracy: 0.9686\n",
            "Epoch 109/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.9681 - val_loss: 0.2846 - val_accuracy: 0.9685\n",
            "Epoch 110/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9683 - val_loss: 0.2861 - val_accuracy: 0.9685\n",
            "Epoch 111/1000\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.1133 - accuracy: 0.9683 - val_loss: 0.2884 - val_accuracy: 0.9685\n",
            "Epoch 112/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1131 - accuracy: 0.9684 - val_loss: 0.2888 - val_accuracy: 0.9685\n",
            "Epoch 113/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1133 - accuracy: 0.9682 - val_loss: 0.2897 - val_accuracy: 0.9685\n",
            "Epoch 114/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1125 - accuracy: 0.9684 - val_loss: 0.2892 - val_accuracy: 0.9685\n",
            "Epoch 1/1000\n",
            "136/136 [==============================] - 2s 13ms/step - loss: 0.8453 - accuracy: 0.4932 - val_loss: 0.8768 - val_accuracy: 0.1591\n",
            "Epoch 2/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.8025 - accuracy: 0.5223 - val_loss: 0.8482 - val_accuracy: 0.2340\n",
            "Epoch 3/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.7745 - accuracy: 0.5412 - val_loss: 0.8070 - val_accuracy: 0.3104\n",
            "Epoch 4/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.7499 - accuracy: 0.5581 - val_loss: 0.7712 - val_accuracy: 0.3867\n",
            "Epoch 5/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.7302 - accuracy: 0.5762 - val_loss: 0.7426 - val_accuracy: 0.4626\n",
            "Epoch 6/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.7127 - accuracy: 0.5901 - val_loss: 0.7210 - val_accuracy: 0.5286\n",
            "Epoch 7/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.6960 - accuracy: 0.6080 - val_loss: 0.7002 - val_accuracy: 0.5994\n",
            "Epoch 8/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.6803 - accuracy: 0.6263 - val_loss: 0.6814 - val_accuracy: 0.6628\n",
            "Epoch 9/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.6650 - accuracy: 0.6431 - val_loss: 0.6676 - val_accuracy: 0.7110\n",
            "Epoch 10/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.6511 - accuracy: 0.6621 - val_loss: 0.6496 - val_accuracy: 0.7680\n",
            "Epoch 11/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.6375 - accuracy: 0.6815 - val_loss: 0.6375 - val_accuracy: 0.8018\n",
            "Epoch 12/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.6252 - accuracy: 0.6973 - val_loss: 0.6239 - val_accuracy: 0.8362\n",
            "Epoch 13/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.6119 - accuracy: 0.7171 - val_loss: 0.6103 - val_accuracy: 0.8656\n",
            "Epoch 14/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.5988 - accuracy: 0.7349 - val_loss: 0.5990 - val_accuracy: 0.8852\n",
            "Epoch 15/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.5871 - accuracy: 0.7535 - val_loss: 0.5887 - val_accuracy: 0.8995\n",
            "Epoch 16/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5746 - accuracy: 0.7711 - val_loss: 0.5781 - val_accuracy: 0.9101\n",
            "Epoch 17/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.5631 - accuracy: 0.7878 - val_loss: 0.5660 - val_accuracy: 0.9191\n",
            "Epoch 18/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.5517 - accuracy: 0.8047 - val_loss: 0.5591 - val_accuracy: 0.9235\n",
            "Epoch 19/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.5385 - accuracy: 0.8206 - val_loss: 0.5496 - val_accuracy: 0.9285\n",
            "Epoch 20/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.5271 - accuracy: 0.8355 - val_loss: 0.5367 - val_accuracy: 0.9338\n",
            "Epoch 21/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.5153 - accuracy: 0.8480 - val_loss: 0.5266 - val_accuracy: 0.9378\n",
            "Epoch 22/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.5041 - accuracy: 0.8594 - val_loss: 0.5150 - val_accuracy: 0.9408\n",
            "Epoch 23/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4928 - accuracy: 0.8715 - val_loss: 0.5060 - val_accuracy: 0.9426\n",
            "Epoch 24/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4814 - accuracy: 0.8813 - val_loss: 0.4967 - val_accuracy: 0.9451\n",
            "Epoch 25/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4705 - accuracy: 0.8904 - val_loss: 0.4854 - val_accuracy: 0.9473\n",
            "Epoch 26/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4581 - accuracy: 0.8993 - val_loss: 0.4763 - val_accuracy: 0.9489\n",
            "Epoch 27/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4483 - accuracy: 0.9060 - val_loss: 0.4664 - val_accuracy: 0.9504\n",
            "Epoch 28/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.9134 - val_loss: 0.4570 - val_accuracy: 0.9514\n",
            "Epoch 29/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.9186 - val_loss: 0.4471 - val_accuracy: 0.9526\n",
            "Epoch 30/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4170 - accuracy: 0.9233 - val_loss: 0.4384 - val_accuracy: 0.9535\n",
            "Epoch 31/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.4062 - accuracy: 0.9275 - val_loss: 0.4286 - val_accuracy: 0.9542\n",
            "Epoch 32/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3957 - accuracy: 0.9315 - val_loss: 0.4173 - val_accuracy: 0.9551\n",
            "Epoch 33/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3854 - accuracy: 0.9358 - val_loss: 0.4070 - val_accuracy: 0.9558\n",
            "Epoch 34/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3757 - accuracy: 0.9379 - val_loss: 0.3998 - val_accuracy: 0.9565\n",
            "Epoch 35/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3665 - accuracy: 0.9413 - val_loss: 0.3908 - val_accuracy: 0.9572\n",
            "Epoch 36/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3563 - accuracy: 0.9443 - val_loss: 0.3817 - val_accuracy: 0.9577\n",
            "Epoch 37/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3475 - accuracy: 0.9460 - val_loss: 0.3732 - val_accuracy: 0.9586\n",
            "Epoch 38/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3372 - accuracy: 0.9485 - val_loss: 0.3644 - val_accuracy: 0.9591\n",
            "Epoch 39/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3298 - accuracy: 0.9496 - val_loss: 0.3571 - val_accuracy: 0.9595\n",
            "Epoch 40/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3212 - accuracy: 0.9513 - val_loss: 0.3482 - val_accuracy: 0.9600\n",
            "Epoch 41/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3113 - accuracy: 0.9528 - val_loss: 0.3402 - val_accuracy: 0.9605\n",
            "Epoch 42/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.3036 - accuracy: 0.9542 - val_loss: 0.3331 - val_accuracy: 0.9609\n",
            "Epoch 43/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2965 - accuracy: 0.9557 - val_loss: 0.3260 - val_accuracy: 0.9613\n",
            "Epoch 44/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2889 - accuracy: 0.9564 - val_loss: 0.3192 - val_accuracy: 0.9618\n",
            "Epoch 45/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2809 - accuracy: 0.9576 - val_loss: 0.3121 - val_accuracy: 0.9621\n",
            "Epoch 46/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2729 - accuracy: 0.9584 - val_loss: 0.3060 - val_accuracy: 0.9624\n",
            "Epoch 47/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2657 - accuracy: 0.9592 - val_loss: 0.3001 - val_accuracy: 0.9628\n",
            "Epoch 48/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2593 - accuracy: 0.9600 - val_loss: 0.2940 - val_accuracy: 0.9630\n",
            "Epoch 49/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2528 - accuracy: 0.9606 - val_loss: 0.2876 - val_accuracy: 0.9634\n",
            "Epoch 50/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2468 - accuracy: 0.9609 - val_loss: 0.2826 - val_accuracy: 0.9636\n",
            "Epoch 51/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2411 - accuracy: 0.9615 - val_loss: 0.2780 - val_accuracy: 0.9638\n",
            "Epoch 52/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2349 - accuracy: 0.9620 - val_loss: 0.2733 - val_accuracy: 0.9639\n",
            "Epoch 53/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2295 - accuracy: 0.9625 - val_loss: 0.2678 - val_accuracy: 0.9641\n",
            "Epoch 54/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2246 - accuracy: 0.9626 - val_loss: 0.2631 - val_accuracy: 0.9643\n",
            "Epoch 55/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2188 - accuracy: 0.9633 - val_loss: 0.2578 - val_accuracy: 0.9644\n",
            "Epoch 56/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2137 - accuracy: 0.9636 - val_loss: 0.2523 - val_accuracy: 0.9647\n",
            "Epoch 57/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2090 - accuracy: 0.9639 - val_loss: 0.2487 - val_accuracy: 0.9649\n",
            "Epoch 58/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.2041 - accuracy: 0.9642 - val_loss: 0.2439 - val_accuracy: 0.9651\n",
            "Epoch 59/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1997 - accuracy: 0.9645 - val_loss: 0.2411 - val_accuracy: 0.9651\n",
            "Epoch 60/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1947 - accuracy: 0.9645 - val_loss: 0.2371 - val_accuracy: 0.9653\n",
            "Epoch 61/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1916 - accuracy: 0.9648 - val_loss: 0.2328 - val_accuracy: 0.9655\n",
            "Epoch 62/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1882 - accuracy: 0.9650 - val_loss: 0.2295 - val_accuracy: 0.9656\n",
            "Epoch 63/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1839 - accuracy: 0.9651 - val_loss: 0.2281 - val_accuracy: 0.9657\n",
            "Epoch 64/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1806 - accuracy: 0.9653 - val_loss: 0.2242 - val_accuracy: 0.9659\n",
            "Epoch 65/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1765 - accuracy: 0.9659 - val_loss: 0.2203 - val_accuracy: 0.9661\n",
            "Epoch 66/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1743 - accuracy: 0.9654 - val_loss: 0.2188 - val_accuracy: 0.9661\n",
            "Epoch 67/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1709 - accuracy: 0.9660 - val_loss: 0.2169 - val_accuracy: 0.9662\n",
            "Epoch 68/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1676 - accuracy: 0.9658 - val_loss: 0.2148 - val_accuracy: 0.9663\n",
            "Epoch 69/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1652 - accuracy: 0.9662 - val_loss: 0.2129 - val_accuracy: 0.9664\n",
            "Epoch 70/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1623 - accuracy: 0.9663 - val_loss: 0.2099 - val_accuracy: 0.9665\n",
            "Epoch 71/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1598 - accuracy: 0.9661 - val_loss: 0.2089 - val_accuracy: 0.9665\n",
            "Epoch 72/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1571 - accuracy: 0.9665 - val_loss: 0.2066 - val_accuracy: 0.9666\n",
            "Epoch 73/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1544 - accuracy: 0.9666 - val_loss: 0.2078 - val_accuracy: 0.9666\n",
            "Epoch 74/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1525 - accuracy: 0.9666 - val_loss: 0.2054 - val_accuracy: 0.9667\n",
            "Epoch 75/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1498 - accuracy: 0.9667 - val_loss: 0.2048 - val_accuracy: 0.9668\n",
            "Epoch 76/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1490 - accuracy: 0.9667 - val_loss: 0.2030 - val_accuracy: 0.9668\n",
            "Epoch 77/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1468 - accuracy: 0.9668 - val_loss: 0.2009 - val_accuracy: 0.9670\n",
            "Epoch 78/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1449 - accuracy: 0.9671 - val_loss: 0.2007 - val_accuracy: 0.9670\n",
            "Epoch 79/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1432 - accuracy: 0.9672 - val_loss: 0.1992 - val_accuracy: 0.9670\n",
            "Epoch 80/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1410 - accuracy: 0.9672 - val_loss: 0.1986 - val_accuracy: 0.9670\n",
            "Epoch 81/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1394 - accuracy: 0.9672 - val_loss: 0.1976 - val_accuracy: 0.9671\n",
            "Epoch 82/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1385 - accuracy: 0.9671 - val_loss: 0.1981 - val_accuracy: 0.9671\n",
            "Epoch 83/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1360 - accuracy: 0.9675 - val_loss: 0.1974 - val_accuracy: 0.9672\n",
            "Epoch 84/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1350 - accuracy: 0.9674 - val_loss: 0.1966 - val_accuracy: 0.9672\n",
            "Epoch 85/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1346 - accuracy: 0.9673 - val_loss: 0.1950 - val_accuracy: 0.9673\n",
            "Epoch 86/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1331 - accuracy: 0.9674 - val_loss: 0.1952 - val_accuracy: 0.9673\n",
            "Epoch 87/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1311 - accuracy: 0.9674 - val_loss: 0.1943 - val_accuracy: 0.9673\n",
            "Epoch 88/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1305 - accuracy: 0.9675 - val_loss: 0.1956 - val_accuracy: 0.9673\n",
            "Epoch 89/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1301 - accuracy: 0.9677 - val_loss: 0.1949 - val_accuracy: 0.9674\n",
            "Epoch 90/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1283 - accuracy: 0.9675 - val_loss: 0.1948 - val_accuracy: 0.9674\n",
            "Epoch 91/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1282 - accuracy: 0.9676 - val_loss: 0.1954 - val_accuracy: 0.9675\n",
            "Epoch 92/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1276 - accuracy: 0.9676 - val_loss: 0.1939 - val_accuracy: 0.9675\n",
            "Epoch 93/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9677 - val_loss: 0.1937 - val_accuracy: 0.9675\n",
            "Epoch 94/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1248 - accuracy: 0.9679 - val_loss: 0.1946 - val_accuracy: 0.9675\n",
            "Epoch 95/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1243 - accuracy: 0.9681 - val_loss: 0.1953 - val_accuracy: 0.9675\n",
            "Epoch 96/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1237 - accuracy: 0.9678 - val_loss: 0.1945 - val_accuracy: 0.9675\n",
            "Epoch 97/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1233 - accuracy: 0.9680 - val_loss: 0.1937 - val_accuracy: 0.9675\n",
            "Epoch 98/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1223 - accuracy: 0.9679 - val_loss: 0.1946 - val_accuracy: 0.9675\n",
            "Epoch 99/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1214 - accuracy: 0.9681 - val_loss: 0.1945 - val_accuracy: 0.9675\n",
            "Epoch 100/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1210 - accuracy: 0.9680 - val_loss: 0.1953 - val_accuracy: 0.9675\n",
            "Epoch 101/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1204 - accuracy: 0.9681 - val_loss: 0.1947 - val_accuracy: 0.9676\n",
            "Epoch 102/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1206 - accuracy: 0.9680 - val_loss: 0.1961 - val_accuracy: 0.9676\n",
            "Epoch 103/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1194 - accuracy: 0.9682 - val_loss: 0.1961 - val_accuracy: 0.9676\n",
            "Epoch 104/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1192 - accuracy: 0.9681 - val_loss: 0.1955 - val_accuracy: 0.9676\n",
            "Epoch 105/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1184 - accuracy: 0.9684 - val_loss: 0.1965 - val_accuracy: 0.9676\n",
            "Epoch 106/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1179 - accuracy: 0.9681 - val_loss: 0.1973 - val_accuracy: 0.9675\n",
            "Epoch 107/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1177 - accuracy: 0.9682 - val_loss: 0.1983 - val_accuracy: 0.9675\n",
            "Epoch 108/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1178 - accuracy: 0.9682 - val_loss: 0.1982 - val_accuracy: 0.9675\n",
            "Epoch 109/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1176 - accuracy: 0.9682 - val_loss: 0.1986 - val_accuracy: 0.9675\n",
            "Epoch 110/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1162 - accuracy: 0.9684 - val_loss: 0.2000 - val_accuracy: 0.9676\n",
            "Epoch 111/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1156 - accuracy: 0.9686 - val_loss: 0.2021 - val_accuracy: 0.9675\n",
            "Epoch 112/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1160 - accuracy: 0.9685 - val_loss: 0.2018 - val_accuracy: 0.9675\n",
            "Epoch 113/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1155 - accuracy: 0.9685 - val_loss: 0.2013 - val_accuracy: 0.9675\n",
            "Epoch 114/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1147 - accuracy: 0.9687 - val_loss: 0.2032 - val_accuracy: 0.9675\n",
            "Epoch 115/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1148 - accuracy: 0.9687 - val_loss: 0.2042 - val_accuracy: 0.9675\n",
            "Epoch 116/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1154 - accuracy: 0.9685 - val_loss: 0.2035 - val_accuracy: 0.9675\n",
            "Epoch 117/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1143 - accuracy: 0.9687 - val_loss: 0.2058 - val_accuracy: 0.9675\n",
            "Epoch 118/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1141 - accuracy: 0.9687 - val_loss: 0.2061 - val_accuracy: 0.9675\n",
            "Epoch 119/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1137 - accuracy: 0.9688 - val_loss: 0.2066 - val_accuracy: 0.9675\n",
            "Epoch 120/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1133 - accuracy: 0.9687 - val_loss: 0.2070 - val_accuracy: 0.9675\n",
            "Epoch 121/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1133 - accuracy: 0.9688 - val_loss: 0.2059 - val_accuracy: 0.9675\n",
            "Epoch 122/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1129 - accuracy: 0.9690 - val_loss: 0.2065 - val_accuracy: 0.9674\n",
            "Epoch 123/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1124 - accuracy: 0.9690 - val_loss: 0.2092 - val_accuracy: 0.9674\n",
            "Epoch 124/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1127 - accuracy: 0.9688 - val_loss: 0.2086 - val_accuracy: 0.9674\n",
            "Epoch 125/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1117 - accuracy: 0.9692 - val_loss: 0.2096 - val_accuracy: 0.9674\n",
            "Epoch 126/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1119 - accuracy: 0.9691 - val_loss: 0.2098 - val_accuracy: 0.9674\n",
            "Epoch 127/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1119 - accuracy: 0.9689 - val_loss: 0.2094 - val_accuracy: 0.9674\n",
            "Epoch 128/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1119 - accuracy: 0.9691 - val_loss: 0.2104 - val_accuracy: 0.9674\n",
            "Epoch 129/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1111 - accuracy: 0.9691 - val_loss: 0.2114 - val_accuracy: 0.9673\n",
            "Epoch 130/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1113 - accuracy: 0.9689 - val_loss: 0.2121 - val_accuracy: 0.9673\n",
            "Epoch 131/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1113 - accuracy: 0.9692 - val_loss: 0.2136 - val_accuracy: 0.9673\n",
            "Epoch 132/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1111 - accuracy: 0.9691 - val_loss: 0.2139 - val_accuracy: 0.9673\n",
            "Epoch 133/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1109 - accuracy: 0.9694 - val_loss: 0.2150 - val_accuracy: 0.9673\n",
            "Epoch 134/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1105 - accuracy: 0.9693 - val_loss: 0.2164 - val_accuracy: 0.9673\n",
            "Epoch 135/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1103 - accuracy: 0.9694 - val_loss: 0.2174 - val_accuracy: 0.9673\n",
            "Epoch 136/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1100 - accuracy: 0.9692 - val_loss: 0.2181 - val_accuracy: 0.9673\n",
            "Epoch 137/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1104 - accuracy: 0.9693 - val_loss: 0.2188 - val_accuracy: 0.9673\n",
            "Epoch 138/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1099 - accuracy: 0.9693 - val_loss: 0.2202 - val_accuracy: 0.9673\n",
            "Epoch 139/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1100 - accuracy: 0.9693 - val_loss: 0.2208 - val_accuracy: 0.9672\n",
            "Epoch 140/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1100 - accuracy: 0.9693 - val_loss: 0.2215 - val_accuracy: 0.9672\n",
            "Epoch 141/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1093 - accuracy: 0.9693 - val_loss: 0.2218 - val_accuracy: 0.9673\n",
            "Epoch 142/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1095 - accuracy: 0.9695 - val_loss: 0.2221 - val_accuracy: 0.9672\n",
            "Epoch 143/1000\n",
            "136/136 [==============================] - 1s 7ms/step - loss: 0.1093 - accuracy: 0.9696 - val_loss: 0.2228 - val_accuracy: 0.9672\n",
            "Epoch 1/1000\n",
            "88/88 [==============================] - 2s 21ms/step - loss: 0.8431 - accuracy: 0.5256 - val_loss: 0.6984 - val_accuracy: 0.5618\n",
            "Epoch 2/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.8144 - accuracy: 0.5356 - val_loss: 0.6614 - val_accuracy: 0.6514\n",
            "Epoch 3/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.7926 - accuracy: 0.5457 - val_loss: 0.6538 - val_accuracy: 0.6640\n",
            "Epoch 4/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.7745 - accuracy: 0.5535 - val_loss: 0.6510 - val_accuracy: 0.6728\n",
            "Epoch 5/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.7580 - accuracy: 0.5629 - val_loss: 0.6469 - val_accuracy: 0.6910\n",
            "Epoch 6/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.7446 - accuracy: 0.5736 - val_loss: 0.6440 - val_accuracy: 0.7048\n",
            "Epoch 7/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.7311 - accuracy: 0.5845 - val_loss: 0.6415 - val_accuracy: 0.7148\n",
            "Epoch 8/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.7187 - accuracy: 0.5933 - val_loss: 0.6347 - val_accuracy: 0.7403\n",
            "Epoch 9/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.7086 - accuracy: 0.6061 - val_loss: 0.6318 - val_accuracy: 0.7508\n",
            "Epoch 10/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6975 - accuracy: 0.6162 - val_loss: 0.6253 - val_accuracy: 0.7726\n",
            "Epoch 11/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.6290 - val_loss: 0.6198 - val_accuracy: 0.7920\n",
            "Epoch 12/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6778 - accuracy: 0.6394 - val_loss: 0.6182 - val_accuracy: 0.7995\n",
            "Epoch 13/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6674 - accuracy: 0.6505 - val_loss: 0.6106 - val_accuracy: 0.8204\n",
            "Epoch 14/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6600 - accuracy: 0.6642 - val_loss: 0.6082 - val_accuracy: 0.8299\n",
            "Epoch 15/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6487 - accuracy: 0.6752 - val_loss: 0.6017 - val_accuracy: 0.8480\n",
            "Epoch 16/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6413 - accuracy: 0.6881 - val_loss: 0.5955 - val_accuracy: 0.8612\n",
            "Epoch 17/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6318 - accuracy: 0.7014 - val_loss: 0.5916 - val_accuracy: 0.8700\n",
            "Epoch 18/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6235 - accuracy: 0.7125 - val_loss: 0.5851 - val_accuracy: 0.8807\n",
            "Epoch 19/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6155 - accuracy: 0.7270 - val_loss: 0.5800 - val_accuracy: 0.8894\n",
            "Epoch 20/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.6067 - accuracy: 0.7385 - val_loss: 0.5723 - val_accuracy: 0.8983\n",
            "Epoch 21/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5983 - accuracy: 0.7504 - val_loss: 0.5664 - val_accuracy: 0.9050\n",
            "Epoch 22/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5907 - accuracy: 0.7621 - val_loss: 0.5619 - val_accuracy: 0.9097\n",
            "Epoch 23/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5824 - accuracy: 0.7743 - val_loss: 0.5562 - val_accuracy: 0.9142\n",
            "Epoch 24/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5743 - accuracy: 0.7879 - val_loss: 0.5508 - val_accuracy: 0.9170\n",
            "Epoch 25/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5672 - accuracy: 0.7993 - val_loss: 0.5438 - val_accuracy: 0.9228\n",
            "Epoch 26/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5587 - accuracy: 0.8092 - val_loss: 0.5385 - val_accuracy: 0.9274\n",
            "Epoch 27/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5522 - accuracy: 0.8191 - val_loss: 0.5325 - val_accuracy: 0.9289\n",
            "Epoch 28/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5435 - accuracy: 0.8307 - val_loss: 0.5261 - val_accuracy: 0.9324\n",
            "Epoch 29/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5356 - accuracy: 0.8405 - val_loss: 0.5206 - val_accuracy: 0.9348\n",
            "Epoch 30/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5291 - accuracy: 0.8474 - val_loss: 0.5147 - val_accuracy: 0.9370\n",
            "Epoch 31/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5211 - accuracy: 0.8568 - val_loss: 0.5086 - val_accuracy: 0.9386\n",
            "Epoch 32/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5122 - accuracy: 0.8649 - val_loss: 0.4994 - val_accuracy: 0.9401\n",
            "Epoch 33/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.5059 - accuracy: 0.8728 - val_loss: 0.4943 - val_accuracy: 0.9414\n",
            "Epoch 34/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4981 - accuracy: 0.8798 - val_loss: 0.4884 - val_accuracy: 0.9429\n",
            "Epoch 35/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4897 - accuracy: 0.8864 - val_loss: 0.4823 - val_accuracy: 0.9437\n",
            "Epoch 36/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4821 - accuracy: 0.8930 - val_loss: 0.4758 - val_accuracy: 0.9452\n",
            "Epoch 37/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4752 - accuracy: 0.8979 - val_loss: 0.4705 - val_accuracy: 0.9465\n",
            "Epoch 38/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4681 - accuracy: 0.9028 - val_loss: 0.4630 - val_accuracy: 0.9479\n",
            "Epoch 39/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4618 - accuracy: 0.9074 - val_loss: 0.4571 - val_accuracy: 0.9492\n",
            "Epoch 40/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4545 - accuracy: 0.9114 - val_loss: 0.4504 - val_accuracy: 0.9500\n",
            "Epoch 41/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4474 - accuracy: 0.9154 - val_loss: 0.4448 - val_accuracy: 0.9505\n",
            "Epoch 42/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4396 - accuracy: 0.9197 - val_loss: 0.4383 - val_accuracy: 0.9512\n",
            "Epoch 43/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4334 - accuracy: 0.9224 - val_loss: 0.4314 - val_accuracy: 0.9518\n",
            "Epoch 44/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4269 - accuracy: 0.9251 - val_loss: 0.4250 - val_accuracy: 0.9525\n",
            "Epoch 45/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4197 - accuracy: 0.9283 - val_loss: 0.4205 - val_accuracy: 0.9528\n",
            "Epoch 46/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4115 - accuracy: 0.9309 - val_loss: 0.4121 - val_accuracy: 0.9542\n",
            "Epoch 47/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.4057 - accuracy: 0.9332 - val_loss: 0.4071 - val_accuracy: 0.9542\n",
            "Epoch 48/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3972 - accuracy: 0.9367 - val_loss: 0.4006 - val_accuracy: 0.9549\n",
            "Epoch 49/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3912 - accuracy: 0.9389 - val_loss: 0.3965 - val_accuracy: 0.9551\n",
            "Epoch 50/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3839 - accuracy: 0.9400 - val_loss: 0.3913 - val_accuracy: 0.9556\n",
            "Epoch 51/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3795 - accuracy: 0.9407 - val_loss: 0.3850 - val_accuracy: 0.9559\n",
            "Epoch 52/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3724 - accuracy: 0.9431 - val_loss: 0.3793 - val_accuracy: 0.9564\n",
            "Epoch 53/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3658 - accuracy: 0.9450 - val_loss: 0.3734 - val_accuracy: 0.9568\n",
            "Epoch 54/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3601 - accuracy: 0.9460 - val_loss: 0.3686 - val_accuracy: 0.9570\n",
            "Epoch 55/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3532 - accuracy: 0.9476 - val_loss: 0.3623 - val_accuracy: 0.9575\n",
            "Epoch 56/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3482 - accuracy: 0.9489 - val_loss: 0.3580 - val_accuracy: 0.9577\n",
            "Epoch 57/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3410 - accuracy: 0.9499 - val_loss: 0.3517 - val_accuracy: 0.9581\n",
            "Epoch 58/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3354 - accuracy: 0.9507 - val_loss: 0.3469 - val_accuracy: 0.9583\n",
            "Epoch 59/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3304 - accuracy: 0.9521 - val_loss: 0.3411 - val_accuracy: 0.9588\n",
            "Epoch 60/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3238 - accuracy: 0.9531 - val_loss: 0.3366 - val_accuracy: 0.9592\n",
            "Epoch 61/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3182 - accuracy: 0.9538 - val_loss: 0.3315 - val_accuracy: 0.9594\n",
            "Epoch 62/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3123 - accuracy: 0.9546 - val_loss: 0.3283 - val_accuracy: 0.9595\n",
            "Epoch 63/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3065 - accuracy: 0.9557 - val_loss: 0.3212 - val_accuracy: 0.9601\n",
            "Epoch 64/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.3031 - accuracy: 0.9567 - val_loss: 0.3173 - val_accuracy: 0.9601\n",
            "Epoch 65/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2964 - accuracy: 0.9570 - val_loss: 0.3134 - val_accuracy: 0.9602\n",
            "Epoch 66/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2911 - accuracy: 0.9574 - val_loss: 0.3078 - val_accuracy: 0.9607\n",
            "Epoch 67/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2873 - accuracy: 0.9580 - val_loss: 0.3039 - val_accuracy: 0.9608\n",
            "Epoch 68/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2811 - accuracy: 0.9590 - val_loss: 0.2991 - val_accuracy: 0.9611\n",
            "Epoch 69/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2775 - accuracy: 0.9590 - val_loss: 0.2948 - val_accuracy: 0.9613\n",
            "Epoch 70/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2713 - accuracy: 0.9606 - val_loss: 0.2912 - val_accuracy: 0.9615\n",
            "Epoch 71/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2683 - accuracy: 0.9595 - val_loss: 0.2870 - val_accuracy: 0.9617\n",
            "Epoch 72/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2636 - accuracy: 0.9608 - val_loss: 0.2840 - val_accuracy: 0.9618\n",
            "Epoch 73/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2588 - accuracy: 0.9617 - val_loss: 0.2804 - val_accuracy: 0.9619\n",
            "Epoch 74/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2544 - accuracy: 0.9621 - val_loss: 0.2765 - val_accuracy: 0.9621\n",
            "Epoch 75/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2505 - accuracy: 0.9619 - val_loss: 0.2727 - val_accuracy: 0.9622\n",
            "Epoch 76/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2459 - accuracy: 0.9626 - val_loss: 0.2695 - val_accuracy: 0.9623\n",
            "Epoch 77/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2425 - accuracy: 0.9628 - val_loss: 0.2662 - val_accuracy: 0.9625\n",
            "Epoch 78/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2372 - accuracy: 0.9631 - val_loss: 0.2625 - val_accuracy: 0.9628\n",
            "Epoch 79/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2344 - accuracy: 0.9632 - val_loss: 0.2598 - val_accuracy: 0.9628\n",
            "Epoch 80/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2291 - accuracy: 0.9642 - val_loss: 0.2569 - val_accuracy: 0.9629\n",
            "Epoch 81/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2262 - accuracy: 0.9641 - val_loss: 0.2530 - val_accuracy: 0.9631\n",
            "Epoch 82/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2234 - accuracy: 0.9640 - val_loss: 0.2503 - val_accuracy: 0.9632\n",
            "Epoch 83/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2188 - accuracy: 0.9646 - val_loss: 0.2481 - val_accuracy: 0.9634\n",
            "Epoch 84/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2163 - accuracy: 0.9647 - val_loss: 0.2455 - val_accuracy: 0.9634\n",
            "Epoch 85/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2124 - accuracy: 0.9646 - val_loss: 0.2424 - val_accuracy: 0.9635\n",
            "Epoch 86/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2094 - accuracy: 0.9652 - val_loss: 0.2386 - val_accuracy: 0.9638\n",
            "Epoch 87/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2080 - accuracy: 0.9648 - val_loss: 0.2369 - val_accuracy: 0.9638\n",
            "Epoch 88/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2026 - accuracy: 0.9657 - val_loss: 0.2343 - val_accuracy: 0.9639\n",
            "Epoch 89/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.2002 - accuracy: 0.9657 - val_loss: 0.2303 - val_accuracy: 0.9642\n",
            "Epoch 90/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1970 - accuracy: 0.9660 - val_loss: 0.2276 - val_accuracy: 0.9643\n",
            "Epoch 91/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1945 - accuracy: 0.9664 - val_loss: 0.2253 - val_accuracy: 0.9644\n",
            "Epoch 92/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1916 - accuracy: 0.9662 - val_loss: 0.2236 - val_accuracy: 0.9645\n",
            "Epoch 93/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1890 - accuracy: 0.9662 - val_loss: 0.2219 - val_accuracy: 0.9646\n",
            "Epoch 94/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1860 - accuracy: 0.9667 - val_loss: 0.2197 - val_accuracy: 0.9647\n",
            "Epoch 95/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1832 - accuracy: 0.9666 - val_loss: 0.2181 - val_accuracy: 0.9647\n",
            "Epoch 96/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1817 - accuracy: 0.9668 - val_loss: 0.2159 - val_accuracy: 0.9649\n",
            "Epoch 97/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1787 - accuracy: 0.9669 - val_loss: 0.2133 - val_accuracy: 0.9651\n",
            "Epoch 98/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1758 - accuracy: 0.9668 - val_loss: 0.2112 - val_accuracy: 0.9652\n",
            "Epoch 99/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1748 - accuracy: 0.9673 - val_loss: 0.2093 - val_accuracy: 0.9653\n",
            "Epoch 100/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9674 - val_loss: 0.2073 - val_accuracy: 0.9653\n",
            "Epoch 101/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1687 - accuracy: 0.9676 - val_loss: 0.2062 - val_accuracy: 0.9654\n",
            "Epoch 102/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1685 - accuracy: 0.9673 - val_loss: 0.2040 - val_accuracy: 0.9655\n",
            "Epoch 103/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1662 - accuracy: 0.9676 - val_loss: 0.2028 - val_accuracy: 0.9655\n",
            "Epoch 104/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1635 - accuracy: 0.9678 - val_loss: 0.2024 - val_accuracy: 0.9655\n",
            "Epoch 105/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1618 - accuracy: 0.9676 - val_loss: 0.2006 - val_accuracy: 0.9656\n",
            "Epoch 106/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1611 - accuracy: 0.9675 - val_loss: 0.1993 - val_accuracy: 0.9658\n",
            "Epoch 107/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1586 - accuracy: 0.9678 - val_loss: 0.1980 - val_accuracy: 0.9658\n",
            "Epoch 108/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1566 - accuracy: 0.9678 - val_loss: 0.1969 - val_accuracy: 0.9658\n",
            "Epoch 109/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1544 - accuracy: 0.9684 - val_loss: 0.1962 - val_accuracy: 0.9659\n",
            "Epoch 110/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 0.1535 - accuracy: 0.9680 - val_loss: 0.1941 - val_accuracy: 0.9660\n",
            "Epoch 111/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1517 - accuracy: 0.9683 - val_loss: 0.1935 - val_accuracy: 0.9660\n",
            "Epoch 112/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1504 - accuracy: 0.9681 - val_loss: 0.1928 - val_accuracy: 0.9661\n",
            "Epoch 113/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1490 - accuracy: 0.9686 - val_loss: 0.1922 - val_accuracy: 0.9661\n",
            "Epoch 114/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1461 - accuracy: 0.9682 - val_loss: 0.1906 - val_accuracy: 0.9662\n",
            "Epoch 115/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1450 - accuracy: 0.9685 - val_loss: 0.1903 - val_accuracy: 0.9662\n",
            "Epoch 116/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1442 - accuracy: 0.9689 - val_loss: 0.1898 - val_accuracy: 0.9662\n",
            "Epoch 117/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1429 - accuracy: 0.9687 - val_loss: 0.1892 - val_accuracy: 0.9662\n",
            "Epoch 118/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1420 - accuracy: 0.9688 - val_loss: 0.1884 - val_accuracy: 0.9663\n",
            "Epoch 119/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1410 - accuracy: 0.9690 - val_loss: 0.1871 - val_accuracy: 0.9663\n",
            "Epoch 120/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1385 - accuracy: 0.9689 - val_loss: 0.1867 - val_accuracy: 0.9663\n",
            "Epoch 121/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1386 - accuracy: 0.9687 - val_loss: 0.1858 - val_accuracy: 0.9664\n",
            "Epoch 122/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1367 - accuracy: 0.9691 - val_loss: 0.1853 - val_accuracy: 0.9664\n",
            "Epoch 123/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1359 - accuracy: 0.9687 - val_loss: 0.1847 - val_accuracy: 0.9664\n",
            "Epoch 124/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1338 - accuracy: 0.9689 - val_loss: 0.1843 - val_accuracy: 0.9664\n",
            "Epoch 125/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1330 - accuracy: 0.9688 - val_loss: 0.1840 - val_accuracy: 0.9664\n",
            "Epoch 126/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1329 - accuracy: 0.9690 - val_loss: 0.1835 - val_accuracy: 0.9665\n",
            "Epoch 127/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1325 - accuracy: 0.9690 - val_loss: 0.1837 - val_accuracy: 0.9665\n",
            "Epoch 128/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1310 - accuracy: 0.9691 - val_loss: 0.1839 - val_accuracy: 0.9665\n",
            "Epoch 129/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1297 - accuracy: 0.9692 - val_loss: 0.1834 - val_accuracy: 0.9665\n",
            "Epoch 130/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1285 - accuracy: 0.9693 - val_loss: 0.1830 - val_accuracy: 0.9665\n",
            "Epoch 131/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1286 - accuracy: 0.9691 - val_loss: 0.1819 - val_accuracy: 0.9666\n",
            "Epoch 132/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1276 - accuracy: 0.9692 - val_loss: 0.1828 - val_accuracy: 0.9666\n",
            "Epoch 133/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1272 - accuracy: 0.9694 - val_loss: 0.1817 - val_accuracy: 0.9666\n",
            "Epoch 134/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1256 - accuracy: 0.9696 - val_loss: 0.1821 - val_accuracy: 0.9666\n",
            "Epoch 135/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.9697 - val_loss: 0.1821 - val_accuracy: 0.9666\n",
            "Epoch 136/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1246 - accuracy: 0.9695 - val_loss: 0.1821 - val_accuracy: 0.9666\n",
            "Epoch 137/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1237 - accuracy: 0.9694 - val_loss: 0.1822 - val_accuracy: 0.9666\n",
            "Epoch 138/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1233 - accuracy: 0.9696 - val_loss: 0.1822 - val_accuracy: 0.9665\n",
            "Epoch 139/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1222 - accuracy: 0.9698 - val_loss: 0.1813 - val_accuracy: 0.9665\n",
            "Epoch 140/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1216 - accuracy: 0.9695 - val_loss: 0.1813 - val_accuracy: 0.9666\n",
            "Epoch 141/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1207 - accuracy: 0.9699 - val_loss: 0.1811 - val_accuracy: 0.9666\n",
            "Epoch 142/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1205 - accuracy: 0.9697 - val_loss: 0.1812 - val_accuracy: 0.9665\n",
            "Epoch 143/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1200 - accuracy: 0.9696 - val_loss: 0.1816 - val_accuracy: 0.9665\n",
            "Epoch 144/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1199 - accuracy: 0.9697 - val_loss: 0.1816 - val_accuracy: 0.9665\n",
            "Epoch 145/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1181 - accuracy: 0.9699 - val_loss: 0.1815 - val_accuracy: 0.9666\n",
            "Epoch 146/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1177 - accuracy: 0.9702 - val_loss: 0.1814 - val_accuracy: 0.9666\n",
            "Epoch 147/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1174 - accuracy: 0.9699 - val_loss: 0.1817 - val_accuracy: 0.9666\n",
            "Epoch 148/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1178 - accuracy: 0.9698 - val_loss: 0.1813 - val_accuracy: 0.9665\n",
            "Epoch 149/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1169 - accuracy: 0.9698 - val_loss: 0.1813 - val_accuracy: 0.9666\n",
            "Epoch 150/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1163 - accuracy: 0.9699 - val_loss: 0.1824 - val_accuracy: 0.9665\n",
            "Epoch 151/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1166 - accuracy: 0.9700 - val_loss: 0.1818 - val_accuracy: 0.9666\n",
            "Epoch 152/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1153 - accuracy: 0.9701 - val_loss: 0.1821 - val_accuracy: 0.9666\n",
            "Epoch 153/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1150 - accuracy: 0.9701 - val_loss: 0.1813 - val_accuracy: 0.9666\n",
            "Epoch 154/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1147 - accuracy: 0.9700 - val_loss: 0.1820 - val_accuracy: 0.9666\n",
            "Epoch 155/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1146 - accuracy: 0.9701 - val_loss: 0.1825 - val_accuracy: 0.9666\n",
            "Epoch 156/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1139 - accuracy: 0.9703 - val_loss: 0.1830 - val_accuracy: 0.9666\n",
            "Epoch 157/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1130 - accuracy: 0.9702 - val_loss: 0.1838 - val_accuracy: 0.9666\n",
            "Epoch 158/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1124 - accuracy: 0.9704 - val_loss: 0.1835 - val_accuracy: 0.9666\n",
            "Epoch 159/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1129 - accuracy: 0.9703 - val_loss: 0.1841 - val_accuracy: 0.9666\n",
            "Epoch 160/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1117 - accuracy: 0.9703 - val_loss: 0.1841 - val_accuracy: 0.9666\n",
            "Epoch 161/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1120 - accuracy: 0.9705 - val_loss: 0.1843 - val_accuracy: 0.9666\n",
            "Epoch 162/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1120 - accuracy: 0.9704 - val_loss: 0.1841 - val_accuracy: 0.9666\n",
            "Epoch 163/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1109 - accuracy: 0.9706 - val_loss: 0.1846 - val_accuracy: 0.9666\n",
            "Epoch 164/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1113 - accuracy: 0.9704 - val_loss: 0.1840 - val_accuracy: 0.9666\n",
            "Epoch 165/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1108 - accuracy: 0.9704 - val_loss: 0.1848 - val_accuracy: 0.9666\n",
            "Epoch 166/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1103 - accuracy: 0.9704 - val_loss: 0.1844 - val_accuracy: 0.9666\n",
            "Epoch 167/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1098 - accuracy: 0.9706 - val_loss: 0.1844 - val_accuracy: 0.9666\n",
            "Epoch 168/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1100 - accuracy: 0.9706 - val_loss: 0.1856 - val_accuracy: 0.9666\n",
            "Epoch 169/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1092 - accuracy: 0.9704 - val_loss: 0.1871 - val_accuracy: 0.9666\n",
            "Epoch 170/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1096 - accuracy: 0.9705 - val_loss: 0.1870 - val_accuracy: 0.9666\n",
            "Epoch 171/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1096 - accuracy: 0.9706 - val_loss: 0.1873 - val_accuracy: 0.9665\n",
            "Epoch 172/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1088 - accuracy: 0.9706 - val_loss: 0.1868 - val_accuracy: 0.9666\n",
            "Epoch 173/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1084 - accuracy: 0.9710 - val_loss: 0.1872 - val_accuracy: 0.9666\n",
            "Epoch 174/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1087 - accuracy: 0.9706 - val_loss: 0.1874 - val_accuracy: 0.9666\n",
            "Epoch 175/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1081 - accuracy: 0.9708 - val_loss: 0.1880 - val_accuracy: 0.9666\n",
            "Epoch 176/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1076 - accuracy: 0.9709 - val_loss: 0.1880 - val_accuracy: 0.9665\n",
            "Epoch 177/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1081 - accuracy: 0.9709 - val_loss: 0.1876 - val_accuracy: 0.9666\n",
            "Epoch 178/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1075 - accuracy: 0.9710 - val_loss: 0.1879 - val_accuracy: 0.9666\n",
            "Epoch 179/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1076 - accuracy: 0.9708 - val_loss: 0.1884 - val_accuracy: 0.9666\n",
            "Epoch 180/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1072 - accuracy: 0.9710 - val_loss: 0.1885 - val_accuracy: 0.9665\n",
            "Epoch 181/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1061 - accuracy: 0.9711 - val_loss: 0.1895 - val_accuracy: 0.9665\n",
            "Epoch 182/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1069 - accuracy: 0.9709 - val_loss: 0.1898 - val_accuracy: 0.9665\n",
            "Epoch 183/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1066 - accuracy: 0.9709 - val_loss: 0.1898 - val_accuracy: 0.9666\n",
            "Epoch 184/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1060 - accuracy: 0.9710 - val_loss: 0.1906 - val_accuracy: 0.9665\n",
            "Epoch 185/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1067 - accuracy: 0.9709 - val_loss: 0.1900 - val_accuracy: 0.9665\n",
            "Epoch 186/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1056 - accuracy: 0.9712 - val_loss: 0.1902 - val_accuracy: 0.9665\n",
            "Epoch 187/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1055 - accuracy: 0.9712 - val_loss: 0.1908 - val_accuracy: 0.9666\n",
            "Epoch 188/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1060 - accuracy: 0.9713 - val_loss: 0.1906 - val_accuracy: 0.9665\n",
            "Epoch 189/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1053 - accuracy: 0.9712 - val_loss: 0.1908 - val_accuracy: 0.9665\n",
            "Epoch 190/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1054 - accuracy: 0.9710 - val_loss: 0.1914 - val_accuracy: 0.9665\n",
            "Epoch 191/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1047 - accuracy: 0.9714 - val_loss: 0.1920 - val_accuracy: 0.9665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOdQm2sOWzCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30bfdc15-0956-4793-9fdf-0d049930acf2"
      },
      "source": [
        "\n",
        "for en,month in enumerate(range(3,5)):\n",
        "  train=trn.loc[trn['month']>=month]\n",
        "  test=trn.loc[trn['month']<month-2]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  mod.compile(optimizer=Adam(0.00001,decay=1e-5),loss='binary_crossentropy',metrics='accuracy')\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  if en==0:\n",
        "    pre_3=mod.predict(tst)/3\n",
        "  else:\n",
        "    pre_3+=mod.predict(tst)/3"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 0.8432 - accuracy: 0.5168 - val_loss: 0.7915 - val_accuracy: 0.3544\n",
            "Epoch 2/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.8034 - accuracy: 0.5359 - val_loss: 0.7493 - val_accuracy: 0.4854\n",
            "Epoch 3/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.7740 - accuracy: 0.5515 - val_loss: 0.7247 - val_accuracy: 0.5517\n",
            "Epoch 4/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.7509 - accuracy: 0.5666 - val_loss: 0.7093 - val_accuracy: 0.5889\n",
            "Epoch 5/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.7316 - accuracy: 0.5824 - val_loss: 0.6940 - val_accuracy: 0.6303\n",
            "Epoch 6/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.7128 - accuracy: 0.5986 - val_loss: 0.6822 - val_accuracy: 0.6649\n",
            "Epoch 7/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.6972 - accuracy: 0.6131 - val_loss: 0.6701 - val_accuracy: 0.7086\n",
            "Epoch 8/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.6814 - accuracy: 0.6307 - val_loss: 0.6606 - val_accuracy: 0.7381\n",
            "Epoch 9/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.6668 - accuracy: 0.6478 - val_loss: 0.6485 - val_accuracy: 0.7795\n",
            "Epoch 10/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.6521 - accuracy: 0.6651 - val_loss: 0.6377 - val_accuracy: 0.8080\n",
            "Epoch 11/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.6391 - accuracy: 0.6819 - val_loss: 0.6257 - val_accuracy: 0.8323\n",
            "Epoch 12/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.6275 - accuracy: 0.6977 - val_loss: 0.6192 - val_accuracy: 0.8480\n",
            "Epoch 13/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.6136 - accuracy: 0.7163 - val_loss: 0.6102 - val_accuracy: 0.8679\n",
            "Epoch 14/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.6013 - accuracy: 0.7338 - val_loss: 0.5989 - val_accuracy: 0.8855\n",
            "Epoch 15/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5898 - accuracy: 0.7513 - val_loss: 0.5894 - val_accuracy: 0.8995\n",
            "Epoch 16/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5777 - accuracy: 0.7672 - val_loss: 0.5793 - val_accuracy: 0.9109\n",
            "Epoch 17/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5657 - accuracy: 0.7836 - val_loss: 0.5693 - val_accuracy: 0.9199\n",
            "Epoch 18/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5520 - accuracy: 0.7996 - val_loss: 0.5602 - val_accuracy: 0.9260\n",
            "Epoch 19/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5418 - accuracy: 0.8151 - val_loss: 0.5502 - val_accuracy: 0.9311\n",
            "Epoch 20/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5292 - accuracy: 0.8295 - val_loss: 0.5424 - val_accuracy: 0.9357\n",
            "Epoch 21/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5187 - accuracy: 0.8421 - val_loss: 0.5342 - val_accuracy: 0.9386\n",
            "Epoch 22/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.5077 - accuracy: 0.8546 - val_loss: 0.5235 - val_accuracy: 0.9426\n",
            "Epoch 23/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4958 - accuracy: 0.8656 - val_loss: 0.5144 - val_accuracy: 0.9448\n",
            "Epoch 24/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4845 - accuracy: 0.8757 - val_loss: 0.5057 - val_accuracy: 0.9465\n",
            "Epoch 25/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4732 - accuracy: 0.8852 - val_loss: 0.4983 - val_accuracy: 0.9481\n",
            "Epoch 26/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4629 - accuracy: 0.8947 - val_loss: 0.4877 - val_accuracy: 0.9499\n",
            "Epoch 27/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4516 - accuracy: 0.9017 - val_loss: 0.4786 - val_accuracy: 0.9513\n",
            "Epoch 28/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4406 - accuracy: 0.9089 - val_loss: 0.4730 - val_accuracy: 0.9524\n",
            "Epoch 29/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4296 - accuracy: 0.9156 - val_loss: 0.4641 - val_accuracy: 0.9534\n",
            "Epoch 30/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4205 - accuracy: 0.9202 - val_loss: 0.4559 - val_accuracy: 0.9544\n",
            "Epoch 31/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.4090 - accuracy: 0.9252 - val_loss: 0.4493 - val_accuracy: 0.9551\n",
            "Epoch 32/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3994 - accuracy: 0.9296 - val_loss: 0.4401 - val_accuracy: 0.9559\n",
            "Epoch 33/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3887 - accuracy: 0.9341 - val_loss: 0.4301 - val_accuracy: 0.9570\n",
            "Epoch 34/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3788 - accuracy: 0.9368 - val_loss: 0.4222 - val_accuracy: 0.9575\n",
            "Epoch 35/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3691 - accuracy: 0.9399 - val_loss: 0.4162 - val_accuracy: 0.9578\n",
            "Epoch 36/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3602 - accuracy: 0.9426 - val_loss: 0.4076 - val_accuracy: 0.9589\n",
            "Epoch 37/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3494 - accuracy: 0.9453 - val_loss: 0.4006 - val_accuracy: 0.9593\n",
            "Epoch 38/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3406 - accuracy: 0.9473 - val_loss: 0.3923 - val_accuracy: 0.9598\n",
            "Epoch 39/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3322 - accuracy: 0.9495 - val_loss: 0.3854 - val_accuracy: 0.9601\n",
            "Epoch 40/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3237 - accuracy: 0.9508 - val_loss: 0.3776 - val_accuracy: 0.9608\n",
            "Epoch 41/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3156 - accuracy: 0.9527 - val_loss: 0.3715 - val_accuracy: 0.9611\n",
            "Epoch 42/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.3072 - accuracy: 0.9534 - val_loss: 0.3671 - val_accuracy: 0.9613\n",
            "Epoch 43/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2996 - accuracy: 0.9548 - val_loss: 0.3613 - val_accuracy: 0.9617\n",
            "Epoch 44/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2910 - accuracy: 0.9562 - val_loss: 0.3528 - val_accuracy: 0.9624\n",
            "Epoch 45/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2846 - accuracy: 0.9571 - val_loss: 0.3481 - val_accuracy: 0.9626\n",
            "Epoch 46/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2764 - accuracy: 0.9580 - val_loss: 0.3394 - val_accuracy: 0.9632\n",
            "Epoch 47/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2705 - accuracy: 0.9586 - val_loss: 0.3374 - val_accuracy: 0.9632\n",
            "Epoch 48/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2638 - accuracy: 0.9596 - val_loss: 0.3310 - val_accuracy: 0.9637\n",
            "Epoch 49/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2568 - accuracy: 0.9602 - val_loss: 0.3260 - val_accuracy: 0.9640\n",
            "Epoch 50/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2497 - accuracy: 0.9605 - val_loss: 0.3231 - val_accuracy: 0.9643\n",
            "Epoch 51/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2439 - accuracy: 0.9612 - val_loss: 0.3182 - val_accuracy: 0.9646\n",
            "Epoch 52/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2381 - accuracy: 0.9617 - val_loss: 0.3148 - val_accuracy: 0.9647\n",
            "Epoch 53/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2320 - accuracy: 0.9624 - val_loss: 0.3113 - val_accuracy: 0.9649\n",
            "Epoch 54/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2274 - accuracy: 0.9627 - val_loss: 0.3080 - val_accuracy: 0.9653\n",
            "Epoch 55/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2218 - accuracy: 0.9631 - val_loss: 0.3049 - val_accuracy: 0.9656\n",
            "Epoch 56/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2175 - accuracy: 0.9633 - val_loss: 0.3029 - val_accuracy: 0.9657\n",
            "Epoch 57/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2115 - accuracy: 0.9637 - val_loss: 0.2973 - val_accuracy: 0.9660\n",
            "Epoch 58/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2071 - accuracy: 0.9641 - val_loss: 0.2928 - val_accuracy: 0.9663\n",
            "Epoch 59/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.2028 - accuracy: 0.9644 - val_loss: 0.2929 - val_accuracy: 0.9662\n",
            "Epoch 60/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1993 - accuracy: 0.9643 - val_loss: 0.2896 - val_accuracy: 0.9663\n",
            "Epoch 61/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1944 - accuracy: 0.9647 - val_loss: 0.2889 - val_accuracy: 0.9663\n",
            "Epoch 62/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1906 - accuracy: 0.9651 - val_loss: 0.2864 - val_accuracy: 0.9665\n",
            "Epoch 63/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1860 - accuracy: 0.9654 - val_loss: 0.2832 - val_accuracy: 0.9668\n",
            "Epoch 64/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1828 - accuracy: 0.9655 - val_loss: 0.2789 - val_accuracy: 0.9670\n",
            "Epoch 65/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1807 - accuracy: 0.9654 - val_loss: 0.2751 - val_accuracy: 0.9670\n",
            "Epoch 66/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1767 - accuracy: 0.9655 - val_loss: 0.2745 - val_accuracy: 0.9671\n",
            "Epoch 67/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1735 - accuracy: 0.9659 - val_loss: 0.2728 - val_accuracy: 0.9671\n",
            "Epoch 68/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1709 - accuracy: 0.9658 - val_loss: 0.2725 - val_accuracy: 0.9672\n",
            "Epoch 69/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1673 - accuracy: 0.9659 - val_loss: 0.2714 - val_accuracy: 0.9673\n",
            "Epoch 70/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1652 - accuracy: 0.9661 - val_loss: 0.2683 - val_accuracy: 0.9675\n",
            "Epoch 71/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1623 - accuracy: 0.9664 - val_loss: 0.2693 - val_accuracy: 0.9676\n",
            "Epoch 72/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1603 - accuracy: 0.9663 - val_loss: 0.2684 - val_accuracy: 0.9676\n",
            "Epoch 73/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1574 - accuracy: 0.9666 - val_loss: 0.2660 - val_accuracy: 0.9677\n",
            "Epoch 74/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1545 - accuracy: 0.9668 - val_loss: 0.2663 - val_accuracy: 0.9678\n",
            "Epoch 75/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1532 - accuracy: 0.9666 - val_loss: 0.2653 - val_accuracy: 0.9678\n",
            "Epoch 76/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1508 - accuracy: 0.9667 - val_loss: 0.2637 - val_accuracy: 0.9679\n",
            "Epoch 77/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1484 - accuracy: 0.9671 - val_loss: 0.2635 - val_accuracy: 0.9679\n",
            "Epoch 78/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1469 - accuracy: 0.9669 - val_loss: 0.2654 - val_accuracy: 0.9680\n",
            "Epoch 79/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1447 - accuracy: 0.9672 - val_loss: 0.2659 - val_accuracy: 0.9679\n",
            "Epoch 80/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1428 - accuracy: 0.9674 - val_loss: 0.2636 - val_accuracy: 0.9679\n",
            "Epoch 81/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1420 - accuracy: 0.9672 - val_loss: 0.2623 - val_accuracy: 0.9681\n",
            "Epoch 82/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1404 - accuracy: 0.9673 - val_loss: 0.2630 - val_accuracy: 0.9682\n",
            "Epoch 83/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1385 - accuracy: 0.9674 - val_loss: 0.2653 - val_accuracy: 0.9681\n",
            "Epoch 84/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1370 - accuracy: 0.9676 - val_loss: 0.2676 - val_accuracy: 0.9681\n",
            "Epoch 85/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1355 - accuracy: 0.9674 - val_loss: 0.2642 - val_accuracy: 0.9682\n",
            "Epoch 86/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1346 - accuracy: 0.9677 - val_loss: 0.2659 - val_accuracy: 0.9682\n",
            "Epoch 87/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1340 - accuracy: 0.9675 - val_loss: 0.2645 - val_accuracy: 0.9682\n",
            "Epoch 88/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1325 - accuracy: 0.9675 - val_loss: 0.2655 - val_accuracy: 0.9683\n",
            "Epoch 89/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1314 - accuracy: 0.9677 - val_loss: 0.2659 - val_accuracy: 0.9683\n",
            "Epoch 90/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1301 - accuracy: 0.9678 - val_loss: 0.2636 - val_accuracy: 0.9683\n",
            "Epoch 91/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1294 - accuracy: 0.9678 - val_loss: 0.2657 - val_accuracy: 0.9683\n",
            "Epoch 92/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1281 - accuracy: 0.9678 - val_loss: 0.2674 - val_accuracy: 0.9683\n",
            "Epoch 93/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1276 - accuracy: 0.9679 - val_loss: 0.2670 - val_accuracy: 0.9683\n",
            "Epoch 94/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1265 - accuracy: 0.9682 - val_loss: 0.2689 - val_accuracy: 0.9683\n",
            "Epoch 95/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1262 - accuracy: 0.9680 - val_loss: 0.2671 - val_accuracy: 0.9684\n",
            "Epoch 96/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1252 - accuracy: 0.9680 - val_loss: 0.2690 - val_accuracy: 0.9684\n",
            "Epoch 97/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1249 - accuracy: 0.9679 - val_loss: 0.2675 - val_accuracy: 0.9684\n",
            "Epoch 98/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1236 - accuracy: 0.9680 - val_loss: 0.2685 - val_accuracy: 0.9685\n",
            "Epoch 99/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1233 - accuracy: 0.9682 - val_loss: 0.2694 - val_accuracy: 0.9685\n",
            "Epoch 100/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1221 - accuracy: 0.9681 - val_loss: 0.2661 - val_accuracy: 0.9685\n",
            "Epoch 101/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9681 - val_loss: 0.2685 - val_accuracy: 0.9685\n",
            "Epoch 102/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1210 - accuracy: 0.9684 - val_loss: 0.2711 - val_accuracy: 0.9685\n",
            "Epoch 103/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1204 - accuracy: 0.9682 - val_loss: 0.2714 - val_accuracy: 0.9685\n",
            "Epoch 104/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1208 - accuracy: 0.9683 - val_loss: 0.2687 - val_accuracy: 0.9685\n",
            "Epoch 105/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.9683 - val_loss: 0.2736 - val_accuracy: 0.9684\n",
            "Epoch 106/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.9682 - val_loss: 0.2741 - val_accuracy: 0.9685\n",
            "Epoch 107/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1192 - accuracy: 0.9682 - val_loss: 0.2729 - val_accuracy: 0.9686\n",
            "Epoch 108/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1188 - accuracy: 0.9683 - val_loss: 0.2745 - val_accuracy: 0.9686\n",
            "Epoch 109/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1188 - accuracy: 0.9683 - val_loss: 0.2729 - val_accuracy: 0.9686\n",
            "Epoch 110/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1182 - accuracy: 0.9683 - val_loss: 0.2751 - val_accuracy: 0.9685\n",
            "Epoch 111/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1175 - accuracy: 0.9685 - val_loss: 0.2759 - val_accuracy: 0.9685\n",
            "Epoch 112/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1169 - accuracy: 0.9688 - val_loss: 0.2776 - val_accuracy: 0.9685\n",
            "Epoch 113/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1171 - accuracy: 0.9686 - val_loss: 0.2757 - val_accuracy: 0.9685\n",
            "Epoch 114/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1163 - accuracy: 0.9686 - val_loss: 0.2812 - val_accuracy: 0.9684\n",
            "Epoch 115/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1163 - accuracy: 0.9688 - val_loss: 0.2775 - val_accuracy: 0.9685\n",
            "Epoch 116/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1153 - accuracy: 0.9687 - val_loss: 0.2794 - val_accuracy: 0.9684\n",
            "Epoch 117/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1154 - accuracy: 0.9688 - val_loss: 0.2812 - val_accuracy: 0.9684\n",
            "Epoch 118/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1146 - accuracy: 0.9688 - val_loss: 0.2832 - val_accuracy: 0.9685\n",
            "Epoch 119/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1144 - accuracy: 0.9687 - val_loss: 0.2848 - val_accuracy: 0.9685\n",
            "Epoch 120/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1149 - accuracy: 0.9688 - val_loss: 0.2837 - val_accuracy: 0.9685\n",
            "Epoch 121/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1142 - accuracy: 0.9688 - val_loss: 0.2831 - val_accuracy: 0.9685\n",
            "Epoch 122/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1130 - accuracy: 0.9693 - val_loss: 0.2848 - val_accuracy: 0.9685\n",
            "Epoch 123/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9691 - val_loss: 0.2869 - val_accuracy: 0.9685\n",
            "Epoch 124/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1137 - accuracy: 0.9688 - val_loss: 0.2867 - val_accuracy: 0.9685\n",
            "Epoch 125/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1133 - accuracy: 0.9689 - val_loss: 0.2890 - val_accuracy: 0.9685\n",
            "Epoch 126/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1130 - accuracy: 0.9690 - val_loss: 0.2893 - val_accuracy: 0.9685\n",
            "Epoch 127/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1126 - accuracy: 0.9691 - val_loss: 0.2883 - val_accuracy: 0.9685\n",
            "Epoch 128/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1130 - accuracy: 0.9691 - val_loss: 0.2900 - val_accuracy: 0.9685\n",
            "Epoch 129/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1123 - accuracy: 0.9692 - val_loss: 0.2906 - val_accuracy: 0.9685\n",
            "Epoch 130/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1125 - accuracy: 0.9691 - val_loss: 0.2930 - val_accuracy: 0.9685\n",
            "Epoch 131/1000\n",
            "136/136 [==============================] - 1s 6ms/step - loss: 0.1119 - accuracy: 0.9692 - val_loss: 0.2932 - val_accuracy: 0.9684\n",
            "Epoch 1/1000\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.8753 - accuracy: 0.5060 - val_loss: 0.8698 - val_accuracy: 0.1484\n",
            "Epoch 2/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.8403 - accuracy: 0.5213 - val_loss: 0.8440 - val_accuracy: 0.2688\n",
            "Epoch 3/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.8163 - accuracy: 0.5317 - val_loss: 0.8232 - val_accuracy: 0.3423\n",
            "Epoch 4/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.7944 - accuracy: 0.5418 - val_loss: 0.8165 - val_accuracy: 0.3625\n",
            "Epoch 5/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.7772 - accuracy: 0.5499 - val_loss: 0.8046 - val_accuracy: 0.3894\n",
            "Epoch 6/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.7613 - accuracy: 0.5617 - val_loss: 0.7951 - val_accuracy: 0.4036\n",
            "Epoch 7/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.7476 - accuracy: 0.5717 - val_loss: 0.7875 - val_accuracy: 0.4225\n",
            "Epoch 8/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.7340 - accuracy: 0.5805 - val_loss: 0.7844 - val_accuracy: 0.4251\n",
            "Epoch 9/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.7229 - accuracy: 0.5897 - val_loss: 0.7760 - val_accuracy: 0.4420\n",
            "Epoch 10/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.7089 - accuracy: 0.6007 - val_loss: 0.7676 - val_accuracy: 0.4614\n",
            "Epoch 11/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.7002 - accuracy: 0.6108 - val_loss: 0.7572 - val_accuracy: 0.4933\n",
            "Epoch 12/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6899 - accuracy: 0.6227 - val_loss: 0.7484 - val_accuracy: 0.5139\n",
            "Epoch 13/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6782 - accuracy: 0.6336 - val_loss: 0.7454 - val_accuracy: 0.5150\n",
            "Epoch 14/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6691 - accuracy: 0.6430 - val_loss: 0.7336 - val_accuracy: 0.5475\n",
            "Epoch 15/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6607 - accuracy: 0.6544 - val_loss: 0.7242 - val_accuracy: 0.5767\n",
            "Epoch 16/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6497 - accuracy: 0.6662 - val_loss: 0.7135 - val_accuracy: 0.6056\n",
            "Epoch 17/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6410 - accuracy: 0.6761 - val_loss: 0.7062 - val_accuracy: 0.6260\n",
            "Epoch 18/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6321 - accuracy: 0.6884 - val_loss: 0.7000 - val_accuracy: 0.6460\n",
            "Epoch 19/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6238 - accuracy: 0.6980 - val_loss: 0.6883 - val_accuracy: 0.6792\n",
            "Epoch 20/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6158 - accuracy: 0.7093 - val_loss: 0.6794 - val_accuracy: 0.7063\n",
            "Epoch 21/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.6071 - accuracy: 0.7209 - val_loss: 0.6713 - val_accuracy: 0.7303\n",
            "Epoch 22/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5996 - accuracy: 0.7315 - val_loss: 0.6599 - val_accuracy: 0.7601\n",
            "Epoch 23/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5884 - accuracy: 0.7443 - val_loss: 0.6545 - val_accuracy: 0.7734\n",
            "Epoch 24/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5811 - accuracy: 0.7540 - val_loss: 0.6460 - val_accuracy: 0.7944\n",
            "Epoch 25/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5733 - accuracy: 0.7650 - val_loss: 0.6374 - val_accuracy: 0.8136\n",
            "Epoch 26/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5666 - accuracy: 0.7757 - val_loss: 0.6277 - val_accuracy: 0.8325\n",
            "Epoch 27/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5583 - accuracy: 0.7850 - val_loss: 0.6181 - val_accuracy: 0.8517\n",
            "Epoch 28/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5493 - accuracy: 0.7978 - val_loss: 0.6138 - val_accuracy: 0.8612\n",
            "Epoch 29/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5431 - accuracy: 0.8062 - val_loss: 0.6030 - val_accuracy: 0.8783\n",
            "Epoch 30/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5340 - accuracy: 0.8175 - val_loss: 0.5944 - val_accuracy: 0.8897\n",
            "Epoch 31/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5269 - accuracy: 0.8249 - val_loss: 0.5854 - val_accuracy: 0.8985\n",
            "Epoch 32/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5182 - accuracy: 0.8346 - val_loss: 0.5758 - val_accuracy: 0.9074\n",
            "Epoch 33/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5119 - accuracy: 0.8452 - val_loss: 0.5692 - val_accuracy: 0.9130\n",
            "Epoch 34/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.5032 - accuracy: 0.8528 - val_loss: 0.5622 - val_accuracy: 0.9182\n",
            "Epoch 35/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4972 - accuracy: 0.8604 - val_loss: 0.5532 - val_accuracy: 0.9240\n",
            "Epoch 36/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4878 - accuracy: 0.8678 - val_loss: 0.5472 - val_accuracy: 0.9272\n",
            "Epoch 37/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4816 - accuracy: 0.8757 - val_loss: 0.5393 - val_accuracy: 0.9308\n",
            "Epoch 38/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4728 - accuracy: 0.8814 - val_loss: 0.5294 - val_accuracy: 0.9340\n",
            "Epoch 39/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4675 - accuracy: 0.8872 - val_loss: 0.5219 - val_accuracy: 0.9369\n",
            "Epoch 40/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4590 - accuracy: 0.8939 - val_loss: 0.5138 - val_accuracy: 0.9394\n",
            "Epoch 41/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4504 - accuracy: 0.9001 - val_loss: 0.5055 - val_accuracy: 0.9412\n",
            "Epoch 42/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4450 - accuracy: 0.9043 - val_loss: 0.4994 - val_accuracy: 0.9428\n",
            "Epoch 43/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.9101 - val_loss: 0.4939 - val_accuracy: 0.9434\n",
            "Epoch 44/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4286 - accuracy: 0.9142 - val_loss: 0.4853 - val_accuracy: 0.9455\n",
            "Epoch 45/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.9183 - val_loss: 0.4776 - val_accuracy: 0.9467\n",
            "Epoch 46/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4163 - accuracy: 0.9213 - val_loss: 0.4714 - val_accuracy: 0.9476\n",
            "Epoch 47/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4086 - accuracy: 0.9249 - val_loss: 0.4638 - val_accuracy: 0.9487\n",
            "Epoch 48/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.4021 - accuracy: 0.9282 - val_loss: 0.4568 - val_accuracy: 0.9497\n",
            "Epoch 49/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3954 - accuracy: 0.9313 - val_loss: 0.4498 - val_accuracy: 0.9505\n",
            "Epoch 50/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3889 - accuracy: 0.9332 - val_loss: 0.4420 - val_accuracy: 0.9515\n",
            "Epoch 51/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3817 - accuracy: 0.9365 - val_loss: 0.4369 - val_accuracy: 0.9519\n",
            "Epoch 52/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3760 - accuracy: 0.9387 - val_loss: 0.4307 - val_accuracy: 0.9526\n",
            "Epoch 53/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3689 - accuracy: 0.9407 - val_loss: 0.4230 - val_accuracy: 0.9535\n",
            "Epoch 54/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3624 - accuracy: 0.9430 - val_loss: 0.4158 - val_accuracy: 0.9541\n",
            "Epoch 55/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3562 - accuracy: 0.9448 - val_loss: 0.4096 - val_accuracy: 0.9548\n",
            "Epoch 56/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3513 - accuracy: 0.9456 - val_loss: 0.4034 - val_accuracy: 0.9555\n",
            "Epoch 57/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3435 - accuracy: 0.9484 - val_loss: 0.3972 - val_accuracy: 0.9557\n",
            "Epoch 58/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3387 - accuracy: 0.9488 - val_loss: 0.3903 - val_accuracy: 0.9562\n",
            "Epoch 59/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3322 - accuracy: 0.9505 - val_loss: 0.3826 - val_accuracy: 0.9569\n",
            "Epoch 60/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.3279 - accuracy: 0.9509 - val_loss: 0.3783 - val_accuracy: 0.9574\n",
            "Epoch 61/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3214 - accuracy: 0.9522 - val_loss: 0.3731 - val_accuracy: 0.9575\n",
            "Epoch 62/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3160 - accuracy: 0.9532 - val_loss: 0.3692 - val_accuracy: 0.9578\n",
            "Epoch 63/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3096 - accuracy: 0.9545 - val_loss: 0.3619 - val_accuracy: 0.9584\n",
            "Epoch 64/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3051 - accuracy: 0.9551 - val_loss: 0.3567 - val_accuracy: 0.9587\n",
            "Epoch 65/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.3003 - accuracy: 0.9552 - val_loss: 0.3514 - val_accuracy: 0.9590\n",
            "Epoch 66/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2936 - accuracy: 0.9571 - val_loss: 0.3464 - val_accuracy: 0.9590\n",
            "Epoch 67/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2888 - accuracy: 0.9576 - val_loss: 0.3428 - val_accuracy: 0.9591\n",
            "Epoch 68/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2825 - accuracy: 0.9587 - val_loss: 0.3374 - val_accuracy: 0.9594\n",
            "Epoch 69/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2790 - accuracy: 0.9592 - val_loss: 0.3324 - val_accuracy: 0.9598\n",
            "Epoch 70/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2739 - accuracy: 0.9592 - val_loss: 0.3270 - val_accuracy: 0.9602\n",
            "Epoch 71/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2698 - accuracy: 0.9601 - val_loss: 0.3227 - val_accuracy: 0.9605\n",
            "Epoch 72/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2646 - accuracy: 0.9604 - val_loss: 0.3170 - val_accuracy: 0.9608\n",
            "Epoch 73/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2601 - accuracy: 0.9609 - val_loss: 0.3148 - val_accuracy: 0.9607\n",
            "Epoch 74/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2552 - accuracy: 0.9613 - val_loss: 0.3089 - val_accuracy: 0.9612\n",
            "Epoch 75/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2518 - accuracy: 0.9620 - val_loss: 0.3054 - val_accuracy: 0.9612\n",
            "Epoch 76/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2482 - accuracy: 0.9616 - val_loss: 0.3014 - val_accuracy: 0.9614\n",
            "Epoch 77/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2431 - accuracy: 0.9629 - val_loss: 0.2984 - val_accuracy: 0.9614\n",
            "Epoch 78/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2398 - accuracy: 0.9625 - val_loss: 0.2924 - val_accuracy: 0.9618\n",
            "Epoch 79/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2365 - accuracy: 0.9631 - val_loss: 0.2879 - val_accuracy: 0.9621\n",
            "Epoch 80/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2313 - accuracy: 0.9634 - val_loss: 0.2831 - val_accuracy: 0.9623\n",
            "Epoch 81/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.2269 - accuracy: 0.9640 - val_loss: 0.2800 - val_accuracy: 0.9624\n",
            "Epoch 82/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2251 - accuracy: 0.9640 - val_loss: 0.2761 - val_accuracy: 0.9627\n",
            "Epoch 83/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2201 - accuracy: 0.9645 - val_loss: 0.2735 - val_accuracy: 0.9628\n",
            "Epoch 84/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2176 - accuracy: 0.9644 - val_loss: 0.2707 - val_accuracy: 0.9629\n",
            "Epoch 85/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2143 - accuracy: 0.9648 - val_loss: 0.2679 - val_accuracy: 0.9630\n",
            "Epoch 86/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2102 - accuracy: 0.9650 - val_loss: 0.2654 - val_accuracy: 0.9631\n",
            "Epoch 87/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2080 - accuracy: 0.9645 - val_loss: 0.2625 - val_accuracy: 0.9632\n",
            "Epoch 88/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2048 - accuracy: 0.9653 - val_loss: 0.2590 - val_accuracy: 0.9634\n",
            "Epoch 89/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.2019 - accuracy: 0.9655 - val_loss: 0.2555 - val_accuracy: 0.9636\n",
            "Epoch 90/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1982 - accuracy: 0.9658 - val_loss: 0.2538 - val_accuracy: 0.9636\n",
            "Epoch 91/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1948 - accuracy: 0.9660 - val_loss: 0.2506 - val_accuracy: 0.9637\n",
            "Epoch 92/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1930 - accuracy: 0.9662 - val_loss: 0.2473 - val_accuracy: 0.9638\n",
            "Epoch 93/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1900 - accuracy: 0.9664 - val_loss: 0.2437 - val_accuracy: 0.9640\n",
            "Epoch 94/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1876 - accuracy: 0.9663 - val_loss: 0.2423 - val_accuracy: 0.9640\n",
            "Epoch 95/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1854 - accuracy: 0.9667 - val_loss: 0.2386 - val_accuracy: 0.9642\n",
            "Epoch 96/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1816 - accuracy: 0.9669 - val_loss: 0.2363 - val_accuracy: 0.9643\n",
            "Epoch 97/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1798 - accuracy: 0.9668 - val_loss: 0.2342 - val_accuracy: 0.9644\n",
            "Epoch 98/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1769 - accuracy: 0.9668 - val_loss: 0.2326 - val_accuracy: 0.9645\n",
            "Epoch 99/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1755 - accuracy: 0.9667 - val_loss: 0.2297 - val_accuracy: 0.9646\n",
            "Epoch 100/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1724 - accuracy: 0.9673 - val_loss: 0.2276 - val_accuracy: 0.9647\n",
            "Epoch 101/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1699 - accuracy: 0.9674 - val_loss: 0.2253 - val_accuracy: 0.9648\n",
            "Epoch 102/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1684 - accuracy: 0.9675 - val_loss: 0.2233 - val_accuracy: 0.9649\n",
            "Epoch 103/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1672 - accuracy: 0.9673 - val_loss: 0.2222 - val_accuracy: 0.9648\n",
            "Epoch 104/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1650 - accuracy: 0.9674 - val_loss: 0.2200 - val_accuracy: 0.9651\n",
            "Epoch 105/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1634 - accuracy: 0.9675 - val_loss: 0.2197 - val_accuracy: 0.9652\n",
            "Epoch 106/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1608 - accuracy: 0.9678 - val_loss: 0.2167 - val_accuracy: 0.9652\n",
            "Epoch 107/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1589 - accuracy: 0.9677 - val_loss: 0.2148 - val_accuracy: 0.9655\n",
            "Epoch 108/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1575 - accuracy: 0.9679 - val_loss: 0.2137 - val_accuracy: 0.9655\n",
            "Epoch 109/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1558 - accuracy: 0.9679 - val_loss: 0.2125 - val_accuracy: 0.9654\n",
            "Epoch 110/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1543 - accuracy: 0.9680 - val_loss: 0.2110 - val_accuracy: 0.9655\n",
            "Epoch 111/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1520 - accuracy: 0.9681 - val_loss: 0.2094 - val_accuracy: 0.9657\n",
            "Epoch 112/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1508 - accuracy: 0.9682 - val_loss: 0.2096 - val_accuracy: 0.9657\n",
            "Epoch 113/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1490 - accuracy: 0.9682 - val_loss: 0.2070 - val_accuracy: 0.9658\n",
            "Epoch 114/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1476 - accuracy: 0.9684 - val_loss: 0.2068 - val_accuracy: 0.9658\n",
            "Epoch 115/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1469 - accuracy: 0.9682 - val_loss: 0.2051 - val_accuracy: 0.9659\n",
            "Epoch 116/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1454 - accuracy: 0.9682 - val_loss: 0.2047 - val_accuracy: 0.9659\n",
            "Epoch 117/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1435 - accuracy: 0.9684 - val_loss: 0.2035 - val_accuracy: 0.9659\n",
            "Epoch 118/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1426 - accuracy: 0.9687 - val_loss: 0.2025 - val_accuracy: 0.9660\n",
            "Epoch 119/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1412 - accuracy: 0.9685 - val_loss: 0.2013 - val_accuracy: 0.9661\n",
            "Epoch 120/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1400 - accuracy: 0.9685 - val_loss: 0.2008 - val_accuracy: 0.9661\n",
            "Epoch 121/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1396 - accuracy: 0.9684 - val_loss: 0.1992 - val_accuracy: 0.9662\n",
            "Epoch 122/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1378 - accuracy: 0.9688 - val_loss: 0.1987 - val_accuracy: 0.9662\n",
            "Epoch 123/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1367 - accuracy: 0.9685 - val_loss: 0.1985 - val_accuracy: 0.9663\n",
            "Epoch 124/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1357 - accuracy: 0.9685 - val_loss: 0.1962 - val_accuracy: 0.9664\n",
            "Epoch 125/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1341 - accuracy: 0.9690 - val_loss: 0.1967 - val_accuracy: 0.9664\n",
            "Epoch 126/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1335 - accuracy: 0.9687 - val_loss: 0.1967 - val_accuracy: 0.9664\n",
            "Epoch 127/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1325 - accuracy: 0.9688 - val_loss: 0.1959 - val_accuracy: 0.9665\n",
            "Epoch 128/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1317 - accuracy: 0.9688 - val_loss: 0.1955 - val_accuracy: 0.9665\n",
            "Epoch 129/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1305 - accuracy: 0.9688 - val_loss: 0.1953 - val_accuracy: 0.9666\n",
            "Epoch 130/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1298 - accuracy: 0.9691 - val_loss: 0.1950 - val_accuracy: 0.9666\n",
            "Epoch 131/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1288 - accuracy: 0.9689 - val_loss: 0.1936 - val_accuracy: 0.9667\n",
            "Epoch 132/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1288 - accuracy: 0.9688 - val_loss: 0.1933 - val_accuracy: 0.9667\n",
            "Epoch 133/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1272 - accuracy: 0.9694 - val_loss: 0.1937 - val_accuracy: 0.9667\n",
            "Epoch 134/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1264 - accuracy: 0.9689 - val_loss: 0.1944 - val_accuracy: 0.9667\n",
            "Epoch 135/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.9692 - val_loss: 0.1936 - val_accuracy: 0.9667\n",
            "Epoch 136/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.9689 - val_loss: 0.1944 - val_accuracy: 0.9667\n",
            "Epoch 137/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1246 - accuracy: 0.9690 - val_loss: 0.1925 - val_accuracy: 0.9669\n",
            "Epoch 138/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1239 - accuracy: 0.9691 - val_loss: 0.1934 - val_accuracy: 0.9669\n",
            "Epoch 139/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1234 - accuracy: 0.9692 - val_loss: 0.1934 - val_accuracy: 0.9669\n",
            "Epoch 140/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1223 - accuracy: 0.9694 - val_loss: 0.1930 - val_accuracy: 0.9669\n",
            "Epoch 141/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1215 - accuracy: 0.9696 - val_loss: 0.1928 - val_accuracy: 0.9669\n",
            "Epoch 142/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1216 - accuracy: 0.9695 - val_loss: 0.1930 - val_accuracy: 0.9669\n",
            "Epoch 143/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1205 - accuracy: 0.9694 - val_loss: 0.1933 - val_accuracy: 0.9670\n",
            "Epoch 144/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1205 - accuracy: 0.9693 - val_loss: 0.1926 - val_accuracy: 0.9670\n",
            "Epoch 145/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1194 - accuracy: 0.9694 - val_loss: 0.1926 - val_accuracy: 0.9670\n",
            "Epoch 146/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1194 - accuracy: 0.9695 - val_loss: 0.1938 - val_accuracy: 0.9669\n",
            "Epoch 147/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1185 - accuracy: 0.9698 - val_loss: 0.1931 - val_accuracy: 0.9670\n",
            "Epoch 148/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1183 - accuracy: 0.9694 - val_loss: 0.1940 - val_accuracy: 0.9670\n",
            "Epoch 149/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9697 - val_loss: 0.1936 - val_accuracy: 0.9670\n",
            "Epoch 150/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9696 - val_loss: 0.1937 - val_accuracy: 0.9671\n",
            "Epoch 151/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1171 - accuracy: 0.9693 - val_loss: 0.1941 - val_accuracy: 0.9671\n",
            "Epoch 152/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1163 - accuracy: 0.9697 - val_loss: 0.1957 - val_accuracy: 0.9671\n",
            "Epoch 153/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1161 - accuracy: 0.9696 - val_loss: 0.1961 - val_accuracy: 0.9671\n",
            "Epoch 154/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1156 - accuracy: 0.9697 - val_loss: 0.1954 - val_accuracy: 0.9671\n",
            "Epoch 155/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1147 - accuracy: 0.9698 - val_loss: 0.1960 - val_accuracy: 0.9672\n",
            "Epoch 156/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1150 - accuracy: 0.9698 - val_loss: 0.1959 - val_accuracy: 0.9672\n",
            "Epoch 157/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1144 - accuracy: 0.9698 - val_loss: 0.1958 - val_accuracy: 0.9672\n",
            "Epoch 158/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1142 - accuracy: 0.9699 - val_loss: 0.1958 - val_accuracy: 0.9672\n",
            "Epoch 159/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1143 - accuracy: 0.9697 - val_loss: 0.1950 - val_accuracy: 0.9673\n",
            "Epoch 160/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1135 - accuracy: 0.9700 - val_loss: 0.1956 - val_accuracy: 0.9673\n",
            "Epoch 161/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1135 - accuracy: 0.9699 - val_loss: 0.1954 - val_accuracy: 0.9673\n",
            "Epoch 162/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1124 - accuracy: 0.9700 - val_loss: 0.1961 - val_accuracy: 0.9674\n",
            "Epoch 163/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1118 - accuracy: 0.9701 - val_loss: 0.1960 - val_accuracy: 0.9674\n",
            "Epoch 164/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1112 - accuracy: 0.9702 - val_loss: 0.1970 - val_accuracy: 0.9674\n",
            "Epoch 165/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1111 - accuracy: 0.9701 - val_loss: 0.1983 - val_accuracy: 0.9673\n",
            "Epoch 166/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1113 - accuracy: 0.9701 - val_loss: 0.1995 - val_accuracy: 0.9673\n",
            "Epoch 167/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1109 - accuracy: 0.9700 - val_loss: 0.1985 - val_accuracy: 0.9674\n",
            "Epoch 168/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1112 - accuracy: 0.9703 - val_loss: 0.1987 - val_accuracy: 0.9674\n",
            "Epoch 169/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1103 - accuracy: 0.9701 - val_loss: 0.1988 - val_accuracy: 0.9674\n",
            "Epoch 170/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1106 - accuracy: 0.9700 - val_loss: 0.1985 - val_accuracy: 0.9674\n",
            "Epoch 171/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1098 - accuracy: 0.9701 - val_loss: 0.1984 - val_accuracy: 0.9674\n",
            "Epoch 172/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1098 - accuracy: 0.9702 - val_loss: 0.1979 - val_accuracy: 0.9674\n",
            "Epoch 173/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1093 - accuracy: 0.9702 - val_loss: 0.1986 - val_accuracy: 0.9674\n",
            "Epoch 174/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1090 - accuracy: 0.9705 - val_loss: 0.2004 - val_accuracy: 0.9673\n",
            "Epoch 175/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1097 - accuracy: 0.9703 - val_loss: 0.2004 - val_accuracy: 0.9674\n",
            "Epoch 176/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1098 - accuracy: 0.9703 - val_loss: 0.1993 - val_accuracy: 0.9674\n",
            "Epoch 177/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1085 - accuracy: 0.9706 - val_loss: 0.2007 - val_accuracy: 0.9674\n",
            "Epoch 178/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1082 - accuracy: 0.9705 - val_loss: 0.2006 - val_accuracy: 0.9673\n",
            "Epoch 179/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1084 - accuracy: 0.9704 - val_loss: 0.2001 - val_accuracy: 0.9673\n",
            "Epoch 180/1000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1075 - accuracy: 0.9706 - val_loss: 0.1996 - val_accuracy: 0.9673\n",
            "Epoch 181/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1077 - accuracy: 0.9706 - val_loss: 0.2014 - val_accuracy: 0.9673\n",
            "Epoch 182/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1076 - accuracy: 0.9704 - val_loss: 0.2013 - val_accuracy: 0.9673\n",
            "Epoch 183/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1077 - accuracy: 0.9703 - val_loss: 0.2023 - val_accuracy: 0.9674\n",
            "Epoch 184/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1077 - accuracy: 0.9706 - val_loss: 0.2025 - val_accuracy: 0.9673\n",
            "Epoch 185/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1078 - accuracy: 0.9705 - val_loss: 0.2032 - val_accuracy: 0.9673\n",
            "Epoch 186/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1071 - accuracy: 0.9707 - val_loss: 0.2045 - val_accuracy: 0.9673\n",
            "Epoch 187/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.1068 - accuracy: 0.9704 - val_loss: 0.2041 - val_accuracy: 0.9673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZP7ZacgSk89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77d87f0a-93db-4c23-cfde-a422dcf73184"
      },
      "source": [
        "pre=(pre_2+pre_3+pre)/3\n",
        "pre.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506691, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_PE_9_lxF-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ss=pd.read_csv('sample_submission.csv.zip')\n",
        "ss['isFraud']=pre\n",
        "ss=ss.set_index('TransactionID')\n",
        "ss.to_csv('sub.csv')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWwcLvsG3DgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2b6042c4-3afa-458f-e320-31436eee9668"
      },
      "source": [
        "ss.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.026307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.028804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.031692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.022375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.026066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.026307\n",
              "3663550        0.028804\n",
              "3663551        0.031692\n",
              "3663552        0.022375\n",
              "3663553        0.026066"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsV8r_MTxUNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "07be9516-749f-4d59-c7ca-4fb421bd9d69"
      },
      "source": [
        "ss.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.024190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.027627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.030551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.021533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.025596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.024190\n",
              "3663550        0.027627\n",
              "3663551        0.030551\n",
              "3663552        0.021533\n",
              "3663553        0.025596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYtlUPuCxVBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ss.to_csv('sub.csv')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw5PePWLxWIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}