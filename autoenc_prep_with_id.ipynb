{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoenc_prep_with_id.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/autoenc_prep_with_id.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYECXu2m6I7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import gc\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "be2cc795-5f0b-4ef2-ba55-1440fc1befef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJem4-mp8otc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6d12ae35-0c1c-4ce2-f1b9-2169d3239ca1"
      },
      "source": [
        "\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')\n",
        "trn=trn.drop(['isFraud'],1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (210,222) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNrwMqVr7Efu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cats=list(trn.select_dtypes(include=object))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuFAreiwFokj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dum=list(trn.filter(regex='dum'))\n",
        "cat=list(trn.select_dtypes(include=object))\n",
        "isna=list(trn.filter(regex='isna'))\n",
        "tot=dum+cat+isna+['date','month','week']\n",
        "num=[ i for i in list(trn) if i not in tot]\n",
        "for col in num:\n",
        "  trn[col+'_mean']=trn.groupby(['id'])[col].transform('mean')\n",
        "  trn[col+'_std']=trn.groupby(['id'])[col].transform('std')\n",
        "  \n",
        "  tst[col+'_mean']=tst.groupby(['id'])[col].transform('mean')\n",
        "  tst[col+'_std']=tst.groupby(['id'])[col].transform('std')\n",
        "trn=trn.drop(['id'],1)\n",
        "tst=tst.drop(['id'],1)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkujRQIB_CUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c0fbb4be-d648-4bd2-f15a-2d8ce991c44d"
      },
      "source": [
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in tqdm(cols):\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/21 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "100%|██████████| 21/21 [01:11<00:00,  3.40s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdBqOuVp7ZUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cats+=list(trn.filter(regex='dum'))\n",
        "no_dum=[i for i in list(trn) if i not in cats]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmRf4pwN5FxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKYcx1CSuEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "a4df4db3-d3fb-47dc-bbfc-f587a516323a"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 4491.95 MB\n",
            "Memory usage after optimization is: 1168.04 MB\n",
            "Decreased by 74.0%\n",
            "Memory usage of dataframe is 3854.15 MB\n",
            "Memory usage after optimization is: 1022.97 MB\n",
            "Decreased by 73.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8azxXaFE8T0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "np.random.seed(42) # NumPy\n",
        "random.seed(42) # Python"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EskXmTJOPUZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIcL-BDLW9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import concatenate\n",
        "from keras.optimizers import Adam\n",
        "def create_model():\n",
        "    K.clear_session()\n",
        "    num_inp = Input(shape=(num_shape,))\n",
        "    cat_inp = Input(shape=(cat_shape,))\n",
        "    inps = concatenate([num_inp, cat_inp])\n",
        "    x = Dense(512, activation=custom_gelu)(inps)\n",
        "    x = Dense(256, activation=custom_gelu)(x)\n",
        "    x = Dense(512, activation = custom_gelu)(x)\n",
        "    x = Dropout(.2)(x)\n",
        "    cat_out = Dense(cat_shape, activation = \"linear\")(x)\n",
        "    num_out = Dense(num_shape, activation = \"linear\")(x)\n",
        "    model = Model(inputs=[num_inp,cat_inp], outputs=[num_out, cat_out])\n",
        "    model.compile(\n",
        "        optimizer=Adam(.05, clipnorm = 1, clipvalue = 1),\n",
        "        loss=[\"mse\", \"mse\"]\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUP6flTnU2AG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "77dd830e-d9a1-41ae-d501-f27144b7b27e"
      },
      "source": [
        "X=pd.concat([trn,tst],0)\n",
        "del([trn,tst])\n",
        "gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3jsXf1YVEmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cats.remove('id')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuryyjU0VYuK",
        "colab_type": "text"
      },
      "source": [
        "Make the final dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W59njV2kUjJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "7e98a347-632e-403f-8462-bc1bd1196682"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss=StandardScaler()\n",
        "numerical=pd.DataFrame(ss.fit_transform(X[no_dum]))\n",
        "numerical.columns=no_dum\n",
        "categorical=pd.DataFrame(ss.fit_transform(X[cats]))\n",
        "categorical.columns=cats\n",
        "X=pd.concat([categorical,numerical],1)\n",
        "X=reduce_mem_usage(X)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:765: RuntimeWarning: invalid value encountered in true_divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:706: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  result = op(x, *args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 7460.84 MB\n",
            "Memory usage after optimization is: 2105.36 MB\n",
            "Decreased by 71.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf25ibJI8T5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class WarmUpLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Warmup learning rate scheduler\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup_batches, init_lr, verbose=0):\n",
        "        \"\"\"Constructor for warmup learning rate scheduler\n",
        "\n",
        "        Arguments:\n",
        "            warmup_batches {int} -- Number of batch for warmup.\n",
        "            init_lr {float} -- Learning rate after warmup.\n",
        "\n",
        "        Keyword Arguments:\n",
        "            verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
        "        \"\"\"\n",
        "\n",
        "        super(WarmUpLearningRateScheduler, self).__init__()\n",
        "        self.warmup_batches = warmup_batches\n",
        "        self.init_lr = init_lr\n",
        "        self.verbose = verbose\n",
        "        self.batch_count = 0\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.batch_count = self.batch_count + 1\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        if self.batch_count <= self.warmup_batches:\n",
        "            lr = self.batch_count*self.init_lr/self.warmup_batches\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "            if self.verbose > 0:\n",
        "                print('\\nBatch %05d: WarmUpLearningRateScheduler setting learning '\n",
        "                      'rate to %s.' % (self.batch_count + 1, lr))\n",
        "warm_up_lr = WarmUpLearningRateScheduler(400, init_lr=0.005)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyjXsW3U8Txj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "class DAESequence(Sequence):\n",
        "    def __init__(self,df,no_dum,frac=0.15,dumm=range(911),batch_size=2048):\n",
        "        self.batch_size=batch_size\n",
        "        self.frac=0.15\n",
        "        self.dumm=dumm\n",
        "        self.df=df\n",
        "        self.cat_data=df[dumm].values\n",
        "        self.num_data=df[no_dum].values\n",
        "        self.no_dumm=no_dum\n",
        "        self.len_data=df.shape[0]\n",
        "        self.columns=df.shape[1]\n",
        "        self.data=df\n",
        "        self.idx=[]\n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(ceil(self.len_data/self.batch_size))\n",
        "    \n",
        "    \n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        self.idx.append(idx)\n",
        "        last=min((idx+1)*self.batch_size,self.len_data)\n",
        "        idx=idx*self.batch_size\n",
        "        size=last-idx\n",
        "        \n",
        "        \n",
        "        inps=[]\n",
        "        outs=[]\n",
        "        output_x=self.data.iloc[idx:last]\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        data=output_x[self.no_dumm].values\n",
        "        noise_x=data.copy()\n",
        "        for i in range(len(self.no_dumm)):\n",
        "            to=np.random.randint(0,size,int(size*self.frac))\n",
        "            frm=np.random.randint(0,size,int(size*self.frac))\n",
        "            noise_x[to,i]=noise_x[frm,i]\n",
        "            \n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "        \n",
        "        data=output_x[self.dumm].values\n",
        "        noise_x=data.copy()\n",
        "        for i in range(len(self.dumm)):\n",
        "            to=np.random.randint(0,size,int(size*self.frac))\n",
        "            frm=np.random.randint(0,size,int(size*self.frac))\n",
        "            noise_x[to,i]=noise_x[frm,i]\n",
        "        \n",
        "        \n",
        "        \n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        return inps,outs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KICgfvdw7l5t",
        "colab_type": "text"
      },
      "source": [
        "Fill the std columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ryHot0g1BwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eb8221bf-2c22-47c9-b102-debb22dcb1a3"
      },
      "source": [
        "from tqdm import tqdm\n",
        "a=X.isna().sum()\n",
        "a=a[a>0]\n",
        "cls=list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "  if col in cls:\n",
        "    X[col]=X[col].fillna(X[col].mean())\n",
        "\n",
        "a=X.isna().sum()\n",
        "a=a[a>0]\n",
        "cls=list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "  X=X.drop([col],1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 218/218 [00:09<00:00, 23.69it/s]\n",
            "100%|██████████| 32/32 [01:04<00:00,  2.00s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yJJBa1Bo_zD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tot.remove('id')\n",
        "tot.remove('date')\n",
        "tot.append('day')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXdXM2kpNXgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "646f812c-5c32-46ce-f915-57fd52d97856"
      },
      "source": [
        "\n",
        "num=[ i for i in list(X) if i not in tot]\n",
        "batch_size=2048\n",
        "auto_ckpt = ModelCheckpoint(\"ae.model\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "warm_up_lr = WarmUpLearningRateScheduler(400, init_lr=0.0001)\n",
        "num_shape=len(num)\n",
        "cat_shape=len(tot)\n",
        "model_mse = create_model()\n",
        "from math import *\n",
        "gc.collect()\n",
        "epochs = 50\n",
        "batch_size=2048\n",
        "train_gen=DAESequence(X,num,batch_size=batch_size,dumm=tot)\n",
        "hist = model_mse.fit_generator(train_gen, steps_per_epoch=len(X)//batch_size, epochs=epochs,\n",
        "                           verbose=1, workers=-1,\n",
        "                           use_multiprocessing=True,\n",
        "                              callbacks=[auto_ckpt, warm_up_lr])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 1.6205 - dense_4_loss: 0.8004 - dense_3_loss: 0.8201\n",
            "Epoch 00001: loss improved from inf to 1.62051, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 1.6205 - dense_4_loss: 0.8004 - dense_3_loss: 0.8201\n",
            "Epoch 2/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 1.0455 - dense_4_loss: 0.5701 - dense_3_loss: 0.4754\n",
            "Epoch 00002: loss improved from 1.62051 to 1.04554, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 1.0455 - dense_4_loss: 0.5701 - dense_3_loss: 0.4754\n",
            "Epoch 3/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.8173 - dense_4_loss: 0.4639 - dense_3_loss: 0.3534\n",
            "Epoch 00003: loss improved from 1.04554 to 0.81731, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.8173 - dense_4_loss: 0.4639 - dense_3_loss: 0.3534\n",
            "Epoch 4/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.6970 - dense_4_loss: 0.3978 - dense_3_loss: 0.2992\n",
            "Epoch 00004: loss improved from 0.81731 to 0.69700, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.6970 - dense_4_loss: 0.3978 - dense_3_loss: 0.2992\n",
            "Epoch 5/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.6255 - dense_4_loss: 0.3595 - dense_3_loss: 0.2660\n",
            "Epoch 00005: loss improved from 0.69700 to 0.62554, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.6255 - dense_4_loss: 0.3595 - dense_3_loss: 0.2660\n",
            "Epoch 6/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.5738 - dense_4_loss: 0.3322 - dense_3_loss: 0.2416\n",
            "Epoch 00006: loss improved from 0.62554 to 0.57378, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.5738 - dense_4_loss: 0.3322 - dense_3_loss: 0.2416\n",
            "Epoch 7/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.5363 - dense_4_loss: 0.3128 - dense_3_loss: 0.2235\n",
            "Epoch 00007: loss improved from 0.57378 to 0.53632, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.5363 - dense_4_loss: 0.3128 - dense_3_loss: 0.2235\n",
            "Epoch 8/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.5063 - dense_4_loss: 0.2968 - dense_3_loss: 0.2095\n",
            "Epoch 00008: loss improved from 0.53632 to 0.50629, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.5063 - dense_4_loss: 0.2968 - dense_3_loss: 0.2095\n",
            "Epoch 9/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.4803 - dense_4_loss: 0.2839 - dense_3_loss: 0.1963\n",
            "Epoch 00009: loss improved from 0.50629 to 0.48025, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.4803 - dense_4_loss: 0.2839 - dense_3_loss: 0.1963\n",
            "Epoch 10/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.4622 - dense_4_loss: 0.2758 - dense_3_loss: 0.1863\n",
            "Epoch 00010: loss improved from 0.48025 to 0.46217, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.4622 - dense_4_loss: 0.2758 - dense_3_loss: 0.1863\n",
            "Epoch 11/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.4438 - dense_4_loss: 0.2644 - dense_3_loss: 0.1794\n",
            "Epoch 00011: loss improved from 0.46217 to 0.44383, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.4438 - dense_4_loss: 0.2644 - dense_3_loss: 0.1794\n",
            "Epoch 12/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.4323 - dense_4_loss: 0.2598 - dense_3_loss: 0.1726\n",
            "Epoch 00012: loss improved from 0.44383 to 0.43235, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.4323 - dense_4_loss: 0.2598 - dense_3_loss: 0.1726\n",
            "Epoch 13/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.4178 - dense_4_loss: 0.2506 - dense_3_loss: 0.1671\n",
            "Epoch 00013: loss improved from 0.43235 to 0.41777, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.4178 - dense_4_loss: 0.2506 - dense_3_loss: 0.1671\n",
            "Epoch 14/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.4035 - dense_4_loss: 0.2428 - dense_3_loss: 0.1608\n",
            "Epoch 00014: loss improved from 0.41777 to 0.40353, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.4035 - dense_4_loss: 0.2428 - dense_3_loss: 0.1608\n",
            "Epoch 15/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3966 - dense_4_loss: 0.2376 - dense_3_loss: 0.1590\n",
            "Epoch 00015: loss improved from 0.40353 to 0.39658, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3966 - dense_4_loss: 0.2376 - dense_3_loss: 0.1590\n",
            "Epoch 16/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3887 - dense_4_loss: 0.2338 - dense_3_loss: 0.1548\n",
            "Epoch 00016: loss improved from 0.39658 to 0.38865, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3887 - dense_4_loss: 0.2338 - dense_3_loss: 0.1548\n",
            "Epoch 17/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3840 - dense_4_loss: 0.2290 - dense_3_loss: 0.1550\n",
            "Epoch 00017: loss improved from 0.38865 to 0.38401, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3840 - dense_4_loss: 0.2290 - dense_3_loss: 0.1550\n",
            "Epoch 18/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3760 - dense_4_loss: 0.2258 - dense_3_loss: 0.1501\n",
            "Epoch 00018: loss improved from 0.38401 to 0.37596, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3760 - dense_4_loss: 0.2258 - dense_3_loss: 0.1501\n",
            "Epoch 19/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3716 - dense_4_loss: 0.2230 - dense_3_loss: 0.1486\n",
            "Epoch 00019: loss improved from 0.37596 to 0.37157, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3716 - dense_4_loss: 0.2230 - dense_3_loss: 0.1486\n",
            "Epoch 20/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3629 - dense_4_loss: 0.2183 - dense_3_loss: 0.1446\n",
            "Epoch 00020: loss improved from 0.37157 to 0.36290, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3629 - dense_4_loss: 0.2183 - dense_3_loss: 0.1446\n",
            "Epoch 21/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3580 - dense_4_loss: 0.2137 - dense_3_loss: 0.1444\n",
            "Epoch 00021: loss improved from 0.36290 to 0.35803, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3580 - dense_4_loss: 0.2137 - dense_3_loss: 0.1444\n",
            "Epoch 22/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3564 - dense_4_loss: 0.2120 - dense_3_loss: 0.1444\n",
            "Epoch 00022: loss improved from 0.35803 to 0.35636, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3564 - dense_4_loss: 0.2120 - dense_3_loss: 0.1444\n",
            "Epoch 23/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3528 - dense_4_loss: 0.2097 - dense_3_loss: 0.1431\n",
            "Epoch 00023: loss improved from 0.35636 to 0.35278, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3528 - dense_4_loss: 0.2097 - dense_3_loss: 0.1431\n",
            "Epoch 24/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3467 - dense_4_loss: 0.2082 - dense_3_loss: 0.1385\n",
            "Epoch 00024: loss improved from 0.35278 to 0.34675, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3467 - dense_4_loss: 0.2082 - dense_3_loss: 0.1385\n",
            "Epoch 25/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3428 - dense_4_loss: 0.2058 - dense_3_loss: 0.1370\n",
            "Epoch 00025: loss improved from 0.34675 to 0.34282, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3428 - dense_4_loss: 0.2058 - dense_3_loss: 0.1370\n",
            "Epoch 26/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3464 - dense_4_loss: 0.2076 - dense_3_loss: 0.1388\n",
            "Epoch 00026: loss did not improve from 0.34282\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3464 - dense_4_loss: 0.2076 - dense_3_loss: 0.1388\n",
            "Epoch 27/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3373 - dense_4_loss: 0.2020 - dense_3_loss: 0.1353\n",
            "Epoch 00027: loss improved from 0.34282 to 0.33732, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3373 - dense_4_loss: 0.2020 - dense_3_loss: 0.1353\n",
            "Epoch 28/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3363 - dense_4_loss: 0.1999 - dense_3_loss: 0.1364\n",
            "Epoch 00028: loss improved from 0.33732 to 0.33626, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3363 - dense_4_loss: 0.1999 - dense_3_loss: 0.1364\n",
            "Epoch 29/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3349 - dense_4_loss: 0.2003 - dense_3_loss: 0.1346\n",
            "Epoch 00029: loss improved from 0.33626 to 0.33485, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3349 - dense_4_loss: 0.2003 - dense_3_loss: 0.1346\n",
            "Epoch 30/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3298 - dense_4_loss: 0.1973 - dense_3_loss: 0.1325\n",
            "Epoch 00030: loss improved from 0.33485 to 0.32977, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3298 - dense_4_loss: 0.1973 - dense_3_loss: 0.1325\n",
            "Epoch 31/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3276 - dense_4_loss: 0.1969 - dense_3_loss: 0.1307\n",
            "Epoch 00031: loss improved from 0.32977 to 0.32762, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3276 - dense_4_loss: 0.1969 - dense_3_loss: 0.1307\n",
            "Epoch 32/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3266 - dense_4_loss: 0.1949 - dense_3_loss: 0.1317\n",
            "Epoch 00032: loss improved from 0.32762 to 0.32663, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3266 - dense_4_loss: 0.1949 - dense_3_loss: 0.1317\n",
            "Epoch 33/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3237 - dense_4_loss: 0.1961 - dense_3_loss: 0.1276\n",
            "Epoch 00033: loss improved from 0.32663 to 0.32372, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3237 - dense_4_loss: 0.1961 - dense_3_loss: 0.1276\n",
            "Epoch 34/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3204 - dense_4_loss: 0.1921 - dense_3_loss: 0.1283\n",
            "Epoch 00034: loss improved from 0.32372 to 0.32039, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3204 - dense_4_loss: 0.1921 - dense_3_loss: 0.1283\n",
            "Epoch 35/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3186 - dense_4_loss: 0.1920 - dense_3_loss: 0.1267\n",
            "Epoch 00035: loss improved from 0.32039 to 0.31862, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3186 - dense_4_loss: 0.1920 - dense_3_loss: 0.1267\n",
            "Epoch 36/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3169 - dense_4_loss: 0.1901 - dense_3_loss: 0.1268\n",
            "Epoch 00036: loss improved from 0.31862 to 0.31693, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3169 - dense_4_loss: 0.1901 - dense_3_loss: 0.1268\n",
            "Epoch 37/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3175 - dense_4_loss: 0.1900 - dense_3_loss: 0.1275\n",
            "Epoch 00037: loss did not improve from 0.31693\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3175 - dense_4_loss: 0.1900 - dense_3_loss: 0.1275\n",
            "Epoch 38/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3150 - dense_4_loss: 0.1888 - dense_3_loss: 0.1262\n",
            "Epoch 00038: loss improved from 0.31693 to 0.31503, saving model to ae.model\n",
            "535/535 [==============================] - 40s 76ms/step - loss: 0.3150 - dense_4_loss: 0.1888 - dense_3_loss: 0.1262\n",
            "Epoch 39/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3126 - dense_4_loss: 0.1888 - dense_3_loss: 0.1238\n",
            "Epoch 00039: loss improved from 0.31503 to 0.31255, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3126 - dense_4_loss: 0.1888 - dense_3_loss: 0.1238\n",
            "Epoch 40/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3137 - dense_4_loss: 0.1874 - dense_3_loss: 0.1263\n",
            "Epoch 00040: loss did not improve from 0.31255\n",
            "535/535 [==============================] - 41s 76ms/step - loss: 0.3137 - dense_4_loss: 0.1874 - dense_3_loss: 0.1263\n",
            "Epoch 41/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3101 - dense_4_loss: 0.1870 - dense_3_loss: 0.1231\n",
            "Epoch 00041: loss improved from 0.31255 to 0.31007, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3101 - dense_4_loss: 0.1870 - dense_3_loss: 0.1231\n",
            "Epoch 42/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3073 - dense_4_loss: 0.1856 - dense_3_loss: 0.1217\n",
            "Epoch 00042: loss improved from 0.31007 to 0.30731, saving model to ae.model\n",
            "535/535 [==============================] - 41s 76ms/step - loss: 0.3073 - dense_4_loss: 0.1856 - dense_3_loss: 0.1217\n",
            "Epoch 43/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3067 - dense_4_loss: 0.1845 - dense_3_loss: 0.1222\n",
            "Epoch 00043: loss improved from 0.30731 to 0.30670, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3067 - dense_4_loss: 0.1845 - dense_3_loss: 0.1222\n",
            "Epoch 44/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3086 - dense_4_loss: 0.1844 - dense_3_loss: 0.1242\n",
            "Epoch 00044: loss did not improve from 0.30670\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3086 - dense_4_loss: 0.1844 - dense_3_loss: 0.1242\n",
            "Epoch 45/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3076 - dense_4_loss: 0.1854 - dense_3_loss: 0.1222\n",
            "Epoch 00045: loss did not improve from 0.30670\n",
            "535/535 [==============================] - 41s 77ms/step - loss: 0.3076 - dense_4_loss: 0.1854 - dense_3_loss: 0.1222\n",
            "Epoch 46/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3035 - dense_4_loss: 0.1831 - dense_3_loss: 0.1204\n",
            "Epoch 00046: loss improved from 0.30670 to 0.30350, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3035 - dense_4_loss: 0.1831 - dense_3_loss: 0.1204\n",
            "Epoch 47/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3056 - dense_4_loss: 0.1836 - dense_3_loss: 0.1220\n",
            "Epoch 00047: loss did not improve from 0.30350\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3056 - dense_4_loss: 0.1836 - dense_3_loss: 0.1220\n",
            "Epoch 48/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3009 - dense_4_loss: 0.1806 - dense_3_loss: 0.1203\n",
            "Epoch 00048: loss improved from 0.30350 to 0.30092, saving model to ae.model\n",
            "535/535 [==============================] - 40s 75ms/step - loss: 0.3009 - dense_4_loss: 0.1806 - dense_3_loss: 0.1203\n",
            "Epoch 49/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2998 - dense_4_loss: 0.1808 - dense_3_loss: 0.1190\n",
            "Epoch 00049: loss improved from 0.30092 to 0.29978, saving model to ae.model\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.2998 - dense_4_loss: 0.1808 - dense_3_loss: 0.1190\n",
            "Epoch 50/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3050 - dense_4_loss: 0.1836 - dense_3_loss: 0.1215\n",
            "Epoch 00050: loss did not improve from 0.29978\n",
            "535/535 [==============================] - 40s 74ms/step - loss: 0.3050 - dense_4_loss: 0.1836 - dense_3_loss: 0.1215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz4LdSiR0bem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f43bf7e7-ff6d-4f13-8c66-37af9f10bef5"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7kGh-p9H_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "8019bfa3-ec30-4bda-98ab-660810c3283f"
      },
      "source": [
        "mod=Model(inputs=model_mse.inputs,outputs=model_mse.layers[4].output)\n",
        "mod.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 615)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 350)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 965)          0           input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          494592      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 625,920\n",
            "Trainable params: 625,920\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMPMxxWQ0dgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f27d7e56-30ff-4da4-cc1d-1ff49fd61fce"
      },
      "source": [
        "pre=mod.predict((X[num],X[tot]))\n",
        "pre.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1097231, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vlRpVoF0fsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/gdrive/My Drive/fraud/with_id.npy',pre)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XNkvXTE03Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}