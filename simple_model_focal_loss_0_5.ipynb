{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_focal_loss_0.5",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_focal_loss_0_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "59c04b86-705d-4345-99fb-7b2df85b5b7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "a1c9cdb8-c674-4a4e-940c-ebd65d555f86"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 76.5MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 79% 41.0M/52.2M [00:02<00:01, 9.16MB/s]\n",
            "100% 52.2M/52.2M [00:02<00:00, 18.4MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 84% 49.0M/58.3M [00:02<00:00, 16.9MB/s]\n",
            "100% 58.3M/58.3M [00:03<00:00, 20.3MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 106MB/s]\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 108MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold=5\n",
        "lr=0.001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')\n",
        "ls=list(trn.filter(regex='V'))\n",
        "trn=trn.drop(ls,1)\n",
        "tst=tst.drop(ls,1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDrCIAqHzl6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "5baecd36-ae8c-470b-e086-025e2d16263d"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in cols:\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EWJ-hzcznam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "ss=StandardScaler()\n",
        "frd=trn['isFraud']\n",
        "ls=list(trn)\n",
        "trn=ss.fit_transform(trn.drop(['isFraud'],1))\n",
        "trn=pd.DataFrame(trn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF5OQjb1zo6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls.remove('isFraud')\n",
        "trn.columns=ls\n",
        "trn['isFraud']=frd\n",
        "\n",
        "ls=list(tst)\n",
        "tst=ss.fit_transform(tst)\n",
        "tst=pd.DataFrame(tst)\n",
        "tst.columns=ls"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "bb08990b-573a-46d1-d3bb-fec482d24699"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 860.54 MB\n",
            "Memory usage after optimization is: 215.14 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 734.49 MB\n",
            "Memory usage after optimization is: 183.62 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "77b2453c-e4a3-41a8-eaeb-5a9309df7642"
      },
      "source": [
        "trn_n=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_n=pd.read_csv('test_transaction.csv.zip')\n",
        "trn['month']=trn_n['TransactionDT']//(86400*30)\n",
        "trn_n.head()\n",
        "trn_ls=list(trn_n)\n",
        "tst_ls=list(tst_n)\n",
        "for col in trn:\n",
        "  if col in trn_ls:\n",
        "    trn[col+'_isna']=trn_n[col].isna().astype('uint8')\n",
        "for col in tst:\n",
        "  if col in tst_ls:\n",
        "    tst[col+'_isna']=tst_n[col].isna().astype('uint8')\n",
        "import gc\n",
        "del([trn_n,tst_n])\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f0r3SuH1K97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.drop(['isFraud_isna'],1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HQ20JqWATak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        if self.ep%10==0:\n",
        "          y_pred_val = self.model.predict(self.x_val)\n",
        "          roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "          print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnQIVOLKBFIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e21cf9cc-ec00-465b-afc5-ee355d67d360"
      },
      "source": [
        "1-0.036"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6gnpm4CjDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1439ebb2-2c86-4eef-8ad5-5c45a7a6c4b3"
      },
      "source": [
        "def fl():\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        gamma=0.5\n",
        "        alpha=1-0.036\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\n",
        "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
        "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
        "\n",
        "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
        "    return focal_loss\n",
        "dk={}\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "  inp=Input((233,))\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=inp,outputs=x)\n",
        "  return mod\n",
        "for en,month in enumerate([(4,5),(3,4),(3,5)]):\n",
        "  train=trn.loc[trn['month']>=month[1]]\n",
        "  test=trn.loc[trn['month']<=month[0]]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  mod.compile(optimizer=Adam(0.0001,decay=1e-3),loss=fl())\n",
        "  roc = RocCallback(\n",
        "                  validation_data=(test.drop(['isFraud'],1), test['isFraud']))\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es,roc])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  df=trn.loc[trn['month']==6].reset_index(drop=True).drop(['month'],1)\n",
        "  pre=mod.predict(df.drop(['isFraud'],1))\n",
        "  scr=roc_auc_score(df['isFraud'],pre)\n",
        "  dk[str(scr)]=mod.predict(tst)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "47/47 [==============================] - 1s 27ms/step - loss: 84.9736 - val_loss: 62.4354\n",
            "Epoch 2/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 74.8832 - val_loss: 62.1139\n",
            "Epoch 3/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 70.1803 - val_loss: 61.8624\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 66.9904 - val_loss: 61.6686\n",
            "Epoch 5/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 65.7614 - val_loss: 61.0666\n",
            "Epoch 6/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 63.7032 - val_loss: 60.7776\n",
            "Epoch 7/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 63.2693 - val_loss: 60.5598\n",
            "Epoch 8/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 60.9303 - val_loss: 60.2755\n",
            "Epoch 9/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 60.5064 - val_loss: 59.9544\n",
            "Epoch 10/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 59.3322roc-auc_val: 0.7807\n",
            "47/47 [==============================] - 14s 304ms/step - loss: 59.4481 - val_loss: 59.5972\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 59.2208 - val_loss: 59.4905\n",
            "Epoch 12/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 57.5575 - val_loss: 59.1406\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 56.7517 - val_loss: 58.7260\n",
            "Epoch 14/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 56.8062 - val_loss: 58.3991\n",
            "Epoch 15/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 55.8590 - val_loss: 58.0030\n",
            "Epoch 16/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 55.5317 - val_loss: 58.0082\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 54.9328 - val_loss: 57.6041\n",
            "Epoch 18/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 54.3349 - val_loss: 57.5053\n",
            "Epoch 19/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 54.1658 - val_loss: 57.5140\n",
            "Epoch 20/1000\n",
            "40/47 [========================>.....] - ETA: 0s - loss: 53.1625roc-auc_val: 0.7921\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 52.7397 - val_loss: 57.5079\n",
            "Epoch 21/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 53.4362 - val_loss: 57.3430\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 53.7839 - val_loss: 57.2926\n",
            "Epoch 23/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 52.2206 - val_loss: 57.0885\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 52.4325 - val_loss: 56.9937\n",
            "Epoch 25/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 52.2084 - val_loss: 56.9971\n",
            "Epoch 26/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 51.6743 - val_loss: 57.0590\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 51.6923 - val_loss: 57.0198\n",
            "Epoch 28/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 51.3356 - val_loss: 56.8327\n",
            "Epoch 29/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.8577 - val_loss: 56.7552\n",
            "Epoch 30/1000\n",
            "40/47 [========================>.....] - ETA: 0s - loss: 50.8301roc-auc_val: 0.797\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 50.6806 - val_loss: 56.7543\n",
            "Epoch 31/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.3361 - val_loss: 56.6322\n",
            "Epoch 32/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.3445 - val_loss: 56.7411\n",
            "Epoch 33/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.0034 - val_loss: 56.8091\n",
            "Epoch 34/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.0577 - val_loss: 56.6407\n",
            "Epoch 35/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.2339 - val_loss: 56.5295\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 49.2966 - val_loss: 56.5083\n",
            "Epoch 37/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 48.9828 - val_loss: 56.5607\n",
            "Epoch 38/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 49.3545 - val_loss: 56.3675\n",
            "Epoch 39/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 49.1608 - val_loss: 56.3916\n",
            "Epoch 40/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 49.5427roc-auc_val: 0.8005\n",
            "47/47 [==============================] - 14s 306ms/step - loss: 49.1060 - val_loss: 56.3794\n",
            "Epoch 41/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 49.0333 - val_loss: 56.3742\n",
            "Epoch 42/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 49.0880 - val_loss: 56.3408\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 48.8558 - val_loss: 56.3584\n",
            "Epoch 44/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 47.5102 - val_loss: 56.2757\n",
            "Epoch 45/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 48.1679 - val_loss: 56.2948\n",
            "Epoch 46/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 47.9690 - val_loss: 56.2550\n",
            "Epoch 47/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 47.3188 - val_loss: 56.2428\n",
            "Epoch 48/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 47.8512 - val_loss: 56.3311\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 47.3861 - val_loss: 56.3200\n",
            "Epoch 50/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 47.6510roc-auc_val: 0.8023\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 47.4288 - val_loss: 56.2878\n",
            "Epoch 51/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.5627 - val_loss: 56.3128\n",
            "Epoch 52/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 47.5791 - val_loss: 56.2815\n",
            "Epoch 53/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 47.0216 - val_loss: 56.2990\n",
            "Epoch 54/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.4661 - val_loss: 56.3109\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.9902 - val_loss: 56.1733\n",
            "Epoch 56/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.0021 - val_loss: 56.1494\n",
            "Epoch 57/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.6158 - val_loss: 56.1919\n",
            "Epoch 58/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.7593 - val_loss: 56.1755\n",
            "Epoch 59/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.1976 - val_loss: 56.1082\n",
            "Epoch 60/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 45.9035roc-auc_val: 0.8043\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 45.3759 - val_loss: 56.1252\n",
            "Epoch 61/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.5735 - val_loss: 56.1132\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.0321 - val_loss: 56.0672\n",
            "Epoch 63/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.9040 - val_loss: 56.0168\n",
            "Epoch 64/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.6557 - val_loss: 56.0245\n",
            "Epoch 65/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.0544 - val_loss: 56.0493\n",
            "Epoch 66/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.4190 - val_loss: 56.0656\n",
            "Epoch 67/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.0518 - val_loss: 56.0157\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.9835 - val_loss: 56.0126\n",
            "Epoch 69/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.4705 - val_loss: 55.9795\n",
            "Epoch 70/1000\n",
            "40/47 [========================>.....] - ETA: 0s - loss: 45.2292roc-auc_val: 0.806\n",
            "47/47 [==============================] - 14s 298ms/step - loss: 45.0837 - val_loss: 56.0147\n",
            "Epoch 71/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.1806 - val_loss: 56.0501\n",
            "Epoch 72/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.4083 - val_loss: 56.0823\n",
            "Epoch 73/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.3615 - val_loss: 56.0236\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.4249 - val_loss: 56.0745\n",
            "Epoch 75/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.1073 - val_loss: 56.0485\n",
            "Epoch 76/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.7038 - val_loss: 56.0030\n",
            "Epoch 77/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.7990 - val_loss: 56.0253\n",
            "Epoch 78/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.8273 - val_loss: 56.0128\n",
            "Epoch 79/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.3356 - val_loss: 56.0666\n",
            "Epoch 80/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 44.6726roc-auc_val: 0.8063\n",
            "47/47 [==============================] - 14s 298ms/step - loss: 44.3338 - val_loss: 56.0440\n",
            "Epoch 81/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.2623 - val_loss: 56.0549\n",
            "Epoch 82/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.0959 - val_loss: 56.1054\n",
            "Epoch 83/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 44.1392 - val_loss: 56.1468\n",
            "Epoch 84/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 43.9096 - val_loss: 56.1138\n",
            "Epoch 85/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.5109 - val_loss: 56.1261\n",
            "Epoch 86/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.9867 - val_loss: 56.1280\n",
            "Epoch 87/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.0112 - val_loss: 56.1143\n",
            "Epoch 88/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.3261 - val_loss: 56.1044\n",
            "Epoch 89/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.1253 - val_loss: 56.0738\n",
            "Epoch 90/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 43.9008roc-auc_val: 0.8077\n",
            "47/47 [==============================] - 14s 301ms/step - loss: 43.5945 - val_loss: 56.0812\n",
            "Epoch 91/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 43.3951 - val_loss: 56.0922\n",
            "Epoch 92/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.1138 - val_loss: 56.0876\n",
            "Epoch 93/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 42.9938 - val_loss: 56.1217\n",
            "Epoch 94/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.4780 - val_loss: 56.1644\n",
            "Epoch 95/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.7256 - val_loss: 56.1654\n",
            "Epoch 96/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.4325 - val_loss: 56.1947\n",
            "Epoch 97/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.0639 - val_loss: 56.2233\n",
            "Epoch 98/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.8465 - val_loss: 56.2038\n",
            "Epoch 99/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.6766 - val_loss: 56.1535\n",
            "Epoch 100/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 43.5895roc-auc_val: 0.8079\n",
            "47/47 [==============================] - 15s 324ms/step - loss: 43.3171 - val_loss: 56.1490\n",
            "Epoch 101/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.7418 - val_loss: 56.1636\n",
            "Epoch 102/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 42.7938 - val_loss: 56.1773\n",
            "Epoch 103/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 41.9032 - val_loss: 56.2368\n",
            "Epoch 104/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 42.7006 - val_loss: 56.2480\n",
            "Epoch 105/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.4349 - val_loss: 56.2481\n",
            "Epoch 106/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.5196 - val_loss: 56.2999\n",
            "Epoch 107/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.7098 - val_loss: 56.3134\n",
            "Epoch 108/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.3899 - val_loss: 56.3002\n",
            "Epoch 109/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 41.5543 - val_loss: 56.3255\n",
            "Epoch 110/1000\n",
            "40/47 [========================>.....] - ETA: 0s - loss: 42.4232roc-auc_val: 0.8082\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 41.8830 - val_loss: 56.3488\n",
            "Epoch 111/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.2251 - val_loss: 56.3425\n",
            "Epoch 112/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 42.0402 - val_loss: 56.4005\n",
            "Epoch 113/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 42.3165 - val_loss: 56.3515\n",
            "Epoch 114/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 41.4884 - val_loss: 56.3808\n",
            "Epoch 115/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 41.5365 - val_loss: 56.3978\n",
            "Epoch 116/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.1006 - val_loss: 56.4010\n",
            "Epoch 117/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 41.9004 - val_loss: 56.3775\n",
            "Epoch 118/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 41.3394 - val_loss: 56.3811\n",
            "Epoch 119/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.1512 - val_loss: 56.3803\n",
            "Epoch 1/1000\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 83.7504 - val_loss: 64.3072\n",
            "Epoch 2/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 73.3099 - val_loss: 62.8479\n",
            "Epoch 3/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 69.4858 - val_loss: 62.3690\n",
            "Epoch 4/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 65.8174 - val_loss: 61.6132\n",
            "Epoch 5/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 64.2166 - val_loss: 61.1854\n",
            "Epoch 6/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 62.6836 - val_loss: 60.5598\n",
            "Epoch 7/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 60.3817 - val_loss: 59.7828\n",
            "Epoch 8/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 60.5225 - val_loss: 60.0790\n",
            "Epoch 9/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 59.7650 - val_loss: 59.3216\n",
            "Epoch 10/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 58.8110roc-auc_val: 0.7876\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 58.8110 - val_loss: 59.1767\n",
            "Epoch 11/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 57.7461 - val_loss: 59.0339\n",
            "Epoch 12/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 56.9028 - val_loss: 58.6500\n",
            "Epoch 13/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 56.2788 - val_loss: 58.2457\n",
            "Epoch 14/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.8474 - val_loss: 58.0063\n",
            "Epoch 15/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.4816 - val_loss: 57.9620\n",
            "Epoch 16/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.2914 - val_loss: 57.7593\n",
            "Epoch 17/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.2703 - val_loss: 57.3746\n",
            "Epoch 18/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 54.3962 - val_loss: 57.3315\n",
            "Epoch 19/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.9456 - val_loss: 57.2662\n",
            "Epoch 20/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 53.6774roc-auc_val: 0.7995\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 53.3888 - val_loss: 57.1666\n",
            "Epoch 21/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.4275 - val_loss: 57.0427\n",
            "Epoch 22/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.6815 - val_loss: 56.9590\n",
            "Epoch 23/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.8006 - val_loss: 56.9383\n",
            "Epoch 24/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.5640 - val_loss: 56.7631\n",
            "Epoch 25/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.4848 - val_loss: 56.7325\n",
            "Epoch 26/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.8028 - val_loss: 56.5600\n",
            "Epoch 27/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 51.4139 - val_loss: 56.5287\n",
            "Epoch 28/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.3716 - val_loss: 56.3999\n",
            "Epoch 29/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.0643 - val_loss: 56.2910\n",
            "Epoch 30/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 51.2743roc-auc_val: 0.8043\n",
            "88/88 [==============================] - 12s 135ms/step - loss: 51.0170 - val_loss: 56.3506\n",
            "Epoch 31/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 50.7616 - val_loss: 56.1466\n",
            "Epoch 32/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.0607 - val_loss: 56.1281\n",
            "Epoch 33/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.6301 - val_loss: 56.1258\n",
            "Epoch 34/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.4924 - val_loss: 56.1515\n",
            "Epoch 35/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.0209 - val_loss: 56.0882\n",
            "Epoch 36/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.3025 - val_loss: 55.9722\n",
            "Epoch 37/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 49.9634 - val_loss: 55.8822\n",
            "Epoch 38/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.2192 - val_loss: 55.8743\n",
            "Epoch 39/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 49.5763 - val_loss: 55.9098\n",
            "Epoch 40/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 49.7045roc-auc_val: 0.807\n",
            "88/88 [==============================] - 12s 138ms/step - loss: 49.7045 - val_loss: 55.9107\n",
            "Epoch 41/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.6075 - val_loss: 55.8363\n",
            "Epoch 42/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 49.0275 - val_loss: 55.8832\n",
            "Epoch 43/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 48.8815 - val_loss: 55.6800\n",
            "Epoch 44/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.7573 - val_loss: 55.6504\n",
            "Epoch 45/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.6668 - val_loss: 55.6625\n",
            "Epoch 46/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.5939 - val_loss: 55.6093\n",
            "Epoch 47/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.4571 - val_loss: 55.5956\n",
            "Epoch 48/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1104 - val_loss: 55.5842\n",
            "Epoch 49/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.5523 - val_loss: 55.5852\n",
            "Epoch 50/1000\n",
            "76/88 [========================>.....] - ETA: 0s - loss: 48.1527roc-auc_val: 0.8094\n",
            "88/88 [==============================] - 12s 137ms/step - loss: 47.8709 - val_loss: 55.4340\n",
            "Epoch 51/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.2803 - val_loss: 55.4620\n",
            "Epoch 52/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.5142 - val_loss: 55.3720\n",
            "Epoch 53/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.9471 - val_loss: 55.3632\n",
            "Epoch 54/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.6612 - val_loss: 55.3268\n",
            "Epoch 55/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 47.6829 - val_loss: 55.3358\n",
            "Epoch 56/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.5141 - val_loss: 55.2630\n",
            "Epoch 57/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.3378 - val_loss: 55.2561\n",
            "Epoch 58/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.3613 - val_loss: 55.1995\n",
            "Epoch 59/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.3061 - val_loss: 55.1632\n",
            "Epoch 60/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 47.6400roc-auc_val: 0.8112\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 47.3600 - val_loss: 55.0831\n",
            "Epoch 61/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 46.8088 - val_loss: 55.0936\n",
            "Epoch 62/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.0490 - val_loss: 55.0273\n",
            "Epoch 63/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 46.9958 - val_loss: 55.0531\n",
            "Epoch 64/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.3478 - val_loss: 55.0780\n",
            "Epoch 65/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 46.4767 - val_loss: 55.0457\n",
            "Epoch 66/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 46.7776 - val_loss: 54.9901\n",
            "Epoch 67/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 46.6431 - val_loss: 54.9969\n",
            "Epoch 68/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 46.1358 - val_loss: 54.9520\n",
            "Epoch 69/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 46.1467 - val_loss: 55.0033\n",
            "Epoch 70/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 46.7991roc-auc_val: 0.8121\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 46.5070 - val_loss: 54.9554\n",
            "Epoch 71/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 46.6326 - val_loss: 54.9136\n",
            "Epoch 72/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 46.2282 - val_loss: 54.8942\n",
            "Epoch 73/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 46.1614 - val_loss: 54.9450\n",
            "Epoch 74/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 45.9237 - val_loss: 54.8875\n",
            "Epoch 75/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 45.7427 - val_loss: 54.8853\n",
            "Epoch 76/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 46.2233 - val_loss: 54.8140\n",
            "Epoch 77/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 46.0526 - val_loss: 54.8079\n",
            "Epoch 78/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 45.9672 - val_loss: 54.7556\n",
            "Epoch 79/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.6609 - val_loss: 54.7153\n",
            "Epoch 80/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 45.3970roc-auc_val: 0.8132\n",
            "88/88 [==============================] - 12s 137ms/step - loss: 45.3970 - val_loss: 54.7023\n",
            "Epoch 81/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.4588 - val_loss: 54.6859\n",
            "Epoch 82/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.9212 - val_loss: 54.6611\n",
            "Epoch 83/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.4645 - val_loss: 54.6932\n",
            "Epoch 84/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.6158 - val_loss: 54.6954\n",
            "Epoch 85/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.2897 - val_loss: 54.6379\n",
            "Epoch 86/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.5203 - val_loss: 54.6177\n",
            "Epoch 87/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.9582 - val_loss: 54.5972\n",
            "Epoch 88/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.1521 - val_loss: 54.6044\n",
            "Epoch 89/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.0293 - val_loss: 54.6284\n",
            "Epoch 90/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 44.7652roc-auc_val: 0.8141\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 44.7652 - val_loss: 54.6056\n",
            "Epoch 91/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 45.4196 - val_loss: 54.5608\n",
            "Epoch 92/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.3120 - val_loss: 54.5912\n",
            "Epoch 93/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.1619 - val_loss: 54.5707\n",
            "Epoch 94/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.0023 - val_loss: 54.5632\n",
            "Epoch 95/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.8384 - val_loss: 54.5730\n",
            "Epoch 96/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.8512 - val_loss: 54.5728\n",
            "Epoch 97/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 45.0131 - val_loss: 54.5259\n",
            "Epoch 98/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.4838 - val_loss: 54.5062\n",
            "Epoch 99/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.4739 - val_loss: 54.4813\n",
            "Epoch 100/1000\n",
            "86/88 [============================>.] - ETA: 0s - loss: 44.3983roc-auc_val: 0.8147\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 44.4298 - val_loss: 54.4763\n",
            "Epoch 101/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.6487 - val_loss: 54.5058\n",
            "Epoch 102/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.7570 - val_loss: 54.4597\n",
            "Epoch 103/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.3934 - val_loss: 54.4564\n",
            "Epoch 104/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 44.7237 - val_loss: 54.4389\n",
            "Epoch 105/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.8534 - val_loss: 54.4165\n",
            "Epoch 106/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.5789 - val_loss: 54.4170\n",
            "Epoch 107/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.5031 - val_loss: 54.3886\n",
            "Epoch 108/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.9422 - val_loss: 54.3714\n",
            "Epoch 109/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.9513 - val_loss: 54.3720\n",
            "Epoch 110/1000\n",
            "77/88 [=========================>....] - ETA: 0s - loss: 44.2009roc-auc_val: 0.8154\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 44.2761 - val_loss: 54.3452\n",
            "Epoch 111/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.1015 - val_loss: 54.3485\n",
            "Epoch 112/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.8416 - val_loss: 54.3458\n",
            "Epoch 113/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.8949 - val_loss: 54.3123\n",
            "Epoch 114/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.0382 - val_loss: 54.3483\n",
            "Epoch 115/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.0235 - val_loss: 54.3401\n",
            "Epoch 116/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 43.6796 - val_loss: 54.3644\n",
            "Epoch 117/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.7302 - val_loss: 54.3620\n",
            "Epoch 118/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 44.2258 - val_loss: 54.2929\n",
            "Epoch 119/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.7263 - val_loss: 54.3046\n",
            "Epoch 120/1000\n",
            "77/88 [=========================>....] - ETA: 0s - loss: 43.9996roc-auc_val: 0.8158\n",
            "88/88 [==============================] - 12s 135ms/step - loss: 43.8549 - val_loss: 54.3100\n",
            "Epoch 121/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.3131 - val_loss: 54.3051\n",
            "Epoch 122/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.5434 - val_loss: 54.3184\n",
            "Epoch 123/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.7491 - val_loss: 54.3123\n",
            "Epoch 124/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.8319 - val_loss: 54.3091\n",
            "Epoch 125/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.8893 - val_loss: 54.2967\n",
            "Epoch 126/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.5295 - val_loss: 54.2978\n",
            "Epoch 127/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.3221 - val_loss: 54.2835\n",
            "Epoch 128/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.2059 - val_loss: 54.2577\n",
            "Epoch 129/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.5249 - val_loss: 54.2804\n",
            "Epoch 130/1000\n",
            "76/88 [========================>.....] - ETA: 0s - loss: 43.7834roc-auc_val: 0.8163\n",
            "88/88 [==============================] - 12s 137ms/step - loss: 43.5583 - val_loss: 54.2453\n",
            "Epoch 131/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 43.3893 - val_loss: 54.2118\n",
            "Epoch 132/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.4315 - val_loss: 54.2293\n",
            "Epoch 133/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.1482 - val_loss: 54.2222\n",
            "Epoch 134/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.4719 - val_loss: 54.2210\n",
            "Epoch 135/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 43.4662 - val_loss: 54.2108\n",
            "Epoch 136/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.5128 - val_loss: 54.2228\n",
            "Epoch 137/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.9014 - val_loss: 54.2065\n",
            "Epoch 138/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 43.1515 - val_loss: 54.1927\n",
            "Epoch 139/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.7776 - val_loss: 54.1451\n",
            "Epoch 140/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 43.3559roc-auc_val: 0.8168\n",
            "88/88 [==============================] - 13s 147ms/step - loss: 43.3559 - val_loss: 54.1356\n",
            "Epoch 141/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 42.9342 - val_loss: 54.1147\n",
            "Epoch 142/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.5152 - val_loss: 54.1350\n",
            "Epoch 143/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.2784 - val_loss: 54.1555\n",
            "Epoch 144/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.0926 - val_loss: 54.1342\n",
            "Epoch 145/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.1390 - val_loss: 54.1128\n",
            "Epoch 146/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.6031 - val_loss: 54.0933\n",
            "Epoch 147/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.1509 - val_loss: 54.1097\n",
            "Epoch 148/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.7698 - val_loss: 54.0966\n",
            "Epoch 149/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.5248 - val_loss: 54.1010\n",
            "Epoch 150/1000\n",
            "77/88 [=========================>....] - ETA: 0s - loss: 43.0289roc-auc_val: 0.8172\n",
            "88/88 [==============================] - 12s 135ms/step - loss: 43.0373 - val_loss: 54.1055\n",
            "Epoch 151/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.8990 - val_loss: 54.1068\n",
            "Epoch 152/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.4941 - val_loss: 54.1168\n",
            "Epoch 153/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.7798 - val_loss: 54.1140\n",
            "Epoch 154/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.3844 - val_loss: 54.1080\n",
            "Epoch 155/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.5506 - val_loss: 54.0929\n",
            "Epoch 156/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.5562 - val_loss: 54.0738\n",
            "Epoch 157/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.4473 - val_loss: 54.0351\n",
            "Epoch 158/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.6612 - val_loss: 54.0663\n",
            "Epoch 159/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 43.0209 - val_loss: 54.0687\n",
            "Epoch 160/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 42.8305roc-auc_val: 0.8173\n",
            "88/88 [==============================] - 12s 135ms/step - loss: 42.6169 - val_loss: 54.0343\n",
            "Epoch 161/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.1044 - val_loss: 54.0240\n",
            "Epoch 162/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.5780 - val_loss: 54.0302\n",
            "Epoch 163/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.4385 - val_loss: 54.0176\n",
            "Epoch 164/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.3063 - val_loss: 54.0001\n",
            "Epoch 165/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.5048 - val_loss: 54.0122\n",
            "Epoch 166/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.5894 - val_loss: 54.0181\n",
            "Epoch 167/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.2830 - val_loss: 54.0071\n",
            "Epoch 168/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.1181 - val_loss: 53.9869\n",
            "Epoch 169/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.5132 - val_loss: 54.0137\n",
            "Epoch 170/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 42.4692roc-auc_val: 0.8177\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 42.3685 - val_loss: 54.0120\n",
            "Epoch 171/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.4265 - val_loss: 54.0016\n",
            "Epoch 172/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.9577 - val_loss: 53.9955\n",
            "Epoch 173/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.0754 - val_loss: 54.0014\n",
            "Epoch 174/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.3090 - val_loss: 54.0049\n",
            "Epoch 175/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.9155 - val_loss: 54.0110\n",
            "Epoch 176/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.2696 - val_loss: 54.0061\n",
            "Epoch 177/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.0884 - val_loss: 54.0036\n",
            "Epoch 178/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.7612 - val_loss: 53.9853\n",
            "Epoch 179/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 42.2740 - val_loss: 53.9679\n",
            "Epoch 180/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 42.1866roc-auc_val: 0.8177\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 41.9416 - val_loss: 53.9768\n",
            "Epoch 181/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.7812 - val_loss: 53.9797\n",
            "Epoch 182/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.1116 - val_loss: 53.9731\n",
            "Epoch 183/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.8948 - val_loss: 53.9692\n",
            "Epoch 184/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.0736 - val_loss: 53.9557\n",
            "Epoch 185/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.9335 - val_loss: 53.9725\n",
            "Epoch 186/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.8429 - val_loss: 53.9692\n",
            "Epoch 187/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.7733 - val_loss: 53.9679\n",
            "Epoch 188/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.7065 - val_loss: 53.9846\n",
            "Epoch 189/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.9794 - val_loss: 53.9875\n",
            "Epoch 190/1000\n",
            "77/88 [=========================>....] - ETA: 0s - loss: 41.8160roc-auc_val: 0.8178\n",
            "88/88 [==============================] - 12s 135ms/step - loss: 41.8229 - val_loss: 53.9690\n",
            "Epoch 191/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.7652 - val_loss: 53.9765\n",
            "Epoch 192/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.9604 - val_loss: 53.9788\n",
            "Epoch 193/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.5432 - val_loss: 53.9656\n",
            "Epoch 194/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.7835 - val_loss: 53.9450\n",
            "Epoch 195/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 42.3164 - val_loss: 53.9546\n",
            "Epoch 196/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.6919 - val_loss: 53.9593\n",
            "Epoch 197/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.4445 - val_loss: 53.9522\n",
            "Epoch 198/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.4384 - val_loss: 53.9508\n",
            "Epoch 199/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.9883 - val_loss: 53.9706\n",
            "Epoch 200/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 41.7928roc-auc_val: 0.818\n",
            "88/88 [==============================] - 12s 135ms/step - loss: 41.6078 - val_loss: 53.9309\n",
            "Epoch 201/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 41.7569 - val_loss: 53.8851\n",
            "Epoch 202/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.4097 - val_loss: 53.9088\n",
            "Epoch 203/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.4047 - val_loss: 53.8693\n",
            "Epoch 204/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.3973 - val_loss: 53.8931\n",
            "Epoch 205/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.8007 - val_loss: 53.8935\n",
            "Epoch 206/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.5995 - val_loss: 53.9104\n",
            "Epoch 207/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.3985 - val_loss: 53.9170\n",
            "Epoch 208/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.8543 - val_loss: 53.9110\n",
            "Epoch 209/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.6677 - val_loss: 53.9312\n",
            "Epoch 210/1000\n",
            "77/88 [=========================>....] - ETA: 0s - loss: 41.4942roc-auc_val: 0.8182\n",
            "88/88 [==============================] - 12s 135ms/step - loss: 41.6141 - val_loss: 53.9297\n",
            "Epoch 211/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.2630 - val_loss: 53.9159\n",
            "Epoch 212/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.3771 - val_loss: 53.9146\n",
            "Epoch 213/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.7148 - val_loss: 53.9039\n",
            "Epoch 214/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.1518 - val_loss: 53.9111\n",
            "Epoch 215/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.1657 - val_loss: 53.9285\n",
            "Epoch 216/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.0373 - val_loss: 53.9107\n",
            "Epoch 217/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.6554 - val_loss: 53.8941\n",
            "Epoch 218/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.1533 - val_loss: 53.8903\n",
            "Epoch 219/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.0824 - val_loss: 53.8908\n",
            "Epoch 220/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 41.6186roc-auc_val: 0.8183\n",
            "88/88 [==============================] - 12s 137ms/step - loss: 41.5298 - val_loss: 53.9020\n",
            "Epoch 221/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.3636 - val_loss: 53.8883\n",
            "Epoch 222/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.2065 - val_loss: 53.9084\n",
            "Epoch 223/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.5310 - val_loss: 53.9103\n",
            "Epoch 224/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.0209 - val_loss: 53.8978\n",
            "Epoch 225/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.9739 - val_loss: 53.8757\n",
            "Epoch 226/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.8326 - val_loss: 53.8783\n",
            "Epoch 227/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.9910 - val_loss: 53.9085\n",
            "Epoch 228/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.4025 - val_loss: 53.9078\n",
            "Epoch 229/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.2562 - val_loss: 53.8993\n",
            "Epoch 230/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 40.8711roc-auc_val: 0.8181\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 40.8917 - val_loss: 53.9327\n",
            "Epoch 231/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.0119 - val_loss: 53.8897\n",
            "Epoch 232/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.0538 - val_loss: 53.8897\n",
            "Epoch 233/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.0580 - val_loss: 53.9006\n",
            "Epoch 234/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.9934 - val_loss: 53.9255\n",
            "Epoch 235/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.0419 - val_loss: 53.9090\n",
            "Epoch 236/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 40.9303 - val_loss: 53.8682\n",
            "Epoch 237/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.7623 - val_loss: 53.8865\n",
            "Epoch 238/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.3236 - val_loss: 53.8909\n",
            "Epoch 239/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 41.0634 - val_loss: 53.8979\n",
            "Epoch 240/1000\n",
            "85/88 [===========================>..] - ETA: 0s - loss: 40.6792roc-auc_val: 0.8184\n",
            "88/88 [==============================] - 12s 138ms/step - loss: 40.7424 - val_loss: 53.9011\n",
            "Epoch 241/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.8990 - val_loss: 53.8947\n",
            "Epoch 242/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.7109 - val_loss: 53.8712\n",
            "Epoch 243/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4671 - val_loss: 53.8698\n",
            "Epoch 244/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 41.3241 - val_loss: 53.8531\n",
            "Epoch 245/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.7168 - val_loss: 53.8472\n",
            "Epoch 246/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.6533 - val_loss: 53.8704\n",
            "Epoch 247/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 40.5548 - val_loss: 53.8913\n",
            "Epoch 248/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.7773 - val_loss: 53.8848\n",
            "Epoch 249/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.7476 - val_loss: 53.8686\n",
            "Epoch 250/1000\n",
            "87/88 [============================>.] - ETA: 0s - loss: 40.3325roc-auc_val: 0.8185\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 40.2962 - val_loss: 53.8773\n",
            "Epoch 251/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.8832 - val_loss: 53.8790\n",
            "Epoch 252/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.6101 - val_loss: 53.8651\n",
            "Epoch 253/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.5638 - val_loss: 53.8572\n",
            "Epoch 254/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.9136 - val_loss: 53.8635\n",
            "Epoch 255/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.6788 - val_loss: 53.8640\n",
            "Epoch 256/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4570 - val_loss: 53.8533\n",
            "Epoch 257/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.6087 - val_loss: 53.8538\n",
            "Epoch 258/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.8872 - val_loss: 53.8841\n",
            "Epoch 259/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4819 - val_loss: 53.8950\n",
            "Epoch 260/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 40.9176roc-auc_val: 0.8185\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 40.6644 - val_loss: 53.8886\n",
            "Epoch 261/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.6721 - val_loss: 53.8977\n",
            "Epoch 262/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.5953 - val_loss: 53.8914\n",
            "Epoch 263/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3626 - val_loss: 53.8837\n",
            "Epoch 264/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4973 - val_loss: 53.9012\n",
            "Epoch 265/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.5037 - val_loss: 53.8898\n",
            "Epoch 266/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.7657 - val_loss: 53.9172\n",
            "Epoch 267/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.2917 - val_loss: 53.9052\n",
            "Epoch 268/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3514 - val_loss: 53.9140\n",
            "Epoch 269/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3068 - val_loss: 53.9035\n",
            "Epoch 270/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 40.5238roc-auc_val: 0.8185\n",
            "88/88 [==============================] - 12s 137ms/step - loss: 40.2754 - val_loss: 53.9055\n",
            "Epoch 271/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.5466 - val_loss: 53.8895\n",
            "Epoch 272/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.1952 - val_loss: 53.8941\n",
            "Epoch 273/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.7330 - val_loss: 53.9026\n",
            "Epoch 274/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3831 - val_loss: 53.9173\n",
            "Epoch 275/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3678 - val_loss: 53.9239\n",
            "Epoch 276/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.2737 - val_loss: 53.8956\n",
            "Epoch 277/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 39.9714 - val_loss: 53.8927\n",
            "Epoch 278/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4203 - val_loss: 53.9095\n",
            "Epoch 279/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3914 - val_loss: 53.9182\n",
            "Epoch 280/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 39.9613roc-auc_val: 0.8184\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 40.0130 - val_loss: 53.9205\n",
            "Epoch 281/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4799 - val_loss: 53.8879\n",
            "Epoch 282/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 39.8144 - val_loss: 53.8955\n",
            "Epoch 283/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3061 - val_loss: 53.8923\n",
            "Epoch 284/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.1236 - val_loss: 53.8815\n",
            "Epoch 285/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3999 - val_loss: 53.8801\n",
            "Epoch 286/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.6516 - val_loss: 53.8792\n",
            "Epoch 287/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3097 - val_loss: 53.8912\n",
            "Epoch 288/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4795 - val_loss: 53.9032\n",
            "Epoch 289/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.2678 - val_loss: 53.9033\n",
            "Epoch 290/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 40.1062roc-auc_val: 0.8188\n",
            "88/88 [==============================] - 12s 136ms/step - loss: 40.0994 - val_loss: 53.8810\n",
            "Epoch 291/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4521 - val_loss: 53.8902\n",
            "Epoch 292/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.0689 - val_loss: 53.9031\n",
            "Epoch 293/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.2118 - val_loss: 53.9034\n",
            "Epoch 294/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.3553 - val_loss: 53.9011\n",
            "Epoch 295/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 40.4842 - val_loss: 53.8819\n",
            "Epoch 1/1000\n",
            "47/47 [==============================] - 1s 26ms/step - loss: 84.6357 - val_loss: 63.4844\n",
            "Epoch 2/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 75.0869 - val_loss: 61.8162\n",
            "Epoch 3/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 71.8180 - val_loss: 61.2285\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 68.0663 - val_loss: 60.8041\n",
            "Epoch 5/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 66.4611 - val_loss: 60.7936\n",
            "Epoch 6/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 65.7955 - val_loss: 60.5318\n",
            "Epoch 7/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 62.5744 - val_loss: 60.3133\n",
            "Epoch 8/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 62.4868 - val_loss: 60.3871\n",
            "Epoch 9/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 61.5205 - val_loss: 59.8656\n",
            "Epoch 10/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 61.4671roc-auc_val: 0.7648\n",
            "47/47 [==============================] - 12s 261ms/step - loss: 60.8040 - val_loss: 59.7466\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 59.2123 - val_loss: 59.4745\n",
            "Epoch 12/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 58.9027 - val_loss: 59.3702\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 57.8588 - val_loss: 59.2776\n",
            "Epoch 14/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 56.6926 - val_loss: 59.0217\n",
            "Epoch 15/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 56.8420 - val_loss: 58.7691\n",
            "Epoch 16/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 56.8371 - val_loss: 58.6191\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 55.0211 - val_loss: 58.6585\n",
            "Epoch 18/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 54.8368 - val_loss: 58.7612\n",
            "Epoch 19/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 54.8516 - val_loss: 58.6108\n",
            "Epoch 20/1000\n",
            "40/47 [========================>.....] - ETA: 0s - loss: 55.4534roc-auc_val: 0.778\n",
            "47/47 [==============================] - 12s 250ms/step - loss: 55.2278 - val_loss: 58.4855\n",
            "Epoch 21/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 53.9502 - val_loss: 58.4587\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 54.5329 - val_loss: 58.5362\n",
            "Epoch 23/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 53.2770 - val_loss: 58.3894\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 53.4355 - val_loss: 58.4205\n",
            "Epoch 25/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 52.9018 - val_loss: 58.3400\n",
            "Epoch 26/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 52.6373 - val_loss: 58.3615\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 52.6505 - val_loss: 58.2672\n",
            "Epoch 28/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 51.9949 - val_loss: 58.2225\n",
            "Epoch 29/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 51.3488 - val_loss: 58.1437\n",
            "Epoch 30/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 51.5349roc-auc_val: 0.7834\n",
            "47/47 [==============================] - 12s 250ms/step - loss: 51.4399 - val_loss: 58.1331\n",
            "Epoch 31/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 51.1689 - val_loss: 58.0899\n",
            "Epoch 32/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 51.2910 - val_loss: 58.0667\n",
            "Epoch 33/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 51.2805 - val_loss: 58.1498\n",
            "Epoch 34/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 50.5436 - val_loss: 58.1199\n",
            "Epoch 35/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 50.2107 - val_loss: 58.1974\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 51.1441 - val_loss: 58.1526\n",
            "Epoch 37/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 49.7979 - val_loss: 58.1297\n",
            "Epoch 38/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 49.9058 - val_loss: 58.2043\n",
            "Epoch 39/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 50.1567 - val_loss: 58.3105\n",
            "Epoch 40/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 49.5050roc-auc_val: 0.786\n",
            "47/47 [==============================] - 12s 253ms/step - loss: 49.4194 - val_loss: 58.2742\n",
            "Epoch 41/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 49.7441 - val_loss: 58.2999\n",
            "Epoch 42/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 48.8517 - val_loss: 58.2917\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 49.0583 - val_loss: 58.3293\n",
            "Epoch 44/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 49.0344 - val_loss: 58.2927\n",
            "Epoch 45/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 48.6893 - val_loss: 58.3611\n",
            "Epoch 46/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 48.7927 - val_loss: 58.4076\n",
            "Epoch 47/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 48.2836 - val_loss: 58.5365\n",
            "Epoch 48/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 47.7654 - val_loss: 58.5152\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 47.7727 - val_loss: 58.5157\n",
            "Epoch 50/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 47.5446roc-auc_val: 0.7875\n",
            "47/47 [==============================] - 12s 251ms/step - loss: 47.5090 - val_loss: 58.5863\n",
            "Epoch 51/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.9576 - val_loss: 58.6754\n",
            "Epoch 52/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 48.4330 - val_loss: 58.7121\n",
            "Epoch 53/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 47.4597 - val_loss: 58.6824\n",
            "Epoch 54/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 47.5419 - val_loss: 58.6834\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 47.4776 - val_loss: 58.7326\n",
            "Epoch 56/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.7675 - val_loss: 58.6685\n",
            "Epoch 57/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.6774 - val_loss: 58.7194\n",
            "Epoch 58/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.8522 - val_loss: 58.7779\n",
            "Epoch 59/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.9850 - val_loss: 58.7900\n",
            "Epoch 60/1000\n",
            "38/47 [=======================>......] - ETA: 0s - loss: 47.1736roc-auc_val: 0.7891\n",
            "47/47 [==============================] - 12s 251ms/step - loss: 47.1478 - val_loss: 58.8019\n",
            "Epoch 61/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.4604 - val_loss: 58.8789\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.8135 - val_loss: 58.9245\n",
            "Epoch 63/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.7128 - val_loss: 58.9586\n",
            "Epoch 64/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.0462 - val_loss: 58.9573\n",
            "Epoch 65/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.4092 - val_loss: 59.0414\n",
            "Epoch 66/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.9092 - val_loss: 59.0714\n",
            "Epoch 67/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 46.7527 - val_loss: 59.0737\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.6448 - val_loss: 59.1365\n",
            "Epoch 69/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.7739 - val_loss: 59.1541\n",
            "Epoch 70/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 46.0563roc-auc_val: 0.7895\n",
            "47/47 [==============================] - 12s 251ms/step - loss: 45.6216 - val_loss: 59.2472\n",
            "Epoch 71/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.7226 - val_loss: 59.2158\n",
            "Epoch 72/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.0106 - val_loss: 59.2441\n",
            "Epoch 73/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.2729 - val_loss: 59.2954\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.5749 - val_loss: 59.2018\n",
            "Epoch 75/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.5640 - val_loss: 59.2646\n",
            "Epoch 76/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.2863 - val_loss: 59.3278\n",
            "Epoch 77/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 45.0690 - val_loss: 59.3062\n",
            "Epoch 78/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 44.5725 - val_loss: 59.3387\n",
            "Epoch 79/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 44.1946 - val_loss: 59.3295\n",
            "Epoch 80/1000\n",
            "40/47 [========================>.....] - ETA: 0s - loss: 44.6015roc-auc_val: 0.7904\n",
            "47/47 [==============================] - 12s 250ms/step - loss: 44.5321 - val_loss: 59.4077\n",
            "Epoch 81/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 44.8105 - val_loss: 59.4496\n",
            "Epoch 82/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 44.6008 - val_loss: 59.5370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnpeTPNLkiCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "e350f9fb-9dba-4962-c92a-68f4617749bb"
      },
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "for i in dk.keys():\n",
        "  sns.distplot(dk[i])\n",
        "  plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn6S7Pv_rc-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}