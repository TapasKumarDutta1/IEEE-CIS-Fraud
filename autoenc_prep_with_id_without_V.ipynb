{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoenc_prep_with_id_without_V.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/autoenc_prep_with_id_without_V.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybGVY3nPjPV0",
        "colab_type": "text"
      },
      "source": [
        "Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYECXu2m6I7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import gc\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l6tSRenjRw7",
        "colab_type": "text"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a2732e28-b939-4bdc-faa8-0ecfad60785c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biKd2dPljT-R",
        "colab_type": "text"
      },
      "source": [
        "Load dataframe and drop Vs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJem4-mp8otc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c6affde8-c5c7-4182-d9a5-984553b11f28"
      },
      "source": [
        "\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')\n",
        "ls=list(trn.filter(regex='V'))\n",
        "trn=trn.drop(ls,1)\n",
        "tst=tst.drop(ls,1)\n",
        "trn=trn.drop(['isFraud'],1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (210,222) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwtQ0snVje6c",
        "colab_type": "text"
      },
      "source": [
        "Divide data as numerical and categorical and create grouped mean and std with numerical and drop id "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuFAreiwFokj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dum=list(trn.filter(regex='dum'))\n",
        "cat=list(trn.select_dtypes(include=object))\n",
        "cat.remove('id')\n",
        "isna=list(trn.filter(regex='isna'))\n",
        "\n",
        "tot=dum+cat+isna+['day','month','week']\n",
        "num=[ i for i in list(trn) if i not in tot]\n",
        "\n",
        "num.remove('id')\n",
        "for col in num:\n",
        "  trn[col+'_mean']=trn.groupby(['id'])[col].transform('mean')\n",
        "  trn[col+'_std']=trn.groupby(['id'])[col].transform('std')\n",
        "  \n",
        "  tst[col+'_mean']=tst.groupby(['id'])[col].transform('mean')\n",
        "  tst[col+'_std']=tst.groupby(['id'])[col].transform('std')\n",
        "trn=trn.drop(['id'],1)\n",
        "tst=tst.drop(['id'],1)\n",
        "\n",
        "num=[ i for i in list(trn) if i not in tot]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IaQmKRpjv-q",
        "colab_type": "text"
      },
      "source": [
        "Label encode categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkujRQIB_CUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "34f249ff-162b-4875-deb7-2f6bc04b4b15"
      },
      "source": [
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in tqdm(cols):\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/21 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "100%|██████████| 21/21 [01:25<00:00,  4.08s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpJV_AeYjzMU",
        "colab_type": "text"
      },
      "source": [
        "Reduce memory used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKYcx1CSuEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "1e7f4326-786d-40aa-bd93-bc552bf09462"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1248.01 MB\n",
            "Memory usage after optimization is: 312.00 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 1070.81 MB\n",
            "Memory usage after optimization is: 267.22 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8azxXaFE8T0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "np.random.seed(42) # NumPy\n",
        "random.seed(42) # Python"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EskXmTJOPUZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuryyjU0VYuK",
        "colab_type": "text"
      },
      "source": [
        "Make the final dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmhak0ipj8MQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b6829b33-55ee-4e8d-98b5-84c833fe6600"
      },
      "source": [
        "X=pd.concat([trn,tst],0)\n",
        "del([trn,tst])\n",
        "gc.collect()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwjQgl2bj8zf",
        "colab_type": "text"
      },
      "source": [
        "Scale the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W59njV2kUjJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "e8ccb3ac-898a-4b9c-86e2-d03324925225"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss=StandardScaler()\n",
        "numerical=pd.DataFrame(ss.fit_transform(X[tot]))\n",
        "numerical.columns=tot\n",
        "categorical=pd.DataFrame(ss.fit_transform(X[num]))\n",
        "categorical.columns=num\n",
        "X=pd.concat([categorical,numerical],1)\n",
        "X=reduce_mem_usage(X)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1653.31 MB\n",
            "Memory usage after optimization is: 569.24 MB\n",
            "Decreased by 65.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-oBBENzuLH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "303a78a5-0d3f-4809-e665-dc37bd3cb5c9"
      },
      "source": [
        "0.99**50"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6050060671375364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0qJM2N4j_g6",
        "colab_type": "text"
      },
      "source": [
        "Create warmup lr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf25ibJI8T5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class WarmUpLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Warmup learning rate scheduler\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup_batches, init_lr, verbose=0):\n",
        "        \"\"\"Constructor for warmup learning rate scheduler\n",
        "\n",
        "        Arguments:\n",
        "            warmup_batches {int} -- Number of batch for warmup.\n",
        "            init_lr {float} -- Learning rate after warmup.\n",
        "\n",
        "        Keyword Arguments:\n",
        "            verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
        "        \"\"\"\n",
        "\n",
        "        super(WarmUpLearningRateScheduler, self).__init__()\n",
        "        self.warmup_batches = warmup_batches\n",
        "        self.init_lr = init_lr\n",
        "        self.verbose = verbose\n",
        "        self.batch_count = 0\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.batch_count = self.batch_count + 1\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        if self.batch_count <= self.warmup_batches:\n",
        "            lr = self.batch_count*self.init_lr/self.warmup_batches\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "            if self.verbose > 0:\n",
        "                print('\\nBatch %05d: WarmUpLearningRateScheduler setting learning '\n",
        "                      'rate to %s.' % (self.batch_count + 1, lr))\n",
        "warm_up_lr = WarmUpLearningRateScheduler(400, init_lr=0.005)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv_MyCaDkBiS",
        "colab_type": "text"
      },
      "source": [
        "Create data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyjXsW3U8Txj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "class DAESequence(Sequence):\n",
        "    def __init__(self,df,no_dum,frac=0.15,dumm=range(911),batch_size=2048):\n",
        "        self.batch_size=batch_size\n",
        "        self.frac=0.15\n",
        "        self.dumm=dumm\n",
        "        self.df=df\n",
        "        self.cat_data=df[dumm].values\n",
        "        self.num_data=df[no_dum].values\n",
        "        self.no_dumm=no_dum\n",
        "        self.len_data=df.shape[0]\n",
        "        self.columns=df.shape[1]\n",
        "        self.data=df\n",
        "        self.idx=[]\n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(ceil(self.len_data/self.batch_size))\n",
        "    \n",
        "    \n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        self.idx.append(idx)\n",
        "        last=min((idx+1)*self.batch_size,self.len_data)\n",
        "        idx=idx*self.batch_size\n",
        "        size=last-idx\n",
        "        \n",
        "        \n",
        "        inps=[]\n",
        "        outs=[]\n",
        "        output_x=self.data.iloc[idx:last]\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        data=output_x[self.no_dumm].values\n",
        "        noise_x=data.copy()\n",
        "        for i in range(len(self.no_dumm)):\n",
        "            to=np.random.randint(0,size,int(size*self.frac))\n",
        "            frm=np.random.randint(0,size,int(size*self.frac))\n",
        "            noise_x[to,i]=noise_x[frm,i]\n",
        "            \n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "        \n",
        "        data=output_x[self.dumm].values\n",
        "        noise_x=data.copy()\n",
        "        for i in range(len(self.dumm)):\n",
        "            to=np.random.randint(0,size,int(size*self.frac))\n",
        "            frm=np.random.randint(0,size,int(size*self.frac))\n",
        "            noise_x[to,i]=noise_x[frm,i]\n",
        "        \n",
        "        \n",
        "        \n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        return inps,outs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KICgfvdw7l5t",
        "colab_type": "text"
      },
      "source": [
        "Fill the std columns and drop columns having nan mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ryHot0g1BwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ff82fdb9-b2e0-4557-e7a0-6fc06de75cdd"
      },
      "source": [
        "from tqdm import tqdm\n",
        "a=X.isna().sum()\n",
        "a=a[a>0]\n",
        "cls=list(X)\n",
        "for col in tqdm(list(a.index)):\n",
        "  if col in cls:\n",
        "    X[col]=X[col].fillna(X[col].mean())\n",
        "a=X.isna().sum()\n",
        "a=a[a>0]\n",
        "for col in tqdm(list(a.index)):\n",
        "  X=X.drop([col],1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:01<00:00, 25.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JeRPlfhkSea",
        "colab_type": "text"
      },
      "source": [
        "Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eT7uAwsjOWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import concatenate\n",
        "from keras.optimizers import Adam\n",
        "def create_model():\n",
        "    K.clear_session()\n",
        "    num_inp = Input(shape=(num_shape,))\n",
        "    cat_inp = Input(shape=(cat_shape,))\n",
        "    inps = concatenate([num_inp, cat_inp])\n",
        "    x = Dense(512, activation=custom_gelu)(inps)\n",
        "    a = Dense(256, activation=custom_gelu)(x)\n",
        "    b = Dense(512, activation = custom_gelu)(a)\n",
        "    x = Dropout(.2)(b)\n",
        "    cat_out = Dense(cat_shape, activation = \"linear\")(x)\n",
        "    num_out = Dense(num_shape, activation = \"linear\")(x)\n",
        "    model = Model(inputs=[num_inp,cat_inp], outputs=[num_out, cat_out])\n",
        "    model.compile(\n",
        "        optimizer=Adam(.05, clipnorm = 1, clipvalue = 1),\n",
        "        loss=[\"mse\", \"mse\"]\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AyyVWdykkLj",
        "colab_type": "text"
      },
      "source": [
        "Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXdXM2kpNXgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea56fff3-7c23-4633-97c2-d4a53fde5b36"
      },
      "source": [
        "\n",
        "num=[ i for i in list(X) if i not in tot]\n",
        "batch_size=2048\n",
        "auto_ckpt = ModelCheckpoint(\"ae.model\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "warm_up_lr = WarmUpLearningRateScheduler(400, init_lr=0.0001)\n",
        "num_shape=len(num)\n",
        "cat_shape=len(tot)\n",
        "model_mse = create_model()\n",
        "from math import *\n",
        "gc.collect()\n",
        "epochs = 50\n",
        "batch_size=2048\n",
        "train_gen=DAESequence(X,num,batch_size=batch_size,dumm=tot)\n",
        "hist = model_mse.fit_generator(train_gen, steps_per_epoch=len(X)//batch_size, epochs=epochs,\n",
        "                           verbose=1, workers=-1,\n",
        "                           use_multiprocessing=True,\n",
        "                              callbacks=[auto_ckpt, warm_up_lr])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 1.4775 - dense_4_loss: 0.6576 - dense_3_loss: 0.8200\n",
            "Epoch 00001: loss improved from inf to 1.47753, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 1.4775 - dense_4_loss: 0.6576 - dense_3_loss: 0.8200\n",
            "Epoch 2/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.7247 - dense_4_loss: 0.2763 - dense_3_loss: 0.4484\n",
            "Epoch 00002: loss improved from 1.47753 to 0.72469, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.7247 - dense_4_loss: 0.2763 - dense_3_loss: 0.4484\n",
            "Epoch 3/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.5433 - dense_4_loss: 0.2142 - dense_3_loss: 0.3291\n",
            "Epoch 00003: loss improved from 0.72469 to 0.54335, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.5433 - dense_4_loss: 0.2142 - dense_3_loss: 0.3291\n",
            "Epoch 4/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.4648 - dense_4_loss: 0.1845 - dense_3_loss: 0.2803\n",
            "Epoch 00004: loss improved from 0.54335 to 0.46477, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.4648 - dense_4_loss: 0.1845 - dense_3_loss: 0.2803\n",
            "Epoch 5/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.4195 - dense_4_loss: 0.1666 - dense_3_loss: 0.2529\n",
            "Epoch 00005: loss improved from 0.46477 to 0.41949, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.4195 - dense_4_loss: 0.1666 - dense_3_loss: 0.2529\n",
            "Epoch 6/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3928 - dense_4_loss: 0.1543 - dense_3_loss: 0.2384\n",
            "Epoch 00006: loss improved from 0.41949 to 0.39276, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3928 - dense_4_loss: 0.1543 - dense_3_loss: 0.2384\n",
            "Epoch 7/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3742 - dense_4_loss: 0.1466 - dense_3_loss: 0.2277\n",
            "Epoch 00007: loss improved from 0.39276 to 0.37422, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3742 - dense_4_loss: 0.1466 - dense_3_loss: 0.2277\n",
            "Epoch 8/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3617 - dense_4_loss: 0.1416 - dense_3_loss: 0.2201\n",
            "Epoch 00008: loss improved from 0.37422 to 0.36174, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3617 - dense_4_loss: 0.1416 - dense_3_loss: 0.2201\n",
            "Epoch 9/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3481 - dense_4_loss: 0.1352 - dense_3_loss: 0.2129\n",
            "Epoch 00009: loss improved from 0.36174 to 0.34814, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3481 - dense_4_loss: 0.1352 - dense_3_loss: 0.2129\n",
            "Epoch 10/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3392 - dense_4_loss: 0.1313 - dense_3_loss: 0.2078\n",
            "Epoch 00010: loss improved from 0.34814 to 0.33915, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3392 - dense_4_loss: 0.1313 - dense_3_loss: 0.2078\n",
            "Epoch 11/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3324 - dense_4_loss: 0.1278 - dense_3_loss: 0.2045\n",
            "Epoch 00011: loss improved from 0.33915 to 0.33236, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3324 - dense_4_loss: 0.1278 - dense_3_loss: 0.2045\n",
            "Epoch 12/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3255 - dense_4_loss: 0.1247 - dense_3_loss: 0.2008\n",
            "Epoch 00012: loss improved from 0.33236 to 0.32548, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3255 - dense_4_loss: 0.1247 - dense_3_loss: 0.2008\n",
            "Epoch 13/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3195 - dense_4_loss: 0.1220 - dense_3_loss: 0.1976\n",
            "Epoch 00013: loss improved from 0.32548 to 0.31951, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3195 - dense_4_loss: 0.1220 - dense_3_loss: 0.1976\n",
            "Epoch 14/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3132 - dense_4_loss: 0.1208 - dense_3_loss: 0.1924\n",
            "Epoch 00014: loss improved from 0.31951 to 0.31320, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3132 - dense_4_loss: 0.1208 - dense_3_loss: 0.1924\n",
            "Epoch 15/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3085 - dense_4_loss: 0.1193 - dense_3_loss: 0.1892\n",
            "Epoch 00015: loss improved from 0.31320 to 0.30849, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3085 - dense_4_loss: 0.1193 - dense_3_loss: 0.1892\n",
            "Epoch 16/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3038 - dense_4_loss: 0.1171 - dense_3_loss: 0.1867\n",
            "Epoch 00016: loss improved from 0.30849 to 0.30382, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3038 - dense_4_loss: 0.1171 - dense_3_loss: 0.1867\n",
            "Epoch 17/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.3027 - dense_4_loss: 0.1155 - dense_3_loss: 0.1872\n",
            "Epoch 00017: loss improved from 0.30382 to 0.30270, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.3027 - dense_4_loss: 0.1155 - dense_3_loss: 0.1872\n",
            "Epoch 18/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2995 - dense_4_loss: 0.1153 - dense_3_loss: 0.1842\n",
            "Epoch 00018: loss improved from 0.30270 to 0.29948, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2995 - dense_4_loss: 0.1153 - dense_3_loss: 0.1842\n",
            "Epoch 19/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2952 - dense_4_loss: 0.1149 - dense_3_loss: 0.1803\n",
            "Epoch 00019: loss improved from 0.29948 to 0.29520, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2952 - dense_4_loss: 0.1149 - dense_3_loss: 0.1803\n",
            "Epoch 20/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2928 - dense_4_loss: 0.1134 - dense_3_loss: 0.1793\n",
            "Epoch 00020: loss improved from 0.29520 to 0.29278, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2928 - dense_4_loss: 0.1134 - dense_3_loss: 0.1793\n",
            "Epoch 21/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2895 - dense_4_loss: 0.1116 - dense_3_loss: 0.1779\n",
            "Epoch 00021: loss improved from 0.29278 to 0.28950, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2895 - dense_4_loss: 0.1116 - dense_3_loss: 0.1779\n",
            "Epoch 22/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2873 - dense_4_loss: 0.1103 - dense_3_loss: 0.1770\n",
            "Epoch 00022: loss improved from 0.28950 to 0.28726, saving model to ae.model\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2873 - dense_4_loss: 0.1103 - dense_3_loss: 0.1770\n",
            "Epoch 23/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2861 - dense_4_loss: 0.1104 - dense_3_loss: 0.1757\n",
            "Epoch 00023: loss improved from 0.28726 to 0.28610, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2861 - dense_4_loss: 0.1104 - dense_3_loss: 0.1757\n",
            "Epoch 24/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2845 - dense_4_loss: 0.1113 - dense_3_loss: 0.1732\n",
            "Epoch 00024: loss improved from 0.28610 to 0.28449, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2845 - dense_4_loss: 0.1113 - dense_3_loss: 0.1732\n",
            "Epoch 25/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2809 - dense_4_loss: 0.1079 - dense_3_loss: 0.1731\n",
            "Epoch 00025: loss improved from 0.28449 to 0.28095, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2809 - dense_4_loss: 0.1079 - dense_3_loss: 0.1731\n",
            "Epoch 26/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2783 - dense_4_loss: 0.1076 - dense_3_loss: 0.1707\n",
            "Epoch 00026: loss improved from 0.28095 to 0.27826, saving model to ae.model\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2783 - dense_4_loss: 0.1076 - dense_3_loss: 0.1707\n",
            "Epoch 27/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2750 - dense_4_loss: 0.1064 - dense_3_loss: 0.1686\n",
            "Epoch 00027: loss improved from 0.27826 to 0.27504, saving model to ae.model\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2750 - dense_4_loss: 0.1064 - dense_3_loss: 0.1686\n",
            "Epoch 28/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2781 - dense_4_loss: 0.1060 - dense_3_loss: 0.1721\n",
            "Epoch 00028: loss did not improve from 0.27504\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2781 - dense_4_loss: 0.1060 - dense_3_loss: 0.1721\n",
            "Epoch 29/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2733 - dense_4_loss: 0.1061 - dense_3_loss: 0.1672\n",
            "Epoch 00029: loss improved from 0.27504 to 0.27328, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2733 - dense_4_loss: 0.1061 - dense_3_loss: 0.1672\n",
            "Epoch 30/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2717 - dense_4_loss: 0.1044 - dense_3_loss: 0.1672\n",
            "Epoch 00030: loss improved from 0.27328 to 0.27166, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2717 - dense_4_loss: 0.1044 - dense_3_loss: 0.1672\n",
            "Epoch 31/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2701 - dense_4_loss: 0.1046 - dense_3_loss: 0.1655\n",
            "Epoch 00031: loss improved from 0.27166 to 0.27009, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2701 - dense_4_loss: 0.1046 - dense_3_loss: 0.1655\n",
            "Epoch 32/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2712 - dense_4_loss: 0.1045 - dense_3_loss: 0.1667\n",
            "Epoch 00032: loss did not improve from 0.27009\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2712 - dense_4_loss: 0.1045 - dense_3_loss: 0.1667\n",
            "Epoch 33/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2656 - dense_4_loss: 0.1034 - dense_3_loss: 0.1622\n",
            "Epoch 00033: loss improved from 0.27009 to 0.26559, saving model to ae.model\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2656 - dense_4_loss: 0.1034 - dense_3_loss: 0.1622\n",
            "Epoch 34/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2676 - dense_4_loss: 0.1038 - dense_3_loss: 0.1638\n",
            "Epoch 00034: loss did not improve from 0.26559\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2676 - dense_4_loss: 0.1038 - dense_3_loss: 0.1638\n",
            "Epoch 35/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2647 - dense_4_loss: 0.1022 - dense_3_loss: 0.1625\n",
            "Epoch 00035: loss improved from 0.26559 to 0.26474, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2647 - dense_4_loss: 0.1022 - dense_3_loss: 0.1625\n",
            "Epoch 36/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2620 - dense_4_loss: 0.1020 - dense_3_loss: 0.1601\n",
            "Epoch 00036: loss improved from 0.26474 to 0.26203, saving model to ae.model\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2620 - dense_4_loss: 0.1020 - dense_3_loss: 0.1601\n",
            "Epoch 37/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2640 - dense_4_loss: 0.1019 - dense_3_loss: 0.1621\n",
            "Epoch 00037: loss did not improve from 0.26203\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2640 - dense_4_loss: 0.1019 - dense_3_loss: 0.1621\n",
            "Epoch 38/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2604 - dense_4_loss: 0.1012 - dense_3_loss: 0.1592\n",
            "Epoch 00038: loss improved from 0.26203 to 0.26043, saving model to ae.model\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2604 - dense_4_loss: 0.1012 - dense_3_loss: 0.1592\n",
            "Epoch 39/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2623 - dense_4_loss: 0.1020 - dense_3_loss: 0.1603\n",
            "Epoch 00039: loss did not improve from 0.26043\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2623 - dense_4_loss: 0.1020 - dense_3_loss: 0.1603\n",
            "Epoch 40/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2572 - dense_4_loss: 0.1002 - dense_3_loss: 0.1570\n",
            "Epoch 00040: loss improved from 0.26043 to 0.25720, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2572 - dense_4_loss: 0.1002 - dense_3_loss: 0.1570\n",
            "Epoch 41/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2596 - dense_4_loss: 0.1008 - dense_3_loss: 0.1588\n",
            "Epoch 00041: loss did not improve from 0.25720\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2596 - dense_4_loss: 0.1008 - dense_3_loss: 0.1588\n",
            "Epoch 42/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2563 - dense_4_loss: 0.0993 - dense_3_loss: 0.1571\n",
            "Epoch 00042: loss improved from 0.25720 to 0.25635, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2563 - dense_4_loss: 0.0993 - dense_3_loss: 0.1571\n",
            "Epoch 43/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2547 - dense_4_loss: 0.0992 - dense_3_loss: 0.1555\n",
            "Epoch 00043: loss improved from 0.25635 to 0.25467, saving model to ae.model\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2547 - dense_4_loss: 0.0992 - dense_3_loss: 0.1555\n",
            "Epoch 44/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2540 - dense_4_loss: 0.0987 - dense_3_loss: 0.1553\n",
            "Epoch 00044: loss improved from 0.25467 to 0.25402, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2540 - dense_4_loss: 0.0987 - dense_3_loss: 0.1553\n",
            "Epoch 45/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2555 - dense_4_loss: 0.1006 - dense_3_loss: 0.1549\n",
            "Epoch 00045: loss did not improve from 0.25402\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2555 - dense_4_loss: 0.1006 - dense_3_loss: 0.1549\n",
            "Epoch 46/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2530 - dense_4_loss: 0.0984 - dense_3_loss: 0.1547\n",
            "Epoch 00046: loss improved from 0.25402 to 0.25303, saving model to ae.model\n",
            "535/535 [==============================] - 17s 31ms/step - loss: 0.2530 - dense_4_loss: 0.0984 - dense_3_loss: 0.1547\n",
            "Epoch 47/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2537 - dense_4_loss: 0.0981 - dense_3_loss: 0.1556\n",
            "Epoch 00047: loss did not improve from 0.25303\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2537 - dense_4_loss: 0.0981 - dense_3_loss: 0.1556\n",
            "Epoch 48/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2505 - dense_4_loss: 0.0974 - dense_3_loss: 0.1531\n",
            "Epoch 00048: loss improved from 0.25303 to 0.25052, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2505 - dense_4_loss: 0.0974 - dense_3_loss: 0.1531\n",
            "Epoch 49/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2523 - dense_4_loss: 0.0987 - dense_3_loss: 0.1536\n",
            "Epoch 00049: loss did not improve from 0.25052\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2523 - dense_4_loss: 0.0987 - dense_3_loss: 0.1536\n",
            "Epoch 50/50\n",
            "535/535 [==============================] - ETA: 0s - loss: 0.2504 - dense_4_loss: 0.0971 - dense_3_loss: 0.1533\n",
            "Epoch 00050: loss improved from 0.25052 to 0.25040, saving model to ae.model\n",
            "535/535 [==============================] - 17s 32ms/step - loss: 0.2504 - dense_4_loss: 0.0971 - dense_3_loss: 0.1533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7kGh-p9H_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "593d7f0d-27e2-48a5-c6d5-9f061c216821"
      },
      "source": [
        "mod=Model(inputs=model_mse.inputs,outputs=model_mse.layers[4].output)\n",
        "mod.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 122)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 149)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 271)          0           input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          139264      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 270,592\n",
            "Trainable params: 270,592\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWuRO3iEz71E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4b695a42-e277-4ceb-f984-213db4450ddd"
      },
      "source": [
        "del([model_mse])\n",
        "gc.collect()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKOSJhAZhwqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "17e94122-d89e-4c85-9dc0-6e9ac2b66382"
      },
      "source": [
        "pre=mod.predict((X[num],X[tot]))\n",
        "pre.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1097231, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fo3vB-6zXjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/gdrive/My Drive/fraud/with_id_withpoutV.npy',pre)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01hxoE120rsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}