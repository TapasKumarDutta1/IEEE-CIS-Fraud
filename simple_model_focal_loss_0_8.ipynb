{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_focal_loss_0.8",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_focal_loss_0_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "065e5fc2-4a35-4d93-fe66-24ede21e24fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "98b1bc3a-42e6-48ae-8cc9-4db88012e37f"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 79.5MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 106MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 94% 49.0M/52.2M [00:00<00:00, 89.8MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 118MB/s] \n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 222MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 94% 55.0M/58.3M [00:00<00:00, 86.9MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 108MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold=5\n",
        "lr=0.001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')\n",
        "ls=list(trn.filter(regex='V'))\n",
        "trn=trn.drop(ls,1)\n",
        "tst=tst.drop(ls,1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDrCIAqHzl6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d4e8610d-8d91-4507-9459-dfbcd92bce3d"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in cols:\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EWJ-hzcznam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "ss=StandardScaler()\n",
        "frd=trn['isFraud']\n",
        "ls=list(trn)\n",
        "trn=ss.fit_transform(trn.drop(['isFraud'],1))\n",
        "trn=pd.DataFrame(trn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF5OQjb1zo6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls.remove('isFraud')\n",
        "trn.columns=ls\n",
        "trn['isFraud']=frd\n",
        "\n",
        "ls=list(tst)\n",
        "tst=ss.fit_transform(tst)\n",
        "tst=pd.DataFrame(tst)\n",
        "tst.columns=ls"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "180de84a-6954-46fe-d18c-fd6aa06979cf"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 860.54 MB\n",
            "Memory usage after optimization is: 215.14 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 734.49 MB\n",
            "Memory usage after optimization is: 183.62 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b7728c54-d60a-4546-a512-b9b0fc7d555f"
      },
      "source": [
        "trn_n=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_n=pd.read_csv('test_transaction.csv.zip')\n",
        "trn['month']=trn_n['TransactionDT']//(86400*30)\n",
        "trn_n.head()\n",
        "trn_ls=list(trn_n)\n",
        "tst_ls=list(tst_n)\n",
        "for col in trn:\n",
        "  if col in trn_ls:\n",
        "    trn[col+'_isna']=trn_n[col].isna().astype('uint8')\n",
        "for col in tst:\n",
        "  if col in tst_ls:\n",
        "    tst[col+'_isna']=tst_n[col].isna().astype('uint8')\n",
        "import gc\n",
        "del([trn_n,tst_n])\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f0r3SuH1K97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.drop(['isFraud_isna'],1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HQ20JqWATak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        if self.ep%10==0:\n",
        "          y_pred_val = self.model.predict(self.x_val)\n",
        "          roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "          print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnQIVOLKBFIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4a05c855-cc0c-460e-87a1-648c9fcc86a9"
      },
      "source": [
        "1-0.036"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6gnpm4CjDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb5e0f98-a140-4477-933e-b29155771b68"
      },
      "source": [
        "def fl():\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        gamma=0.8\n",
        "        alpha=1-0.036\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\n",
        "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
        "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
        "\n",
        "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
        "    return focal_loss\n",
        "dk={}\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "  inp=Input((233,))\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=inp,outputs=x)\n",
        "  return mod\n",
        "for en,month in enumerate([(4,5),(3,4),(3,5)]):\n",
        "  train=trn.loc[trn['month']>=month[1]]\n",
        "  test=trn.loc[trn['month']<=month[0]]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  mod.compile(optimizer=Adam(0.0001,decay=1e-3),loss=fl())\n",
        "  roc = RocCallback(\n",
        "                  validation_data=(test.drop(['isFraud'],1), test['isFraud']))\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es,roc])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  df=trn.loc[trn['month']==6].reset_index(drop=True).drop(['month'],1)\n",
        "  pre=mod.predict(df.drop(['isFraud'],1))\n",
        "  scr=roc_auc_score(df['isFraud'],pre)\n",
        "  dk[str(scr)]=mod.predict(tst)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "47/47 [==============================] - 1s 31ms/step - loss: 75.2373 - val_loss: 50.4905\n",
            "Epoch 2/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 64.0855 - val_loss: 48.0840\n",
            "Epoch 3/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 60.8026 - val_loss: 47.1765\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 58.1474 - val_loss: 46.8827\n",
            "Epoch 5/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.5600 - val_loss: 46.7266\n",
            "Epoch 6/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 56.1182 - val_loss: 46.6576\n",
            "Epoch 7/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.4465 - val_loss: 46.7923\n",
            "Epoch 8/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.1445 - val_loss: 46.6631\n",
            "Epoch 9/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 51.3126 - val_loss: 46.6697\n",
            "Epoch 10/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 50.7731roc-auc_val: 0.7814\n",
            "47/47 [==============================] - 17s 356ms/step - loss: 50.7254 - val_loss: 46.6351\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 50.0878 - val_loss: 46.7406\n",
            "Epoch 12/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 48.7959 - val_loss: 46.6564\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 48.9651 - val_loss: 46.6849\n",
            "Epoch 14/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 47.9960 - val_loss: 46.6481\n",
            "Epoch 15/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 47.9666 - val_loss: 46.5502\n",
            "Epoch 16/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 48.1877 - val_loss: 46.5612\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 47.2942 - val_loss: 46.4213\n",
            "Epoch 18/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 47.3223 - val_loss: 46.4720\n",
            "Epoch 19/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 45.7826 - val_loss: 46.4616\n",
            "Epoch 20/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 46.4192roc-auc_val: 0.7909\n",
            "47/47 [==============================] - 17s 355ms/step - loss: 46.2482 - val_loss: 46.4175\n",
            "Epoch 21/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 45.4164 - val_loss: 46.5039\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 44.8645 - val_loss: 46.3910\n",
            "Epoch 23/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 44.6019 - val_loss: 46.4444\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 44.5003 - val_loss: 46.3797\n",
            "Epoch 25/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 44.1133 - val_loss: 46.4673\n",
            "Epoch 26/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 44.0179 - val_loss: 46.3441\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 44.1726 - val_loss: 46.3505\n",
            "Epoch 28/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 42.9950 - val_loss: 46.3997\n",
            "Epoch 29/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 42.6974 - val_loss: 46.5190\n",
            "Epoch 30/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 42.8499roc-auc_val: 0.7955\n",
            "47/47 [==============================] - 17s 359ms/step - loss: 42.7408 - val_loss: 46.3777\n",
            "Epoch 31/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 42.6287 - val_loss: 46.4110\n",
            "Epoch 32/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 42.4267 - val_loss: 46.4429\n",
            "Epoch 33/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 42.6661 - val_loss: 46.4218\n",
            "Epoch 34/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 42.3863 - val_loss: 46.4843\n",
            "Epoch 35/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 41.9230 - val_loss: 46.4649\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 42.0292 - val_loss: 46.5090\n",
            "Epoch 37/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 41.8037 - val_loss: 46.4833\n",
            "Epoch 38/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 41.4917 - val_loss: 46.4619\n",
            "Epoch 39/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 41.6445 - val_loss: 46.4379\n",
            "Epoch 40/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 40.9839roc-auc_val: 0.799\n",
            "47/47 [==============================] - 17s 357ms/step - loss: 40.8932 - val_loss: 46.4230\n",
            "Epoch 41/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.4808 - val_loss: 46.4522\n",
            "Epoch 42/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 41.0883 - val_loss: 46.4673\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.8989 - val_loss: 46.5141\n",
            "Epoch 44/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.7822 - val_loss: 46.5037\n",
            "Epoch 45/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.6291 - val_loss: 46.4930\n",
            "Epoch 46/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.0223 - val_loss: 46.5214\n",
            "Epoch 47/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.4549 - val_loss: 46.5477\n",
            "Epoch 48/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.2639 - val_loss: 46.5642\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.0779 - val_loss: 46.5373\n",
            "Epoch 50/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 39.5619roc-auc_val: 0.8002\n",
            "47/47 [==============================] - 17s 356ms/step - loss: 39.3001 - val_loss: 46.5606\n",
            "Epoch 51/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 39.5302 - val_loss: 46.5545\n",
            "Epoch 52/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 39.4348 - val_loss: 46.5642\n",
            "Epoch 53/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 39.7924 - val_loss: 46.5675\n",
            "Epoch 54/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.9460 - val_loss: 46.6115\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 39.0565 - val_loss: 46.6148\n",
            "Epoch 56/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 39.5177 - val_loss: 46.5904\n",
            "Epoch 57/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.8139 - val_loss: 46.6338\n",
            "Epoch 58/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.7371 - val_loss: 46.6506\n",
            "Epoch 59/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.4356 - val_loss: 46.6296\n",
            "Epoch 60/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 39.0238roc-auc_val: 0.8024\n",
            "47/47 [==============================] - 17s 357ms/step - loss: 39.0453 - val_loss: 46.6575\n",
            "Epoch 61/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.3312 - val_loss: 46.7037\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.5828 - val_loss: 46.6753\n",
            "Epoch 63/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.4536 - val_loss: 46.6677\n",
            "Epoch 64/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.2445 - val_loss: 46.7086\n",
            "Epoch 65/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 38.1916 - val_loss: 46.7750\n",
            "Epoch 66/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 37.5376 - val_loss: 46.7471\n",
            "Epoch 67/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 37.8176 - val_loss: 46.7235\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 37.7423 - val_loss: 46.7480\n",
            "Epoch 69/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 37.9319 - val_loss: 46.7781\n",
            "Epoch 70/1000\n",
            "42/47 [=========================>....] - ETA: 0s - loss: 37.7387roc-auc_val: 0.8038\n",
            "47/47 [==============================] - 18s 378ms/step - loss: 37.6092 - val_loss: 46.7936\n",
            "Epoch 71/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 37.4663 - val_loss: 46.8195\n",
            "Epoch 72/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 37.5813 - val_loss: 46.8863\n",
            "Epoch 73/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 37.2284 - val_loss: 46.9046\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 37.6808 - val_loss: 46.9001\n",
            "Epoch 75/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 37.2307 - val_loss: 46.9387\n",
            "Epoch 76/1000\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 37.2613 - val_loss: 47.0042\n",
            "Epoch 1/1000\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 73.4419 - val_loss: 49.1826\n",
            "Epoch 2/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 62.7542 - val_loss: 47.9105\n",
            "Epoch 3/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 58.1430 - val_loss: 47.7612\n",
            "Epoch 4/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 55.3065 - val_loss: 47.3165\n",
            "Epoch 5/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 53.4884 - val_loss: 47.2658\n",
            "Epoch 6/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 52.2156 - val_loss: 46.9358\n",
            "Epoch 7/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 51.7788 - val_loss: 46.7542\n",
            "Epoch 8/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 50.2039 - val_loss: 46.6331\n",
            "Epoch 9/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 49.3908 - val_loss: 46.6529\n",
            "Epoch 10/1000\n",
            "82/88 [==========================>...] - ETA: 0s - loss: 49.5303roc-auc_val: 0.79\n",
            "88/88 [==============================] - 14s 165ms/step - loss: 49.3384 - val_loss: 46.5464\n",
            "Epoch 11/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 48.5009 - val_loss: 46.4285\n",
            "Epoch 12/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 47.5510 - val_loss: 46.4509\n",
            "Epoch 13/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 46.6453 - val_loss: 46.2958\n",
            "Epoch 14/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 47.3979 - val_loss: 46.1316\n",
            "Epoch 15/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 46.2972 - val_loss: 46.0480\n",
            "Epoch 16/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 46.1278 - val_loss: 45.9631\n",
            "Epoch 17/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 45.3496 - val_loss: 45.8287\n",
            "Epoch 18/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 45.4494 - val_loss: 45.8086\n",
            "Epoch 19/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 44.7473 - val_loss: 45.6862\n",
            "Epoch 20/1000\n",
            "83/88 [===========================>..] - ETA: 0s - loss: 44.6150roc-auc_val: 0.8011\n",
            "88/88 [==============================] - 14s 162ms/step - loss: 44.4423 - val_loss: 45.6300\n",
            "Epoch 21/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 43.9074 - val_loss: 45.6752\n",
            "Epoch 22/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 43.7657 - val_loss: 45.6272\n",
            "Epoch 23/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 43.6751 - val_loss: 45.5447\n",
            "Epoch 24/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 43.7280 - val_loss: 45.4996\n",
            "Epoch 25/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 42.8269 - val_loss: 45.4342\n",
            "Epoch 26/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 43.0560 - val_loss: 45.3429\n",
            "Epoch 27/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 42.8280 - val_loss: 45.2755\n",
            "Epoch 28/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 42.7363 - val_loss: 45.2061\n",
            "Epoch 29/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 42.2183 - val_loss: 45.1895\n",
            "Epoch 30/1000\n",
            "85/88 [===========================>..] - ETA: 0s - loss: 42.0589roc-auc_val: 0.8062\n",
            "88/88 [==============================] - 15s 165ms/step - loss: 42.0943 - val_loss: 45.1618\n",
            "Epoch 31/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 41.6027 - val_loss: 45.1170\n",
            "Epoch 32/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 41.9491 - val_loss: 45.1170\n",
            "Epoch 33/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 41.7923 - val_loss: 45.0452\n",
            "Epoch 34/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 42.0628 - val_loss: 45.0143\n",
            "Epoch 35/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 41.2179 - val_loss: 45.0177\n",
            "Epoch 36/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 41.1182 - val_loss: 44.9602\n",
            "Epoch 37/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 40.8389 - val_loss: 44.9327\n",
            "Epoch 38/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 41.1217 - val_loss: 44.9186\n",
            "Epoch 39/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 40.7569 - val_loss: 44.8509\n",
            "Epoch 40/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 40.5052roc-auc_val: 0.8094\n",
            "88/88 [==============================] - 14s 165ms/step - loss: 40.5052 - val_loss: 44.8071\n",
            "Epoch 41/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 40.8212 - val_loss: 44.8644\n",
            "Epoch 42/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 40.8867 - val_loss: 44.8513\n",
            "Epoch 43/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 40.3386 - val_loss: 44.8408\n",
            "Epoch 44/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 40.0520 - val_loss: 44.8215\n",
            "Epoch 45/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 40.0983 - val_loss: 44.7996\n",
            "Epoch 46/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.7798 - val_loss: 44.7735\n",
            "Epoch 47/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 40.0148 - val_loss: 44.7573\n",
            "Epoch 48/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.3778 - val_loss: 44.7208\n",
            "Epoch 49/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.5540 - val_loss: 44.7230\n",
            "Epoch 50/1000\n",
            "86/88 [============================>.] - ETA: 0s - loss: 39.6124roc-auc_val: 0.8113\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 39.5795 - val_loss: 44.6914\n",
            "Epoch 51/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.2050 - val_loss: 44.6497\n",
            "Epoch 52/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.6591 - val_loss: 44.6527\n",
            "Epoch 53/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.3124 - val_loss: 44.6127\n",
            "Epoch 54/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.2926 - val_loss: 44.5810\n",
            "Epoch 55/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.2763 - val_loss: 44.5867\n",
            "Epoch 56/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.3592 - val_loss: 44.5667\n",
            "Epoch 57/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.0121 - val_loss: 44.5522\n",
            "Epoch 58/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.6685 - val_loss: 44.5283\n",
            "Epoch 59/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 39.2011 - val_loss: 44.5208\n",
            "Epoch 60/1000\n",
            "86/88 [============================>.] - ETA: 0s - loss: 39.1459roc-auc_val: 0.8129\n",
            "88/88 [==============================] - 15s 165ms/step - loss: 39.1352 - val_loss: 44.5168\n",
            "Epoch 61/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.6148 - val_loss: 44.5169\n",
            "Epoch 62/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.3909 - val_loss: 44.5223\n",
            "Epoch 63/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.7503 - val_loss: 44.5275\n",
            "Epoch 64/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.8599 - val_loss: 44.5276\n",
            "Epoch 65/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.5681 - val_loss: 44.4827\n",
            "Epoch 66/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.2769 - val_loss: 44.4752\n",
            "Epoch 67/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.1182 - val_loss: 44.4719\n",
            "Epoch 68/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 38.3800 - val_loss: 44.4630\n",
            "Epoch 69/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.9621 - val_loss: 44.4399\n",
            "Epoch 70/1000\n",
            "82/88 [==========================>...] - ETA: 0s - loss: 38.0108roc-auc_val: 0.8138\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 38.1673 - val_loss: 44.4459\n",
            "Epoch 71/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.9605 - val_loss: 44.4229\n",
            "Epoch 72/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.2157 - val_loss: 44.4083\n",
            "Epoch 73/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.0581 - val_loss: 44.3957\n",
            "Epoch 74/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.7596 - val_loss: 44.3850\n",
            "Epoch 75/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.6972 - val_loss: 44.3696\n",
            "Epoch 76/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.2785 - val_loss: 44.3505\n",
            "Epoch 77/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 38.2018 - val_loss: 44.3547\n",
            "Epoch 78/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.8346 - val_loss: 44.3464\n",
            "Epoch 79/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.6102 - val_loss: 44.3591\n",
            "Epoch 80/1000\n",
            "83/88 [===========================>..] - ETA: 0s - loss: 38.4311roc-auc_val: 0.8147\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 38.2667 - val_loss: 44.3551\n",
            "Epoch 81/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.8632 - val_loss: 44.3354\n",
            "Epoch 82/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.8942 - val_loss: 44.3273\n",
            "Epoch 83/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.4991 - val_loss: 44.3091\n",
            "Epoch 84/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.3604 - val_loss: 44.2882\n",
            "Epoch 85/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.4710 - val_loss: 44.2965\n",
            "Epoch 86/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.0201 - val_loss: 44.2758\n",
            "Epoch 87/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.5983 - val_loss: 44.2341\n",
            "Epoch 88/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.2057 - val_loss: 44.2483\n",
            "Epoch 89/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.2977 - val_loss: 44.2438\n",
            "Epoch 90/1000\n",
            "84/88 [===========================>..] - ETA: 0s - loss: 37.3364roc-auc_val: 0.8157\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 37.3428 - val_loss: 44.2343\n",
            "Epoch 91/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.3677 - val_loss: 44.2328\n",
            "Epoch 92/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.9829 - val_loss: 44.2198\n",
            "Epoch 93/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.8471 - val_loss: 44.2172\n",
            "Epoch 94/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.2090 - val_loss: 44.2102\n",
            "Epoch 95/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.9805 - val_loss: 44.2222\n",
            "Epoch 96/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.7295 - val_loss: 44.2278\n",
            "Epoch 97/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 37.0397 - val_loss: 44.2170\n",
            "Epoch 98/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.7404 - val_loss: 44.2050\n",
            "Epoch 99/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.8954 - val_loss: 44.2030\n",
            "Epoch 100/1000\n",
            "85/88 [===========================>..] - ETA: 0s - loss: 36.8391roc-auc_val: 0.816\n",
            "88/88 [==============================] - 14s 163ms/step - loss: 36.7796 - val_loss: 44.2182\n",
            "Epoch 101/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.9581 - val_loss: 44.2086\n",
            "Epoch 102/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.7555 - val_loss: 44.2018\n",
            "Epoch 103/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.5571 - val_loss: 44.2084\n",
            "Epoch 104/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.7198 - val_loss: 44.1952\n",
            "Epoch 105/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.4585 - val_loss: 44.2039\n",
            "Epoch 106/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.2226 - val_loss: 44.2015\n",
            "Epoch 107/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.5610 - val_loss: 44.1791\n",
            "Epoch 108/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.5241 - val_loss: 44.1741\n",
            "Epoch 109/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.6194 - val_loss: 44.1868\n",
            "Epoch 110/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 36.1895roc-auc_val: 0.8166\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 36.1895 - val_loss: 44.1838\n",
            "Epoch 111/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.4167 - val_loss: 44.1671\n",
            "Epoch 112/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.3271 - val_loss: 44.1748\n",
            "Epoch 113/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.4138 - val_loss: 44.1804\n",
            "Epoch 114/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.0597 - val_loss: 44.1694\n",
            "Epoch 115/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.1678 - val_loss: 44.1728\n",
            "Epoch 116/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.1793 - val_loss: 44.1730\n",
            "Epoch 117/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.0139 - val_loss: 44.1769\n",
            "Epoch 118/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.4559 - val_loss: 44.1715\n",
            "Epoch 119/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.8686 - val_loss: 44.1756\n",
            "Epoch 120/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 36.2837roc-auc_val: 0.8169\n",
            "88/88 [==============================] - 15s 170ms/step - loss: 36.2837 - val_loss: 44.2049\n",
            "Epoch 121/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 36.0981 - val_loss: 44.1941\n",
            "Epoch 122/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 35.7570 - val_loss: 44.1865\n",
            "Epoch 123/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 36.0965 - val_loss: 44.1872\n",
            "Epoch 124/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 36.0045 - val_loss: 44.1916\n",
            "Epoch 125/1000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 35.8590 - val_loss: 44.1912\n",
            "Epoch 126/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.7916 - val_loss: 44.1712\n",
            "Epoch 127/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.0390 - val_loss: 44.1776\n",
            "Epoch 128/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.7342 - val_loss: 44.1568\n",
            "Epoch 129/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.9679 - val_loss: 44.1623\n",
            "Epoch 130/1000\n",
            "87/88 [============================>.] - ETA: 0s - loss: 36.0055roc-auc_val: 0.8173\n",
            "88/88 [==============================] - 15s 170ms/step - loss: 36.0004 - val_loss: 44.1677\n",
            "Epoch 131/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.6805 - val_loss: 44.1690\n",
            "Epoch 132/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.6455 - val_loss: 44.1744\n",
            "Epoch 133/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 36.0008 - val_loss: 44.1664\n",
            "Epoch 134/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.8215 - val_loss: 44.1691\n",
            "Epoch 135/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.9876 - val_loss: 44.1437\n",
            "Epoch 136/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.6972 - val_loss: 44.1204\n",
            "Epoch 137/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.3763 - val_loss: 44.1108\n",
            "Epoch 138/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.7295 - val_loss: 44.1180\n",
            "Epoch 139/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.8905 - val_loss: 44.1129\n",
            "Epoch 140/1000\n",
            "84/88 [===========================>..] - ETA: 0s - loss: 35.6374roc-auc_val: 0.8178\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 35.5599 - val_loss: 44.1061\n",
            "Epoch 141/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.4385 - val_loss: 44.1161\n",
            "Epoch 142/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.2144 - val_loss: 44.1066\n",
            "Epoch 143/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.4619 - val_loss: 44.1147\n",
            "Epoch 144/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.5577 - val_loss: 44.1313\n",
            "Epoch 145/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.6185 - val_loss: 44.1470\n",
            "Epoch 146/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.3366 - val_loss: 44.1352\n",
            "Epoch 147/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.5114 - val_loss: 44.1179\n",
            "Epoch 148/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.4011 - val_loss: 44.1258\n",
            "Epoch 149/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.1901 - val_loss: 44.1527\n",
            "Epoch 150/1000\n",
            "85/88 [===========================>..] - ETA: 0s - loss: 35.3498roc-auc_val: 0.818\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 35.3282 - val_loss: 44.1373\n",
            "Epoch 151/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.3610 - val_loss: 44.1288\n",
            "Epoch 152/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.6853 - val_loss: 44.1106\n",
            "Epoch 153/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.1542 - val_loss: 44.1238\n",
            "Epoch 154/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.2343 - val_loss: 44.1084\n",
            "Epoch 155/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.1438 - val_loss: 44.1019\n",
            "Epoch 156/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.2265 - val_loss: 44.1222\n",
            "Epoch 157/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.4012 - val_loss: 44.1201\n",
            "Epoch 158/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.3728 - val_loss: 44.1152\n",
            "Epoch 159/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.9087 - val_loss: 44.1168\n",
            "Epoch 160/1000\n",
            "86/88 [============================>.] - ETA: 0s - loss: 35.0292roc-auc_val: 0.8183\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 34.8743 - val_loss: 44.0979\n",
            "Epoch 161/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7576 - val_loss: 44.1099\n",
            "Epoch 162/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.9567 - val_loss: 44.1011\n",
            "Epoch 163/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.2055 - val_loss: 44.1146\n",
            "Epoch 164/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.9864 - val_loss: 44.0912\n",
            "Epoch 165/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7170 - val_loss: 44.1039\n",
            "Epoch 166/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.8336 - val_loss: 44.1129\n",
            "Epoch 167/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.0522 - val_loss: 44.1092\n",
            "Epoch 168/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.8099 - val_loss: 44.1103\n",
            "Epoch 169/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.9151 - val_loss: 44.1311\n",
            "Epoch 170/1000\n",
            "84/88 [===========================>..] - ETA: 0s - loss: 35.1179roc-auc_val: 0.8184\n",
            "88/88 [==============================] - 14s 163ms/step - loss: 35.0430 - val_loss: 44.1304\n",
            "Epoch 171/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7757 - val_loss: 44.1368\n",
            "Epoch 172/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.9364 - val_loss: 44.1229\n",
            "Epoch 173/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7761 - val_loss: 44.1180\n",
            "Epoch 174/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 35.2205 - val_loss: 44.1124\n",
            "Epoch 175/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.6888 - val_loss: 44.1010\n",
            "Epoch 176/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7501 - val_loss: 44.0929\n",
            "Epoch 177/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7823 - val_loss: 44.1093\n",
            "Epoch 178/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.5537 - val_loss: 44.1157\n",
            "Epoch 179/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.5813 - val_loss: 44.1259\n",
            "Epoch 180/1000\n",
            "85/88 [===========================>..] - ETA: 0s - loss: 34.8628roc-auc_val: 0.8187\n",
            "88/88 [==============================] - 14s 164ms/step - loss: 34.7807 - val_loss: 44.1403\n",
            "Epoch 181/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7400 - val_loss: 44.1372\n",
            "Epoch 182/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.6806 - val_loss: 44.1482\n",
            "Epoch 183/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7692 - val_loss: 44.1417\n",
            "Epoch 184/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.7062 - val_loss: 44.1321\n",
            "Epoch 185/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.3648 - val_loss: 44.1337\n",
            "Epoch 186/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.8318 - val_loss: 44.1377\n",
            "Epoch 187/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.8521 - val_loss: 44.1413\n",
            "Epoch 188/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4666 - val_loss: 44.1369\n",
            "Epoch 189/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4731 - val_loss: 44.1289\n",
            "Epoch 190/1000\n",
            "83/88 [===========================>..] - ETA: 0s - loss: 34.6201roc-auc_val: 0.8188\n",
            "88/88 [==============================] - 14s 163ms/step - loss: 34.6271 - val_loss: 44.1454\n",
            "Epoch 191/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4013 - val_loss: 44.1383\n",
            "Epoch 192/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4690 - val_loss: 44.1358\n",
            "Epoch 193/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4414 - val_loss: 44.1090\n",
            "Epoch 194/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.5448 - val_loss: 44.1276\n",
            "Epoch 195/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.6343 - val_loss: 44.1387\n",
            "Epoch 196/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.3137 - val_loss: 44.1537\n",
            "Epoch 197/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.5392 - val_loss: 44.1621\n",
            "Epoch 198/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4253 - val_loss: 44.1590\n",
            "Epoch 199/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.6460 - val_loss: 44.1205\n",
            "Epoch 200/1000\n",
            "86/88 [============================>.] - ETA: 0s - loss: 34.3572roc-auc_val: 0.8191\n",
            "88/88 [==============================] - 14s 165ms/step - loss: 34.4173 - val_loss: 44.1273\n",
            "Epoch 201/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.1756 - val_loss: 44.1341\n",
            "Epoch 202/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.0548 - val_loss: 44.1471\n",
            "Epoch 203/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.1765 - val_loss: 44.1440\n",
            "Epoch 204/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4841 - val_loss: 44.1568\n",
            "Epoch 205/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4509 - val_loss: 44.1462\n",
            "Epoch 206/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.0910 - val_loss: 44.1509\n",
            "Epoch 207/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.0826 - val_loss: 44.1526\n",
            "Epoch 208/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.1298 - val_loss: 44.1677\n",
            "Epoch 209/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 33.9756 - val_loss: 44.1704\n",
            "Epoch 210/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 34.2006roc-auc_val: 0.8191\n",
            "88/88 [==============================] - 14s 163ms/step - loss: 34.2006 - val_loss: 44.1618\n",
            "Epoch 211/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.1570 - val_loss: 44.1598\n",
            "Epoch 212/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.4263 - val_loss: 44.1558\n",
            "Epoch 213/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.1549 - val_loss: 44.1577\n",
            "Epoch 214/1000\n",
            "88/88 [==============================] - 1s 10ms/step - loss: 34.0339 - val_loss: 44.1431\n",
            "Epoch 1/1000\n",
            "47/47 [==============================] - 1s 31ms/step - loss: 74.7480 - val_loss: 51.2071\n",
            "Epoch 2/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 63.8379 - val_loss: 49.3164\n",
            "Epoch 3/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 61.6847 - val_loss: 48.7603\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 57.6092 - val_loss: 48.6581\n",
            "Epoch 5/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 56.5976 - val_loss: 48.6604\n",
            "Epoch 6/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 54.8732 - val_loss: 48.4633\n",
            "Epoch 7/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 53.4681 - val_loss: 48.4072\n",
            "Epoch 8/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 52.9909 - val_loss: 48.3770\n",
            "Epoch 9/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 51.3696 - val_loss: 48.4018\n",
            "Epoch 10/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 50.9003roc-auc_val: 0.7744\n",
            "47/47 [==============================] - 14s 304ms/step - loss: 50.8914 - val_loss: 48.0816\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 49.9376 - val_loss: 48.2154\n",
            "Epoch 12/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 49.5023 - val_loss: 48.0836\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 49.6015 - val_loss: 48.0011\n",
            "Epoch 14/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 48.8586 - val_loss: 47.9655\n",
            "Epoch 15/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 48.3448 - val_loss: 47.8878\n",
            "Epoch 16/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 47.5912 - val_loss: 47.8364\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.9690 - val_loss: 47.5947\n",
            "Epoch 18/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 46.5721 - val_loss: 47.5731\n",
            "Epoch 19/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.8598 - val_loss: 47.6052\n",
            "Epoch 20/1000\n",
            "43/47 [==========================>...] - ETA: 0s - loss: 45.1377roc-auc_val: 0.7839\n",
            "47/47 [==============================] - 14s 304ms/step - loss: 45.0514 - val_loss: 47.5781\n",
            "Epoch 21/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.3856 - val_loss: 47.5380\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.6090 - val_loss: 47.4852\n",
            "Epoch 23/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 45.1157 - val_loss: 47.5688\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.0822 - val_loss: 47.6060\n",
            "Epoch 25/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.0424 - val_loss: 47.6424\n",
            "Epoch 26/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.4330 - val_loss: 47.4968\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 43.1159 - val_loss: 47.5695\n",
            "Epoch 28/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 44.0208 - val_loss: 47.6410\n",
            "Epoch 29/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.7803 - val_loss: 47.5353\n",
            "Epoch 30/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 43.2503roc-auc_val: 0.7889\n",
            "47/47 [==============================] - 14s 303ms/step - loss: 43.1039 - val_loss: 47.5382\n",
            "Epoch 31/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.3002 - val_loss: 47.4244\n",
            "Epoch 32/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.7457 - val_loss: 47.4476\n",
            "Epoch 33/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.4063 - val_loss: 47.4077\n",
            "Epoch 34/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.2107 - val_loss: 47.3569\n",
            "Epoch 35/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.4246 - val_loss: 47.3551\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 41.7866 - val_loss: 47.4152\n",
            "Epoch 37/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 42.3541 - val_loss: 47.4598\n",
            "Epoch 38/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 41.1377 - val_loss: 47.5102\n",
            "Epoch 39/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 41.0478 - val_loss: 47.5853\n",
            "Epoch 40/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 41.3548roc-auc_val: 0.7912\n",
            "47/47 [==============================] - 15s 313ms/step - loss: 41.0264 - val_loss: 47.5273\n",
            "Epoch 41/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.5926 - val_loss: 47.5175\n",
            "Epoch 42/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 41.0249 - val_loss: 47.5248\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.7439 - val_loss: 47.4767\n",
            "Epoch 44/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.3043 - val_loss: 47.4777\n",
            "Epoch 45/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.8498 - val_loss: 47.4636\n",
            "Epoch 46/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 40.5307 - val_loss: 47.4337\n",
            "Epoch 47/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 39.7391 - val_loss: 47.4311\n",
            "Epoch 48/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 39.9183 - val_loss: 47.3869\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 39.9825 - val_loss: 47.4961\n",
            "Epoch 50/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 40.1021roc-auc_val: 0.7942\n",
            "47/47 [==============================] - 15s 310ms/step - loss: 39.9630 - val_loss: 47.5081\n",
            "Epoch 51/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 40.2796 - val_loss: 47.4945\n",
            "Epoch 52/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 39.5304 - val_loss: 47.4501\n",
            "Epoch 53/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 39.5951 - val_loss: 47.5237\n",
            "Epoch 54/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 40.0064 - val_loss: 47.4878\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 39.2008 - val_loss: 47.4387\n",
            "Epoch 56/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 39.0512 - val_loss: 47.4280\n",
            "Epoch 57/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.9089 - val_loss: 47.4239\n",
            "Epoch 58/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 39.2675 - val_loss: 47.4959\n",
            "Epoch 59/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.8787 - val_loss: 47.4191\n",
            "Epoch 60/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 38.5324roc-auc_val: 0.7966\n",
            "47/47 [==============================] - 14s 303ms/step - loss: 38.4865 - val_loss: 47.4690\n",
            "Epoch 61/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.5962 - val_loss: 47.4670\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.1189 - val_loss: 47.4350\n",
            "Epoch 63/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.8376 - val_loss: 47.4467\n",
            "Epoch 64/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.7208 - val_loss: 47.4961\n",
            "Epoch 65/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.1744 - val_loss: 47.4827\n",
            "Epoch 66/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.5785 - val_loss: 47.5639\n",
            "Epoch 67/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 38.3047 - val_loss: 47.5554\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.9649 - val_loss: 47.5952\n",
            "Epoch 69/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.7834 - val_loss: 47.5961\n",
            "Epoch 70/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 37.9334roc-auc_val: 0.7978\n",
            "47/47 [==============================] - 14s 304ms/step - loss: 37.7435 - val_loss: 47.6105\n",
            "Epoch 71/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.6897 - val_loss: 47.5850\n",
            "Epoch 72/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.9372 - val_loss: 47.6541\n",
            "Epoch 73/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.8779 - val_loss: 47.5912\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.6834 - val_loss: 47.5677\n",
            "Epoch 75/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.0420 - val_loss: 47.6087\n",
            "Epoch 76/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.0365 - val_loss: 47.6271\n",
            "Epoch 77/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.3047 - val_loss: 47.6754\n",
            "Epoch 78/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.7549 - val_loss: 47.6637\n",
            "Epoch 79/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 36.8600 - val_loss: 47.6286\n",
            "Epoch 80/1000\n",
            "43/47 [==========================>...] - ETA: 0s - loss: 36.7789roc-auc_val: 0.7994\n",
            "47/47 [==============================] - 14s 302ms/step - loss: 36.7704 - val_loss: 47.6633\n",
            "Epoch 81/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 36.9836 - val_loss: 47.6879\n",
            "Epoch 82/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 37.0262 - val_loss: 47.7028\n",
            "Epoch 83/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 36.5233 - val_loss: 47.7701\n",
            "Epoch 84/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 36.8196 - val_loss: 47.7531\n",
            "Epoch 85/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 36.3882 - val_loss: 47.7684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnpeTPNLkiCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "outputId": "ea43e5b7-acff-4b5f-ea85-81781fd12386"
      },
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "for i in dk.keys():\n",
        "  sns.distplot(dk[i])\n",
        "  plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU5b3//9dnZrLve8geIIBsAUxBwbVWXI6CWtuqtdVW69e2tt9Te873rLX92X7Pt+e0Pac9rdZSD9X2FK3LUalFca0IyBKEsIQtBBKyb5B9sl6/PzKxARMySSZzz/J5Ph55MHPf92TeN4FPrrnu674uMcaglFIqcNmsDqCUUmp6aaFXSqkAp4VeKaUCnBZ6pZQKcFrolVIqwDmsDjCa5ORkk5eXZ3UMpZTyG3v27GkyxqSMts8nC31eXh7FxcVWx1BKKb8hIhVj7dOuG6WUCnBa6JVSKsBpoVdKqQCnhV4ppQKcFnqllApwWuiVUirAaaFXSqkAp4VeKaUCnBZ6pZQKcD55Z6zyrA07Kz+27a4VORYkUUpZQQu9j7tQka5rdXL6TBd1rU5aOnvp6Omns6cfEbCJkBITxuzUaLp6+okM0x+1UsFK//f7EWMMx+o7uOnnW6ls7qTN2f+xY+w2QYABYxheJdImsCAjjpWzkshJjEREvBtcKWUpLfR+oqK5k9cO1lHZ0kVMmIP8lChyEiNJjg4jNiKE6DAHX7w0lzCHDRHBGENDew/H6tv51XvlFFe0cKC6lXnpMawpzLD6dJRSXqSF3g+U1rTxzK5KosLsrF2SwcW5CThsH7+O/j8fVo/6+hsXzeCai1LZWd7C20fq+dnbx4kJd/D5FbnYbNq6VyrQaaH3caU1rTyz6zQz4sP58qp8wkPsk/o+YQ47V8xJYWFmHC/vreY7rxxiY0kN/++2xcxOjfZwaqWUL9HhlT5sT8UZNuyqJGOKRX6kxKhQvrQqjx/dvphj9R3c+LP3+dHmI3T1fry/XykVGLTQ+yhn3wD/54USYsND+JKHivwwEeEzRdm89fCV/NXiGTz27gmu+cl7/LGkBjN8BVcpFTDGLfQisl5EGkTk4Bj7/1ZE9rm+DorIgIgkuvadEpEDrn26ZNQE/Pyd45xo7OTWpZkeLfIjpcSE8R+fW8ILD15KYlQo33hmL3f+egdH6tqm5f2UUtaQ8VpwInIF0AH81hizcJxjbwa+ZYz5pOv5KaDIGNM0kVBFRUUmmJcSPFjdytrHtnHb0kyW5iR45T0HjWH3qRbeLK3H2TfAjYtmcOnMJEREb65Syg+IyB5jTNFo+8Zt0RtjtgAtbr7XncAzE8imzmOM4XsbD5EQGco//9V8r72vTYQV+Uk8/Kk5zEmL4dX9tfyh+DS9/YNey6CUmh4e66MXkUjgeuDFEZsN8IaI7BGRB8Z5/QMiUiwixY2NjZ6K5Xe2HG+iuOIM//tTBcRFhnj9/SPDHNx9SS6r56dxoKqVde+foL7N6fUcSinP8eTF2JuBbcaYka3/y4wxy4AbgK+7uoFGZYxZZ4wpMsYUpaSkeDCW/zDG8O9vHCUzPoLPFWVblsMmwlVzU/nipbk0tfdy62PbtN9eKT/myUJ/B+d12xhjql1/NgAvAcs9+H4BZcPOSh555RAlVa2syE/khT1Vo85z401z02N54IqZDBjD7b/8gPeOBe8nLaX8mUcKvYjEAVcCr4zYFiUiMcOPgdXAqCN31FBr/q3D9SRGhXrtAqw7MuIjePnrq8hOjOTLT+22/JePUmri3Ble+QzwATBXRKpE5D4ReVBEHhxx2K3AG8aYzhHb0oCtIlIC7AL+ZIx53ZPhA0lZYwe1rU6unpuK3cemJZgRF8HzD17K5QXJ/ONLB/jrZ/dytqvX6lhKKTeNOwWCMeZON455CnjqvG3lQOFkgwWb7WXNRIc5KMyKszrKxwy34q+Zl4bdJmwsqeHtww18/5aF3LR4Bg77+B8MdU58payjc934gPLGDo7Wt3PNvFS3iqZV7DbhmnlpXJQey4sfVvHXf9jHj984yt2X5FKYFc/s1GjOdvVS3tTJ4do29le1crqli6U58dhtNualxxDiw+enVKDSQu8Dntp+CrtNWJ6faHUUt2TER/D1q2eTFhvOE++d4IevHfnYMSIwOyWarIQIXj9YR5uzn5zESL68Kp9QhxZ7pbxJC73FWrv7eGFPFYVZccSEe3/c/GTZRGhs7+HTy7K4dn4a9a1OGtp7iApzkBwdSkp0GGGuqRs+OS+NkqqzvLiniueKT3PXihxsuviJUl6jhd5iL+6poqt3gEtnJVsdZdJiw0OIDQ+hIC1m1P12m7AsJwFn3wCv7q/l1f01rCnM9HJKpYKXFnqLvbS3moWZsWTGR1gdZdqtnJXM2a4+tpY1sTDT9y46KxWotLPUQmUNHRyobuWWJcHTur12fhpxESG8dqCOwUGdElkpb9AWvQWGhxq+WVqHAP1BVPBC7DZWz0/j+T1VvFJSza1Ls6yOpFTA0xa9RYwx7Dt9ltmp0cT60UVYTyjMjiczPoIfvX4UZ9+A1XGUCnha6C1S2dLFma4+CrPjrY7idTYRbliUTk2rk//aetLqOEoFPC30Ftl7+iwhdmHBjFiro1hiZnI0185P4/F3y2hs77E6jlIBTQu9BQaN4VBNG/PSYz8aax6M/uGGefT0D/Ifbx2zOopSAU0LvQVqW5109vQzL330cefBYmZKNHdfksuzuyo5Xt9udRylApYWegsMF7XZqdEWJ7HeN68pICrMwaOvljLe+sVKqcnRQm+BY/XtZMSH+9WUB9MlMSqUv1k9l/ePN/Hs7tNWx1EqIGmh97I2Zx+VLV3MSQ3ubpuRvnBJLitnJfGDV0s53dJldRylAo7eMOVl28uaGDSMOS9MMBk5R/2q2cnsqTjDF9fv4q2Hr/S5xVeU8mfaovey9441EuawkZMYaXUUn5IQGcpNizM42dTJt5/bR//AoNWRlAoY2qL3ImMM7x1tZHZqtLZYR3FxbgLtzj5e3ldD34Dhp3cs0YVKlPIA/V/kRScaO6hpdVKg/fNjumpuKv/8VxfxpwO13Pb4draXNVkdSSm/587i4OtFpEFEDo6x/yoRaRWRfa6vR0bsu15EjopImYj8vSeD+6Pdp84AMDMlyuIkvu3+y2fy8zuX0tzRw11P7uTOdTv4/c4KGtqcVkdTyi+503XzFPAL4LcXOOZ9Y8xNIzeIiB14DLgWqAJ2i8hGY0zpJLP6vQ8rzpAYFUpSVKjVUXzezYUZXDs/jd9+cIr/3lHJP710kH966SDZCRHMnxHL4ux4EiJDdYFxpdwwbqE3xmwRkbxJfO/lQJkxphxARJ4F1gLBW+grz7A0Ox7RZfQuaORonOiwEP7XFTOpb+/hcG0bh2vb2Fxaz9tHGrh2fhqf+0S2Xu9Qahye6qO/VERKROQ1EVng2pYJjLwDpsq1bVQi8oCIFItIcWNjo4di+Y6zXb2caOxkWW6C1VH8joiQHhvO1XNT+dpVs/nb6+ZSkBbDawfruO2X22nq0EnRlLoQTxT6D4FcY0wh8HPg5cl8E2PMOmNMkTGmKCUlxQOxfMveyrMALM0JvmmJPS0hMpS7V+TwuU9kc7SujS/9ZjcdPf1Wx1LKZ015eKUxpm3E400i8riIJAPVQPaIQ7Nc24LSh5VnsAkUZsVzqknv/pwqEaEwK54wh43/3lHBml9s5d5L83C4hmNq371SfzHlFr2IpIur01lElru+ZzOwGygQkXwRCQXuADZO9f381YeVZ5iXHktUmN664Enz0mP59LIsyhs72VhSY3UcpXzSuFVHRJ4BrgKSRaQK+C4QAmCMeQK4HfiqiPQD3cAdZmgawn4ReQjYDNiB9caYQ9NyFj5uYNCwr/Isty4LnkXAvWlpTgKN7T38+Vgjc9JiWJgZZ3UkpXyKO6Nu7hxn/y8YGn452r5NwKbJRfN/w6NHalu76ewdoKdv8JwRJcpzrrkojbLGDl7aW022Ti+h1Dn0zlgvqHTNyKjz20wfu034bFE2/YODvLDnNIODOre9UsO00HtBVUs3kaF2EvVGqWmVHB3GTYsyONHYydMfnLI6jlI+Qwu9F9S0dpMZH6E3SnlBUV4Cc9Ni+OFrRzjR2GF1HKV8ghb6aTYwaGho7yE9LtzqKEFBRLh1WSYRoXYefq5EpztWCi30066xvYeBQcOMuAirowSN2PAQvr92ISWnz/LEeyesjqOU5bTQT7Pa1m4AZmiL3qtuLszg5sIMfvrWcQ5Wt1odRylLaaGfZrWtThw2ITk6zOooQef7axeQGBXKt58road/wOo4SllGC/00q2t1khYbrjMsetmGnZVsOlDHDQvTOVrfzv1PFVsdSSnLaKGfRsYYalq79UKsheamx7IiP5H3y5rYfKjO6jhKWUIL/TRqd/bT1Tug/fMWu3HRDDLjI/ib50oo1yGXKghpoZ9Gta1DS9/piBtrhdht3LUiB4ddePC/9+iUxiroaKGfRjrixnckRIby8zuXcaKxk6/+9x56+3V8vQoeWuinUW2rk4TIEMJD7FZHUcBlBcn88LZFvH+8ib97cb/Oh6OChk6OPo3qWp3abeNDhmcOvXZ+Gi/trabmbDc3F2Zw9yW5FidTanppoZ8mzr4Bmjp6WJSlc6P7mqvmpODsG+D940109g7wmaIswhxT+9S1YWclxhjanP3YbUKo3ca9q/I8E1ipKdJCP03KGzsxQGqM3ijla0SEGxbOIDrMwWsH6/jCk7v48WcKyUma+DTSxhiO1LWz+VAd+6vOcqar76N9f9hdyZolmcRFhJzzGl3mUHmbFvppcryhHYDUWL0Q66suL0ghJjyEP+2v4bqfbuHbq+fwhUtz3Wrdn2zq5I8lNWwsqaGsoQObwKyUaFbNTkZEaOvuY/uJJn729jHWFGayJFsXhVfW0UI/TU40dCBAss5B79OWZMfz158q4DsvH+QHfzrMY++WcevSLK5bkMactBgSokIxxtDVO0BJ1VmefP8kR+raqDk7NHQ2LymKNYUZLMyMI/q89YAvzk3gxT1VPF98msSoUF14RllGC/00Od7QQWJUKA67DmzydRnxETx5TxFby5p4dtdpfrfjFOu3nQQgOsyBs2+AftcIHQEyEyK4cWE6i7LiP9YtM1JydBj3rMzjP985zvPFp/nGJwsIdei/B+V97iwOvh64CWgwxiwcZf/ngb9j6P9AO/BVY0yJa98p17YBoN8YU+S56L6trKFDu238xMh1fFfNTmZpdjyz0qIpq++g+uzQ6mDR4Q7mpsVwqqmLiFD3L9yGh9i5fVkWT249yeuHallTqAvEK+9zp3nxFHD9BfafBK40xiwCvg+sO2//1caYJcFU5PsGBjnZ1KkXYv1UZJiD2rNOosIczEmLISshkviIUOrbeiZU5IfNTIlm1awkdpS3UNHcOQ2JlbqwcQu9MWYL0HKB/duNMWdcT3cAWR7K5rcqmrvoHzRa6NVHrp2fTmSonfeONVodRQUhT3cY3ge8NuK5Ad4QkT0i8sCFXigiD4hIsYgUNzb693+GsoahibNStNArl1CHjRX5SRypa9eJ1ZTXeazQi8jVDBX6vxux+TJjzDLgBuDrInLFWK83xqwzxhQZY4pSUlI8FcsSZa6hlVro1UiXzEzEYRP+a+tJq6OoIOORQi8ii4EngbXGmObh7caYatefDcBLwHJPvJ+vK2voIDM+Ysp3W6rAEhMewpLseF78sIqWzl6r46ggMuVCLyI5wP8AXzDGHBuxPUpEYoYfA6uBg1N9P39wvKGD2anRVsdQPmjV7GScfYP8fkeF1VFUEBm30IvIM8AHwFwRqRKR+0TkQRF50HXII0AS8LiI7BOR4TXb0oCtIlIC7AL+ZIx5fRrOwacMDhpONGqhV6NLiw3n8oJknttzGmN09kzlHeOOozfG3DnO/vuB+0fZXg4UTj6af6o+242zb5CC1Gh0Flw1mluWZPLt50v4sPIMF+cmWh1HBQG9Tc/DhkfcaItejaWtu48Qu/CjzUfZsLPynBu2lJoOWug97IRr6NysFC30anRhIXbmpceyv6qVAf3Yp7xAC72HlTd1khAZQoJOZqYuYEl2PF29Ax8NxVVqOmmh97CTjZ3kJ0dZHUP5uIK0aCJC7Ow7fdbqKCoIaKH3sFPNneRpoVfjcNhsLMqMo7S2TRcqV9NOC70HdfX2U9vqZKYWeuWGxVlx9A0YjtZr942aXjofvYds2FlJbWs3ANVnnTqSQo0rLzmKqDAHB6tbrY6iApy26D2oqWPotvbkaL0Qq8ZnE2FBRixH69rp7h2wOo4KYFroPai5oweApCidzEy5Z2FGHL0Dg7x3rMHqKCqAaaH3oKaOHmLDHbpcnHJbfnIUkaF2Nh2oszqKCmBakTyoqaOX5GhtzSv32W1D3TdvH67H2afdN2p6aKH3oKaOHi30asIWZsbR2TvAFl19Sk0TLfQe0tXbT1fvAEl6IVZN0MzkaOIjQ9h0oNbqKCpAaaH3kOaPRtxoi15NjN0mrJ6fxluHG+jp1+4b5Xla6D2kyTXiRgu9mowbF82go6efrcebrI6iApAWeg9p6ujBJpAQFWJ1FOWHVs5KJjbcwZ+0+0ZNAy30HtLU0Ut8ZCgOm/6VqokLddhYvSCdN0vrde4b5XFalTykuaNH74hVU3LjonTanf1sK9PuG+VZWug9wBhDc2ev3hGrpmTV7GRiwhw6+kZ5nFuFXkTWi0iDiBwcY7+IyH+KSJmI7BeRZSP23SMix11f93gquC9p7uylp39Qh1aqKQlz2Ll2QRqvH6qb1Nw3w8sSjvxSCtxv0T8FXH+B/TcABa6vB4BfAohIIvBdYAWwHPiuiCRMNqyvqmjuAiBRV5VSU/TZomzanf3aqlce5VahN8ZsAVoucMha4LdmyA4gXkRmANcBbxpjWowxZ4A3ufAvDL9U0dwJ6GRmaupW5CcyMzmKZ3Zpa1x5jqfmo88ETo94XuXaNtb2jxGRBxj6NEBOTo6HYnlHRXMXAiRE6tBKNTkju1nmpsfw2sE6/uPNY3zr2jkWplKBwmcuxhpj1hljiowxRSkpKVbHmZCK5k7iIkNw2H3mr1P5sWU5Cdhtwq5TF/oQrZT7PFWZqoHsEc+zXNvG2h5QKlq6tH9eeUxUmIMFGbHsrTyjM1oqj/BUod8IfNE1+uYSoNUYUwtsBlaLSILrIuxq17aAUtHcpf3zyqOW5yXi7Bvk+eLT4x+s1DjcHV75DPABMFdEqkTkPhF5UEQedB2yCSgHyoBfA18DMMa0AN8Hdru+HnVtCxhtzj5aOntJ0ha98qD85ChykyL5+TtlusygmjK3LsYaY+4cZ78Bvj7GvvXA+olH8w+VOrRSTQMR4br56ax7v5yntp/iq1fNsjqS8mN69XCKTg0PrdSbpZSH5SVHcfXcFJ547wSt3X1Wx1F+TAv9FOnNUmo6/c11c2nt7uOxd8usjqL8mBb6Kapo7iQlJowwh93qKCoALciI487l2azbUs5rY9wta4zhhT1V/Pyd4zxffJoD1a30DegMmOovtNBPUUVzF7mJkVbHUAFqw85KLkqPJScxkm8+u5cfbz56zv66Vif3P13M3zxfwqAxHKlr55ldlXpnrTqHp+6MDVoVzV2smp1sdQwVwBx2G59fkcPjfz7Bb7afQgSumpvKawdq+d2OCgD++a8uIjzEjjHw7tEG3jnSwMmmTouTK1+hLfopcPYNUNfmJDdJW/RqesWEh3DPyjzSYsN47N0yPv3L7azfdpKbFmfw5reu5P7LZ2ITwW4TrihIISbMwZuldQwNiFPBTlv0U1DZMnQhNjcpks4eHeuspld6bDj3XzaT1QvS2Hq8iUVZccxKif7YcaEOG1fNS+WPJTW8f7yJK+b415QiyvO0RT8FwyNucpOiLE6igklydBi3LM0ctcgP+0ReAvGRIfz4jaPaqlda6KdieHriPO26UT7GYbNx5ZwU9le1cqimzeo4ymJa6KegormL2HAH8ZE6hl75ngUZcdgENh+qszqKspgW+ik41dxJXrJ22yjfFB3m4BN5iVrolRb6qaho7iJHx9ArH3bdgnSO1XfoUMsgp4V+kvoGBqk+202eXohVPmz1gjRAu2+CnQ6vnKTqM90MDBodQ6+8buSyg+PJSohkYWYsmw/V8eCVOgNmsNIW/SRVtOjQSuUfrpufzt7Ks9S3Oa2OoiyihX6SdGil8hfXLUwH4I3SeouTKKtooZ+kiuYuIkLspMToEoLKtxWkRpOfHMUb2k8ftLTQT1JFcye5SZGIiNVRlLogEWH1gjQ+ONFMa5cuYBKMtNBPkg6tVP7kugXp9A8a3jmq3TfByK1RNyJyPfAzwA48aYz54Xn7/wO42vU0Ekg1xsS79g0AB1z7Ko0xazwR3CobdlYyaAwnmzpJjw2f0AgIpayyJCue1JgwNh+s59alWVbHUV42bqEXETvwGHAtUAXsFpGNxpjS4WOMMd8acfw3gKUjvkW3MWaJ5yJbr627j/5BQ6KuE6v8hM021H3z4p5qnH0DhIfoimjBxJ0W/XKgzBhTDiAizwJrgdIxjr8T+K5n4vmmls5eAJKi9EKs8m0jP3GG2G109w3wg1cP84NbF1qYSnmbO330mcDpEc+rXNs+RkRygXzgnRGbw0WkWER2iMgtY72JiDzgOq64sbHRjVjWaf6o0GuLXvmPmcnRhIfYKK1ttTqK8jJPX4y9A3jBGDNyFY5cY0wRcBfwUxEZ9fY8Y8w6Y0yRMaYoJcW3F0po6ezFLkJcZIjVUZRym90mXJQeS2ltG929ulBOMHGn0FcD2SOeZ7m2jeYO4JmRG4wx1a4/y4E/c27/vV9q6ughISoEmw6tVH7m4rwEnH2DbDpQa3UU5UXuFPrdQIGI5ItIKEPFfOP5B4nIPCAB+GDEtgQRCXM9TgZWMXbfvt9o7uglOVr755X/yU+KIjk6lGd26WixYDJuoTfG9AMPAZuBw8BzxphDIvKoiIwcKnkH8Kw5d92yi4BiESkB3gV+OHK0jj8aNIbmzh4t9MoviQifyEukuOIMx+vbrY6jvMStcfTGmE3ApvO2PXLe8++N8rrtwKIp5PM5bd199A0YknRopfJTS3MSeOtwPc/sOs0jN8+3Oo7yAr0zdoKGR9xoi175q+gwB6sXpPM/e6tw9ulF2WCghX6Cmjp6AC30yr99fkUOZ7v6+L3e2R0UtNBPUFN7DyF2ISZc12xR/uvSmUlcOSeFn755jMb2HqvjqGmmhX6Cmjt7SYoK06GVyq+JCI/cPB9n/wD/9voRq+OoaaaFfoKaOnpI1guxKgDMSonmy6vyeX5PFXsrz1gdR00jLfQT0D8wSEtnL0naP68CxDeuKSAtNoyHnyvRueoDmBb6Cag6082g0QuxKnBEhzn4xV3LqDrTxdc27KFvYNDqSGoa6BXFCTjZNLROrHbdKH93/joKawozefHDKr638RA/uGWhrpwWYLTQT0C5q9Br140KNBfnJtDY7uT3OyvJiI/g61fPtjqS8iAt9BNwqqmT8BAbUaG6aIMKPKsXpNPm7OdHm49yrL6dFflJANy1IsfiZGqqtNBPwMmmTpKjw/RjrQpINhE+vSyL7t4BNu6rITrMwYKMOKtjKQ/Qi7ETMFzolQpUdptw5/IcshIieL64irpWp9WRlAdooXdTV28/Na3dOpmZCnihDhufX5FLeIiN3+049dHSmcp/aaF3U1lDB8ZAWky41VGUmnaxESHcfUku7c5+vvnMXgYHzfgvUj5LC72bjtYNzd2dHqeFXgWHrIRIblqcwdayJn6vC5X4NS30bjpW306Yw0aiLgiugsgn8hK4vCCZH246TNWZLqvjqEnSUTduOlrfQUFatE5mpoKKiHDJzCR2nmzh3t/s5ksr8z4adabDLv2HtujddLSujTlpMVbHUMrrEiJDuX5BOmUNHRyobrU6jpoELfRuONvVS31bD3O10KsgtTw/kbTYMN4srWdAL8z6HbcKvYhcLyJHRaRMRP5+lP33ikijiOxzfd0/Yt89InLc9XWPJ8N7y7H6DgDmpGuhV8HJJsLq+ek0d/ayp0KnNPY34xZ6EbEDjwE3APOBO0VktBWF/2CMWeL6etL12kTgu8AKYDnwXRFJ8Fh6LzlaPzTiRlv0KpjNS48hJzGSd47U6yyXfsadFv1yoMwYU26M6QWeBda6+f2vA940xrQYY84AbwLXTy6qdY7VtRMT7mCGDq1UQUxEWL0gjTZnPzvKm62OoybAnUKfCZwe8bzKte18nxaR/SLygohkT/C1iMgDIlIsIsWNjY1uxPKeo/XtzE2L0TluVNCbmRzN7JRoth5voqd/wOo4yk2euhj7RyDPGLOYoVb70xP9BsaYdcaYImNMUUpKiodiTZ0xhmP17do/r5TL5XOSae/p5+W91VZHUW5yp9BXA9kjnme5tn3EGNNsjBleSv5J4GJ3X+vrGtp7ONvVp/3zSrnMTolmRlw467aU69QIfsKdQr8bKBCRfBEJBe4ANo48QERmjHi6BjjserwZWC0iCa6LsKtd2/zG8NQHOoZeqSEiwuUFKZxo7OSdIw1Wx1FuGLfQG2P6gYcYKtCHgeeMMYdE5FERWeM67JsickhESoBvAve6XtsCfJ+hXxa7gUdd2/zGoZo2YGjEgVJqyKLMODLjI/jVlhNWR1FucGsKBGPMJmDTedseGfH4H4B/GOO164H1U8hoqX2nz5CbFEmCznGj1EfsNuG+y/J59NVS9lSc4eJcvxs1HVT0ztgLMMawt/IsS7PjrY6ilM/53CeyiYsIYZ226n2eFvoLqG110tDewxIt9Ep9TFSYgy9ckssbpfWUN3ZYHUddgBb6C9h3+iwAS3L0Y6lSo7lnZR4hdhu/fv+k1VHUBWihv4B9p88S6rAxf0as1VGU8kkpMWF8elkWL35YRWN7z/gvUJbQQn8BeyvPsCAjllCH/jUpNZavXJ5P38Cg9tX7MF14ZAx9A4McqG7lruW5VkdRyidt2PmX5QWXZifwm22nuHdVPpnxERamUqPRpuoYjta14+wbZEmOXohVajyfuigVgJ+8cdTiJGo02qIfw7ot5QBUNned03JRSuL+HF4AAA6wSURBVH1cfGQoK2cl8dLeau6/bCbzM/S6li/RFv0Yqs50ERXmICEyxOooSvmFK+ekEhsewr9sOowxOgeOL9FCP4ZTzV3kJETo1MRKuSki1M63V89ha1kTz+4+Pf4LlNdooR9F1ZkuWjp7mZkSbXUUpfzK3StyWTkriR+8Wsrpli6r4ygXLfSj2H5iaPWcWVrolZoQm034t9sXIyL87QslOo2xj9BCP4rtZU1EhTlIiw2zOopSfmXDzkq2HGti9fw0dpS38MDv9uhgBh+go27OY4xh+4lmZqVEaf+8UpN0cW4CJ5s6eftwvY6r9wHaoj/PicYOGtp7mJWs3TZKTZaIsHZJJulx4fyhuJKK5k6rIwU1LfQMfdwc/vrZW8cBmJWqhV6pqQh12Lh7RS6CcP/TxbR291kdKWhpoT/PicZO4iNDdPy8Uh6QEBXK51fkcKq5k6///kP6BgatjhSUtNCPMGgM5U0dzEqJ1v55pTxkZko0//fWRWwta+KRVw7qzVQW0IuxI9Sc7cbZN6jDKpXysM8WZVPR3Mlj754gLiKUv7t+rjamvMitFr2IXC8iR0WkTET+fpT9D4tIqYjsF5G3RSR3xL4BEdnn+troyfCedqy+HQFma/+8Uh61YWclGXERLM9P5In3TvCV3+6xOlJQGbfQi4gdeAy4AZgP3Cki8887bC9QZIxZDLwA/NuIfd3GmCWurzUeyj0tjtV3kBEfQXSYftBRytNEhDWFGSzNjuetw/X85I2jekOVl7jTol8OlBljyo0xvcCzwNqRBxhj3jXGDN/vvAPI8mzM6dfV28/pli7mpMVYHUWpgGUT4bZlWVycm8DP3ynjG8/upbt3wOpYAc+dQp8JjJyhqMq1bSz3Aa+NeB4uIsUiskNEbhnrRSLygOu44sbGRjdieVZZQwcGmJOm3TZKTSe7TbhtaSb/eOM8Nh2o5dbHt3GwutXqWAHNo6NuRORuoAj40YjNucaYIuAu4KciMmu01xpj1hljiowxRSkpKZ6M5Zbj9R1EhNjJSoj0+nsrFWxEhAeumMX6ez5Bc2cvax/bxo82H8HZp6376eBOoa8Gskc8z3JtO4eIfAr4J2CNMeajVYKNMdWuP8uBPwNLp5B3WhhjONbQzuzUaOw2HQmglDds2FlJbauTB6+YRWFWPI+9e4LL//Vd9lScsTpawHGn0O8GCkQkX0RCgTuAc0bPiMhS4FcMFfmGEdsTRCTM9TgZWAWUeiq8p9S1OWl39mv/vFIWiAi1c/vFWdy7Mo++gUFuf2I7/98fD9HV2291tIAx7vASY0y/iDwEbAbswHpjzCEReRQoNsZsZKirJhp43jU2ttI1wuYi4FciMsjQL5UfGmN8rtAfq2sHoED755WyzJy0GP73NQVsLq3jN9tO8fLeam5blvXRfS13rcixOKH/cmscoTFmE7DpvG2PjHj8qTFetx1YNJWA3nCsoYMZceHEhuu0B0pZKSzEzprCTBZlxvM/H1axfutJPjU/javmeP+6XSAJ+ikQ2p19VDR3areNUj4kPzmKb3yygMLseN4srWfDrko6e7QrZ7KCvtBvK2tm0Gi3jVK+JtRh4zMXZ3HDwnRKa9q47fHtOt3xJAV9oX/vWCNhDhu5iVFWR1FKnUdEuLwghXtX5VHX5mTNL7bx/nHv32fj74K60BtjeO9oA7NSdFilUr6sIDWGPz50GTPiwrn3N7v53QenrI7kV4K60Jc1dFDT6mSu9s8r5fNykiJ54asruWpOCt955RDf23iIAZ0rxy1BPXvXn48OfQTU/nmlfN/wIuNXz0ulp3+Qp7afora1m5/dsZTwELvF6XxbULfo3zvWSEFqNPGRoVZHUUq5ySbCjYtmcNPiGWw+VM8963fR5tRlCi8kaFv0rd197DrZwj0rc8c/WCnlc1bOSiYq1MELe6q4/qdb+PLKfCJdU4zrzVXnCtoW/esHa+kdGOSmxRlWR1FKTVJhdjx3X5JLQ1sPT249SYeOtR9V0LboX95bQ35yFIuz4jhU02Z1HKXUJM1Nj+GLl+bxux2nePL9cr58Wb5X33/42sH5fOlTRVC26Otanew42cyawgxdt1KpADA7NZp7VuZxtquPJ98vp67VaXUknxKUhX5jSTXGwC1LL7R+ilLKn8xMjuZLq/Jod/bz2V99QGVz1/gvChJBWehf2VdDYVYc+cl6N6xSgSQ3KYovr8qntbuPWx7fRvGpFqsj+YSg66Mva2jnUE0bj9x0/vrmSqlAkJ0YyUtfW8l9Txdz16938oNbFvKZoiyPdtMODhpKqs7y1uF63jncQJuzn76BQXKToihIjWZuum/dhBl0hf7xP58g1GHjpsIZVkdRSk2TmSnRvPS1lXzt9x/yf17czxul9fzLbQtJjQmf0vc9XNvGi3uq2FhSQ0N7D3abkBIdRky4A5s42F91lt2nWkiODqMwO54l2fEeOqOpCapCf6imlZf2VvPA5TOn/ANXSvmu4ZEwNy6aQXxECG+U1nPtv2/hK5fn88WVeRNae6KxvYeNJTW8uKeK0to27CLMSY/hqrkpzE2LJSL0L3flDgwajte380pJDbc9vo2HPlnAX19TgM3iubSCptAbY/h/m44QFxHC166ebXUcpZQX2ES4rCCFOekx7K9q5cdvHGPdlnJuXZrJtfPTWTEzkRD7uZcqe/sHOVzbxs6TzbxZWs+eijMMGijMiuPmxTNYnBVPVNjopdNuE+bNiCUvOYqDNa3859vHOdHQwU8+W2jpNA1BU+jfO9bI1rImvnPTfOIidCUppYJJakw46++dw4GqVn75XhnP7j7N0x9UEGq3MSM+nPTYcHoHBmnt7qOqpZvegUEAZsSFc/XcVBZmxpEW634vQHiInZ98ppB56TH8y6Yj1Lc5eeILF5McHTZdp3hBYozvzf5WVFRkiouLPfb9jtW388X/2kWow8ZbD19JqOPc3+Bj3fCglApMvf2DlDV0UNnSSWxECPVtTsJD7MSGh5CZEEG7s5+cxMgpNQqHb5h6dX8NDz9XQnxECD+7YymXzkry1GmcQ0T2GGOKRtvnVoteRK4HfsbQ4uBPGmN+eN7+MOC3wMVAM/A5Y8wp175/AO4DBoBvGmM2T/I8JmVneTNf+W0x4SF2nrj74o8VeaVU8Al12JifEcv8jNhpf6+bFmcwMzmahzZ8yOef3MGXVuVz/+X5zIiLmPb3HjZuoRcRO/AYcC1QBewWkY3GmNIRh90HnDHGzBaRO4B/BT4nIvOBO4AFQAbwlojMMcYMePpEYGjIU0tXL00dPeyvamXTgVq2Hm8iNymSp7+8nKyEyOl4W6WUuqD5GbH88RuX8egfS/nNtpM8vf0U1y1MZ0V+Igsz45gRF05seAiRofZpuVvfnRb9cqDMGFMOICLPAmuBkYV+LfA91+MXgF/IUNq1wLPGmB7gpIiUub7fB56J/xfGGC565HV6+gc/2paVEMF9l+Xz1atm6VTESilLRYU5+NfbF/PQJ2ezfttJXtlXw5/2155zTHJ0KMX/fK3H39udQp8JnB7xvApYMdYxxph+EWkFklzbd5z32lHnHRCRB4AHXE87ROSoG9kuqALYBvzj+IcmA01TfT8fFsjnF8jnBoF9foF8bnx+EudXAch3Jv2WY8657jOjbowx64B1Vry3iBSPdREjEATy+QXyuUFgn18gnxv41vm5c2WyGsge8TzLtW3UY0TEAcQxdFHWndcqpZSaRu4U+t1AgYjki0goQxdXN553zEbgHtfj24F3zNC4zY3AHSISJiL5QAGwyzPRlVJKuWPcrhtXn/tDwGaGhleuN8YcEpFHgWJjzEbgv4DfuS62tjD0ywDXcc8xdOG2H/j6dI24mSJLuoy8KJDPL5DPDQL7/AL53MCHzs8nb5hSSinlOXr3kFJKBTgt9EopFeCCqtCLyPUiclREykTk70fZHyYif3Dt3ykied5POTlunNvDIlIqIvtF5G0RGXPMrS8a7/xGHPdpETEi4hPD2tzhzrmJyGddP79DIrLB2xmnwo1/mzki8q6I7HX9+7zRipyTISLrRaRBRA6OsV9E5D9d575fRJZ5OyMwdEdpMHwxdCH5BDATCAVKgPnnHfM14AnX4zuAP1id24PndjUQ6Xr8VX85N3fPz3VcDLCFoZv0iqzO7cGfXQGwF0hwPU+1OreHz28d8FXX4/nAKatzT+D8rgCWAQfH2H8j8BogwCXATityBlOL/qOpHIwxvcDwVA4jrQWedj1+AbhGpmPiCc8b99yMMe8aY4ZXS97B0D0N/sKdnx3A9xmaZ8npzXBT5M65fQV4zBhzBsAY0+DljFPhzvkZYHh2sTigxov5psQYs4WhkYZjWQv81gzZAcSLiNeXtwumQj/aVA7nT8dwzlQOwPBUDr7OnXMb6T6GWhn+Ytzzc30kzjbG/MmbwTzAnZ/dHGCOiGwTkR2u2WT9hTvn9z3gbhGpAjYB3/BONK+Y6P/NaeEzUyAo7xCRu4Ei4Eqrs3iKiNiAfwfutTjKdHEw1H1zFUOfxLaIyCJjzFlLU3nOncBTxpifiMilDN2Ts9AYMzjeC5V7gqlFP5WpHHydW1NNiMingH8C1pihGUX9xXjnFwMsBP4sIqcY6gvd6CcXZN352VUBG40xfcaYk8Axhgq/P3Dn/O4DngMwxnwAhDM0IVgg8IlpYIKp0E9lKgdfN+65ichS4FcMFXl/6uOFcc7PGNNqjEk2xuQZY/IYugaxxhjjuWXKpo87/y5fZqg1j4gkM9SVU+7NkFPgzvlVAtcAiMhFDBX6Rq+mnD4bgS+6Rt9cArQaY2rHe5GnBU3XjZnCVA6+zs1z+xEQDTzvur5caYxZY1noCXDz/PySm+e2GVgtIqUMrdT2t8YYf/ik6e75fRv4tYh8i6ELs/f6SQMLEXmGoV/Cya5rDN8FQgCMMU8wdM3hRqAM6AK+ZElOP/n7VEopNUnB1HWjlFJBSQu9UkoFOC30SikV4LTQK6VUgNNCr5RSAU4LvVJKBTgt9EopFeD+f/NgmP8aqBbfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn6S7Pv_rc-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}