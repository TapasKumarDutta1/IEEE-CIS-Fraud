{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_focal_loss",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_focal_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6cccf38e-26b6-4588-a83d-6c407b5e3a82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ee2a8a38-1c88-46aa-811a-0ae9847ebd7a"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold=5\n",
        "lr=0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDrCIAqHzl6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "91e25491-a107-4b67-cdd5-617fbbae750c"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in cols:\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EWJ-hzcznam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "ss=StandardScaler()\n",
        "frd=trn['isFraud']\n",
        "ls=list(trn)\n",
        "trn=ss.fit_transform(trn.drop(['isFraud'],1))\n",
        "trn=pd.DataFrame(trn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF5OQjb1zo6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls.remove('isFraud')\n",
        "trn.columns=ls\n",
        "trn['isFraud']=frd\n",
        "\n",
        "ls=list(tst)\n",
        "tst=ss.fit_transform(tst)\n",
        "tst=pd.DataFrame(tst)\n",
        "tst.columns=ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b6bacd24-82af-4415-80e1-3e3074a0a1b5"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1671.53 MB\n",
            "Memory usage after optimization is: 417.88 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 1430.33 MB\n",
            "Memory usage after optimization is: 357.58 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cb31877-8a28-4431-ffe5-e370ceaa3858"
      },
      "source": [
        "trn_n=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_n=pd.read_csv('test_transaction.csv.zip')\n",
        "trn['month']=trn_n['TransactionDT']//(86400*30)\n",
        "trn_n.head()\n",
        "trn_ls=list(trn_n)\n",
        "tst_ls=list(tst_n)\n",
        "for col in trn:\n",
        "  if col in trn_ls:\n",
        "    trn[col+'_isna']=trn_n[col].isna().astype('uint8')\n",
        "for col in tst:\n",
        "  if col in tst_ls:\n",
        "    tst[col+'_isna']=tst_n[col].isna().astype('uint8')\n",
        "import gc\n",
        "del([trn_n,tst_n])\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f0r3SuH1K97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.drop(['isFraud_isna'],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HQ20JqWATak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        if self.ep%10==0:\n",
        "          y_pred_val = self.model.predict(self.x_val)\n",
        "          roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "          print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6gnpm4CjDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d36c3f0-65ca-487e-bd6e-10e6a12557b5"
      },
      "source": [
        "def fl():\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        gamma=0.5\n",
        "        alpha=1-0.036\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\n",
        "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
        "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
        "\n",
        "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
        "    return focal_loss\n",
        "\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "  inp=Input((593,))\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=inp,outputs=x)\n",
        "  return mod\n",
        "for en,month in enumerate([(4,5),(4,6),(3,4),(3,5),(3,6)]):\n",
        "  train=trn.loc[trn['month']>=month[1]]\n",
        "  test=trn.loc[trn['month']<=month[0]]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  mod.compile(optimizer=Adam(0.00001,decay=1e-3),loss=fl())\n",
        "  roc = RocCallback(\n",
        "                  validation_data=(test.drop(['isFraud'],1), test['isFraud']))\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es,roc])\n",
        "  del([train,test])\n",
        "  if en==0:\n",
        "    pre=mod.predict(tst)/5\n",
        "    tot=mod.predict(trn.loc[trn['month']==6].drop(['month','isFraud'],1))/5\n",
        "  else:\n",
        "    pre+=mod.predict(tst)/5\n",
        "    tot+=mod.predict(trn.loc[trn['month']==6].drop(['month','isFraud'],1))/5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "47/47 [==============================] - 2s 46ms/step - loss: 89.0216 - val_loss: 65.6012\n",
            "Epoch 2/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 83.9005 - val_loss: 63.3218\n",
            "Epoch 3/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 81.3210 - val_loss: 61.9699\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 78.9447 - val_loss: 61.2191\n",
            "Epoch 5/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 79.5740 - val_loss: 60.6934\n",
            "Epoch 6/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 76.3411 - val_loss: 60.2437\n",
            "Epoch 7/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 76.0745 - val_loss: 59.9301\n",
            "Epoch 8/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 74.9312 - val_loss: 59.6105\n",
            "Epoch 9/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 74.4927 - val_loss: 59.1810\n",
            "Epoch 10/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 73.9572roc-auc_val: 0.7637\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 73.5243 - val_loss: 58.8891\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 74.0979 - val_loss: 58.6845\n",
            "Epoch 12/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 71.2430 - val_loss: 58.4384\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 71.7085 - val_loss: 58.1983\n",
            "Epoch 14/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 71.5086 - val_loss: 57.9630\n",
            "Epoch 15/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 71.2167 - val_loss: 57.7274\n",
            "Epoch 16/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 71.0620 - val_loss: 57.4920\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 69.9738 - val_loss: 57.3967\n",
            "Epoch 18/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 69.9232 - val_loss: 57.2484\n",
            "Epoch 19/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 69.2932 - val_loss: 57.1330\n",
            "Epoch 20/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 70.2996roc-auc_val: 0.7819\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 69.6300 - val_loss: 56.9673\n",
            "Epoch 21/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 68.7564 - val_loss: 56.8020\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 69.1496 - val_loss: 56.6954\n",
            "Epoch 23/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 68.9990 - val_loss: 56.6106\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 68.3171 - val_loss: 56.4972\n",
            "Epoch 25/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 67.2312 - val_loss: 56.3904\n",
            "Epoch 26/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 67.8218 - val_loss: 56.3446\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 67.2735 - val_loss: 56.2719\n",
            "Epoch 28/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 67.6006 - val_loss: 56.1653\n",
            "Epoch 29/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 67.6340 - val_loss: 56.0935\n",
            "Epoch 30/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 67.0128roc-auc_val: 0.7899\n",
            "47/47 [==============================] - 14s 297ms/step - loss: 66.4121 - val_loss: 56.0114\n",
            "Epoch 31/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 66.9080 - val_loss: 55.9639\n",
            "Epoch 32/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 65.7865 - val_loss: 55.9222\n",
            "Epoch 33/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 67.5564 - val_loss: 55.7979\n",
            "Epoch 34/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 65.9742 - val_loss: 55.7095\n",
            "Epoch 35/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 65.5320 - val_loss: 55.6583\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 65.6828 - val_loss: 55.6341\n",
            "Epoch 37/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 65.8209 - val_loss: 55.5831\n",
            "Epoch 38/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 64.9438 - val_loss: 55.5188\n",
            "Epoch 39/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 65.5809 - val_loss: 55.4644\n",
            "Epoch 40/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 64.7250roc-auc_val: 0.7945\n",
            "47/47 [==============================] - 14s 301ms/step - loss: 64.7250 - val_loss: 55.4212\n",
            "Epoch 41/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 65.2074 - val_loss: 55.3541\n",
            "Epoch 42/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 64.2580 - val_loss: 55.2972\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 64.7646 - val_loss: 55.2753\n",
            "Epoch 44/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 64.3874 - val_loss: 55.2573\n",
            "Epoch 45/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 63.8365 - val_loss: 55.2323\n",
            "Epoch 46/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 64.1356 - val_loss: 55.2163\n",
            "Epoch 47/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 64.0494 - val_loss: 55.1827\n",
            "Epoch 48/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 63.8647 - val_loss: 55.1611\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 63.0492 - val_loss: 55.1118\n",
            "Epoch 50/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 63.0215roc-auc_val: 0.7975\n",
            "47/47 [==============================] - 14s 298ms/step - loss: 63.1526 - val_loss: 55.0409\n",
            "Epoch 51/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 63.4114 - val_loss: 55.0020\n",
            "Epoch 52/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 64.1770 - val_loss: 54.9599\n",
            "Epoch 53/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 63.3156 - val_loss: 54.9181\n",
            "Epoch 54/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 63.8593 - val_loss: 54.8794\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.7725 - val_loss: 54.8516\n",
            "Epoch 56/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 63.1815 - val_loss: 54.8199\n",
            "Epoch 57/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.3307 - val_loss: 54.8006\n",
            "Epoch 58/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 63.4773 - val_loss: 54.7512\n",
            "Epoch 59/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 62.7520 - val_loss: 54.7323\n",
            "Epoch 60/1000\n",
            "38/47 [=======================>......] - ETA: 0s - loss: 63.0480roc-auc_val: 0.8\n",
            "47/47 [==============================] - 14s 297ms/step - loss: 62.8584 - val_loss: 54.6977\n",
            "Epoch 61/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.4345 - val_loss: 54.6617\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.6770 - val_loss: 54.6425\n",
            "Epoch 63/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.6318 - val_loss: 54.6240\n",
            "Epoch 64/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.1608 - val_loss: 54.5765\n",
            "Epoch 65/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.9176 - val_loss: 54.5797\n",
            "Epoch 66/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.1014 - val_loss: 54.5598\n",
            "Epoch 67/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.3269 - val_loss: 54.5230\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.7005 - val_loss: 54.5136\n",
            "Epoch 69/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.1241 - val_loss: 54.5043\n",
            "Epoch 70/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 62.2127roc-auc_val: 0.8016\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 62.3517 - val_loss: 54.4850\n",
            "Epoch 71/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.9997 - val_loss: 54.4465\n",
            "Epoch 72/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.3023 - val_loss: 54.4250\n",
            "Epoch 73/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.0187 - val_loss: 54.4117\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 61.0023 - val_loss: 54.3764\n",
            "Epoch 75/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 62.2240 - val_loss: 54.3563\n",
            "Epoch 76/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 61.9945 - val_loss: 54.3239\n",
            "Epoch 77/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 60.9941 - val_loss: 54.3402\n",
            "Epoch 78/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 61.4195 - val_loss: 54.3132\n",
            "Epoch 79/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 61.6171 - val_loss: 54.3083\n",
            "Epoch 80/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 61.8371roc-auc_val: 0.8032\n",
            "47/47 [==============================] - 15s 312ms/step - loss: 61.5151 - val_loss: 54.2595\n",
            "Epoch 81/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 60.7414 - val_loss: 54.2445\n",
            "Epoch 82/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.8724 - val_loss: 54.2292\n",
            "Epoch 83/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.2155 - val_loss: 54.2262\n",
            "Epoch 84/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.9471 - val_loss: 54.2035\n",
            "Epoch 85/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.1738 - val_loss: 54.1803\n",
            "Epoch 86/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.1532 - val_loss: 54.1633\n",
            "Epoch 87/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.6451 - val_loss: 54.1533\n",
            "Epoch 88/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.5866 - val_loss: 54.1428\n",
            "Epoch 89/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.3726 - val_loss: 54.1250\n",
            "Epoch 90/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 61.1739roc-auc_val: 0.8042\n",
            "47/47 [==============================] - 14s 302ms/step - loss: 60.7760 - val_loss: 54.1060\n",
            "Epoch 91/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.6741 - val_loss: 54.0838\n",
            "Epoch 92/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.4235 - val_loss: 54.0644\n",
            "Epoch 93/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.8788 - val_loss: 54.0250\n",
            "Epoch 94/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.0940 - val_loss: 54.0083\n",
            "Epoch 95/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.4357 - val_loss: 53.9883\n",
            "Epoch 96/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 61.0474 - val_loss: 53.9926\n",
            "Epoch 97/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.7118 - val_loss: 53.9474\n",
            "Epoch 98/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.7089 - val_loss: 53.9444\n",
            "Epoch 99/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.9701 - val_loss: 53.9423\n",
            "Epoch 100/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 59.9675roc-auc_val: 0.8055\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 60.6059 - val_loss: 53.9208\n",
            "Epoch 101/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.2821 - val_loss: 53.8988\n",
            "Epoch 102/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 59.5445 - val_loss: 53.8982\n",
            "Epoch 103/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.7078 - val_loss: 53.8923\n",
            "Epoch 104/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.1716 - val_loss: 53.8911\n",
            "Epoch 105/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 60.2683 - val_loss: 53.8863\n",
            "Epoch 106/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.2325 - val_loss: 53.8587\n",
            "Epoch 107/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.1690 - val_loss: 53.8312\n",
            "Epoch 108/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.3251 - val_loss: 53.8068\n",
            "Epoch 109/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.4038 - val_loss: 53.7963\n",
            "Epoch 110/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 60.2104roc-auc_val: 0.8064\n",
            "47/47 [==============================] - 14s 304ms/step - loss: 60.2510 - val_loss: 53.7730\n",
            "Epoch 111/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.0355 - val_loss: 53.7562\n",
            "Epoch 112/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.3330 - val_loss: 53.7495\n",
            "Epoch 113/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 59.5748 - val_loss: 53.7409\n",
            "Epoch 114/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.7432 - val_loss: 53.7423\n",
            "Epoch 115/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.1997 - val_loss: 53.7011\n",
            "Epoch 116/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.3058 - val_loss: 53.6882\n",
            "Epoch 117/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 59.3541 - val_loss: 53.6809\n",
            "Epoch 118/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.6621 - val_loss: 53.6721\n",
            "Epoch 119/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.4359 - val_loss: 53.6747\n",
            "Epoch 120/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 60.2069roc-auc_val: 0.8071\n",
            "47/47 [==============================] - 14s 302ms/step - loss: 59.4823 - val_loss: 53.6475\n",
            "Epoch 121/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.6259 - val_loss: 53.6616\n",
            "Epoch 122/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.0465 - val_loss: 53.6562\n",
            "Epoch 123/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.1826 - val_loss: 53.6371\n",
            "Epoch 124/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.1733 - val_loss: 53.6137\n",
            "Epoch 125/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.9277 - val_loss: 53.6071\n",
            "Epoch 126/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 58.1297 - val_loss: 53.5914\n",
            "Epoch 127/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 58.2855 - val_loss: 53.5770\n",
            "Epoch 128/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 59.0174 - val_loss: 53.5670\n",
            "Epoch 129/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 58.6662 - val_loss: 53.5825\n",
            "Epoch 130/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 58.9788roc-auc_val: 0.8078\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 58.7389 - val_loss: 53.5869\n",
            "Epoch 131/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.1059 - val_loss: 53.5756\n",
            "Epoch 132/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 59.1074 - val_loss: 53.5784\n",
            "Epoch 133/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.3703 - val_loss: 53.5584\n",
            "Epoch 134/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.0824 - val_loss: 53.5221\n",
            "Epoch 135/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.6678 - val_loss: 53.5082\n",
            "Epoch 136/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 58.0465 - val_loss: 53.5001\n",
            "Epoch 137/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.9995 - val_loss: 53.4782\n",
            "Epoch 138/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.1275 - val_loss: 53.4767\n",
            "Epoch 139/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.0090 - val_loss: 53.4783\n",
            "Epoch 140/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 57.5999roc-auc_val: 0.8084\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 57.7596 - val_loss: 53.4498\n",
            "Epoch 141/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 57.9127 - val_loss: 53.4403\n",
            "Epoch 142/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.3941 - val_loss: 53.4209\n",
            "Epoch 143/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.2468 - val_loss: 53.4180\n",
            "Epoch 144/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.7752 - val_loss: 53.4209\n",
            "Epoch 145/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.6324 - val_loss: 53.4216\n",
            "Epoch 146/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.4502 - val_loss: 53.4217\n",
            "Epoch 147/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.6277 - val_loss: 53.4133\n",
            "Epoch 148/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.6931 - val_loss: 53.3865\n",
            "Epoch 149/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.0812 - val_loss: 53.3843\n",
            "Epoch 150/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 58.1520roc-auc_val: 0.8089\n",
            "47/47 [==============================] - 14s 297ms/step - loss: 58.1520 - val_loss: 53.3655\n",
            "Epoch 151/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.6791 - val_loss: 53.3481\n",
            "Epoch 152/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.0128 - val_loss: 53.3518\n",
            "Epoch 153/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.5452 - val_loss: 53.3243\n",
            "Epoch 154/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.3814 - val_loss: 53.3257\n",
            "Epoch 155/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.6253 - val_loss: 53.3260\n",
            "Epoch 156/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.5965 - val_loss: 53.3313\n",
            "Epoch 157/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.7745 - val_loss: 53.3277\n",
            "Epoch 158/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.4269 - val_loss: 53.2984\n",
            "Epoch 159/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.5870 - val_loss: 53.2952\n",
            "Epoch 160/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 58.5195roc-auc_val: 0.8094\n",
            "47/47 [==============================] - 14s 305ms/step - loss: 58.0382 - val_loss: 53.2797\n",
            "Epoch 161/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.3526 - val_loss: 53.2856\n",
            "Epoch 162/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.8782 - val_loss: 53.2775\n",
            "Epoch 163/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.6972 - val_loss: 53.2731\n",
            "Epoch 164/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.4535 - val_loss: 53.2693\n",
            "Epoch 165/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.9393 - val_loss: 53.2628\n",
            "Epoch 166/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.8158 - val_loss: 53.2531\n",
            "Epoch 167/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 58.2521 - val_loss: 53.2440\n",
            "Epoch 168/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.4281 - val_loss: 53.2428\n",
            "Epoch 169/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.3489 - val_loss: 53.2330\n",
            "Epoch 170/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 56.1832roc-auc_val: 0.8096\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 56.9891 - val_loss: 53.2283\n",
            "Epoch 171/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.6980 - val_loss: 53.2235\n",
            "Epoch 172/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.2014 - val_loss: 53.2180\n",
            "Epoch 173/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.2327 - val_loss: 53.2091\n",
            "Epoch 174/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.2560 - val_loss: 53.2056\n",
            "Epoch 175/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 57.6613 - val_loss: 53.2104\n",
            "Epoch 176/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.9336 - val_loss: 53.1863\n",
            "Epoch 177/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.5564 - val_loss: 53.1589\n",
            "Epoch 178/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.1077 - val_loss: 53.1699\n",
            "Epoch 179/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.2103 - val_loss: 53.1656\n",
            "Epoch 180/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 57.3701roc-auc_val: 0.8103\n",
            "47/47 [==============================] - 14s 300ms/step - loss: 57.0199 - val_loss: 53.1622\n",
            "Epoch 181/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.6095 - val_loss: 53.1541\n",
            "Epoch 182/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.8183 - val_loss: 53.1384\n",
            "Epoch 183/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.5291 - val_loss: 53.1303\n",
            "Epoch 184/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.1126 - val_loss: 53.1255\n",
            "Epoch 185/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.4296 - val_loss: 53.1266\n",
            "Epoch 186/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.3416 - val_loss: 53.1277\n",
            "Epoch 187/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.5506 - val_loss: 53.1224\n",
            "Epoch 188/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.9541 - val_loss: 53.1110\n",
            "Epoch 189/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.3077 - val_loss: 53.1126\n",
            "Epoch 190/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 58.3078roc-auc_val: 0.8106\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 57.6583 - val_loss: 53.1039\n",
            "Epoch 191/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.7454 - val_loss: 53.0905\n",
            "Epoch 192/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.9758 - val_loss: 53.0762\n",
            "Epoch 193/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.9072 - val_loss: 53.0840\n",
            "Epoch 194/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.6094 - val_loss: 53.0822\n",
            "Epoch 195/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.1907 - val_loss: 53.0851\n",
            "Epoch 196/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.3186 - val_loss: 53.0835\n",
            "Epoch 197/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.0660 - val_loss: 53.0657\n",
            "Epoch 198/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.5954 - val_loss: 53.0567\n",
            "Epoch 199/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.8924 - val_loss: 53.0566\n",
            "Epoch 200/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 57.4821roc-auc_val: 0.8109\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 56.9342 - val_loss: 53.0586\n",
            "Epoch 201/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.7994 - val_loss: 53.0354\n",
            "Epoch 202/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.1869 - val_loss: 53.0424\n",
            "Epoch 203/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.7231 - val_loss: 53.0366\n",
            "Epoch 204/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.3664 - val_loss: 53.0398\n",
            "Epoch 205/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.4377 - val_loss: 53.0306\n",
            "Epoch 206/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 57.1342 - val_loss: 53.0328\n",
            "Epoch 207/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.3909 - val_loss: 53.0404\n",
            "Epoch 208/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.1981 - val_loss: 53.0254\n",
            "Epoch 209/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 56.4421 - val_loss: 53.0130\n",
            "Epoch 210/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 56.2939roc-auc_val: 0.8112\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 56.2939 - val_loss: 52.9965\n",
            "Epoch 211/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.5418 - val_loss: 52.9899\n",
            "Epoch 212/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.1656 - val_loss: 52.9764\n",
            "Epoch 213/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.7875 - val_loss: 52.9766\n",
            "Epoch 214/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.3295 - val_loss: 52.9779\n",
            "Epoch 215/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.2870 - val_loss: 52.9762\n",
            "Epoch 216/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.4954 - val_loss: 52.9799\n",
            "Epoch 217/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.6494 - val_loss: 52.9636\n",
            "Epoch 218/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.8982 - val_loss: 52.9592\n",
            "Epoch 219/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.1020 - val_loss: 52.9601\n",
            "Epoch 220/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 56.0044roc-auc_val: 0.8115\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 55.8143 - val_loss: 52.9428\n",
            "Epoch 221/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.3778 - val_loss: 52.9267\n",
            "Epoch 222/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.6702 - val_loss: 52.9275\n",
            "Epoch 223/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.6373 - val_loss: 52.9243\n",
            "Epoch 224/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.3715 - val_loss: 52.9063\n",
            "Epoch 225/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.8013 - val_loss: 52.9114\n",
            "Epoch 226/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 56.7314 - val_loss: 52.9117\n",
            "Epoch 227/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 56.0598 - val_loss: 52.9246\n",
            "Epoch 228/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 55.9534 - val_loss: 52.9135\n",
            "Epoch 229/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 56.1827 - val_loss: 52.9151\n",
            "Epoch 230/1000\n",
            "43/47 [==========================>...] - ETA: 0s - loss: 56.2923roc-auc_val: 0.8117\n",
            "47/47 [==============================] - 15s 313ms/step - loss: 55.9351 - val_loss: 52.9153\n",
            "Epoch 231/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.9284 - val_loss: 52.9040\n",
            "Epoch 232/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 56.2543 - val_loss: 52.8834\n",
            "Epoch 233/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.0430 - val_loss: 52.8772\n",
            "Epoch 234/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.6142 - val_loss: 52.8837\n",
            "Epoch 235/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 56.1398 - val_loss: 52.8968\n",
            "Epoch 236/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.3486 - val_loss: 52.8978\n",
            "Epoch 237/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.6714 - val_loss: 52.8831\n",
            "Epoch 238/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.5008 - val_loss: 52.8777\n",
            "Epoch 239/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 56.1735 - val_loss: 52.8702\n",
            "Epoch 240/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 56.1883roc-auc_val: 0.812\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 55.9795 - val_loss: 52.8725\n",
            "Epoch 241/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.2345 - val_loss: 52.8762\n",
            "Epoch 242/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.7265 - val_loss: 52.8629\n",
            "Epoch 243/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.6636 - val_loss: 52.8501\n",
            "Epoch 244/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.3307 - val_loss: 52.8485\n",
            "Epoch 245/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.5989 - val_loss: 52.8451\n",
            "Epoch 246/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.4510 - val_loss: 52.8396\n",
            "Epoch 247/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.7548 - val_loss: 52.8404\n",
            "Epoch 248/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.2422 - val_loss: 52.8403\n",
            "Epoch 249/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.5852 - val_loss: 52.8422\n",
            "Epoch 250/1000\n",
            "38/47 [=======================>......] - ETA: 0s - loss: 56.3140roc-auc_val: 0.8122\n",
            "47/47 [==============================] - 14s 297ms/step - loss: 55.9913 - val_loss: 52.8239\n",
            "Epoch 251/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.8766 - val_loss: 52.8191\n",
            "Epoch 252/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.1500 - val_loss: 52.8271\n",
            "Epoch 253/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.5813 - val_loss: 52.8200\n",
            "Epoch 254/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.6245 - val_loss: 52.8399\n",
            "Epoch 255/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.7471 - val_loss: 52.8431\n",
            "Epoch 256/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.8177 - val_loss: 52.8178\n",
            "Epoch 257/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.4465 - val_loss: 52.8084\n",
            "Epoch 258/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.0462 - val_loss: 52.8095\n",
            "Epoch 259/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.0566 - val_loss: 52.8090\n",
            "Epoch 260/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 55.3000roc-auc_val: 0.8124\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 55.1527 - val_loss: 52.7917\n",
            "Epoch 261/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.5033 - val_loss: 52.7875\n",
            "Epoch 262/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.8043 - val_loss: 52.7926\n",
            "Epoch 263/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.0867 - val_loss: 52.7823\n",
            "Epoch 264/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.3824 - val_loss: 52.7737\n",
            "Epoch 265/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.3670 - val_loss: 52.7744\n",
            "Epoch 266/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.4493 - val_loss: 52.7715\n",
            "Epoch 267/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.8158 - val_loss: 52.7650\n",
            "Epoch 268/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.0012 - val_loss: 52.7666\n",
            "Epoch 269/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.9425 - val_loss: 52.7659\n",
            "Epoch 270/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 55.2623roc-auc_val: 0.8126\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 55.2766 - val_loss: 52.7661\n",
            "Epoch 271/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.2950 - val_loss: 52.7464\n",
            "Epoch 272/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.7268 - val_loss: 52.7509\n",
            "Epoch 273/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.1505 - val_loss: 52.7398\n",
            "Epoch 274/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.0653 - val_loss: 52.7325\n",
            "Epoch 275/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.6345 - val_loss: 52.7267\n",
            "Epoch 276/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.2995 - val_loss: 52.7372\n",
            "Epoch 277/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.6759 - val_loss: 52.7417\n",
            "Epoch 278/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.2664 - val_loss: 52.7351\n",
            "Epoch 279/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7251 - val_loss: 52.7368\n",
            "Epoch 280/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 55.2501roc-auc_val: 0.8129\n",
            "47/47 [==============================] - 14s 294ms/step - loss: 54.9320 - val_loss: 52.7236\n",
            "Epoch 281/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.3800 - val_loss: 52.7136\n",
            "Epoch 282/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.1518 - val_loss: 52.7071\n",
            "Epoch 283/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.3744 - val_loss: 52.6994\n",
            "Epoch 284/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 56.1519 - val_loss: 52.6963\n",
            "Epoch 285/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.8301 - val_loss: 52.6914\n",
            "Epoch 286/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.0976 - val_loss: 52.6854\n",
            "Epoch 287/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7585 - val_loss: 52.6891\n",
            "Epoch 288/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.6744 - val_loss: 52.6905\n",
            "Epoch 289/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.9807 - val_loss: 52.6977\n",
            "Epoch 290/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 54.9311roc-auc_val: 0.8131\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 54.8512 - val_loss: 52.6991\n",
            "Epoch 291/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.6495 - val_loss: 52.6924\n",
            "Epoch 292/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.8008 - val_loss: 52.6747\n",
            "Epoch 293/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.3806 - val_loss: 52.6901\n",
            "Epoch 294/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.6986 - val_loss: 52.6872\n",
            "Epoch 295/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7754 - val_loss: 52.6734\n",
            "Epoch 296/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.2109 - val_loss: 52.6705\n",
            "Epoch 297/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.9403 - val_loss: 52.6780\n",
            "Epoch 298/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.0387 - val_loss: 52.6613\n",
            "Epoch 299/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.4891 - val_loss: 52.6594\n",
            "Epoch 300/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 54.3537roc-auc_val: 0.8132\n",
            "47/47 [==============================] - 14s 305ms/step - loss: 54.3537 - val_loss: 52.6748\n",
            "Epoch 301/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.3101 - val_loss: 52.6579\n",
            "Epoch 302/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.4304 - val_loss: 52.6638\n",
            "Epoch 303/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.5555 - val_loss: 52.6609\n",
            "Epoch 304/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7479 - val_loss: 52.6613\n",
            "Epoch 305/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.5969 - val_loss: 52.6432\n",
            "Epoch 306/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.7290 - val_loss: 52.6393\n",
            "Epoch 307/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.0954 - val_loss: 52.6377\n",
            "Epoch 308/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.7150 - val_loss: 52.6575\n",
            "Epoch 309/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 55.0656 - val_loss: 52.6570\n",
            "Epoch 310/1000\n",
            "45/47 [===========================>..] - ETA: 0s - loss: 55.0812roc-auc_val: 0.8134\n",
            "47/47 [==============================] - 14s 308ms/step - loss: 54.9738 - val_loss: 52.6574\n",
            "Epoch 311/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 55.0615 - val_loss: 52.6503\n",
            "Epoch 312/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.6275 - val_loss: 52.6464\n",
            "Epoch 313/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 55.0367 - val_loss: 52.6379\n",
            "Epoch 314/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.8357 - val_loss: 52.6510\n",
            "Epoch 315/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.9704 - val_loss: 52.6446\n",
            "Epoch 316/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.5480 - val_loss: 52.6331\n",
            "Epoch 317/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.7472 - val_loss: 52.6162\n",
            "Epoch 318/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.9064 - val_loss: 52.6075\n",
            "Epoch 319/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.6992 - val_loss: 52.6158\n",
            "Epoch 320/1000\n",
            "44/47 [===========================>..] - ETA: 0s - loss: 54.6757roc-auc_val: 0.8136\n",
            "47/47 [==============================] - 15s 314ms/step - loss: 54.3544 - val_loss: 52.6167\n",
            "Epoch 321/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.3971 - val_loss: 52.6052\n",
            "Epoch 322/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.5458 - val_loss: 52.6082\n",
            "Epoch 323/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2577 - val_loss: 52.5937\n",
            "Epoch 324/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.4158 - val_loss: 52.6066\n",
            "Epoch 325/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.0717 - val_loss: 52.5998\n",
            "Epoch 326/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.6121 - val_loss: 52.6120\n",
            "Epoch 327/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.4455 - val_loss: 52.6036\n",
            "Epoch 328/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.4337 - val_loss: 52.5903\n",
            "Epoch 329/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7066 - val_loss: 52.5846\n",
            "Epoch 330/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 54.9155roc-auc_val: 0.8138\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 54.7828 - val_loss: 52.5871\n",
            "Epoch 331/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2204 - val_loss: 52.5880\n",
            "Epoch 332/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7303 - val_loss: 52.5840\n",
            "Epoch 333/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.6012 - val_loss: 52.5877\n",
            "Epoch 334/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7815 - val_loss: 52.5911\n",
            "Epoch 335/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.8179 - val_loss: 52.5762\n",
            "Epoch 336/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.4192 - val_loss: 52.5703\n",
            "Epoch 337/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.8189 - val_loss: 52.5661\n",
            "Epoch 338/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.9253 - val_loss: 52.5628\n",
            "Epoch 339/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.6210 - val_loss: 52.5705\n",
            "Epoch 340/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 55.4453roc-auc_val: 0.8138\n",
            "47/47 [==============================] - 14s 297ms/step - loss: 55.0241 - val_loss: 52.5728\n",
            "Epoch 341/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.5427 - val_loss: 52.5631\n",
            "Epoch 342/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2320 - val_loss: 52.5710\n",
            "Epoch 343/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.8447 - val_loss: 52.5723\n",
            "Epoch 344/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7739 - val_loss: 52.5718\n",
            "Epoch 345/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.8316 - val_loss: 52.5835\n",
            "Epoch 346/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.3140 - val_loss: 52.5712\n",
            "Epoch 347/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.0943 - val_loss: 52.5609\n",
            "Epoch 348/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.8076 - val_loss: 52.5471\n",
            "Epoch 349/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.1751 - val_loss: 52.5434\n",
            "Epoch 350/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.9326roc-auc_val: 0.814\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 54.5085 - val_loss: 52.5460\n",
            "Epoch 351/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9343 - val_loss: 52.5378\n",
            "Epoch 352/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.6613 - val_loss: 52.5470\n",
            "Epoch 353/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.3396 - val_loss: 52.5420\n",
            "Epoch 354/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7277 - val_loss: 52.5388\n",
            "Epoch 355/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9293 - val_loss: 52.5380\n",
            "Epoch 356/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.5035 - val_loss: 52.5415\n",
            "Epoch 357/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 55.0392 - val_loss: 52.5481\n",
            "Epoch 358/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.3400 - val_loss: 52.5414\n",
            "Epoch 359/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.4673 - val_loss: 52.5377\n",
            "Epoch 360/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 53.8106roc-auc_val: 0.8141\n",
            "47/47 [==============================] - 14s 294ms/step - loss: 53.8106 - val_loss: 52.5275\n",
            "Epoch 361/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.8154 - val_loss: 52.5284\n",
            "Epoch 362/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.8794 - val_loss: 52.5286\n",
            "Epoch 363/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2149 - val_loss: 52.5276\n",
            "Epoch 364/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.8665 - val_loss: 52.5247\n",
            "Epoch 365/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.3488 - val_loss: 52.5192\n",
            "Epoch 366/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2515 - val_loss: 52.5077\n",
            "Epoch 367/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.6175 - val_loss: 52.5187\n",
            "Epoch 368/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7579 - val_loss: 52.5195\n",
            "Epoch 369/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.1942 - val_loss: 52.4985\n",
            "Epoch 370/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 54.7680roc-auc_val: 0.8143\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 54.1868 - val_loss: 52.5035\n",
            "Epoch 371/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9040 - val_loss: 52.5103\n",
            "Epoch 372/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9360 - val_loss: 52.5048\n",
            "Epoch 373/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.1665 - val_loss: 52.5095\n",
            "Epoch 374/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2565 - val_loss: 52.5065\n",
            "Epoch 375/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2091 - val_loss: 52.5009\n",
            "Epoch 376/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7304 - val_loss: 52.5072\n",
            "Epoch 377/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 54.3868 - val_loss: 52.4999\n",
            "Epoch 378/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 54.0150 - val_loss: 52.4940\n",
            "Epoch 379/1000\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 54.0800 - val_loss: 52.4882\n",
            "Epoch 380/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 54.5125roc-auc_val: 0.8144\n",
            "47/47 [==============================] - 15s 317ms/step - loss: 54.3039 - val_loss: 52.4877\n",
            "Epoch 381/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.1445 - val_loss: 52.4880\n",
            "Epoch 382/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.7301 - val_loss: 52.4894\n",
            "Epoch 383/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.6156 - val_loss: 52.4934\n",
            "Epoch 384/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9653 - val_loss: 52.4933\n",
            "Epoch 385/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.4753 - val_loss: 52.4872\n",
            "Epoch 386/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.1385 - val_loss: 52.4876\n",
            "Epoch 387/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2913 - val_loss: 52.4902\n",
            "Epoch 388/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7754 - val_loss: 52.4848\n",
            "Epoch 389/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.2759 - val_loss: 52.4655\n",
            "Epoch 390/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 54.2574roc-auc_val: 0.8145\n",
            "47/47 [==============================] - 14s 300ms/step - loss: 53.7074 - val_loss: 52.4652\n",
            "Epoch 391/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.8636 - val_loss: 52.4697\n",
            "Epoch 392/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.3087 - val_loss: 52.4650\n",
            "Epoch 393/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2779 - val_loss: 52.4818\n",
            "Epoch 394/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.4885 - val_loss: 52.4713\n",
            "Epoch 395/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5889 - val_loss: 52.4747\n",
            "Epoch 396/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.3265 - val_loss: 52.4736\n",
            "Epoch 397/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.8018 - val_loss: 52.4742\n",
            "Epoch 398/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9308 - val_loss: 52.4555\n",
            "Epoch 399/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.8006 - val_loss: 52.4575\n",
            "Epoch 400/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 53.8364roc-auc_val: 0.8146\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 53.6878 - val_loss: 52.4498\n",
            "Epoch 401/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9446 - val_loss: 52.4501\n",
            "Epoch 402/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.4182 - val_loss: 52.4512\n",
            "Epoch 403/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2732 - val_loss: 52.4497\n",
            "Epoch 404/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.8317 - val_loss: 52.4456\n",
            "Epoch 405/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9134 - val_loss: 52.4539\n",
            "Epoch 406/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7888 - val_loss: 52.4468\n",
            "Epoch 407/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2676 - val_loss: 52.4475\n",
            "Epoch 408/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.9293 - val_loss: 52.4465\n",
            "Epoch 409/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.0934 - val_loss: 52.4399\n",
            "Epoch 410/1000\n",
            "38/47 [=======================>......] - ETA: 0s - loss: 53.7241roc-auc_val: 0.8147\n",
            "47/47 [==============================] - 14s 298ms/step - loss: 53.6547 - val_loss: 52.4403\n",
            "Epoch 411/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.6158 - val_loss: 52.4426\n",
            "Epoch 412/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.3243 - val_loss: 52.4420\n",
            "Epoch 413/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.6350 - val_loss: 52.4401\n",
            "Epoch 414/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5438 - val_loss: 52.4366\n",
            "Epoch 415/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 54.3008 - val_loss: 52.4339\n",
            "Epoch 416/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5413 - val_loss: 52.4375\n",
            "Epoch 417/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.8536 - val_loss: 52.4308\n",
            "Epoch 418/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.8906 - val_loss: 52.4375\n",
            "Epoch 419/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7213 - val_loss: 52.4232\n",
            "Epoch 420/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 54.6303roc-auc_val: 0.8148\n",
            "47/47 [==============================] - 14s 301ms/step - loss: 54.2562 - val_loss: 52.4151\n",
            "Epoch 421/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.6586 - val_loss: 52.4207\n",
            "Epoch 422/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2650 - val_loss: 52.4245\n",
            "Epoch 423/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5856 - val_loss: 52.4265\n",
            "Epoch 424/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1265 - val_loss: 52.4202\n",
            "Epoch 425/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2568 - val_loss: 52.4117\n",
            "Epoch 426/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.8481 - val_loss: 52.4190\n",
            "Epoch 427/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3298 - val_loss: 52.4116\n",
            "Epoch 428/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2475 - val_loss: 52.4143\n",
            "Epoch 429/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.1724 - val_loss: 52.4157\n",
            "Epoch 430/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.9868roc-auc_val: 0.8149\n",
            "47/47 [==============================] - 14s 300ms/step - loss: 53.7680 - val_loss: 52.4057\n",
            "Epoch 431/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.6447 - val_loss: 52.4134\n",
            "Epoch 432/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2596 - val_loss: 52.3993\n",
            "Epoch 433/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.6596 - val_loss: 52.4002\n",
            "Epoch 434/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7160 - val_loss: 52.3914\n",
            "Epoch 435/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5606 - val_loss: 52.3936\n",
            "Epoch 436/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9449 - val_loss: 52.4019\n",
            "Epoch 437/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1918 - val_loss: 52.3920\n",
            "Epoch 438/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.7284 - val_loss: 52.3852\n",
            "Epoch 439/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6886 - val_loss: 52.3896\n",
            "Epoch 440/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.5096roc-auc_val: 0.815\n",
            "47/47 [==============================] - 14s 297ms/step - loss: 53.3841 - val_loss: 52.3740\n",
            "Epoch 441/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.4197 - val_loss: 52.3837\n",
            "Epoch 442/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7948 - val_loss: 52.3823\n",
            "Epoch 443/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7662 - val_loss: 52.3791\n",
            "Epoch 444/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.4674 - val_loss: 52.3721\n",
            "Epoch 445/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.4537 - val_loss: 52.3902\n",
            "Epoch 446/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1194 - val_loss: 52.3865\n",
            "Epoch 447/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.6229 - val_loss: 52.3648\n",
            "Epoch 448/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3597 - val_loss: 52.3594\n",
            "Epoch 449/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3191 - val_loss: 52.3583\n",
            "Epoch 450/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 53.0645roc-auc_val: 0.8152\n",
            "47/47 [==============================] - 14s 302ms/step - loss: 53.2804 - val_loss: 52.3677\n",
            "Epoch 451/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9489 - val_loss: 52.3669\n",
            "Epoch 452/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5791 - val_loss: 52.3665\n",
            "Epoch 453/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7950 - val_loss: 52.3665\n",
            "Epoch 454/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7290 - val_loss: 52.3699\n",
            "Epoch 455/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 54.2018 - val_loss: 52.3641\n",
            "Epoch 456/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.9524 - val_loss: 52.3627\n",
            "Epoch 457/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0602 - val_loss: 52.3636\n",
            "Epoch 458/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5438 - val_loss: 52.3593\n",
            "Epoch 459/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3364 - val_loss: 52.3640\n",
            "Epoch 460/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.8581roc-auc_val: 0.8152\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 53.5758 - val_loss: 52.3519\n",
            "Epoch 461/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6855 - val_loss: 52.3470\n",
            "Epoch 462/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8860 - val_loss: 52.3580\n",
            "Epoch 463/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1478 - val_loss: 52.3610\n",
            "Epoch 464/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0037 - val_loss: 52.3678\n",
            "Epoch 465/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.4000 - val_loss: 52.3655\n",
            "Epoch 466/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3064 - val_loss: 52.3699\n",
            "Epoch 467/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.3849 - val_loss: 52.3765\n",
            "Epoch 468/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2364 - val_loss: 52.3757\n",
            "Epoch 469/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0220 - val_loss: 52.3612\n",
            "Epoch 470/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.8204roc-auc_val: 0.8153\n",
            "47/47 [==============================] - 14s 301ms/step - loss: 53.1002 - val_loss: 52.3582\n",
            "Epoch 471/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7685 - val_loss: 52.3660\n",
            "Epoch 472/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2725 - val_loss: 52.3658\n",
            "Epoch 473/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.3093 - val_loss: 52.3561\n",
            "Epoch 474/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.4497 - val_loss: 52.3505\n",
            "Epoch 475/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3867 - val_loss: 52.3250\n",
            "Epoch 476/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3020 - val_loss: 52.3326\n",
            "Epoch 477/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2074 - val_loss: 52.3360\n",
            "Epoch 478/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9085 - val_loss: 52.3419\n",
            "Epoch 479/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5201 - val_loss: 52.3445\n",
            "Epoch 480/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.2012roc-auc_val: 0.8154\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 53.0446 - val_loss: 52.3394\n",
            "Epoch 481/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9512 - val_loss: 52.3321\n",
            "Epoch 482/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3050 - val_loss: 52.3372\n",
            "Epoch 483/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3121 - val_loss: 52.3362\n",
            "Epoch 484/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.4797 - val_loss: 52.3235\n",
            "Epoch 485/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2579 - val_loss: 52.3336\n",
            "Epoch 486/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2740 - val_loss: 52.3390\n",
            "Epoch 487/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0305 - val_loss: 52.3367\n",
            "Epoch 488/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7391 - val_loss: 52.3444\n",
            "Epoch 489/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7434 - val_loss: 52.3493\n",
            "Epoch 490/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.5721roc-auc_val: 0.8154\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 53.0448 - val_loss: 52.3462\n",
            "Epoch 491/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7368 - val_loss: 52.3366\n",
            "Epoch 492/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0327 - val_loss: 52.3309\n",
            "Epoch 493/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9169 - val_loss: 52.3282\n",
            "Epoch 494/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3048 - val_loss: 52.3274\n",
            "Epoch 495/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7886 - val_loss: 52.3317\n",
            "Epoch 496/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.1486 - val_loss: 52.3249\n",
            "Epoch 497/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1528 - val_loss: 52.3368\n",
            "Epoch 498/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8659 - val_loss: 52.3395\n",
            "Epoch 499/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.2580 - val_loss: 52.3301\n",
            "Epoch 500/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 53.4751roc-auc_val: 0.8154\n",
            "47/47 [==============================] - 14s 301ms/step - loss: 53.3619 - val_loss: 52.3363\n",
            "Epoch 501/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6862 - val_loss: 52.3262\n",
            "Epoch 502/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4403 - val_loss: 52.3254\n",
            "Epoch 503/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.8908 - val_loss: 52.3248\n",
            "Epoch 504/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6850 - val_loss: 52.3160\n",
            "Epoch 505/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3638 - val_loss: 52.3060\n",
            "Epoch 506/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0375 - val_loss: 52.3215\n",
            "Epoch 507/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3791 - val_loss: 52.3171\n",
            "Epoch 508/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1448 - val_loss: 52.3200\n",
            "Epoch 509/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0405 - val_loss: 52.3074\n",
            "Epoch 510/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 52.8938roc-auc_val: 0.8156\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 52.9680 - val_loss: 52.3174\n",
            "Epoch 511/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3826 - val_loss: 52.3082\n",
            "Epoch 512/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8272 - val_loss: 52.3192\n",
            "Epoch 513/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.4149 - val_loss: 52.3191\n",
            "Epoch 514/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3597 - val_loss: 52.3086\n",
            "Epoch 515/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1888 - val_loss: 52.3037\n",
            "Epoch 516/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1807 - val_loss: 52.2934\n",
            "Epoch 517/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6795 - val_loss: 52.3010\n",
            "Epoch 518/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7595 - val_loss: 52.3073\n",
            "Epoch 519/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8876 - val_loss: 52.3012\n",
            "Epoch 520/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.4713roc-auc_val: 0.8157\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 53.4561 - val_loss: 52.3002\n",
            "Epoch 521/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7723 - val_loss: 52.3021\n",
            "Epoch 522/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1498 - val_loss: 52.3023\n",
            "Epoch 523/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9003 - val_loss: 52.3037\n",
            "Epoch 524/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0688 - val_loss: 52.3038\n",
            "Epoch 525/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6521 - val_loss: 52.2941\n",
            "Epoch 526/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9734 - val_loss: 52.2979\n",
            "Epoch 527/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6718 - val_loss: 52.2802\n",
            "Epoch 528/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.7899 - val_loss: 52.2795\n",
            "Epoch 529/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0811 - val_loss: 52.2880\n",
            "Epoch 530/1000\n",
            "46/47 [============================>.] - ETA: 0s - loss: 53.3502roc-auc_val: 0.8157\n",
            "47/47 [==============================] - 15s 318ms/step - loss: 53.1581 - val_loss: 52.2891\n",
            "Epoch 531/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4190 - val_loss: 52.2786\n",
            "Epoch 532/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.2964 - val_loss: 52.2974\n",
            "Epoch 533/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7015 - val_loss: 52.3026\n",
            "Epoch 534/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3025 - val_loss: 52.3061\n",
            "Epoch 535/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6447 - val_loss: 52.2864\n",
            "Epoch 536/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9561 - val_loss: 52.2849\n",
            "Epoch 537/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9839 - val_loss: 52.2844\n",
            "Epoch 538/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8092 - val_loss: 52.2878\n",
            "Epoch 539/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2995 - val_loss: 52.2778\n",
            "Epoch 540/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.2143roc-auc_val: 0.8158\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 52.6911 - val_loss: 52.2910\n",
            "Epoch 541/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6696 - val_loss: 52.2919\n",
            "Epoch 542/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1486 - val_loss: 52.2840\n",
            "Epoch 543/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2539 - val_loss: 52.2846\n",
            "Epoch 544/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6420 - val_loss: 52.2895\n",
            "Epoch 545/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0470 - val_loss: 52.2874\n",
            "Epoch 546/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0033 - val_loss: 52.2760\n",
            "Epoch 547/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3393 - val_loss: 52.2687\n",
            "Epoch 548/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.3315 - val_loss: 52.2620\n",
            "Epoch 549/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3751 - val_loss: 52.2747\n",
            "Epoch 550/1000\n",
            "47/47 [==============================] - ETA: 0s - loss: 52.8063roc-auc_val: 0.8159\n",
            "47/47 [==============================] - 14s 298ms/step - loss: 52.8063 - val_loss: 52.2789\n",
            "Epoch 551/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9217 - val_loss: 52.2877\n",
            "Epoch 552/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7770 - val_loss: 52.2716\n",
            "Epoch 553/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9056 - val_loss: 52.2698\n",
            "Epoch 554/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2367 - val_loss: 52.2747\n",
            "Epoch 555/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.1668 - val_loss: 52.2689\n",
            "Epoch 556/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3967 - val_loss: 52.2693\n",
            "Epoch 557/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3968 - val_loss: 52.2751\n",
            "Epoch 558/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4840 - val_loss: 52.2536\n",
            "Epoch 559/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3838 - val_loss: 52.2473\n",
            "Epoch 560/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.6062roc-auc_val: 0.816\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 53.0972 - val_loss: 52.2668\n",
            "Epoch 561/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8419 - val_loss: 52.2492\n",
            "Epoch 562/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.9084 - val_loss: 52.2468\n",
            "Epoch 563/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3844 - val_loss: 52.2497\n",
            "Epoch 564/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4199 - val_loss: 52.2545\n",
            "Epoch 565/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7710 - val_loss: 52.2112\n",
            "Epoch 566/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6676 - val_loss: 52.2367\n",
            "Epoch 567/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3365 - val_loss: 52.2449\n",
            "Epoch 568/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6990 - val_loss: 52.2455\n",
            "Epoch 569/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.5137 - val_loss: 52.2547\n",
            "Epoch 570/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 53.0782roc-auc_val: 0.816\n",
            "47/47 [==============================] - 14s 305ms/step - loss: 52.7410 - val_loss: 52.2738\n",
            "Epoch 571/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.3972 - val_loss: 52.2628\n",
            "Epoch 572/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 51.7692 - val_loss: 52.2623\n",
            "Epoch 573/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4975 - val_loss: 52.2593\n",
            "Epoch 574/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4913 - val_loss: 52.2613\n",
            "Epoch 575/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.2031 - val_loss: 52.2717\n",
            "Epoch 576/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.5784 - val_loss: 52.2797\n",
            "Epoch 577/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4260 - val_loss: 52.2651\n",
            "Epoch 578/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7659 - val_loss: 52.2556\n",
            "Epoch 579/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.5506 - val_loss: 52.2479\n",
            "Epoch 580/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 51.9838roc-auc_val: 0.8161\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 52.1954 - val_loss: 52.2503\n",
            "Epoch 581/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3308 - val_loss: 52.2596\n",
            "Epoch 582/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7840 - val_loss: 52.2545\n",
            "Epoch 583/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8592 - val_loss: 52.2402\n",
            "Epoch 584/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6943 - val_loss: 52.2372\n",
            "Epoch 585/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4269 - val_loss: 52.2363\n",
            "Epoch 586/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.2455 - val_loss: 52.2430\n",
            "Epoch 587/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8322 - val_loss: 52.2365\n",
            "Epoch 588/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 53.3094 - val_loss: 52.2337\n",
            "Epoch 589/1000\n",
            "47/47 [==============================] - 1s 16ms/step - loss: 52.4641 - val_loss: 52.2365\n",
            "Epoch 590/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 53.2001roc-auc_val: 0.8162\n",
            "47/47 [==============================] - 14s 299ms/step - loss: 52.6113 - val_loss: 52.2413\n",
            "Epoch 591/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6319 - val_loss: 52.2416\n",
            "Epoch 592/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3070 - val_loss: 52.2316\n",
            "Epoch 593/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3109 - val_loss: 52.2391\n",
            "Epoch 594/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.0698 - val_loss: 52.2438\n",
            "Epoch 595/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.2021 - val_loss: 52.2481\n",
            "Epoch 596/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.1730 - val_loss: 52.2443\n",
            "Epoch 597/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6116 - val_loss: 52.2447\n",
            "Epoch 598/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.5053 - val_loss: 52.2449\n",
            "Epoch 599/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.5584 - val_loss: 52.2491\n",
            "Epoch 600/1000\n",
            "36/47 [=====================>........] - ETA: 0s - loss: 53.1119roc-auc_val: 0.8163\n",
            "47/47 [==============================] - 14s 296ms/step - loss: 52.6236 - val_loss: 52.2412\n",
            "Epoch 601/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7066 - val_loss: 52.2201\n",
            "Epoch 602/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6353 - val_loss: 52.2318\n",
            "Epoch 603/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3733 - val_loss: 52.2420\n",
            "Epoch 604/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.2765 - val_loss: 52.2470\n",
            "Epoch 605/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.4535 - val_loss: 52.2392\n",
            "Epoch 606/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.8804 - val_loss: 52.2211\n",
            "Epoch 607/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.6054 - val_loss: 52.2201\n",
            "Epoch 608/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.5147 - val_loss: 52.2315\n",
            "Epoch 609/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 53.0063 - val_loss: 52.2347\n",
            "Epoch 610/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 52.1195roc-auc_val: 0.8162\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 52.3797 - val_loss: 52.2391\n",
            "Epoch 611/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3206 - val_loss: 52.2353\n",
            "Epoch 612/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.3181 - val_loss: 52.2317\n",
            "Epoch 613/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.7761 - val_loss: 52.2332\n",
            "Epoch 614/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 52.2126 - val_loss: 52.2208\n",
            "Epoch 615/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 51.9008 - val_loss: 52.2172\n",
            "Epoch 1/1000\n",
            "4/4 [==============================] - 2s 479ms/step - loss: 107.9044 - val_loss: 77.1905\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 111.7300 - val_loss: 76.5246\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 108.5901 - val_loss: 75.9171\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 101.7966 - val_loss: 75.3362\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 103.3047 - val_loss: 74.7405\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 106.6332 - val_loss: 74.1458\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 103.8316 - val_loss: 73.5262\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 104.0569 - val_loss: 72.9008\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 97.3629 - val_loss: 72.2546\n",
            "Epoch 10/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 107.6304roc-auc_val: 0.5359\n",
            "4/4 [==============================] - 15s 4s/step - loss: 102.2821 - val_loss: 71.7187\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 98.7525 - val_loss: 71.1962\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 102.8481 - val_loss: 70.6955\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 97.3083 - val_loss: 70.2091\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 100.8770 - val_loss: 69.7273\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 96.6738 - val_loss: 69.2541\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 101.0988 - val_loss: 68.8389\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 95.1433 - val_loss: 68.4101\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 94.5866 - val_loss: 68.0131\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 96.0026 - val_loss: 67.6968\n",
            "Epoch 20/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 111.3863roc-auc_val: 0.6346\n",
            "4/4 [==============================] - 14s 4s/step - loss: 92.4769 - val_loss: 67.3515\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 90.3624 - val_loss: 67.0806\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 92.2007 - val_loss: 66.8012\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 90.1230 - val_loss: 66.4989\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 95.1397 - val_loss: 66.2005\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 87.9058 - val_loss: 65.9416\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 90.9559 - val_loss: 65.6788\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 1s 138ms/step - loss: 91.4729 - val_loss: 65.4623\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 85.5069 - val_loss: 65.2640\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 92.2855 - val_loss: 65.0536\n",
            "Epoch 30/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 89.6353roc-auc_val: 0.6811\n",
            "4/4 [==============================] - 14s 4s/step - loss: 89.8895 - val_loss: 64.8635\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 90.1317 - val_loss: 64.6848\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 89.4371 - val_loss: 64.5574\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 88.0313 - val_loss: 64.4232\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 90.1768 - val_loss: 64.2759\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 86.7536 - val_loss: 64.1589\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 80.3368 - val_loss: 64.0315\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 89.2843 - val_loss: 63.9347\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 87.7837 - val_loss: 63.8014\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 82.2158 - val_loss: 63.7083\n",
            "Epoch 40/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 91.5360roc-auc_val: 0.7043\n",
            "4/4 [==============================] - 14s 4s/step - loss: 85.4222 - val_loss: 63.6214\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 84.3942 - val_loss: 63.5373\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 81.1297 - val_loss: 63.4333\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 82.5866 - val_loss: 63.3562\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 82.4523 - val_loss: 63.3099\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 83.9558 - val_loss: 63.2414\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 80.9180 - val_loss: 63.1717\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 80.0591 - val_loss: 63.1046\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 86.3706 - val_loss: 63.0566\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 81.9673 - val_loss: 63.0033\n",
            "Epoch 50/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 82.6053roc-auc_val: 0.7185\n",
            "4/4 [==============================] - 14s 3s/step - loss: 84.7747 - val_loss: 62.9548\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 83.0707 - val_loss: 62.9001\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 80.5839 - val_loss: 62.8656\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 81.7162 - val_loss: 62.8278\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 78.4986 - val_loss: 62.8106\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 80.7605 - val_loss: 62.7633\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 82.3829 - val_loss: 62.7519\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 83.3593 - val_loss: 62.7358\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 78.6204 - val_loss: 62.7097\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 78.6527 - val_loss: 62.6834\n",
            "Epoch 60/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 77.2582roc-auc_val: 0.7282\n",
            "4/4 [==============================] - 15s 4s/step - loss: 80.5454 - val_loss: 62.6707\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 81.4670 - val_loss: 62.6499\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 80.9877 - val_loss: 62.6173\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 79.9802 - val_loss: 62.5962\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 75.2128 - val_loss: 62.5771\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 77.9828 - val_loss: 62.5515\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 80.1130 - val_loss: 62.5368\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 75.8540 - val_loss: 62.5137\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 81.1672 - val_loss: 62.4937\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 74.3783 - val_loss: 62.4749\n",
            "Epoch 70/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 81.6272roc-auc_val: 0.7354\n",
            "4/4 [==============================] - 14s 3s/step - loss: 74.4681 - val_loss: 62.4659\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 83.4398 - val_loss: 62.4510\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 77.7223 - val_loss: 62.4315\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 1s 130ms/step - loss: 76.7000 - val_loss: 62.4032\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 77.0250 - val_loss: 62.3865\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 75.0966 - val_loss: 62.3698\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 78.7934 - val_loss: 62.3606\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 76.2487 - val_loss: 62.3498\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 76.1469 - val_loss: 62.3387\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 78.3268 - val_loss: 62.3155\n",
            "Epoch 80/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 73.8953roc-auc_val: 0.7403\n",
            "4/4 [==============================] - 14s 3s/step - loss: 76.5901 - val_loss: 62.3093\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 75.3215 - val_loss: 62.3007\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 74.3772 - val_loss: 62.2726\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 78.2932 - val_loss: 62.2639\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 75.8707 - val_loss: 62.2506\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 78.5865 - val_loss: 62.2453\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 82.8898 - val_loss: 62.2280\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 75.8639 - val_loss: 62.2146\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 80.0315 - val_loss: 62.1960\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 78.5326 - val_loss: 62.1698\n",
            "Epoch 90/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 75.9806roc-auc_val: 0.745\n",
            "4/4 [==============================] - 14s 4s/step - loss: 77.5691 - val_loss: 62.1432\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 80.4713 - val_loss: 62.1192\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 74.5056 - val_loss: 62.1078\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 74.0892 - val_loss: 62.0894\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 75.7659 - val_loss: 62.0960\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 1s 131ms/step - loss: 76.1690 - val_loss: 62.0721\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 73.1821 - val_loss: 62.0539\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 75.3617 - val_loss: 62.0276\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 76.4087 - val_loss: 61.9796\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 76.9649 - val_loss: 61.9560\n",
            "Epoch 100/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 75.0632roc-auc_val: 0.7492\n",
            "4/4 [==============================] - 14s 3s/step - loss: 74.0138 - val_loss: 61.9282\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 1s 140ms/step - loss: 77.2800 - val_loss: 61.8989\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 73.4197 - val_loss: 61.8718\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 76.3787 - val_loss: 61.8566\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 76.5065 - val_loss: 61.8432\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 75.5503 - val_loss: 61.8221\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 75.5054 - val_loss: 61.8004\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 1s 139ms/step - loss: 71.8363 - val_loss: 61.7822\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 75.4606 - val_loss: 61.7566\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 1s 132ms/step - loss: 72.7317 - val_loss: 61.7161\n",
            "Epoch 110/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 76.5008roc-auc_val: 0.7521\n",
            "4/4 [==============================] - 14s 3s/step - loss: 73.3695 - val_loss: 61.6860\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 72.9432 - val_loss: 61.6558\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 72.7802 - val_loss: 61.6138\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 74.5173 - val_loss: 61.5936\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 73.7114 - val_loss: 61.5719\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 76.2683 - val_loss: 61.5275\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 75.6284 - val_loss: 61.5133\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 74.4840 - val_loss: 61.4972\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 77.7505 - val_loss: 61.4823\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 70.6697 - val_loss: 61.4621\n",
            "Epoch 120/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 69.4459"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYP9tzJFf3Td",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "161cdbc1-f7d4-474a-b013-37eb367f71a2"
      },
      "source": [
        "dk.keys()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['0.8842399233615262', '0.8680248437397996', '0.8654564376773441'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JYUDyGKf4DJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "46c2ed76-ebbb-4418-d9f8-a51fcc87bd17"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(dk['0.8842399233615262'])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fc917dc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pwh4KS7gH6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d50b78e9-d9d9-4bc0-f17f-71b0ca6e04e7"
      },
      "source": [
        "\n",
        "sns.distplot(dk['0.8680248437397996'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fc907ab00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFU8fAUIgJ5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "e566d599-fdc4-4815-eefa-c0d165ef7f36"
      },
      "source": [
        "\n",
        "sns.distplot(dk['0.8654564376773441'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fc916c278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xa2b7VxgM7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}