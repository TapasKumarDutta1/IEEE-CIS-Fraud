{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "raw_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMapiMN0cZJCDFFxE0QtW4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/raw_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkisredxEoDr",
        "colab_type": "code",
        "outputId": "4e020dea-25da-4333-b9d6-002544554603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        }
      },
      "source": [
        "pip install tensorflow==2.1.0-rc0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0-rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/fd/7528e5ef327abde9b7425aea24198d8b139795c1233d1658c1279055d860/tensorflow-2.1.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (402.3MB)\n",
            "\u001b[K     |████████████████████████████████| 402.3MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (3.2.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.2.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.18.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.24.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (46.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0-rc0) (2.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 2.1.0rc0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cFlpVqvGDAy",
        "colab_type": "code",
        "outputId": "6d85b64a-0df4-4e7d-c59a-90f7d575dfd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "pip install keras==2.3.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmEILqBeGDDw",
        "colab_type": "code",
        "outputId": "7bd87184-7531-4e62-a608-7d5b22632799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMr65yMzGDG-",
        "colab_type": "code",
        "outputId": "ed0e39f3-c866-40db-87c6-bbf163e51d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"c147d874a8706a6a8d429eb3d7ea1682\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test_identity.csv.zip to /content\n",
            "\r  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "\r100% 3.21M/3.21M [00:00<00:00, 110MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "\r  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 141MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 96% 50.0M/52.2M [00:00<00:00, 71.8MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 96.8MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 84% 49.0M/58.3M [00:00<00:00, 82.5MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 105MB/s] \n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 102MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ0WFyXdGDKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5mWhMNJGDNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEpkt7TTGBGM",
        "colab_type": "code",
        "outputId": "5ef5dfb6-459b-45dd-8451-dddeb0ed817c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#read raw data\n",
        "trn_trans=pd.read_csv('train_identity.csv.zip',nrows=10000)\n",
        "trn=pd.read_csv('train_transaction.csv.zip',nrows=10000)\n",
        "tst_trans=pd.read_csv('test_identity.csv.zip',nrows=10000)\n",
        "tst=pd.read_csv('test_transaction.csv.zip',nrows=10000)\n",
        "\n",
        "#merge data\n",
        "\n",
        "fnl_trn=trn.merge(trn_trans,on='TransactionID',how='left')\n",
        "fnl_tst=tst.merge(tst_trans,on='TransactionID',how='left')\n",
        "\n",
        "#drop columns causing overfit\n",
        "\n",
        "fnl_trn=fnl_trn.drop(list(fnl_trn.filter(regex='V')),1)\n",
        "fnl_tst=fnl_tst.drop(list(fnl_tst.filter(regex='V')),1)\n",
        "\n",
        "#rename columns\n",
        "\n",
        "import gc\n",
        "dk={}\n",
        "for i in range(1,39):\n",
        "    if i<10:\n",
        "        dk['id-0'+str(i)]='id_0'+str(i)\n",
        "    else:\n",
        "        dk['id-'+str(i)]='id_'+str(i)\n",
        "fnl_tst=fnl_tst.rename(columns=dk)\n",
        "\n",
        "#free memory\n",
        "\n",
        "del([trn,tst,trn_trans,tst_trans])\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1095"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JZOGR-CFT2G",
        "colab_type": "code",
        "outputId": "77b3eb8d-1d36-4724-ff9c-5ac1e898e06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#give identifier column\n",
        "\n",
        "fnl_trn['is_train']=1\n",
        "fnl_tst['is_train']=0\n",
        "\n",
        "#concat all data\n",
        "\n",
        "fnl=pd.concat([fnl_trn,fnl_tst],0)\n",
        "fnl=fnl.reset_index(drop=True)\n",
        "gc.collect()\n",
        "numerical = [\"TransactionAmt\", \"dist1\", \"dist2\"] + [\"C\" + str(i) for i in range(1, 15)]+[\"D\" + str(i) for i in range(1, 16)]\n",
        "\n",
        "categorical = [\"ProductCD\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\",\n",
        "               \"P_emaildomain\", \"R_emaildomain\",\n",
        "              \"DeviceInfo\", \"DeviceType\"] + [\"id_0\" + str(i) for i in range(1, 10)] +\\\n",
        "                [\"id_\" + str(i) for i in range(10, 39)] + \\\n",
        "                 [\"M\" + str(i) for i in range(1, 10)]\n",
        "\n",
        "#fill numericals with their mean and categoricals with nan\n",
        "fnl[[\"D\" + str(i) for i in range(1, 16)]]=fnl[[\"D\" + str(i) for i in range(1, 16)]].fillna(-1)\n",
        "fnl[[\"C\" + str(i) for i in range(1, 15)]]=fnl[[\"C\" + str(i) for i in range(1, 15)]].fillna(-1)\n",
        "for col in numerical:\n",
        "    fnl[col]=fnl[col].fillna(fnl[col].mean())\n",
        "for col in categorical:\n",
        "    fnl[col]=fnl[col].fillna('nan')\n",
        "\n",
        "    \n",
        "#create id column    \n",
        "\n",
        "fnl['days']=fnl['TransactionDT']//86400\n",
        "fnl['id']=fnl['days']-fnl['D1']\n",
        "fnl['id']=fnl['id'].astype(str)+fnl['P_emaildomain'].astype(str)+fnl['card1'].astype(str)+fnl['C9'].astype(str)+fnl['C11'].astype(str)+fnl['dist1'].astype(str)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "fnl['id']=le.fit_transform(fnl['id'])\n",
        "\n",
        "#for numericals groupby id then find mean and std\n",
        "\n",
        "from tqdm import tqdm\n",
        "for col in tqdm(numerical):\n",
        "    try:\n",
        "        fnl[col+'_mean']=fnl.groupby(['id'])[col].transform('mean')\n",
        "        fnl[col+'_std']=fnl.groupby(['id'])[col].transform('std')\n",
        "    except:\n",
        "        continue\n",
        "fnl=fnl.drop(['id'],1)\n",
        "\n",
        "#get dummies of top 5 most frequent values for categoricals\n",
        "\n",
        "from tqdm import tqdm\n",
        "for col in tqdm(categorical):\n",
        "        print('before '+str(fnl[col].nunique()))\n",
        "        fnl.loc[~fnl[col].isin(list(fnl[col].value_counts().index[:5])),col]='other'\n",
        "        print('before '+str(fnl[col].nunique()))\n",
        "        if col!='card1' or col !='id_02':\n",
        "            fnl_dum=pd.get_dummies(fnl[col]).astype('uint8')\n",
        "            fnl_dum.columns=list(np.char.add(col,np.asarray(list(fnl_dum)).astype(str)))\n",
        "            fnl_dum.columns=fnl_dum.columns+'_dum'\n",
        "            \n",
        "            #fnl=fnl.drop([col],1)\n",
        "            fnl=pd.concat([fnl,fnl_dum],1)\n",
        "fnl['day']=fnl['TransactionDT']//86400\n",
        "fnl['month']=fnl['day']//30\n",
        "fnl['week']=fnl['day']//7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  import sys\n",
            "100%|██████████| 32/32 [00:00<00:00, 38.82it/s]\n",
            "  3%|▎         | 2/60 [00:00<00:03, 17.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 5\n",
            "before 5\n",
            "before 3175\n",
            "before 6\n",
            "before 476\n",
            "before 6\n",
            "before 45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 6/60 [00:00<00:03, 16.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 6\n",
            "before 5\n",
            "before 5\n",
            "before 50\n",
            "before 6\n",
            "before 3\n",
            "before 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 10/60 [00:00<00:03, 15.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 68\n",
            "before 6\n",
            "before 9\n",
            "before 6\n",
            "before 56\n",
            "before 6\n",
            "before 46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 12/60 [00:00<00:03, 15.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 6\n",
            "before 286\n",
            "before 6\n",
            "before 3\n",
            "before 3\n",
            "before 28\n",
            "before 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 16/60 [00:01<00:02, 15.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 3276\n",
            "before 6\n",
            "before 12\n",
            "before 6\n",
            "before 8\n",
            "before 6\n",
            "before 59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 20/60 [00:01<00:02, 15.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 6\n",
            "before 61\n",
            "before 6\n",
            "before 34\n",
            "before 6\n",
            "before 43\n",
            "before 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 24/60 [00:01<00:02, 15.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 22\n",
            "before 6\n",
            "before 19\n",
            "before 6\n",
            "before 82\n",
            "before 6\n",
            "before 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 26/60 [00:01<00:02, 15.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 3\n",
            "before 24\n",
            "before 6\n",
            "before 14\n",
            "before 6\n",
            "before 4\n",
            "before 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 30/60 [00:01<00:02, 14.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 3\n",
            "before 3\n",
            "before 30\n",
            "before 6\n",
            "before 12\n",
            "before 6\n",
            "before 180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 34/60 [00:02<00:01, 14.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 6\n",
            "before 120\n",
            "before 6\n",
            "before 22\n",
            "before 6\n",
            "before 6\n",
            "before 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 38/60 [00:02<00:01, 15.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 4\n",
            "before 4\n",
            "before 5\n",
            "before 5\n",
            "before 23\n",
            "before 6\n",
            "before 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 40/60 [00:02<00:01, 14.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 6\n",
            "before 2\n",
            "before 2\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 44/60 [00:02<00:01, 14.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 67\n",
            "before 6\n",
            "before 87\n",
            "before 6\n",
            "before 3\n",
            "before 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 48/60 [00:03<00:00, 14.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 76\n",
            "before 6\n",
            "before 4\n",
            "before 4\n",
            "before 3\n",
            "before 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 50/60 [00:03<00:00, 14.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 54/60 [00:03<00:00, 14.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 2\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 4\n",
            "before 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 58/60 [00:03<00:00, 14.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n",
            "before 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [00:04<00:00, 14.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "before 3\n",
            "before 3\n",
            "before 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFpkRVSzFT49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "import gc\n",
        "fnl.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in fnl.columns]\n",
        "fnl=fnl.drop(['TransactionID','TransactionDT'],1)\n",
        "fnl=fnl.reset_index(drop=True)\n",
        "gc.collect()\n",
        "fnl=fnl.fillna(-1)\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        df[col]=df[col].fillna(-1)\n",
        "        df[col]=df[col].replace([np.inf,-np.inf],-1)\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "\n",
        "#add fraud column\n",
        "\n",
        "trn=pd.read_csv('train_transaction.csv.zip',usecols=['isFraud'])\n",
        "fnl['isFraud']=trn['isFraud']\n",
        "fnl=fnl.loc[:,~(fnl.columns.duplicated())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An5TpsOWFT8u",
        "colab_type": "code",
        "outputId": "b18ec724-9841-40aa-bb57-212d45502f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import gc\n",
        "pds=['day','month','week']\n",
        "\n",
        "#since these columns increase with time scale these columns wrt different time periods \n",
        "\n",
        "cols =  [\"C\" + str(i) for i in range(1, 15)] + \\\n",
        "            [\"D\" + str(i) for i in range(1, 16)] \n",
        "for pd in pds:\n",
        "  for col in tqdm(cols):\n",
        "    col=str(col)\n",
        "    use_col=str(col)+'_'+pd+'_ss'\n",
        "    fnl['a']=fnl.groupby([pd])[col].transform('max')\n",
        "    fnl['b']=fnl.groupby([pd])[col].transform('min')\n",
        "    fnl[use_col]=fnl[col]-fnl['b']/(fnl['a']-fnl['b'])\n",
        "    use_col=str(col)+'_'+pd+'_norm'\n",
        "    fnl['a']=fnl.groupby([pd])[col].transform('std')\n",
        "    fnl['b']=fnl.groupby([pd])[col].transform('mean')\n",
        "    fnl[use_col]=(fnl[col]-fnl['a'])/fnl['b']\n",
        "  \n",
        "del([fnl['a'],fnl['b']])\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 26.68it/s]\n",
            "100%|██████████| 29/29 [00:01<00:00, 21.62it/s]\n",
            "100%|██████████| 29/29 [00:01<00:00, 17.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zTghkUXFUAf",
        "colab_type": "code",
        "outputId": "d245b4d4-42c0-4897-b806-3c68aecf6790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        if col_type in ['int','float']:\n",
        "            df[col]=df[col].fillna(-1)\n",
        "            df[col]=df[col].replace([np.inf,-np.inf],-1)\n",
        "        \n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "\n",
        "#replace inf with 0 and remove duplicate columns then reduce memory\n",
        "\n",
        "fnl=fnl.replace([np.inf,-np.inf],0)\n",
        "fnl=fnl.loc[:,~(fnl.columns.duplicated())]\n",
        "fnl=reduce_mem_usage(fnl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 95.06 MB\n",
            "Memory usage after optimization is: 17.08 MB\n",
            "Decreased by 82.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keiGwCE4FUEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnl.to_csv('prepared.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPQWz-WpFUMF",
        "colab_type": "code",
        "outputId": "e2c36c84-0bd1-476c-873c-a4416ec9ae66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "path = F\"/content/gdrive/My Drive/raw.csv\" \n",
        "fnl.to_csv(path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGuRR4A6FUHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}