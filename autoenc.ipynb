{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoenc.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMaQKzIhQKGM0QHmXhdMi6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/autoenc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "outputId": "9fbacd84-eab5-4948-ae4c-062f4584c5ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install tensorflow==2.1.0-rc0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0-rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/fd/7528e5ef327abde9b7425aea24198d8b139795c1233d1658c1279055d860/tensorflow-2.1.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (402.3MB)\n",
            "\u001b[K     |████████████████████████████████| 402.3MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (3.2.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (3.10.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.18.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0-rc0) (2.10.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2020.4.5.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=93ed83fee4d067a6b44b7ab17af0c3d1ecf354f7cd6b9780e6174e672f3749ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed gast-0.2.2 tensorboard-2.0.2 tensorflow-2.1.0rc0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKHDi3K-Pljg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "outputId": "eef8dd09-7960-4ebf-c393-3456c35030fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "pip install keras==2.3.1\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "outputId": "4512e203-9339-45ea-d60c-2a1ecfd6290a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train_identity.csv.zip to /content\n",
            "\r  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "\r100% 3.26M/3.26M [00:00<00:00, 108MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "\r  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "\r100% 1.14M/1.14M [00:00<00:00, 163MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "\r  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "\r100% 3.21M/3.21M [00:00<00:00, 106MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            "\r  0% 0.00/58.3M [00:00<?, ?B/s]\r  9% 5.00M/58.3M [00:00<00:01, 29.3MB/s]\r 15% 9.00M/58.3M [00:00<00:01, 31.0MB/s]\r 57% 33.0M/58.3M [00:00<00:00, 38.4MB/s]\r 96% 56.0M/58.3M [00:00<00:00, 51.1MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 85.5MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 86% 45.0M/52.2M [00:00<00:00, 50.9MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 88.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BeDD__pesQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "trn=pd.read_csv('train_transaction.csv.zip')\n",
        "tst=pd.read_csv('test_transaction.csv.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3UJH3B5ezCC",
        "colab_type": "code",
        "outputId": "ae89bef3-98b9-4d45-8ce2-3dae62eb6057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls=list(trn.filter(regex='V'))\n",
        "trn=trn.drop(ls,1)\n",
        "tst=tst.drop(ls,1)\n",
        "trn.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 55)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV4rJqGZjRI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ext(fnl):\n",
        "\n",
        "  fnl['P_1']=fnl['P_emaildomain'].fillna('nan').str.split('.').str[0]\n",
        "  fnl['P_2']=fnl['P_emaildomain'].fillna('nan').str.split('.').str[1]\n",
        "\n",
        "\n",
        "  fnl['R_1']=fnl['R_emaildomain'].fillna('nan').str.split('.').str[0]\n",
        "  fnl['R_2']=fnl['R_emaildomain'].fillna('nan').str.split('.').str[1]\n",
        "  return fnl\n",
        "trn=ext(trn)\n",
        "tst=ext(tst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOW97hGcpelu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.drop(['P_emaildomain','R_emaildomain','TransactionDT','TransactionID'],1)\n",
        "tst=tst.drop(['P_emaildomain','R_emaildomain','TransactionDT','TransactionID'],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXdmBx1pRQ4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkC1MXQpi1GP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def handle_disc(df,df1,cols):\n",
        "#   for col in cols:\n",
        "#     df[col]=df[col].fillna('other')\n",
        "#     cbe=CatBoostEncoder(sigma=0.01)\n",
        "#     df[col]=cbe.fit_transform(df[col].astype(str),df['isFraud'])\n",
        "#     df1[col]=cbe.transform(df1[col])\n",
        "#   return df,df1\n",
        "def handle_disc(df,cols,num):\n",
        "  for col in cols:\n",
        "    par=min(df[col].nunique(),num)\n",
        "    unq = df[col].value_counts().head(par)\n",
        "    dum=pd.get_dummies(df[col])[unq.index]\n",
        "    ls=[]\n",
        "    for i in dum.columns:\n",
        "      ls.append(str(col)+str(i))\n",
        "    dum.columns=ls\n",
        "    df=pd.concat([df,dum],1)\n",
        "\n",
        "  df=df.drop(cols,1)\n",
        "  sp=df.shape[1]\n",
        "  df.columns=list(range(sp))\n",
        "  return df\n",
        "def handle_cont(df,cols):\n",
        "  for col in cols:\n",
        "    df[col]=df[col].fillna(df[col].mean())\n",
        "    mn=df[col].mean()\n",
        "    std=df[col].std()\n",
        "    df[col]=(df[col]-mn)/(std+0.1)\n",
        "    df[col]=np.log10(df[col]+1-min(0,min(df[col])))\n",
        "  return df[cols]\n",
        "disc=['ProductCD','card1','card2','card3','card4','card5','card6','addr1','addr2','P_1','P_2','R_1','R_2','M1','M2','M3','M4','M5','M6','M7','M8','M9']\n",
        "cont=[i for i in tst.columns if i not in disc]\n",
        "trn_cont=handle_cont(trn,cont)\n",
        "tst_cont=handle_cont(tst,cont)\n",
        "trn_cont=trn_cont.replace([np.inf,-np.inf],0)\n",
        "tst_cont=tst_cont.replace([np.inf,-np.inf],0)\n",
        "trn_disc=handle_disc(trn,disc,140)\n",
        "tst_disc=handle_disc(tst,disc,140)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-GXjntws_4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=pd.concat([trn_cont,trn_disc],1).reset_index(drop=True)\n",
        "tst=pd.concat([tst_cont,tst_disc],1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCqKVjlpzag3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls=list(set(list(tst)).intersection(set(list(trn))))\n",
        "trn=trn[ls]\n",
        "tst=tst[ls]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sUgS9Xazr48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.loc[:,~(trn.columns.duplicated())]\n",
        "tst=tst.loc[:,~(tst.columns.duplicated())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFGy6fS5zuxw",
        "colab_type": "code",
        "outputId": "042f0fbe-9466-4406-da7d-d67590ef94fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "fnl=pd.concat([trn,tst],0)\n",
        "fnl=fnl.reset_index(drop=True)\n",
        "z=fnl.isna().sum()\n",
        "z[z>0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENKEV7R_6QJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1a9f6c3f-cfb6-4929-d768-579130a7d8f4"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDqeri-7Ymua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDvknW_60DHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "d173b886-8dc2-49fb-b0f9-bbefc6a7bef9"
      },
      "source": [
        "\n",
        "#input fed to model is original data where 10% columns have their values shuffled within themselves \n",
        "\n",
        "import gc\n",
        "import os\n",
        "gc.collect()\n",
        "import numpy as np\n",
        "import keras \n",
        "from math import ceil\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import Sequence\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Input, Concatenate, Dropout,BatchNormalization\n",
        "from keras.layers import Add\n",
        "import keras.backend as K\n",
        "class DAESequence(Sequence):\n",
        "    def __init__(self,df,batch_size):\n",
        "        self.batch_size=batch_size\n",
        "        self.len_data=df.shape[0]\n",
        "        self.columns=df.shape[1]\n",
        "        self.data=df.values\n",
        "        self.idx=[]\n",
        "    def __len__(self):\n",
        "        return int(ceil(self.len_data/self.batch_size))\n",
        "    def __getitem__(self,idx):\n",
        "        self.idx.append(idx)\n",
        "        last=min((idx+1)*self.batch_size,self.len_data)\n",
        "        idx=idx*self.batch_size\n",
        "        size=last-idx\n",
        "        output_x=self.data[idx:last]\n",
        "        length=last-idx\n",
        "        rnd=np.random.randint(0,self.len_data-size,size)\n",
        "        rnd[rnd>idx]+=size\n",
        "        cols=np.random.randint(0,self.columns,int(self.columns*0.1))\n",
        "        noise_x=output_x.copy()\n",
        "        noise_x[:,cols]=self.data[rnd[:,None],cols]\n",
        "        return noise_x,output_x\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class WarmUpLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Warmup learning rate scheduler\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup_batches, init_lr, verbose=0):\n",
        "        \"\"\"Constructor for warmup learning rate scheduler\n",
        "\n",
        "        Arguments:\n",
        "            warmup_batches {int} -- Number of batch for warmup.\n",
        "            init_lr {float} -- Learning rate after warmup.\n",
        "\n",
        "        Keyword Arguments:\n",
        "            verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
        "        \"\"\"\n",
        "\n",
        "        super(WarmUpLearningRateScheduler, self).__init__()\n",
        "        self.warmup_batches = warmup_batches\n",
        "        self.init_lr = init_lr\n",
        "        self.verbose = verbose\n",
        "        self.batch_count = 0\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.batch_count = self.batch_count + 1\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        if self.batch_count <= self.warmup_batches:\n",
        "            lr = self.batch_count*self.init_lr/self.warmup_batches\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "            if self.verbose > 0:\n",
        "                print('\\nBatch %05d: WarmUpLearningRateScheduler setting learning '\n",
        "                      'rate to %s.' % (self.batch_count + 1, lr))\n",
        "warm_up_lr = WarmUpLearningRateScheduler(400, init_lr=0.005)\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
        "from keras.layers import BatchNormalization\n",
        "#fnl=pd.concat([fnl_trn,fnl_tst],0).select_dtypes(exclude='uint8')\n",
        "batch_size=1024\n",
        "checkpoint_path = \"training_1.hdf5\" \n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback =ModelCheckpoint(checkpoint_path, \n",
        "monitor='loss',save_best_only=True,save_weights_only=True,verbose=1)\n",
        "len_input_columns=fnl.shape[1]\n",
        "model_dae = Sequential()\n",
        "model_dae.add(Dense(units=len_input_columns,input_shape=(len_input_columns,), activation='relu', dtype='float32', name='Input'))\n",
        "model_dae.add(Dense(units=int(512), activation='relu', dtype='float32',name='Hidden_1'))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(256), activation='relu', dtype='float32',name='Hidden_2'))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(512), activation='relu', dtype='float32',name='Hidden_3'))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=len_input_columns, activation='linear', dtype='float32', name='Output'))\n",
        "model_dae.compile(loss='mean_squared_error',optimizer='adam')\n",
        "hist=model_dae.fit_generator(DAESequence(fnl, batch_size=2048),steps_per_epoch=int(ceil(fnl.shape[0]/batch_size)),epochs=10,workers=2,callbacks=[warm_up_lr])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1072/1072 [==============================] - 36s 33ms/step - loss: 0.0311\n",
            "Epoch 2/10\n",
            "1072/1072 [==============================] - 34s 32ms/step - loss: 0.0077\n",
            "Epoch 3/10\n",
            "1072/1072 [==============================] - 34s 31ms/step - loss: 0.0064\n",
            "Epoch 4/10\n",
            "1072/1072 [==============================] - 34s 31ms/step - loss: 0.0057\n",
            "Epoch 5/10\n",
            "1072/1072 [==============================] - 34s 31ms/step - loss: 0.0054\n",
            "Epoch 6/10\n",
            "1072/1072 [==============================] - 33s 31ms/step - loss: 0.0052\n",
            "Epoch 7/10\n",
            "1072/1072 [==============================] - 33s 31ms/step - loss: 0.0051\n",
            "Epoch 8/10\n",
            "1072/1072 [==============================] - 33s 31ms/step - loss: 0.0051\n",
            "Epoch 9/10\n",
            "1072/1072 [==============================] - 33s 31ms/step - loss: 0.0049\n",
            "Epoch 10/10\n",
            "1072/1072 [==============================] - 33s 31ms/step - loss: 0.0049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKwkqfC14s5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/autoenc_final.hdf5\" \n",
        "model_dae.save_weights(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLNPKXhM4uQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}