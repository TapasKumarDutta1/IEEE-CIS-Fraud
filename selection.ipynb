{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "selection.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1WaTbfMSjVJ0Ihk-OgILb_saSn5TePIOp",
      "authorship_tag": "ABX9TyPZtw0n2rYplVoNWUKAJ14Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZqgbAq6ZrDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "12a5d08d-014f-49b1-8afd-a70c011dd353"
      },
      "source": [
        "pip install tensorflow==2.1.0-rc0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0-rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/fd/7528e5ef327abde9b7425aea24198d8b139795c1233d1658c1279055d860/tensorflow-2.1.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (402.3MB)\n",
            "\u001b[K     |████████████████████████████████| 402.3MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (3.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.12.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.24.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.18.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (3.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0-rc0) (2.8.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 2.1.0rc0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97f8LseKZ6Fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "49c89570-df53-4f9c-9979-a83ef97040d6"
      },
      "source": [
        "pip install keras==2.3.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 24.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.8.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm2QkslVZ6Id",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "686ff544-36ec-49a1-a024-b65ff46e3e47"
      },
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmA39xoZZ6LW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f41cdcff-1e12-4ccb-d7f8-16ad837664a5"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 79.2MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 106MB/s]\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 218MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 79% 46.0M/58.3M [00:00<00:00, 31.3MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 70.6MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 63% 33.0M/52.2M [00:01<00:01, 18.8MB/s]\n",
            "100% 52.2M/52.2M [00:01<00:00, 49.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afbLtarxcWOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a729b1cb-1ef3-45f7-93f0-8de441e5b9df"
      },
      "source": [
        "pip install category_encoders"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.25.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3I7S-D3eGs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhObntc6Z6RQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7384cc0e-c63d-4dcb-cf2b-09dd0079fd67"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "trn_trans=pd.read_csv('train_identity.csv.zip')\n",
        "trn=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_trans=pd.read_csv('test_identity.csv.zip')\n",
        "tst=pd.read_csv('test_transaction.csv.zip')\n",
        "fnl_trn=trn.merge(trn_trans,on='TransactionID',how='left')\n",
        "fnl_tst=tst.merge(tst_trans,on='TransactionID',how='left')\n",
        "dk={}\n",
        "for i in range(1,39):\n",
        "    if i<10:\n",
        "        dk['id-0'+str(i)]='id_0'+str(i)\n",
        "    else:\n",
        "        dk['id-'+str(i)]='id_'+str(i)\n",
        "fnl_tst=fnl_tst.rename(columns=dk)\n",
        "import gc\n",
        "del([trn_trans,trn,tst_trans,tst])\n",
        "gc.collect()\n",
        "fnl=pd.concat([fnl_trn,fnl_tst],0)\n",
        "del([fnl_trn,fnl_tst])\n",
        "gc.collect()\n",
        "ids=list(fnl.filter(regex='id_'))\n",
        "fnl[ids]=fnl[ids].fillna(-1)\n",
        "fnl[['addr1','addr2']]=fnl[['addr1','addr2']].fillna(-1)\n",
        "ids=list(fnl.filter(regex='card'))\n",
        "fnl[ids]=fnl[ids].fillna(-1)\n",
        "ids=list(fnl.filter(regex='V'))\n",
        "fnl[ids]=fnl[ids].fillna(-1)\n",
        "fnl[['addr1','addr2','DeviceInfo','DeviceType','P_emaildomain','R_emaildomain']]=fnl[['addr1','addr2','DeviceInfo','DeviceType','P_emaildomain','R_emaildomain']].fillna('nan')\n",
        "ids=list(fnl.filter(regex='D'))\n",
        "fnl[ids]=fnl[ids].fillna(-1)\n",
        "ids=list(fnl.filter(regex='C'))\n",
        "fnl[ids]=fnl[ids].fillna(0)\n",
        "ids=list(fnl.filter(regex='M'))\n",
        "fnl[ids]=fnl[ids].fillna(-1)\n",
        "fnl[['dist1','dist2']]=fnl[['dist1','dist2']].fillna(-1)\n",
        "import re\n",
        "def number(data):\n",
        "  try:\n",
        "      return  ' '.join(re.findall(r'\\d+',data)) \n",
        "  except:\n",
        "    return -1\n",
        "def charac(data):\n",
        "    try:\n",
        "      return ''.join(re.findall(\"[a-zA-Z]+\", data))\n",
        "    except:\n",
        "        return -1\n",
        "fnl['DeviceInfo_char']=list(map(charac,fnl['DeviceInfo'].fillna('nan')))\n",
        "fnl['DeviceInfo_number']=list(map(number,fnl['DeviceInfo'].fillna('nan')))\n",
        "\n",
        "\n",
        "fnl['DeviceType_char']=list(map(charac,fnl['DeviceType'].fillna('nan')))\n",
        "fnl['DeviceType_number']=list(map(number,fnl['DeviceType'].fillna('nan')))\n",
        "\n",
        "\n",
        "fnl['os_char']=list(map(charac,fnl['id_30'].fillna('nan')))\n",
        "fnl['os_number']=list(map(number,fnl['id_30'].fillna('nan')))\n",
        "\n",
        "\n",
        "fnl['browse_char']=list(map(charac,fnl['id_31'].fillna('nan')))\n",
        "fnl['browse_number']=list(map(number,fnl['id_31'].fillna('nan')))\n",
        "\n",
        "\n",
        "fnl['P_1']=fnl['P_emaildomain'].str.split('.').str[0]\n",
        "fnl['P_2']=fnl['P_emaildomain'].str.split('.').str[1]\n",
        "\n",
        "\n",
        "fnl['R_1']=fnl['R_emaildomain'].str.split('.').str[0]\n",
        "fnl['R_2']=fnl['R_emaildomain'].str.split('.').str[1]\n",
        "z=fnl.loc[~(fnl['isFraud'].isna())]\n",
        "from tqdm import tqdm\n",
        "from category_encoders.cat_boost import CatBoostEncoder\n",
        "cols=list(fnl.select_dtypes(include=object))\n",
        "for col in tqdm(cols):\n",
        "    cbe=CatBoostEncoder(sigma=0.01)\n",
        "    cbe.fit(z[col],z['isFraud'])\n",
        "    fnl[col]=cbe.transform(fnl[col],fnl['isFraud'])\n",
        "del(z)\n",
        "gc.collect()\n",
        "fnl.select_dtypes(include=object)\n",
        "# used=['card'+str(i) for i in range(1,7)]\n",
        "# used+=['C'+str(i) for i in range(1,15)]\n",
        "# used+=['D'+str(i) for i in range(1,16)]\n",
        "#fnl[used]=fnl[used].fillna(0)\n",
        "fnl['day']=fnl['TransactionDT']//86400\n",
        "fnl['month']=fnl['day']//30\n",
        "fnl['week']=fnl['day']//7\n",
        "# fnl[used]=fnl[used].fillna('nan')\n",
        "# cats=['ProductCD','DeviceInfo_char','DeviceInfo_number','DeviceType_char','DeviceType_number','os_char','os_number','browse_char','browse_number','P_1','P_2','addr1']\n",
        "# num=fnl\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        df[col]=df[col].fillna(-1)\n",
        "        df[col]=df[col].replace([np.inf,-np.inf],-1)\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "fnl=fnl.drop(['isFraud'],1)\n",
        "fnl=reduce_mem_usage(fnl)\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "ss=StandardScaler()\n",
        "fnl=pd.DataFrame(ss.fit_transform(fnl))\n",
        "mms=MinMaxScaler()\n",
        "fnl=pd.DataFrame(ss.fit_transform(fnl))\n",
        "fnl=reduce_mem_usage(fnl)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "100%|██████████| 43/43 [01:04<00:00,  1.49s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 3798.67 MB\n",
            "Memory usage after optimization is: 1098.96 MB\n",
            "Decreased by 71.1%\n",
            "Memory usage of dataframe is 3750.30 MB\n",
            "Memory usage after optimization is: 937.58 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TardrSoReIwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WOBhYb6aI7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import os\n",
        "gc.collect()\n",
        "import numpy as np\n",
        "import keras \n",
        "from math import ceil\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import Sequence\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Input, Concatenate, Dropout,BatchNormalization\n",
        "from keras.layers import Add\n",
        "import keras.backend as K\n",
        "class DAESequence(Sequence):\n",
        "    def __init__(self,df,batch_size):\n",
        "        self.batch_size=batch_size\n",
        "        self.len_data=df.shape[0]\n",
        "        self.columns=df.shape[1]\n",
        "        self.data=df.values\n",
        "        self.idx=[]\n",
        "    def __len__(self):\n",
        "        return int(ceil(self.len_data/self.batch_size))\n",
        "    def __getitem__(self,idx):\n",
        "        self.idx.append(idx)\n",
        "        last=min((idx+1)*self.batch_size,self.len_data)\n",
        "        idx=idx*self.batch_size\n",
        "        size=last-idx\n",
        "        output_x=self.data[idx:last]\n",
        "        length=last-idx\n",
        "        rnd=np.random.randint(0,self.len_data-size,size)\n",
        "        rnd[rnd>idx]+=size\n",
        "        cols=np.random.randint(0,self.columns,int(self.columns*0.1))\n",
        "        noise_x=output_x.copy()\n",
        "        noise_x[:,cols]=self.data[rnd[:,None],cols]\n",
        "        return noise_x,output_x\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
        "from keras.layers import BatchNormalization\n",
        "#fnl=pd.concat([fnl_trn,fnl_tst],0).select_dtypes(exclude='uint8')\n",
        "batch_size=1024\n",
        "checkpoint_path = \"training_1.hdf5\" \n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback =ModelCheckpoint(checkpoint_path, \n",
        "monitor='loss',save_best_only=True,save_weights_only=True,verbose=1)\n",
        "len_input_columns=fnl.shape[1]\n",
        "kernel_initializer_1=keras.initializers.RandomNormal(mean=-4.74564e-04, stddev=0.031814238148788886, seed=None)\n",
        "kernel_initializer_0=keras.initializers.RandomNormal(mean=-4.74564e-04, stddev=0.04499212706658476, seed=None)\n",
        "kernel_initializer_2=keras.initializers.RandomNormal(mean=-4.74564e-04, stddev=0.031814238148788886, seed=None)\n",
        "model_dae = Sequential()\n",
        "model_dae.add(Dense(units=len_input_columns,input_shape=(len_input_columns,), activation='relu', dtype='float32', name='Input'))\n",
        "model_dae.add(Dense(units=int(300), activation='relu', dtype='float32',name='Hidden_1', kernel_initializer=kernel_initializer_0))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(200), activation='relu', dtype='float32',name='Hidden_2', kernel_initializer=kernel_initializer_1))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(100), activation='relu', dtype='float32',name='Hidden_3', kernel_initializer=kernel_initializer_2))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(25), activation='relu', dtype='float32',name='Hidden_4', kernel_initializer=kernel_initializer_2))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(2), activation='relu', dtype='float32',name='Hidden_5', kernel_initializer=kernel_initializer_2))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(25), activation='relu', dtype='float32',name='Hidden_6', kernel_initializer=kernel_initializer_2))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(100), activation='relu', dtype='float32',name='Hidden_7', kernel_initializer=kernel_initializer_2))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(200), activation='relu', dtype='float32',name='Hidden_8', kernel_initializer=kernel_initializer_2))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=int(300), activation='relu', dtype='float32',name='Hidden_9', kernel_initializer=kernel_initializer_2))\n",
        "model_dae.add(BatchNormalization())\n",
        "model_dae.add(Dense(units=len_input_columns, activation='linear', dtype='float32', name='Output'))\n",
        "model_opt = keras.optimizers.SGD(lr=0.001, decay=1-0.9, momentum=0.7, nesterov=False)\n",
        "model_dae.compile(loss='mean_squared_error',optimizer=model_opt)\n",
        "model_dae.load_weights('autoenc.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbYmRY6TaMUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "e9a69204-346c-43f9-d718-fa5388681bdc"
      },
      "source": [
        "from tqdm import tqdm\n",
        "your_new_df=pd.DataFrame()\n",
        "for i in tqdm(['3','4','5','6','7']):\n",
        "    print('Hidden layer',i)\n",
        "    columns_names = ['Hidden_'+str(i)+'_'+str(l) for l in range(0, len_input_columns)]\n",
        "    intermediate_layer_model = Model(inputs=model_dae.input, outputs=model_dae.get_layer('Hidden_' + i).output)\n",
        "    z = pd.DataFrame(intermediate_layer_model.predict(fnl))\n",
        "    columns_names = ['Hidden_'+str(i)+'_'+str(l) for l in range(0, z.shape[1])]\n",
        "    z.columns=columns_names\n",
        "    your_new_df=pd.concat([your_new_df,z],1)\n",
        "your_new_df=reduce_mem_usage(your_new_df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hidden layer 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 1/5 [00:50<03:20, 50.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hidden layer 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [01:38<02:29, 49.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hidden layer 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [02:30<01:40, 50.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hidden layer 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [03:21<00:50, 50.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hidden layer 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [04:16<00:00, 51.33s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1054.77 MB\n",
            "Memory usage after optimization is: 527.39 MB\n",
            "Decreased by 50.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzjn7alsaMXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "path = F\"/content/gdrive/My Drive/autoenc.csv\" \n",
        "your_new_df.to_csv(path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wC44su0aMaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko4QdlebaMdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}