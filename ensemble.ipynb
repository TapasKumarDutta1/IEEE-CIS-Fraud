{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Hidden_7_22', 'Hidden_7_32', 'Hidden_7_96', 'Hidden_7_8',\n",
    "       'Hidden_3_85', 'Hidden_7_9', 'Hidden_4_5', 'Hidden_3_52',\n",
    "       'Hidden_3_64', 'Hidden_3_63', 'Hidden_7_11', 'Hidden_7_33',\n",
    "       'Hidden_3_28', 'Hidden_7_69', 'Hidden_7_2', 'Hidden_7_92',\n",
    "       'Hidden_7_23', 'Hidden_3_99', 'Hidden_7_28', 'Hidden_3_47',\n",
    "       'Hidden_3_88', 'Hidden_7_0', 'Hidden_7_34', 'Hidden_3_76',\n",
    "       'Hidden_7_31', 'Hidden_7_64', 'Hidden_7_72', 'Hidden_7_70',\n",
    "       'Hidden_7_10', 'Hidden_3_3', 'Hidden_4_13', 'Hidden_7_68',\n",
    "       'Hidden_7_50', 'Hidden_7_57', 'Hidden_7_67', 'Hidden_7_36',\n",
    "       'Hidden_3_6', 'Hidden_7_12', 'Hidden_7_91', 'Hidden_7_39',\n",
    "       'Hidden_6_1', 'Hidden_3_95', 'Hidden_3_40', 'Hidden_7_83',\n",
    "       'Hidden_7_29', 'Hidden_6_19', 'Hidden_4_10', 'Hidden_6_5',\n",
    "       'Hidden_3_70', 'Hidden_3_86', 'Hidden_3_48', 'Hidden_3_30',\n",
    "       'Hidden_7_7', 'Hidden_7_78', 'Hidden_6_10', 'Hidden_7_54',\n",
    "       'Hidden_3_13', 'Hidden_7_46', 'Hidden_7_21', 'Hidden_6_3',\n",
    "       'Hidden_7_73', 'Hidden_6_16', 'Hidden_3_9', 'Hidden_6_22',\n",
    "       'Hidden_7_48', 'Hidden_7_66', 'Hidden_7_45', 'Hidden_6_8',\n",
    "       'Hidden_7_84', 'Hidden_3_5', 'Hidden_7_18', 'Hidden_4_6',\n",
    "       'Hidden_7_38', 'Hidden_6_6', 'Hidden_3_32', 'Hidden_3_83',\n",
    "       'Hidden_7_14', 'Hidden_7_27', 'Hidden_5_0', 'Hidden_3_50',\n",
    "       'Hidden_4_3', 'Hidden_7_65', 'Hidden_3_35', 'Hidden_7_56',\n",
    "       'Hidden_3_33', 'Hidden_4_21', 'Hidden_3_77', 'Hidden_4_17',\n",
    "       'Hidden_3_68', 'Hidden_3_82', 'Hidden_3_4', 'Hidden_3_75',\n",
    "       'Hidden_3_20', 'Hidden_3_27', 'Hidden_3_66', 'Hidden_3_37',\n",
    "       'Hidden_3_71', 'Hidden_3_89', 'Hidden_3_53', 'Hidden_3_46']\n",
    "selected=pd.read_csv('/kaggle/input/selection-0-3/extra_features.csv',usecols=cols)\n",
    "selected=selected.astype('float16')\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype={'C1': 'float16',\n",
    " 'C10': 'float16',\n",
    " 'C11': 'float16',\n",
    " 'C12': 'float16',\n",
    " 'C13': 'float16',\n",
    " 'C14': 'float16',\n",
    " 'C2': 'float16',\n",
    " 'C3': 'float16',\n",
    " 'C4': 'float16',\n",
    " 'C5': 'float16',\n",
    " 'C6': 'float16',\n",
    " 'C7': 'float16',\n",
    " 'C8': 'float16',\n",
    " 'C9': 'float16',\n",
    " 'D1': 'float16',\n",
    " 'D10': 'float16',\n",
    " 'D11': 'float16',\n",
    " 'D12': 'float16',\n",
    " 'D13': 'float16',\n",
    " 'D14': 'float16',\n",
    " 'D15': 'float16',\n",
    " 'D2': 'float16',\n",
    " 'D3': 'float16',\n",
    " 'D4': 'float16',\n",
    " 'D5': 'float16',\n",
    " 'D6': 'float16',\n",
    " 'D7': 'float16',\n",
    " 'D8': 'float16',\n",
    " 'D9': 'float16',\n",
    " 'TransactionAmt': 'float16',\n",
    " 'dist1': 'float16',\n",
    " 'dist2': 'float16',\n",
    " 'days': 'float16',\n",
    " 'TransactionAmt_mean': 'float16',\n",
    " 'TransactionAmt_std': 'float16',\n",
    " 'dist1_mean': 'float16',\n",
    " 'dist1_std': 'float16',\n",
    " 'dist2_mean': 'float16',\n",
    " 'dist2_std': 'float16',\n",
    " 'C1_mean': 'float16',\n",
    " 'C1_std': 'float16',\n",
    " 'C2_mean': 'float16',\n",
    " 'C2_std': 'float16',\n",
    " 'C3_mean': 'float16',\n",
    " 'C3_std': 'float16',\n",
    " 'C4_mean': 'float16',\n",
    " 'C4_std': 'float16',\n",
    " 'C5_mean': 'float16',\n",
    " 'C5_std': 'float16',\n",
    " 'C6_mean': 'float16',\n",
    " 'C6_std': 'float16',\n",
    " 'C7_mean': 'float16',\n",
    " 'C7_std': 'float16',\n",
    " 'C8_mean': 'float16',\n",
    " 'C8_std': 'float16',\n",
    " 'C9_mean': 'float16',\n",
    " 'C9_std': 'float16',\n",
    " 'C10_mean': 'float16',\n",
    " 'C10_std': 'float16',\n",
    " 'C11_mean': 'float16',\n",
    " 'C11_std': 'float16',\n",
    " 'C12_mean': 'float16',\n",
    " 'C12_std': 'float16',\n",
    " 'C13_mean': 'float16',\n",
    " 'C13_std': 'float16',\n",
    " 'C14_mean': 'float16',\n",
    " 'C14_std': 'float16',\n",
    " 'D1_mean': 'float16',\n",
    " 'D1_std': 'float16',\n",
    " 'D2_mean': 'float16',\n",
    " 'D2_std': 'float16',\n",
    " 'D3_mean': 'float16',\n",
    " 'D3_std': 'float16',\n",
    " 'D4_mean': 'float16',\n",
    " 'D4_std': 'float16',\n",
    " 'D5_mean': 'float16',\n",
    " 'D5_std': 'float16',\n",
    " 'D6_mean': 'float16',\n",
    " 'D6_std': 'float16',\n",
    " 'D7_mean': 'float16',\n",
    " 'D7_std': 'float16',\n",
    " 'D8_mean': 'float16',\n",
    " 'D8_std': 'float16',\n",
    " 'D9_mean': 'float16',\n",
    " 'D9_std': 'float16',\n",
    " 'D10_mean': 'float16',\n",
    " 'D10_std': 'float16',\n",
    " 'D11_mean': 'float16',\n",
    " 'D11_std': 'float16',\n",
    " 'D12_mean': 'float16',\n",
    " 'D12_std': 'float16',\n",
    " 'D13_mean': 'float16',\n",
    " 'D13_std': 'float16',\n",
    " 'D14_mean': 'float16',\n",
    " 'D14_std': 'float16',\n",
    " 'D15_mean': 'float16',\n",
    " 'D15_std': 'float16',\n",
    " 'week': 'int8',\n",
    " 'month': 'int8',\n",
    " 'is_train': 'int8',\n",
    " 'isFraud': 'float16',\n",
    " 'ProductCDC_dum': 'int8',\n",
    " 'ProductCDH_dum': 'int8',\n",
    " 'ProductCDR_dum': 'int8',\n",
    " 'ProductCDS_dum': 'int8',\n",
    " 'ProductCDW_dum': 'int8',\n",
    " 'card17919_dum': 'int8',\n",
    " 'card19500_dum': 'int8',\n",
    " 'card115066_dum': 'int8',\n",
    " 'card115885_dum': 'int8',\n",
    " 'card117188_dum': 'int8',\n",
    " 'card1other_dum': 'int8',\n",
    " 'card2111_0_dum': 'int8',\n",
    " 'card2321_0_dum': 'int8',\n",
    " 'card2490_0_dum': 'int8',\n",
    " 'card2555_0_dum': 'int8',\n",
    " 'card2583_0_dum': 'int8',\n",
    " 'card2other_dum': 'int8',\n",
    " 'card3106_0_dum': 'int8',\n",
    " 'card3117_0_dum': 'int8',\n",
    " 'card3150_0_dum': 'int8',\n",
    " 'card3185_0_dum': 'int8',\n",
    " 'card3nan_dum': 'int8',\n",
    " 'card3other_dum': 'int8',\n",
    " 'card4american_express_dum': 'int8',\n",
    " 'card4discover_dum': 'int8',\n",
    " 'card4mastercard_dum': 'int8',\n",
    " 'card4nan_dum': 'int8',\n",
    " 'card4visa_dum': 'int8',\n",
    " 'card5102_0_dum': 'int8',\n",
    " 'card5117_0_dum': 'int8',\n",
    " 'card5166_0_dum': 'int8',\n",
    " 'card5224_0_dum': 'int8',\n",
    " 'card5226_0_dum': 'int8',\n",
    " 'card5other_dum': 'int8',\n",
    " 'card6charge_card_dum': 'int8',\n",
    " 'card6credit_dum': 'int8',\n",
    " 'card6debit_dum': 'int8',\n",
    " 'card6debit_or_credit_dum': 'int8',\n",
    " 'card6nan_dum': 'int8',\n",
    " 'addr1204_0_dum': 'int8',\n",
    " 'addr1264_0_dum': 'int8',\n",
    " 'addr1299_0_dum': 'int8',\n",
    " 'addr1325_0_dum': 'int8',\n",
    " 'addr1nan_dum': 'int8',\n",
    " 'addr1other_dum': 'int8',\n",
    " 'addr232_0_dum': 'int8',\n",
    " 'addr260_0_dum': 'int8',\n",
    " 'addr287_0_dum': 'int8',\n",
    " 'addr296_0_dum': 'int8',\n",
    " 'addr2nan_dum': 'int8',\n",
    " 'addr2other_dum': 'int8',\n",
    " 'P_emaildomainanonymous_com_dum': 'int8',\n",
    " 'P_emaildomaingmail_com_dum': 'int8',\n",
    " 'P_emaildomainhotmail_com_dum': 'int8',\n",
    " 'P_emaildomainnan_dum': 'int8',\n",
    " 'P_emaildomainother_dum': 'int8',\n",
    " 'P_emaildomainyahoo_com_dum': 'int8',\n",
    " 'R_emaildomainanonymous_com_dum': 'int8',\n",
    " 'R_emaildomaingmail_com_dum': 'int8',\n",
    " 'R_emaildomainhotmail_com_dum': 'int8',\n",
    " 'R_emaildomainnan_dum': 'int8',\n",
    " 'R_emaildomainother_dum': 'int8',\n",
    " 'R_emaildomainyahoo_com_dum': 'int8',\n",
    " 'DeviceInfoMacOS_dum': 'int8',\n",
    " 'DeviceInfoTrident_7_0_dum': 'int8',\n",
    " 'DeviceInfoWindows_dum': 'int8',\n",
    " 'DeviceInfoiOS_Device_dum': 'int8',\n",
    " 'DeviceInfonan_dum': 'int8',\n",
    " 'DeviceInfoother_dum': 'int8',\n",
    " 'DeviceTypedesktop_dum': 'int8',\n",
    " 'DeviceTypemobile_dum': 'int8',\n",
    " 'DeviceTypenan_dum': 'int8',\n",
    " 'id_01_20_0_dum': 'int8',\n",
    " 'id_01_10_0_dum': 'int8',\n",
    " 'id_01_5_0_dum': 'int8',\n",
    " 'id_010_0_dum': 'int8',\n",
    " 'id_01nan_dum': 'int8',\n",
    " 'id_01other_dum': 'int8',\n",
    " 'id_02552_0_dum': 'int8',\n",
    " 'id_02696_0_dum': 'int8',\n",
    " 'id_021083_0_dum': 'int8',\n",
    " 'id_021120_0_dum': 'int8',\n",
    " 'id_02nan_dum': 'int8',\n",
    " 'id_02other_dum': 'int8',\n",
    " 'id_030_0_dum': 'int8',\n",
    " 'id_031_0_dum': 'int8',\n",
    " 'id_032_0_dum': 'int8',\n",
    " 'id_033_0_dum': 'int8',\n",
    " 'id_03nan_dum': 'int8',\n",
    " 'id_03other_dum': 'int8',\n",
    " 'id_04_9_0_dum': 'int8',\n",
    " 'id_04_6_0_dum': 'int8',\n",
    " 'id_04_5_0_dum': 'int8',\n",
    " 'id_040_0_dum': 'int8',\n",
    " 'id_04nan_dum': 'int8',\n",
    " 'id_04other_dum': 'int8',\n",
    " 'id_050_0_dum': 'int8',\n",
    " 'id_051_0_dum': 'int8',\n",
    " 'id_052_0_dum': 'int8',\n",
    " 'id_053_0_dum': 'int8',\n",
    " 'id_05nan_dum': 'int8',\n",
    " 'id_05other_dum': 'int8',\n",
    " 'id_06_6_0_dum': 'int8',\n",
    " 'id_06_5_0_dum': 'int8',\n",
    " 'id_06_1_0_dum': 'int8',\n",
    " 'id_060_0_dum': 'int8',\n",
    " 'id_06nan_dum': 'int8',\n",
    " 'id_06other_dum': 'int8',\n",
    " 'id_070_0_dum': 'int8',\n",
    " 'id_0712_0_dum': 'int8',\n",
    " 'id_0714_0_dum': 'int8',\n",
    " 'id_0716_0_dum': 'int8',\n",
    " 'id_07nan_dum': 'int8',\n",
    " 'id_07other_dum': 'int8',\n",
    " 'id_08_100_0_dum': 'int8',\n",
    " 'id_08_34_0_dum': 'int8',\n",
    " 'id_08_33_0_dum': 'int8',\n",
    " 'id_080_0_dum': 'int8',\n",
    " 'id_08nan_dum': 'int8',\n",
    " 'id_08other_dum': 'int8',\n",
    " 'id_090_0_dum': 'int8',\n",
    " 'id_091_0_dum': 'int8',\n",
    " 'id_092_0_dum': 'int8',\n",
    " 'id_093_0_dum': 'int8',\n",
    " 'id_09nan_dum': 'int8',\n",
    " 'id_09other_dum': 'int8',\n",
    " 'id_10_6_0_dum': 'int8',\n",
    " 'id_10_5_0_dum': 'int8',\n",
    " 'id_10_1_0_dum': 'int8',\n",
    " 'id_100_0_dum': 'int8',\n",
    " 'id_10nan_dum': 'int8',\n",
    " 'id_10other_dum': 'int8',\n",
    " 'id_1195_08000183105469_dum': 'int8',\n",
    " 'id_1195_16000366210938_dum': 'int8',\n",
    " 'id_1197_12000274658205_dum': 'int8',\n",
    " 'id_11100_0_dum': 'int8',\n",
    " 'id_11nan_dum': 'int8',\n",
    " 'id_11other_dum': 'int8',\n",
    " 'id_12Found_dum': 'int8',\n",
    " 'id_12NotFound_dum': 'int8',\n",
    " 'id_12nan_dum': 'int8',\n",
    " 'id_1327_0_dum': 'int8',\n",
    " 'id_1349_0_dum': 'int8',\n",
    " 'id_1352_0_dum': 'int8',\n",
    " 'id_1364_0_dum': 'int8',\n",
    " 'id_13nan_dum': 'int8',\n",
    " 'id_13other_dum': 'int8',\n",
    " 'id_14_480_0_dum': 'int8',\n",
    " 'id_14_420_0_dum': 'int8',\n",
    " 'id_14_360_0_dum': 'int8',\n",
    " 'id_14_300_0_dum': 'int8',\n",
    " 'id_14nan_dum': 'int8',\n",
    " 'id_14other_dum': 'int8',\n",
    " 'id_15Found_dum': 'int8',\n",
    " 'id_15New_dum': 'int8',\n",
    " 'id_15Unknown_dum': 'int8',\n",
    " 'id_15nan_dum': 'int8',\n",
    " 'id_16Found_dum': 'int8',\n",
    " 'id_16NotFound_dum': 'int8',\n",
    " 'id_16nan_dum': 'int8',\n",
    " 'id_17102_0_dum': 'int8',\n",
    " 'id_17159_0_dum': 'int8',\n",
    " 'id_17166_0_dum': 'int8',\n",
    " 'id_17225_0_dum': 'int8',\n",
    " 'id_17nan_dum': 'int8',\n",
    " 'id_17other_dum': 'int8',\n",
    " 'id_1812_0_dum': 'int8',\n",
    " 'id_1813_0_dum': 'int8',\n",
    " 'id_1815_0_dum': 'int8',\n",
    " 'id_1817_0_dum': 'int8',\n",
    " 'id_18nan_dum': 'int8',\n",
    " 'id_18other_dum': 'int8',\n",
    " 'id_19266_0_dum': 'int8',\n",
    " 'id_19410_0_dum': 'int8',\n",
    " 'id_19427_0_dum': 'int8',\n",
    " 'id_19529_0_dum': 'int8',\n",
    " 'id_19nan_dum': 'int8',\n",
    " 'id_19other_dum': 'int8',\n",
    " 'id_20222_0_dum': 'int8',\n",
    " 'id_20325_0_dum': 'int8',\n",
    " 'id_20507_0_dum': 'int8',\n",
    " 'id_20533_0_dum': 'int8',\n",
    " 'id_20nan_dum': 'int8',\n",
    " 'id_20other_dum': 'int8',\n",
    " 'id_21228_0_dum': 'int8',\n",
    " 'id_21252_0_dum': 'int8',\n",
    " 'id_21576_0_dum': 'int8',\n",
    " 'id_21711_0_dum': 'int8',\n",
    " 'id_21nan_dum': 'int8',\n",
    " 'id_21other_dum': 'int8',\n",
    " 'id_2214_0_dum': 'int8',\n",
    " 'id_2233_0_dum': 'int8',\n",
    " 'id_2241_0_dum': 'int8',\n",
    " 'id_2243_0_dum': 'int8',\n",
    " 'id_22nan_dum': 'int8',\n",
    " 'id_22other_dum': 'int8',\n",
    " 'id_23IP_PROXY_ANONYMOUS_dum': 'int8',\n",
    " 'id_23IP_PROXY_HIDDEN_dum': 'int8',\n",
    " 'id_23IP_PROXY_TRANSPARENT_dum': 'int8',\n",
    " 'id_23nan_dum': 'int8',\n",
    " 'id_2411_0_dum': 'int8',\n",
    " 'id_2415_0_dum': 'int8',\n",
    " 'id_2416_0_dum': 'int8',\n",
    " 'id_2421_0_dum': 'int8',\n",
    " 'id_24nan_dum': 'int8',\n",
    " 'id_24other_dum': 'int8',\n",
    " 'id_25205_0_dum': 'int8',\n",
    " 'id_25321_0_dum': 'int8',\n",
    " 'id_25426_0_dum': 'int8',\n",
    " 'id_25442_0_dum': 'int8',\n",
    " 'id_25nan_dum': 'int8',\n",
    " 'id_25other_dum': 'int8',\n",
    " 'id_26100_0_dum': 'int8',\n",
    " 'id_26142_0_dum': 'int8',\n",
    " 'id_26161_0_dum': 'int8',\n",
    " 'id_26184_0_dum': 'int8',\n",
    " 'id_26nan_dum': 'int8',\n",
    " 'id_26other_dum': 'int8',\n",
    " 'id_27Found_dum': 'int8',\n",
    " 'id_27NotFound_dum': 'int8',\n",
    " 'id_27nan_dum': 'int8',\n",
    " 'id_28Found_dum': 'int8',\n",
    " 'id_28New_dum': 'int8',\n",
    " 'id_28nan_dum': 'int8',\n",
    " 'id_29Found_dum': 'int8',\n",
    " 'id_29NotFound_dum': 'int8',\n",
    " 'id_29nan_dum': 'int8',\n",
    " 'id_30Mac_OS_X_10_12_6_dum': 'int8',\n",
    " 'id_30Windows_10_dum': 'int8',\n",
    " 'id_30Windows_7_dum': 'int8',\n",
    " 'id_30iOS_12_1_0_dum': 'int8',\n",
    " 'id_30nan_dum': 'int8',\n",
    " 'id_30other_dum': 'int8',\n",
    " 'id_31chrome_63_0_dum': 'int8',\n",
    " 'id_31chrome_70_0_dum': 'int8',\n",
    " 'id_31ie_11_0_for_desktop_dum': 'int8',\n",
    " 'id_31mobile_safari_11_0_dum': 'int8',\n",
    " 'id_31nan_dum': 'int8',\n",
    " 'id_31other_dum': 'int8',\n",
    " 'id_328_0_dum': 'int8',\n",
    " 'id_3216_0_dum': 'int8',\n",
    " 'id_3224_0_dum': 'int8',\n",
    " 'id_3232_0_dum': 'int8',\n",
    " 'id_32nan_dum': 'int8',\n",
    " 'id_32other_dum': 'int8',\n",
    " 'id_331334x750_dum': 'int8',\n",
    " 'id_331366x768_dum': 'int8',\n",
    " 'id_331920x1080_dum': 'int8',\n",
    " 'id_332208x1242_dum': 'int8',\n",
    " 'id_33nan_dum': 'int8',\n",
    " 'id_33other_dum': 'int8',\n",
    " 'id_34match_status__1_dum': 'int8',\n",
    " 'id_34match_status_0_dum': 'int8',\n",
    " 'id_34match_status_1_dum': 'int8',\n",
    " 'id_34match_status_2_dum': 'int8',\n",
    " 'id_34nan_dum': 'int8',\n",
    " 'id_35F_dum': 'int8',\n",
    " 'id_35T_dum': 'int8',\n",
    " 'id_35nan_dum': 'int8',\n",
    " 'id_36F_dum': 'int8',\n",
    " 'id_36T_dum': 'int8',\n",
    " 'id_36nan_dum': 'int8',\n",
    " 'id_37F_dum': 'int8',\n",
    " 'id_37T_dum': 'int8',\n",
    " 'id_37nan_dum': 'int8',\n",
    " 'id_38F_dum': 'int8',\n",
    " 'id_38T_dum': 'int8',\n",
    " 'id_38nan_dum': 'int8',\n",
    " 'M1F_dum': 'int8',\n",
    " 'M1T_dum': 'int8',\n",
    " 'M1nan_dum': 'int8',\n",
    " 'M2F_dum': 'int8',\n",
    " 'M2T_dum': 'int8',\n",
    " 'M2nan_dum': 'int8',\n",
    " 'M3F_dum': 'int8',\n",
    " 'M3T_dum': 'int8',\n",
    " 'M3nan_dum': 'int8',\n",
    " 'M4M0_dum': 'int8',\n",
    " 'M4M1_dum': 'int8',\n",
    " 'M4M2_dum': 'int8',\n",
    " 'M4nan_dum': 'int8',\n",
    " 'M5F_dum': 'int8',\n",
    " 'M5T_dum': 'int8',\n",
    " 'M5nan_dum': 'int8',\n",
    " 'M6F_dum': 'int8',\n",
    " 'M6T_dum': 'int8',\n",
    " 'M6nan_dum': 'int8',\n",
    " 'M7F_dum': 'int8',\n",
    " 'M7T_dum': 'int8',\n",
    " 'M7nan_dum': 'int8',\n",
    " 'M8F_dum': 'int8',\n",
    " 'M8T_dum': 'int8',\n",
    " 'M8nan_dum': 'int8',\n",
    " 'M9F_dum': 'int8',\n",
    " 'M9T_dum': 'int8',\n",
    " 'M9nan_dum': 'int8',\n",
    " 'TransactionAmt_day_ss': 'float16',\n",
    " 'TransactionAmt_day_norm': 'float16',\n",
    " 'dist1_day_ss': 'float16',\n",
    " 'dist1_day_norm': 'float16',\n",
    " 'dist2_day_ss': 'float16',\n",
    " 'dist2_day_norm': 'float16',\n",
    " 'C1_day_ss': 'float16',\n",
    " 'C1_day_norm': 'float16',\n",
    " 'C2_day_ss': 'float16',\n",
    " 'C2_day_norm': 'float16',\n",
    " 'C3_day_ss': 'float16',\n",
    " 'C3_day_norm': 'float16',\n",
    " 'C4_day_ss': 'float16',\n",
    " 'C4_day_norm': 'float16',\n",
    " 'C5_day_ss': 'float16',\n",
    " 'C5_day_norm': 'float16',\n",
    " 'C6_day_ss': 'float16',\n",
    " 'C6_day_norm': 'float16',\n",
    " 'C7_day_ss': 'float16',\n",
    " 'C7_day_norm': 'float16',\n",
    " 'C8_day_ss': 'float16',\n",
    " 'C8_day_norm': 'float16',\n",
    " 'C9_day_ss': 'float16',\n",
    " 'C9_day_norm': 'float32',\n",
    " 'C10_day_ss': 'float16',\n",
    " 'C10_day_norm': 'float16',\n",
    " 'C11_day_ss': 'float16',\n",
    " 'C11_day_norm': 'float16',\n",
    " 'C12_day_ss': 'float16',\n",
    " 'C12_day_norm': 'float16',\n",
    " 'C13_day_ss': 'float16',\n",
    " 'C13_day_norm': 'float16',\n",
    " 'C14_day_ss': 'float16',\n",
    " 'C14_day_norm': 'float16',\n",
    " 'D1_day_ss': 'float16',\n",
    " 'D1_day_norm': 'float16',\n",
    " 'D2_day_ss': 'float16',\n",
    " 'D2_day_norm': 'float16',\n",
    " 'D3_day_ss': 'float16',\n",
    " 'D3_day_norm': 'float16',\n",
    " 'D4_day_ss': 'float16',\n",
    " 'D4_day_norm': 'float16',\n",
    " 'D5_day_ss': 'float16',\n",
    " 'D5_day_norm': 'float16',\n",
    " 'D6_day_ss': 'float16',\n",
    " 'D6_day_norm': 'float16',\n",
    " 'D7_day_ss': 'float16',\n",
    " 'D7_day_norm': 'float16',\n",
    " 'D8_day_ss': 'float16',\n",
    " 'D8_day_norm': 'float16',\n",
    " 'D9_day_ss': 'float16',\n",
    " 'D9_day_norm': 'float16',\n",
    " 'D10_day_ss': 'float16',\n",
    " 'D10_day_norm': 'float16',\n",
    " 'D11_day_ss': 'float16',\n",
    " 'D11_day_norm': 'float16',\n",
    " 'D12_day_ss': 'float16',\n",
    " 'D12_day_norm': 'float16',\n",
    " 'D13_day_ss': 'float16',\n",
    " 'D13_day_norm': 'float16',\n",
    " 'D14_day_ss': 'float16',\n",
    " 'D14_day_norm': 'float16',\n",
    " 'D15_day_ss': 'float16',\n",
    " 'D15_day_norm': 'float16',\n",
    " 'TransactionAmt_month_ss': 'float16',\n",
    " 'TransactionAmt_month_norm': 'float16',\n",
    " 'dist1_month_ss': 'float16',\n",
    " 'dist1_month_norm': 'float16',\n",
    " 'dist2_month_ss': 'float16',\n",
    " 'dist2_month_norm': 'float16',\n",
    " 'C1_month_ss': 'float16',\n",
    " 'C1_month_norm': 'float16',\n",
    " 'C2_month_ss': 'float16',\n",
    " 'C2_month_norm': 'float16',\n",
    " 'C3_month_ss': 'float16',\n",
    " 'C3_month_norm': 'float16',\n",
    " 'C4_month_ss': 'float16',\n",
    " 'C4_month_norm': 'float16',\n",
    " 'C5_month_ss': 'float16',\n",
    " 'C5_month_norm': 'float16',\n",
    " 'C6_month_ss': 'float16',\n",
    " 'C6_month_norm': 'float16',\n",
    " 'C7_month_ss': 'float16',\n",
    " 'C7_month_norm': 'float16',\n",
    " 'C8_month_ss': 'float16',\n",
    " 'C8_month_norm': 'float16',\n",
    " 'C9_month_ss': 'float16',\n",
    " 'C9_month_norm': 'float16',\n",
    " 'C10_month_ss': 'float16',\n",
    " 'C10_month_norm': 'float16',\n",
    " 'C11_month_ss': 'float16',\n",
    " 'C11_month_norm': 'float16',\n",
    " 'C12_month_ss': 'float16',\n",
    " 'C12_month_norm': 'float16',\n",
    " 'C13_month_ss': 'float16',\n",
    " 'C13_month_norm': 'float16',\n",
    " 'C14_month_ss': 'float16',\n",
    " 'C14_month_norm': 'float16',\n",
    " 'D1_month_ss': 'float16',\n",
    " 'D1_month_norm': 'float16',\n",
    " 'D2_month_ss': 'float16',\n",
    " 'D2_month_norm': 'float16',\n",
    " 'D3_month_ss': 'float16',\n",
    " 'D3_month_norm': 'float16',\n",
    " 'D4_month_ss': 'float16',\n",
    " 'D4_month_norm': 'float16',\n",
    " 'D5_month_ss': 'float16',\n",
    " 'D5_month_norm': 'float16',\n",
    " 'D6_month_ss': 'float16',\n",
    " 'D6_month_norm': 'float16',\n",
    " 'D7_month_ss': 'float16',\n",
    " 'D7_month_norm': 'float16',\n",
    " 'D8_month_ss': 'float16',\n",
    " 'D8_month_norm': 'float16',\n",
    " 'D9_month_ss': 'float16',\n",
    " 'D9_month_norm': 'float16',\n",
    " 'D10_month_ss': 'float16',\n",
    " 'D10_month_norm': 'float16',\n",
    " 'D11_month_ss': 'float16',\n",
    " 'D11_month_norm': 'float16',\n",
    " 'D12_month_ss': 'float16',\n",
    " 'D12_month_norm': 'float16',\n",
    " 'D13_month_ss': 'float16',\n",
    " 'D13_month_norm': 'float16',\n",
    " 'D14_month_ss': 'float16',\n",
    " 'D14_month_norm': 'float16',\n",
    " 'D15_month_ss': 'float16',\n",
    " 'D15_month_norm': 'float16',\n",
    " 'TransactionAmt_week_ss': 'float16',\n",
    " 'TransactionAmt_week_norm': 'float16',\n",
    " 'dist1_week_ss': 'float16',\n",
    " 'dist1_week_norm': 'float16',\n",
    " 'dist2_week_ss': 'float16',\n",
    " 'dist2_week_norm': 'float16',\n",
    " 'C1_week_ss': 'float16',\n",
    " 'C1_week_norm': 'float16',\n",
    " 'C2_week_ss': 'float16',\n",
    " 'C2_week_norm': 'float16',\n",
    " 'C3_week_ss': 'float16',\n",
    " 'C3_week_norm': 'float16',\n",
    " 'C4_week_ss': 'float16',\n",
    " 'C4_week_norm': 'float16',\n",
    " 'C5_week_ss': 'float16',\n",
    " 'C5_week_norm': 'float16',\n",
    " 'C6_week_ss': 'float16',\n",
    " 'C6_week_norm': 'float16',\n",
    " 'C7_week_ss': 'float16',\n",
    " 'C7_week_norm': 'float16',\n",
    " 'C8_week_ss': 'float16',\n",
    " 'C8_week_norm': 'float16',\n",
    " 'C9_week_ss': 'float16',\n",
    " 'C9_week_norm': 'float16',\n",
    " 'C10_week_ss': 'float16',\n",
    " 'C10_week_norm': 'float16',\n",
    " 'C11_week_ss': 'float16',\n",
    " 'C11_week_norm': 'float16',\n",
    " 'C12_week_ss': 'float16',\n",
    " 'C12_week_norm': 'float16',\n",
    " 'C13_week_ss': 'float16',\n",
    " 'C13_week_norm': 'float16',\n",
    " 'C14_week_ss': 'float16',\n",
    " 'C14_week_norm': 'float16',\n",
    " 'D1_week_ss': 'float16',\n",
    " 'D1_week_norm': 'float16',\n",
    " 'D2_week_ss': 'float16',\n",
    " 'D2_week_norm': 'float16',\n",
    " 'D3_week_ss': 'float16',\n",
    " 'D3_week_norm': 'float16',\n",
    " 'D4_week_ss': 'float16',\n",
    " 'D4_week_norm': 'float16',\n",
    " 'D5_week_ss': 'float16',\n",
    " 'D5_week_norm': 'float16',\n",
    " 'D6_week_ss': 'float16',\n",
    " 'D6_week_norm': 'float16',\n",
    " 'D7_week_ss': 'float16',\n",
    " 'D7_week_norm': 'float16',\n",
    " 'D8_week_ss': 'float16',\n",
    " 'D8_week_norm': 'float16',\n",
    " 'D9_week_ss': 'float16',\n",
    " 'D9_week_norm': 'float16',\n",
    " 'D10_week_ss': 'float16',\n",
    " 'D10_week_norm': 'float16',\n",
    " 'D11_week_ss': 'float16',\n",
    " 'D11_week_norm': 'float16',\n",
    " 'D12_week_ss': 'float16',\n",
    " 'D12_week_norm': 'float16',\n",
    " 'D13_week_ss': 'float16',\n",
    " 'D13_week_norm': 'float16',\n",
    " 'D14_week_ss': 'float16',\n",
    " 'D14_week_norm': 'float16',\n",
    " 'D15_week_ss': 'float16',\n",
    " 'D15_week_norm': 'float16'}\n",
    "dumm=pd.read_csv('/kaggle/input/raw-preparation-0-3/prepared.csv',dtype=dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            df[col]=df[col].fillna(-1)\n",
    "            df[col]=df[col].replace([np.inf,-np.inf],-1)\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "dumm=reduce_mem_usage(dumm)\n",
    "for_lgb=pd.concat([dumm,selected],1)\n",
    "for_lgb.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in for_lgb.columns]\n",
    "fnl_trn=for_lgb.loc[for_lgb['isFraud']>=0]\n",
    "fnl_tst=for_lgb.loc[for_lgb['isFraud']==-1]\n",
    "fnl_tst=fnl_tst.reset_index(drop=True)\n",
    "import gc\n",
    "del([for_lgb])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps=['ProductCD','card1','card2','card3','card4','card5','card6','P_emaildomain','R_emaildomain']\n",
    "trn_trans=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv',usecols=keeps)\n",
    "tst_trans=pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv',usecols=keeps)\n",
    "trans=pd.concat([trn_trans,tst_trans],0)\n",
    "trans=trans.reset_index(drop=True)\n",
    "del([trn_trans,tst_trans])\n",
    "gc.collect()\n",
    "dumm=dumm.filter(regex='dum')\n",
    "fnl=pd.concat([dumm,selected,trans],1)\n",
    "del([trans,dumm,selected])\n",
    "gc.collect()\n",
    "keeps_fnl=fnl[keeps]\n",
    "fnl=fnl.drop(keeps,1)\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "ss=StandardScaler()\n",
    "mms=MinMaxScaler()\n",
    "ls=list(fnl)\n",
    "fnl=pd.DataFrame(mms.fit_transform(ss.fit_transform(fnl)))\n",
    "fnl.columns=ls\n",
    "fnl=pd.concat([fnl,keeps_fnl],1)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in keeps:\n",
    "    le=LabelEncoder()\n",
    "    fnl[col]=le.fit_transform(fnl[col].astype(str))\n",
    "\n",
    "trn=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv',usecols=['isFraud'])\n",
    "fnl['isFraud']=trn['isFraud']\n",
    "from bayes_opt import BayesianOptimization\n",
    "def rac(y_true, y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    Arguments:\n",
    "        y_pred: `Tensor`. Predicted values.\n",
    "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"RocAucScore\"):\n",
    "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        neg = tf.expand_dims(neg, 1)\n",
    "        # original paper suggests performance is robust to exact parameter choice\n",
    "        gamma = 0.6\n",
    "        p     = 0.5\n",
    "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "        return tf.reduce_sum(tf.pow(-masked, p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn=fnl.dropna()\n",
    "tst=fnl.loc[fnl['isFraud'].isna()]\n",
    "print(trn.shape)\n",
    "print(tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Input,Dense,BatchNormalization,Dropout,Embedding,Concatenate,Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding,Dot,Add,Flatten,concatenate,BatchNormalization,Input,Dense\n",
    "import tensorflow as tf\n",
    "from itertools import combinations\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Nadam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.regularizers import l2,l1\n",
    "import keras\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def model1(shape,er,ar,r1,r2,r3,r4):\n",
    "    K.clear_session()\n",
    "    inps=[]\n",
    "    embs=[]\n",
    "    for col in keeps:\n",
    "        inp=Input((1,))\n",
    "        emb=Embedding(fnl[col].max()+1,5,trainable=True,embeddings_regularizer=l1(er),activity_regularizer=l1(ar))(inp)\n",
    "        inps.append(inp)\n",
    "        embs.append(emb)\n",
    "    x=concatenate(embs)\n",
    "    x=Dense(256,activation='relu',kernel_regularizer=l1(r1))(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    one=[Flatten()(em) for em in embs]\n",
    "    second=[]\n",
    "    for a,b in combinations(embs,2):\n",
    "        second.append(Dot(1)([Flatten()(a),Flatten()(b)]))\n",
    "    one=Add()(one)\n",
    "    second=Add()(second)\n",
    "    x=Flatten()(x)\n",
    "    inp=Input((inp_shape,))\n",
    "    inps.append(inp)\n",
    "    tot=[x,(one),(second),(inp)]\n",
    "    x=concatenate(tot)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(256,activation='relu',kernel_regularizer=l1(r2))(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    x=Dense(256,activation='relu',kernel_regularizer=l1(r3))(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    x=Dense(256,activation='relu',kernel_regularizer=l1(r4))(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    out=Dense(1,activation='sigmoid')(x)\n",
    "    mod=Model(inputs=inps,outputs=out)\n",
    "    return mod\n",
    "def fl(gamma1,alpha1):\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        gamma=gamma1\n",
    "        alpha=alpha1\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.keras.metrics.AUC(y_true, y_pred)\n",
    "    return auc\n",
    "inp_shape=trn.shape[1]-len(keeps)\n",
    "inp_shape=inp_shape-1\n",
    "pre=pd.DataFrame()\n",
    "    \n",
    "fit=400000\n",
    "batch_size=2048\n",
    "validation=trn.loc[fit:]\n",
    "z_val=validation[keeps].values\n",
    "z_tst=tst[keeps].values\n",
    "del([trn])\n",
    "gc.collect()\n",
    "kp1=['ProductCD',\n",
    " 'card1',\n",
    " 'card2',\n",
    " 'card3',\n",
    " 'card4',\n",
    " 'card5',\n",
    " 'card6',\n",
    " 'P_emaildomain',\n",
    " 'R_emaildomain','isFraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=model1(validation.shape[1]-1,0.0360,0.3046,0.01,0.01,0.01,0.01)\n",
    "es=EarlyStopping(monitor='val_loss',patience=100,mode='min',min_delta=0.001,restore_best_weights=True)\n",
    "dc=ReduceLROnPlateau(monitor='val_loss', factor=0.8,mode='min',patience=10,min_delta=0.01)\n",
    "mod.compile(optimizer=Nadam(0.0008),loss=fl(alpha1=0.75,gamma1=2.43),metrics=[tf.keras.metrics.AUC()])\n",
    "mod.load_weights('/kaggle/input/nn-0-3/saved.hdf5')\n",
    "pre_nn=mod.predict([z_tst[:,0],z_tst[:,1],z_tst[:,2],z_tst[:,3],z_tst[:,4],z_tst[:,5],z_tst[:,6],z_tst[:,7],z_tst[:,8],tst.drop(kp1,1).values])\n",
    "pre_nn=pre_nn.reshape(1,-1)[0]\n",
    "del([fnl])\n",
    "gc.collect()\n",
    "fit=fnl_trn\n",
    "vald=fnl_tst\n",
    "import lightgbm as lgb\n",
    "mod=lgb.LGBMClassifier()\n",
    "mod.fit(fit.drop(['isFraud'],1),fit['isFraud'])\n",
    "pre=mod.predict_proba(vald.drop(['isFraud'],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=pre[:,1]\n",
    "a=(pre*0.91)+(pre_nn*0.09)\n",
    "ss=pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')\n",
    "ss=ss.set_index('TransactionID')\n",
    "ss['isFraud']=a\n",
    "ss.to_csv('sub.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
