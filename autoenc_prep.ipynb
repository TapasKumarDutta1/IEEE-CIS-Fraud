{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoenc_prep.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOZgs6XROke/683mrqbiUGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/autoenc_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "outputId": "44f9f399-f232-485c-85b7-a48b83d37314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "pip install tensorflow==2.1.0-rc0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.1.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.1.0rc0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (2.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (3.2.1)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (2.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.28.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0-rc0) (1.18.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0-rc0) (46.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0-rc0) (2.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (2020.4.5.1)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.1.0-rc0) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "outputId": "ffe20273-6c58-4da7-ef70-8b72a3071137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "pip install keras==2.3.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "outputId": "4d5d4eda-b9a2-43f2-c1d1-e11a510862c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "train_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f6cc740e-d87f-48fa-b8ad-77386b5f2fda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJem4-mp8otc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "trn=pd.read_csv('train_transaction.csv.zip')\n",
        "tst=pd.read_csv('test_transaction.csv.zip')\n",
        "trn=trn.drop(['isFraud'],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiE3LbOCCgku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "af7ed85c-ef22-4ebb-e71f-b8d79d053150"
      },
      "source": [
        "ls=list(trn.filter(regex='V'))\n",
        "trn=trn.drop(ls,1)\n",
        "tst=tst.drop(ls,1)\n",
        "trn.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 54)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Ykfkm0dofS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "723fe4df-7a7c-401d-8c10-08862f2f5b99"
      },
      "source": [
        "import gc\n",
        "fnl=pd.concat([trn,tst],0)\n",
        "fnl=fnl.reset_index(drop=True)\n",
        "del([trn,tst])\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6gnpm4CjDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c237fb69-b5f9-446f-f4ed-4119d9d835d2"
      },
      "source": [
        "fnl['nan_count']=fnl.isna().sum(1)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "for col in tqdm(list(fnl.select_dtypes(include=object))):\n",
        "    fnl[col]=fnl[col].fillna('Other')\n",
        "    fnl[col]=LabelEncoder().fit_transform(fnl[col].astype(str))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.56it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukj7lSXPKxRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fnl=fnl.drop(['TransactionDT','TransactionID'],1)\n",
        "def mape(data,ls):\n",
        "    return [data if data in ls else 'Other']\n",
        "\n",
        "def handle_cont(df,cols):\n",
        "  for col in cols:\n",
        "    if df[col].skew()>1:\n",
        "        df[col]=np.log10(df[col]+1-min(0,min(df[col].fillna(0))))\n",
        "    mn=df[col].mean()\n",
        "    std=df[col].std()\n",
        "    df[col]=(df[col]-mn)/(std+1e-6)\n",
        "    df[col]=df[col].fillna(0)\n",
        "  return df[cols]\n",
        "disc=['ProductCD','card1','card2','card3','card4','card5','card6','addr1','addr2','P_emaildomain','R_emaildomain','M1','M2','M3','M4','M5','M6','M7','M8','M9']\n",
        "cont=[i for i in fnl.columns if i not in disc]\n",
        "fnl_cont=handle_cont(fnl,cont)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6TtrpUZLApF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da1fe74e-4f33-47f6-c637-8214ac447534"
      },
      "source": [
        "def handle_disc(df,cols,num):\n",
        "  df=df[cols]\n",
        "  for col in cols:\n",
        "    df[col]=df[col].astype(str)\n",
        "    par=min(df[col].nunique(),num)\n",
        "    vc=list(df[col].value_counts().iloc[:par-1].index)+['Other']\n",
        "    print(df[col].nunique())\n",
        "    df[col]=df[col].apply(lambda x:x if x in vc else 'Other')\n",
        "    print(df[col].nunique())\n",
        "    print()\n",
        "    dum=pd.get_dummies(df[col])\n",
        "    ls=[]\n",
        "    for i in dum.columns:\n",
        "      ls.append(str(col)+str(i)+'_dum')\n",
        "    dum.columns=ls\n",
        "    df=pd.concat([df,dum],1)\n",
        "    del([dum])\n",
        "    gc.collect()\n",
        "  df=df.drop(cols,1)\n",
        "  sp=df.shape[1]\n",
        "  return df\n",
        "fnl_disc=handle_disc(fnl,disc,140)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "\n",
            "17091\n",
            "140\n",
            "\n",
            "502\n",
            "140\n",
            "\n",
            "134\n",
            "134\n",
            "\n",
            "5\n",
            "5\n",
            "\n",
            "139\n",
            "139\n",
            "\n",
            "5\n",
            "5\n",
            "\n",
            "442\n",
            "140\n",
            "\n",
            "94\n",
            "94\n",
            "\n",
            "61\n",
            "61\n",
            "\n",
            "61\n",
            "61\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            "4\n",
            "4\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            "3\n",
            "3\n",
            "\n",
            "3\n",
            "3\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMYANec88Kfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8d581fe6-2814-4020-c32d-7d11002c0928"
      },
      "source": [
        "z=fnl_cont.isna().sum()\n",
        "z[z>0]\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahMnQcCJ8Tqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "006f23a8-cb60-493c-ebd7-487e3597e1a7"
      },
      "source": [
        "z=fnl_disc.isna().sum()\n",
        "z[z>0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8azxXaFE8T0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "eafb92a7-a21a-48f8-a9aa-7c41be3b3b0c"
      },
      "source": [
        "fnl=pd.concat([fnl_disc,fnl_cont],1)\n",
        "import gc\n",
        "fnl=fnl.fillna(0)\n",
        "del([fnl_disc,fnl_cont])\n",
        "gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha_HXo738T8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat=list(fnl.filter(regex='dum'))\n",
        "cat_shape=len(list(fnl.filter(regex='dum')))\n",
        "num_shape=len([i for i in fnl.columns if i not in cat])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIcL-BDLW9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "61833c15-1dfe-4725-b849-f62e4c3b20c7"
      },
      "source": [
        "import keras\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization, Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "np.random.seed(42) # NumPy\n",
        "random.seed(42) # Python\n",
        "# Compatible with tensorflow backend\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "\n",
        "get_custom_objects().update({'custom_gelu': Activation(custom_gelu)})\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import Sequence\n",
        "class DAESequence(Sequence):\n",
        "    def __init__(self,df,no_dum,frac=0.15,dumm=range(911),batch_size=2048):\n",
        "        self.batch_size=batch_size\n",
        "        self.frac=0.15\n",
        "        self.dumm=dumm\n",
        "        self.df=df\n",
        "        self.cat_data=df[dumm].values\n",
        "        self.num_data=df[no_dum].values\n",
        "        self.no_dumm=no_dum\n",
        "        self.len_data=df.shape[0]\n",
        "        self.columns=df.shape[1]\n",
        "        self.data=df\n",
        "        self.idx=[]\n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(ceil(self.len_data/self.batch_size))\n",
        "    \n",
        "    \n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        self.idx.append(idx)\n",
        "        last=min((idx+1)*self.batch_size,self.len_data)\n",
        "        idx=idx*self.batch_size\n",
        "        size=last-idx\n",
        "        \n",
        "        \n",
        "        inps=[]\n",
        "        outs=[]\n",
        "        output_x=self.data.iloc[idx:last]\n",
        "        \n",
        "        data=output_x[self.no_dumm].values\n",
        "        noise_x=data.copy()\n",
        "        for i in range(len(self.no_dumm)):\n",
        "            to=np.random.randint(0,size,int(size*self.frac))\n",
        "            frm=np.random.randint(0,size,int(size*self.frac))\n",
        "            noise_x[to,i]=self.num_data[frm,i]\n",
        "            \n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "        \n",
        "        data=output_x[self.dumm].values\n",
        "        noise_x=data.copy()\n",
        "        for i in range(len(self.dumm)):\n",
        "            to=np.random.randint(0,size,int(size*self.frac))\n",
        "            frm=np.random.randint(0,size,int(size*self.frac))\n",
        "            noise_x[to,i]=self.cat_data[frm,i]\n",
        "        \n",
        "        \n",
        "        \n",
        "        inps.append(noise_x)\n",
        "        outs.append(data)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        return inps,outs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size=2048\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "auto_ckpt = ModelCheckpoint(\"ae.model\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class WarmUpLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Warmup learning rate scheduler\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup_batches, init_lr, verbose=0):\n",
        "        \"\"\"Constructor for warmup learning rate scheduler\n",
        "\n",
        "        Arguments:\n",
        "            warmup_batches {int} -- Number of batch for warmup.\n",
        "            init_lr {float} -- Learning rate after warmup.\n",
        "\n",
        "        Keyword Arguments:\n",
        "            verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
        "        \"\"\"\n",
        "\n",
        "        super(WarmUpLearningRateScheduler, self).__init__()\n",
        "        self.warmup_batches = warmup_batches\n",
        "        self.init_lr = init_lr\n",
        "        self.verbose = verbose\n",
        "        self.batch_count = 0\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.batch_count = self.batch_count + 1\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        if self.batch_count <= self.warmup_batches:\n",
        "            lr = self.batch_count*self.init_lr/self.warmup_batches\n",
        "            K.set_value(self.model.optimizer.lr, lr)\n",
        "            if self.verbose > 0:\n",
        "                print('\\nBatch %05d: WarmUpLearningRateScheduler setting learning '\n",
        "                      'rate to %s.' % (self.batch_count + 1, lr))\n",
        "warm_up_lr = WarmUpLearningRateScheduler(400, init_lr=0.001)\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf25ibJI8T5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import concatenate\n",
        "K.clear_session()\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2 \n",
        "def create_model():\n",
        "    num_inp = Input(shape=(num_shape,))\n",
        "    cat_inp = Input(shape=(cat_shape,))\n",
        "    inps = concatenate([num_inp, cat_inp])\n",
        "    x = Dense(512, activation=custom_gelu)(inps)\n",
        "    x = Dense(256, activation=custom_gelu)(x)\n",
        "    x = Dense(512, activation = custom_gelu)(x)\n",
        "    x = Dropout(.2)(x)\n",
        "    cat_out = Dense(cat_shape, activation = \"linear\")(x)\n",
        "    num_out = Dense(num_shape, activation = \"linear\")(x)\n",
        "    model = Model(inputs=[num_inp, cat_inp], outputs=[num_out, cat_out])\n",
        "    model.compile(\n",
        "        optimizer=Adam(.05, clipnorm = 1, clipvalue = 1),\n",
        "        loss=[\"mse\", \"mse\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyjXsW3U8Txj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "f8637136-8cf9-4658-834d-8dcd3340e344"
      },
      "source": [
        "\n",
        "import gc\n",
        "\n",
        "from math import *\n",
        "gc.collect()\n",
        "epochs = 10\n",
        "num=[i for i in fnl.columns if i not in cat]\n",
        "train_gen=DAESequence(fnl,num,dumm=cat,batch_size=batch_size)\n",
        "model_mse = create_model()\n",
        "hist = model_mse.fit_generator(train_gen, steps_per_epoch=len(fnl)//batch_size, epochs=epochs,\n",
        "                           verbose=1, workers=-1, \n",
        "                           use_multiprocessing=True,\n",
        "                              callbacks=[auto_ckpt, warm_up_lr])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "535/535 [==============================] - 101s 188ms/step - loss: 0.2098 - dense_5_loss: 0.1988 - dense_4_loss: 0.0111\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.20982, saving model to ae.model\n",
            "Epoch 2/10\n",
            "535/535 [==============================] - 100s 186ms/step - loss: 0.0807 - dense_5_loss: 0.0751 - dense_4_loss: 0.0055\n",
            "\n",
            "Epoch 00002: loss improved from 0.20982 to 0.08066, saving model to ae.model\n",
            "Epoch 3/10\n",
            "535/535 [==============================] - 101s 188ms/step - loss: 0.0720 - dense_5_loss: 0.0671 - dense_4_loss: 0.0050\n",
            "\n",
            "Epoch 00003: loss improved from 0.08066 to 0.07204, saving model to ae.model\n",
            "Epoch 4/10\n",
            "535/535 [==============================] - 100s 188ms/step - loss: 0.0685 - dense_5_loss: 0.0637 - dense_4_loss: 0.0048\n",
            "\n",
            "Epoch 00004: loss improved from 0.07204 to 0.06851, saving model to ae.model\n",
            "Epoch 5/10\n",
            "535/535 [==============================] - 106s 198ms/step - loss: 0.0650 - dense_5_loss: 0.0604 - dense_4_loss: 0.0046\n",
            "\n",
            "Epoch 00005: loss improved from 0.06851 to 0.06501, saving model to ae.model\n",
            "Epoch 6/10\n",
            "535/535 [==============================] - 105s 196ms/step - loss: 0.0613 - dense_5_loss: 0.0568 - dense_4_loss: 0.0045\n",
            "\n",
            "Epoch 00006: loss improved from 0.06501 to 0.06129, saving model to ae.model\n",
            "Epoch 7/10\n",
            "535/535 [==============================] - 101s 188ms/step - loss: 0.0595 - dense_5_loss: 0.0551 - dense_4_loss: 0.0044\n",
            "\n",
            "Epoch 00007: loss improved from 0.06129 to 0.05953, saving model to ae.model\n",
            "Epoch 8/10\n",
            "535/535 [==============================] - 99s 186ms/step - loss: 0.0582 - dense_5_loss: 0.0539 - dense_4_loss: 0.0043\n",
            "\n",
            "Epoch 00008: loss improved from 0.05953 to 0.05820, saving model to ae.model\n",
            "Epoch 9/10\n",
            "535/535 [==============================] - 100s 186ms/step - loss: 0.0577 - dense_5_loss: 0.0534 - dense_4_loss: 0.0043\n",
            "\n",
            "Epoch 00009: loss improved from 0.05820 to 0.05766, saving model to ae.model\n",
            "Epoch 10/10\n",
            "535/535 [==============================] - 100s 187ms/step - loss: 0.0565 - dense_5_loss: 0.0523 - dense_4_loss: 0.0042\n",
            "\n",
            "Epoch 00010: loss improved from 0.05766 to 0.05647, saving model to ae.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qewhPehQl0-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "19b92226-e369-4da7-f700-3101f3ec9378"
      },
      "source": [
        "model_mse.layers"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f6fe1106e10>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7f6fe77ed390>,\n",
              " <keras.layers.merge.Concatenate at 0x7f6fe77edd68>,\n",
              " <keras.layers.core.Dense at 0x7f6fe77edb38>,\n",
              " <keras.layers.core.Dense at 0x7f7011477080>,\n",
              " <keras.layers.core.Dense at 0x7f6fe77ed400>,\n",
              " <keras.layers.core.Dropout at 0x7f702a53d160>,\n",
              " <keras.layers.core.Dense at 0x7f70107ba828>,\n",
              " <keras.layers.core.Dense at 0x7f702a532e80>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-XjhtO5yg83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "path = F\"/content/gdrive/My Drive/autoenc_final.hdf5\" \n",
        "model_mse.save_weights(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JliSliPGlsoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2f83861a-f2a8-42af-fd4d-28e9d88857ae"
      },
      "source": [
        "from tqdm import tqdm\n",
        "your_new_df=pd.DataFrame()\n",
        "for i in tqdm([4,5,6]):\n",
        "    intermediate_layer_model = Model(inputs=model_mse.input, outputs=model_mse.layers[i].output)\n",
        "    z = pd.DataFrame(intermediate_layer_model.predict([fnl[num],fnl[cat]]))\n",
        "    columns_names = ['Hidden_'+str(i)+'_'+str(l) for l in range(0, z.shape[1])]\n",
        "    z.columns=columns_names\n",
        "    your_new_df=pd.concat([your_new_df,z],1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [04:10<00:00, 83.38s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAtYsgGrmjBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "041349a3-6ca7-40a7-b8ac-a7c20922d8ce"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        df[col]=df[col].fillna(-1)\n",
        "        df[col]=df[col].replace([np.inf,-np.inf],-1)\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "your_new_df=reduce_mem_usage(your_new_df)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 5357.57 MB\n",
            "Memory usage after optimization is: 2678.79 MB\n",
            "Decreased by 50.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWNPObImjib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trn=pd.read_csv('train_transaction.csv.zip',usecols=['isFraud'])\n",
        "your_new_df=your_new_df.loc[:trn.shape[0]]\n",
        "your_new_df['isFraud']=trn['isFraud']\n",
        "fnl=pd.DataFrame()\n",
        "cols=[]\n",
        "val=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFcZLfs8moDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "your_new_df=your_new_df.dropna()\n",
        "your_new_df=your_new_df.replace([np.inf,-np.inf],0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPZVhMHKmp1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls=list(your_new_df)\n",
        "ls.remove('isFraud')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NtTMSRnmxP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "your_new_df=your_new_df.drop(['isFraud'],1)\n",
        "path = F\"/content/gdrive/My Drive/extra__1.pkl\" \n",
        "your_new_df.to_pickle(path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}