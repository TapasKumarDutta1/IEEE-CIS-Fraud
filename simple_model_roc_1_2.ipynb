{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_roc_1.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_roc_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4bee68d5-aca1-4264-8ca4-85a0f29a95ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c4f0ff18-2a14-49d8-bca2-d3e2a5f1a7ed"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "\r  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 79.4MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 105MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 59% 31.0M/52.2M [00:00<00:00, 131MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 174MB/s]\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 221MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 70% 41.0M/58.3M [00:00<00:00, 202MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 194MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold=5\n",
        "lr=0.0001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')\n",
        "ls=list(trn.filter(regex='V'))\n",
        "trn=trn.drop(ls,1)\n",
        "tst=tst.drop(ls,1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OTCMdEiOn9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv80v8W_Ko2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "86bda257-f480-44d8-997f-309d771b70e2"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in cols:\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4jt2pcxPije",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "ss=StandardScaler()\n",
        "frd=trn['isFraud']\n",
        "ls=list(trn)\n",
        "trn=ss.fit_transform(trn.drop(['isFraud'],1))\n",
        "trn=pd.DataFrame(trn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls.remove('isFraud')\n",
        "trn.columns=ls\n",
        "trn['isFraud']=frd\n",
        "\n",
        "ls=list(tst)\n",
        "tst=ss.fit_transform(tst)\n",
        "tst=pd.DataFrame(tst)\n",
        "tst.columns=ls"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "11a26d4c-6c49-4f12-a232-c52d3dd7e0a6"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 860.54 MB\n",
            "Memory usage after optimization is: 215.14 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 734.49 MB\n",
            "Memory usage after optimization is: 183.62 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvEaxp9jhbvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "1d27da81-6887-4c1f-a7ab-acf90438d9f2"
      },
      "source": [
        "trn_n=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_n=pd.read_csv('test_transaction.csv.zip')\n",
        "trn['month']=trn_n['TransactionDT']//(86400*30)\n",
        "trn_n.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>315.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>325.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>outlook.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>476.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yahoo.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1758.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 394 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  ...  V337 V338  V339\n",
              "0        2987000        0          86400  ...   NaN  NaN   NaN\n",
              "1        2987001        0          86401  ...   NaN  NaN   NaN\n",
              "2        2987002        0          86469  ...   NaN  NaN   NaN\n",
              "3        2987003        0          86499  ...   NaN  NaN   NaN\n",
              "4        2987004        0          86506  ...   0.0  0.0   0.0\n",
              "\n",
              "[5 rows x 394 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "299a8ed0-3781-421a-ecb1-0ef9b252cca8"
      },
      "source": [
        "\n",
        "trn_ls=list(trn_n)\n",
        "tst_ls=list(tst_n)\n",
        "for col in trn:\n",
        "  if col in trn_ls:\n",
        "    trn[col+'_isna']=trn_n[col].isna().astype('uint8')\n",
        "for col in tst:\n",
        "  if col in tst_ls:\n",
        "    tst[col+'_isna']=tst_n[col].isna().astype('uint8')\n",
        "import gc\n",
        "del([trn_n,tst_n])\n",
        "gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJkLEBcl6LHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def rac(y_true, y_pred):\n",
        "    \"\"\" ROC AUC Score.\n",
        "    Approximates the Area Under Curve score, using approximation based on\n",
        "    the Wilcoxon-Mann-Whitney U statistic.\n",
        "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
        "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
        "    Measures overall performance for a full range of threshold levels.\n",
        "    Arguments:\n",
        "        y_pred: `Tensor`. Predicted values.\n",
        "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(\"RocAucScore\"):\n",
        "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
        "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
        "        pos = tf.expand_dims(pos, 0)\n",
        "        neg = tf.expand_dims(neg, 1)\n",
        "        # original paper suggests performance is robust to exact parameter choice\n",
        "        gamma = 0.3\n",
        "        p     = 1.2\n",
        "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
        "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
        "        return tf.reduce_sum(tf.pow(-masked, p))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1TSjSWyTL4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.drop(['isFraud_isna'],1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c88dc293-164f-4277-b0a7-bd9709bf9dcb"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "# trn=trn.drop(['isFraud_isna'],1)\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        if self.ep%10==0:\n",
        "          y_pred_val = self.model.predict(self.x_val)\n",
        "          roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "          print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "  inp=Input((233,))\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=inp,outputs=x)\n",
        "  return mod\n",
        "dk={}\n",
        "for en,month in enumerate(range(1,5)):\n",
        "  train=trn.loc[trn['month']>=month]\n",
        "  test=trn.loc[trn['month']<month]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  roc = RocCallback(\n",
        "                  validation_data=(test.drop(['isFraud'],1), test['isFraud']))\n",
        "  mod.compile(optimizer=Adam(0.001,decay=1e-3),loss=rac,metrics='accuracy')\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.00001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es,roc])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  df=trn.loc[trn['month']==6].reset_index(drop=True).drop(['month'],1)\n",
        "  pre=mod.predict(df.drop(['isFraud'],1))\n",
        "  scr=roc_auc_score(df['isFraud'],pre)\n",
        "  dk[str(scr)]=mod.predict(tst)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "225/225 [==============================] - 2s 9ms/step - loss: 18889.2031 - accuracy: 0.5923 - val_loss: 14237.3867 - val_accuracy: 0.4975\n",
            "Epoch 2/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 14500.4307 - accuracy: 0.6900 - val_loss: 12712.9736 - val_accuracy: 0.6039\n",
            "Epoch 3/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 12850.1094 - accuracy: 0.7472 - val_loss: 12569.9482 - val_accuracy: 0.6200\n",
            "Epoch 4/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 11631.4463 - accuracy: 0.7801 - val_loss: 12010.4590 - val_accuracy: 0.6610\n",
            "Epoch 5/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 10948.6250 - accuracy: 0.7946 - val_loss: 12306.5449 - val_accuracy: 0.7004\n",
            "Epoch 6/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 10244.4609 - accuracy: 0.8059 - val_loss: 11952.6973 - val_accuracy: 0.6911\n",
            "Epoch 7/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 9853.6279 - accuracy: 0.8149 - val_loss: 11776.0723 - val_accuracy: 0.7186\n",
            "Epoch 8/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 9421.2686 - accuracy: 0.8212 - val_loss: 11463.8877 - val_accuracy: 0.7212\n",
            "Epoch 9/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 9116.1357 - accuracy: 0.8279 - val_loss: 11393.8115 - val_accuracy: 0.7330\n",
            "Epoch 10/1000\n",
            "223/225 [============================>.] - ETA: 0s - loss: 8736.0918 - accuracy: 0.8289roc-auc_val: 0.8006\n",
            "225/225 [==============================] - 6s 27ms/step - loss: 8716.8076 - accuracy: 0.8289 - val_loss: 11423.2021 - val_accuracy: 0.7634\n",
            "Epoch 11/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 8571.9502 - accuracy: 0.8313 - val_loss: 11376.6816 - val_accuracy: 0.7267\n",
            "Epoch 12/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 8252.4746 - accuracy: 0.8366 - val_loss: 10798.0283 - val_accuracy: 0.7765\n",
            "Epoch 13/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 8053.4058 - accuracy: 0.8358 - val_loss: 10721.7725 - val_accuracy: 0.7774\n",
            "Epoch 14/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 7908.3145 - accuracy: 0.8352 - val_loss: 10984.3760 - val_accuracy: 0.7372\n",
            "Epoch 15/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 7697.4819 - accuracy: 0.8372 - val_loss: 10781.0869 - val_accuracy: 0.7765\n",
            "Epoch 16/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 7548.0571 - accuracy: 0.8421 - val_loss: 10942.5342 - val_accuracy: 0.7741\n",
            "Epoch 17/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 7351.8823 - accuracy: 0.8428 - val_loss: 10526.8057 - val_accuracy: 0.7840\n",
            "Epoch 18/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 7236.3618 - accuracy: 0.8451 - val_loss: 10442.9570 - val_accuracy: 0.7644\n",
            "Epoch 19/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 7083.6084 - accuracy: 0.8445 - val_loss: 10849.7158 - val_accuracy: 0.7595\n",
            "Epoch 20/1000\n",
            "222/225 [============================>.] - ETA: 0s - loss: 7043.0303 - accuracy: 0.8453roc-auc_val: 0.8251\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 7029.8779 - accuracy: 0.8452 - val_loss: 10235.2871 - val_accuracy: 0.7941\n",
            "Epoch 21/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6857.9912 - accuracy: 0.8441 - val_loss: 10652.4531 - val_accuracy: 0.7763\n",
            "Epoch 22/1000\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 6729.1206 - accuracy: 0.8479 - val_loss: 10441.9199 - val_accuracy: 0.7678\n",
            "Epoch 23/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6689.7124 - accuracy: 0.8467 - val_loss: 10487.0107 - val_accuracy: 0.7835\n",
            "Epoch 24/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6598.2881 - accuracy: 0.8493 - val_loss: 10285.0176 - val_accuracy: 0.7970\n",
            "Epoch 25/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6513.1660 - accuracy: 0.8487 - val_loss: 10294.9062 - val_accuracy: 0.8041\n",
            "Epoch 26/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6379.5815 - accuracy: 0.8524 - val_loss: 10182.6152 - val_accuracy: 0.8051\n",
            "Epoch 27/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6376.7197 - accuracy: 0.8523 - val_loss: 10272.9873 - val_accuracy: 0.7992\n",
            "Epoch 28/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6211.0649 - accuracy: 0.8529 - val_loss: 10300.5049 - val_accuracy: 0.8042\n",
            "Epoch 29/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6134.9727 - accuracy: 0.8551 - val_loss: 10594.7139 - val_accuracy: 0.7846\n",
            "Epoch 30/1000\n",
            "220/225 [============================>.] - ETA: 0s - loss: 6174.4814 - accuracy: 0.8551roc-auc_val: 0.8264\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 6173.9712 - accuracy: 0.8551 - val_loss: 10166.0166 - val_accuracy: 0.8166\n",
            "Epoch 31/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 6056.2949 - accuracy: 0.8558 - val_loss: 10575.8008 - val_accuracy: 0.7928\n",
            "Epoch 32/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5989.6777 - accuracy: 0.8591 - val_loss: 10235.9717 - val_accuracy: 0.8144\n",
            "Epoch 33/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5963.2026 - accuracy: 0.8575 - val_loss: 10058.6025 - val_accuracy: 0.8033\n",
            "Epoch 34/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5965.7192 - accuracy: 0.8575 - val_loss: 10068.1621 - val_accuracy: 0.8018\n",
            "Epoch 35/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5859.7358 - accuracy: 0.8578 - val_loss: 10402.4004 - val_accuracy: 0.7941\n",
            "Epoch 36/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5915.0200 - accuracy: 0.8602 - val_loss: 10178.8291 - val_accuracy: 0.8160\n",
            "Epoch 37/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5736.3892 - accuracy: 0.8612 - val_loss: 10379.1191 - val_accuracy: 0.8026\n",
            "Epoch 38/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5787.7979 - accuracy: 0.8624 - val_loss: 10097.4258 - val_accuracy: 0.8186\n",
            "Epoch 39/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5738.1880 - accuracy: 0.8589 - val_loss: 10271.3252 - val_accuracy: 0.7934\n",
            "Epoch 40/1000\n",
            "222/225 [============================>.] - ETA: 0s - loss: 5624.4189 - accuracy: 0.8595roc-auc_val: 0.8285\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 5605.5967 - accuracy: 0.8597 - val_loss: 10059.4746 - val_accuracy: 0.8150\n",
            "Epoch 41/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5612.8115 - accuracy: 0.8616 - val_loss: 10198.0547 - val_accuracy: 0.8119\n",
            "Epoch 42/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5547.2720 - accuracy: 0.8612 - val_loss: 10236.5566 - val_accuracy: 0.8090\n",
            "Epoch 43/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5585.4209 - accuracy: 0.8618 - val_loss: 10135.1641 - val_accuracy: 0.8159\n",
            "Epoch 44/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5505.7632 - accuracy: 0.8618 - val_loss: 10088.2754 - val_accuracy: 0.8147\n",
            "Epoch 45/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5460.5654 - accuracy: 0.8643 - val_loss: 10222.6055 - val_accuracy: 0.8194\n",
            "Epoch 46/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5457.5039 - accuracy: 0.8637 - val_loss: 10193.6309 - val_accuracy: 0.8113\n",
            "Epoch 47/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5367.1987 - accuracy: 0.8646 - val_loss: 10060.6533 - val_accuracy: 0.8296\n",
            "Epoch 48/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5381.5454 - accuracy: 0.8647 - val_loss: 10266.9082 - val_accuracy: 0.8027\n",
            "Epoch 49/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5342.9385 - accuracy: 0.8662 - val_loss: 10258.2266 - val_accuracy: 0.8072\n",
            "Epoch 50/1000\n",
            "223/225 [============================>.] - ETA: 0s - loss: 5267.8003 - accuracy: 0.8648roc-auc_val: 0.8248\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 5255.0542 - accuracy: 0.8648 - val_loss: 10262.4805 - val_accuracy: 0.8150\n",
            "Epoch 51/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5273.1611 - accuracy: 0.8677 - val_loss: 10080.5908 - val_accuracy: 0.8195\n",
            "Epoch 52/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5269.4473 - accuracy: 0.8674 - val_loss: 10068.6338 - val_accuracy: 0.8179\n",
            "Epoch 53/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5206.6465 - accuracy: 0.8674 - val_loss: 9947.9873 - val_accuracy: 0.8302\n",
            "Epoch 54/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5102.4316 - accuracy: 0.8663 - val_loss: 10075.3730 - val_accuracy: 0.8217\n",
            "Epoch 55/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5211.3193 - accuracy: 0.8693 - val_loss: 10076.7471 - val_accuracy: 0.8224\n",
            "Epoch 56/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5167.0181 - accuracy: 0.8675 - val_loss: 10312.3193 - val_accuracy: 0.8088\n",
            "Epoch 57/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5139.8423 - accuracy: 0.8690 - val_loss: 10160.2617 - val_accuracy: 0.8367\n",
            "Epoch 58/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5054.7388 - accuracy: 0.8688 - val_loss: 10244.9834 - val_accuracy: 0.8197\n",
            "Epoch 59/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5082.9116 - accuracy: 0.8704 - val_loss: 10252.3877 - val_accuracy: 0.8152\n",
            "Epoch 60/1000\n",
            "220/225 [============================>.] - ETA: 0s - loss: 5137.7046 - accuracy: 0.8667roc-auc_val: 0.8249\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 5126.0356 - accuracy: 0.8669 - val_loss: 10250.1572 - val_accuracy: 0.8247\n",
            "Epoch 61/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 5071.2109 - accuracy: 0.8685 - val_loss: 10214.6689 - val_accuracy: 0.8277\n",
            "Epoch 62/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4998.8345 - accuracy: 0.8690 - val_loss: 10143.8135 - val_accuracy: 0.8259\n",
            "Epoch 63/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4960.5415 - accuracy: 0.8703 - val_loss: 10233.7217 - val_accuracy: 0.8098\n",
            "Epoch 64/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4961.9678 - accuracy: 0.8681 - val_loss: 10234.8750 - val_accuracy: 0.8193\n",
            "Epoch 65/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4926.1001 - accuracy: 0.8710 - val_loss: 10160.7051 - val_accuracy: 0.8170\n",
            "Epoch 66/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4845.9189 - accuracy: 0.8710 - val_loss: 10085.1445 - val_accuracy: 0.8237\n",
            "Epoch 67/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4919.5303 - accuracy: 0.8718 - val_loss: 10024.7305 - val_accuracy: 0.8341\n",
            "Epoch 68/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4813.3071 - accuracy: 0.8705 - val_loss: 9989.1699 - val_accuracy: 0.8317\n",
            "Epoch 69/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4843.9629 - accuracy: 0.8706 - val_loss: 9973.0273 - val_accuracy: 0.8285\n",
            "Epoch 70/1000\n",
            "223/225 [============================>.] - ETA: 0s - loss: 4807.1538 - accuracy: 0.8722roc-auc_val: 0.8262\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 4804.4409 - accuracy: 0.8722 - val_loss: 10183.1016 - val_accuracy: 0.8180\n",
            "Epoch 71/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4797.6318 - accuracy: 0.8731 - val_loss: 10044.9521 - val_accuracy: 0.8311\n",
            "Epoch 72/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4773.8765 - accuracy: 0.8741 - val_loss: 10105.9922 - val_accuracy: 0.8270\n",
            "Epoch 73/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4730.8643 - accuracy: 0.8735 - val_loss: 10165.9834 - val_accuracy: 0.8230\n",
            "Epoch 74/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4714.0806 - accuracy: 0.8743 - val_loss: 10105.8379 - val_accuracy: 0.8250\n",
            "Epoch 75/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4824.8701 - accuracy: 0.8733 - val_loss: 10057.3867 - val_accuracy: 0.8253\n",
            "Epoch 76/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4744.0063 - accuracy: 0.8736 - val_loss: 10125.1807 - val_accuracy: 0.8248\n",
            "Epoch 77/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4752.9829 - accuracy: 0.8749 - val_loss: 10085.3262 - val_accuracy: 0.8301\n",
            "Epoch 78/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4678.6587 - accuracy: 0.8754 - val_loss: 10228.4727 - val_accuracy: 0.8221\n",
            "Epoch 79/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4667.7744 - accuracy: 0.8746 - val_loss: 10104.5996 - val_accuracy: 0.8267\n",
            "Epoch 80/1000\n",
            "220/225 [============================>.] - ETA: 0s - loss: 4692.3369 - accuracy: 0.8745roc-auc_val: 0.8287\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 4681.1987 - accuracy: 0.8745 - val_loss: 10040.8105 - val_accuracy: 0.8347\n",
            "Epoch 81/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4686.1216 - accuracy: 0.8752 - val_loss: 10093.0371 - val_accuracy: 0.8318\n",
            "Epoch 82/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4691.5615 - accuracy: 0.8745 - val_loss: 9978.3525 - val_accuracy: 0.8351\n",
            "Epoch 83/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4588.7695 - accuracy: 0.8775 - val_loss: 10076.5254 - val_accuracy: 0.8303\n",
            "Epoch 84/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4575.4980 - accuracy: 0.8753 - val_loss: 10083.4961 - val_accuracy: 0.8316\n",
            "Epoch 85/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4668.0850 - accuracy: 0.8746 - val_loss: 10334.2949 - val_accuracy: 0.8156\n",
            "Epoch 86/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4604.3223 - accuracy: 0.8743 - val_loss: 10038.8555 - val_accuracy: 0.8284\n",
            "Epoch 87/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4663.9536 - accuracy: 0.8766 - val_loss: 10058.4053 - val_accuracy: 0.8220\n",
            "Epoch 88/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4536.3193 - accuracy: 0.8768 - val_loss: 10103.4707 - val_accuracy: 0.8259\n",
            "Epoch 89/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4576.0894 - accuracy: 0.8775 - val_loss: 10046.9043 - val_accuracy: 0.8247\n",
            "Epoch 90/1000\n",
            "224/225 [============================>.] - ETA: 0s - loss: 4522.6572 - accuracy: 0.8771roc-auc_val: 0.8285\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 4515.6704 - accuracy: 0.8770 - val_loss: 10066.1943 - val_accuracy: 0.8319\n",
            "Epoch 91/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4545.7471 - accuracy: 0.8769 - val_loss: 10213.3516 - val_accuracy: 0.8251\n",
            "Epoch 92/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4513.9961 - accuracy: 0.8775 - val_loss: 10009.0381 - val_accuracy: 0.8341\n",
            "Epoch 93/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4492.3516 - accuracy: 0.8754 - val_loss: 10014.7793 - val_accuracy: 0.8288\n",
            "Epoch 94/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4475.4565 - accuracy: 0.8777 - val_loss: 10008.6582 - val_accuracy: 0.8343\n",
            "Epoch 95/1000\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 4483.9355 - accuracy: 0.8773 - val_loss: 10125.1396 - val_accuracy: 0.8212\n",
            "Epoch 96/1000\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 4420.9946 - accuracy: 0.8765 - val_loss: 10192.6641 - val_accuracy: 0.8206\n",
            "Epoch 97/1000\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 4428.0435 - accuracy: 0.8792 - val_loss: 10092.5986 - val_accuracy: 0.8343\n",
            "Epoch 98/1000\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 4434.3374 - accuracy: 0.8775 - val_loss: 9970.6572 - val_accuracy: 0.8350\n",
            "Epoch 99/1000\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 4410.9038 - accuracy: 0.8794 - val_loss: 10045.8301 - val_accuracy: 0.8348\n",
            "Epoch 100/1000\n",
            "220/225 [============================>.] - ETA: 0s - loss: 4381.6851 - accuracy: 0.8776roc-auc_val: 0.8302\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 4375.9604 - accuracy: 0.8775 - val_loss: 9963.0215 - val_accuracy: 0.8403\n",
            "Epoch 101/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4386.3774 - accuracy: 0.8798 - val_loss: 10025.1357 - val_accuracy: 0.8387\n",
            "Epoch 102/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4447.0288 - accuracy: 0.8794 - val_loss: 10089.4697 - val_accuracy: 0.8359\n",
            "Epoch 103/1000\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 4385.3638 - accuracy: 0.8785 - val_loss: 10137.6260 - val_accuracy: 0.8304\n",
            "Epoch 1/1000\n",
            "181/181 [==============================] - 2s 11ms/step - loss: 19879.1191 - accuracy: 0.5755 - val_loss: 15405.7471 - val_accuracy: 0.5201\n",
            "Epoch 2/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 15075.2031 - accuracy: 0.6296 - val_loss: 14247.4053 - val_accuracy: 0.5800\n",
            "Epoch 3/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 13106.6621 - accuracy: 0.6974 - val_loss: 14001.5322 - val_accuracy: 0.6249\n",
            "Epoch 4/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 11986.7441 - accuracy: 0.7447 - val_loss: 13335.1113 - val_accuracy: 0.6568\n",
            "Epoch 5/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 11142.8916 - accuracy: 0.7707 - val_loss: 13759.5928 - val_accuracy: 0.7187\n",
            "Epoch 6/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 10528.6504 - accuracy: 0.7877 - val_loss: 13275.5928 - val_accuracy: 0.7371\n",
            "Epoch 7/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 10019.3701 - accuracy: 0.8019 - val_loss: 13321.8730 - val_accuracy: 0.7342\n",
            "Epoch 8/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 9436.3311 - accuracy: 0.8107 - val_loss: 13187.8906 - val_accuracy: 0.7305\n",
            "Epoch 9/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 9108.4238 - accuracy: 0.8177 - val_loss: 12997.6426 - val_accuracy: 0.7223\n",
            "Epoch 10/1000\n",
            "180/181 [============================>.] - ETA: 0s - loss: 8961.0615 - accuracy: 0.8222roc-auc_val: 0.8175\n",
            "181/181 [==============================] - 9s 49ms/step - loss: 8941.9561 - accuracy: 0.8221 - val_loss: 12716.7607 - val_accuracy: 0.7561\n",
            "Epoch 11/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 8540.4082 - accuracy: 0.8291 - val_loss: 12920.7373 - val_accuracy: 0.7677\n",
            "Epoch 12/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 8237.2803 - accuracy: 0.8298 - val_loss: 13098.8096 - val_accuracy: 0.7603\n",
            "Epoch 13/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 8012.7744 - accuracy: 0.8313 - val_loss: 12843.1885 - val_accuracy: 0.7585\n",
            "Epoch 14/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 7808.4258 - accuracy: 0.8341 - val_loss: 13044.2812 - val_accuracy: 0.7586\n",
            "Epoch 15/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 7583.0176 - accuracy: 0.8364 - val_loss: 13080.0508 - val_accuracy: 0.7665\n",
            "Epoch 16/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 7368.5986 - accuracy: 0.8399 - val_loss: 13041.6055 - val_accuracy: 0.7498\n",
            "Epoch 17/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 7216.1079 - accuracy: 0.8413 - val_loss: 12983.2344 - val_accuracy: 0.7601\n",
            "Epoch 18/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 7087.9062 - accuracy: 0.8449 - val_loss: 13182.6152 - val_accuracy: 0.7941\n",
            "Epoch 19/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6925.9092 - accuracy: 0.8492 - val_loss: 13050.8887 - val_accuracy: 0.7790\n",
            "Epoch 20/1000\n",
            "177/181 [============================>.] - ETA: 0s - loss: 6848.6299 - accuracy: 0.8462roc-auc_val: 0.8102\n",
            "181/181 [==============================] - 9s 48ms/step - loss: 6829.5815 - accuracy: 0.8464 - val_loss: 13119.1484 - val_accuracy: 0.7808\n",
            "Epoch 21/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6647.4370 - accuracy: 0.8482 - val_loss: 13087.8584 - val_accuracy: 0.7548\n",
            "Epoch 22/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6549.9849 - accuracy: 0.8511 - val_loss: 13542.3076 - val_accuracy: 0.7694\n",
            "Epoch 23/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6401.4365 - accuracy: 0.8510 - val_loss: 13300.7773 - val_accuracy: 0.7697\n",
            "Epoch 24/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6283.0146 - accuracy: 0.8512 - val_loss: 13316.5938 - val_accuracy: 0.7843\n",
            "Epoch 25/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6271.7383 - accuracy: 0.8532 - val_loss: 13070.2393 - val_accuracy: 0.7684\n",
            "Epoch 26/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6154.5493 - accuracy: 0.8549 - val_loss: 13225.8760 - val_accuracy: 0.7748\n",
            "Epoch 27/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6074.0430 - accuracy: 0.8540 - val_loss: 13234.3799 - val_accuracy: 0.7997\n",
            "Epoch 28/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 6007.8369 - accuracy: 0.8570 - val_loss: 13398.3389 - val_accuracy: 0.7940\n",
            "Epoch 29/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5933.4648 - accuracy: 0.8569 - val_loss: 13429.8477 - val_accuracy: 0.7924\n",
            "Epoch 30/1000\n",
            "177/181 [============================>.] - ETA: 0s - loss: 5881.5503 - accuracy: 0.8565roc-auc_val: 0.81\n",
            "181/181 [==============================] - 9s 48ms/step - loss: 5859.5249 - accuracy: 0.8563 - val_loss: 13237.9824 - val_accuracy: 0.7890\n",
            "Epoch 31/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5795.4917 - accuracy: 0.8587 - val_loss: 13519.9307 - val_accuracy: 0.7817\n",
            "Epoch 32/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5701.3506 - accuracy: 0.8612 - val_loss: 13484.5947 - val_accuracy: 0.7734\n",
            "Epoch 33/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5625.6768 - accuracy: 0.8584 - val_loss: 13419.4062 - val_accuracy: 0.7910\n",
            "Epoch 34/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5605.4238 - accuracy: 0.8595 - val_loss: 13345.2197 - val_accuracy: 0.7924\n",
            "Epoch 35/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5466.0801 - accuracy: 0.8611 - val_loss: 13558.7412 - val_accuracy: 0.7967\n",
            "Epoch 36/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5475.8311 - accuracy: 0.8638 - val_loss: 13517.7646 - val_accuracy: 0.7940\n",
            "Epoch 37/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5408.6138 - accuracy: 0.8612 - val_loss: 13458.6641 - val_accuracy: 0.8047\n",
            "Epoch 38/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5340.3828 - accuracy: 0.8629 - val_loss: 13447.2705 - val_accuracy: 0.8034\n",
            "Epoch 39/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5315.7842 - accuracy: 0.8637 - val_loss: 13601.4873 - val_accuracy: 0.8165\n",
            "Epoch 40/1000\n",
            "178/181 [============================>.] - ETA: 0s - loss: 5249.5962 - accuracy: 0.8651roc-auc_val: 0.8067\n",
            "181/181 [==============================] - 9s 48ms/step - loss: 5252.4927 - accuracy: 0.8650 - val_loss: 13525.3125 - val_accuracy: 0.8060\n",
            "Epoch 41/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5170.5127 - accuracy: 0.8660 - val_loss: 13582.7754 - val_accuracy: 0.8069\n",
            "Epoch 42/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5206.7998 - accuracy: 0.8644 - val_loss: 13671.3887 - val_accuracy: 0.8016\n",
            "Epoch 43/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5173.1060 - accuracy: 0.8680 - val_loss: 13632.3486 - val_accuracy: 0.8130\n",
            "Epoch 44/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5161.6709 - accuracy: 0.8676 - val_loss: 13529.3203 - val_accuracy: 0.8094\n",
            "Epoch 45/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5088.9683 - accuracy: 0.8690 - val_loss: 13625.7422 - val_accuracy: 0.8117\n",
            "Epoch 46/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 5021.5586 - accuracy: 0.8687 - val_loss: 13605.0283 - val_accuracy: 0.8135\n",
            "Epoch 47/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4990.3359 - accuracy: 0.8691 - val_loss: 13586.1748 - val_accuracy: 0.8119\n",
            "Epoch 48/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4937.5635 - accuracy: 0.8713 - val_loss: 13494.6592 - val_accuracy: 0.8173\n",
            "Epoch 49/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4985.1646 - accuracy: 0.8698 - val_loss: 13559.4492 - val_accuracy: 0.8095\n",
            "Epoch 50/1000\n",
            "177/181 [============================>.] - ETA: 0s - loss: 4959.9902 - accuracy: 0.8696roc-auc_val: 0.8071\n",
            "181/181 [==============================] - 9s 48ms/step - loss: 4939.0552 - accuracy: 0.8695 - val_loss: 13583.3086 - val_accuracy: 0.8051\n",
            "Epoch 51/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4925.7642 - accuracy: 0.8711 - val_loss: 13431.3564 - val_accuracy: 0.8086\n",
            "Epoch 52/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4777.9912 - accuracy: 0.8693 - val_loss: 13536.7793 - val_accuracy: 0.8164\n",
            "Epoch 53/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4766.4390 - accuracy: 0.8729 - val_loss: 13504.6699 - val_accuracy: 0.8145\n",
            "Epoch 54/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4827.2197 - accuracy: 0.8735 - val_loss: 13556.5430 - val_accuracy: 0.8078\n",
            "Epoch 55/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4738.1182 - accuracy: 0.8749 - val_loss: 13685.8574 - val_accuracy: 0.8206\n",
            "Epoch 56/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4742.2334 - accuracy: 0.8749 - val_loss: 13601.3301 - val_accuracy: 0.8223\n",
            "Epoch 57/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4691.5884 - accuracy: 0.8749 - val_loss: 13489.7266 - val_accuracy: 0.8235\n",
            "Epoch 58/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 4606.6147 - accuracy: 0.8753 - val_loss: 13545.7490 - val_accuracy: 0.8375\n",
            "Epoch 59/1000\n",
            "181/181 [==============================] - 2s 9ms/step - loss: 4595.9990 - accuracy: 0.8773 - val_loss: 13614.5557 - val_accuracy: 0.8237\n",
            "Epoch 60/1000\n",
            "177/181 [============================>.] - ETA: 0s - loss: 4617.8145 - accuracy: 0.8757roc-auc_val: 0.8175\n",
            "181/181 [==============================] - 9s 49ms/step - loss: 4606.2266 - accuracy: 0.8757 - val_loss: 13676.4482 - val_accuracy: 0.8229\n",
            "Epoch 1/1000\n",
            "136/136 [==============================] - 2s 15ms/step - loss: 19355.0879 - accuracy: 0.5501 - val_loss: 15984.7803 - val_accuracy: 0.5592\n",
            "Epoch 2/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 14990.7168 - accuracy: 0.6229 - val_loss: 15555.9404 - val_accuracy: 0.5613\n",
            "Epoch 3/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 13069.8926 - accuracy: 0.6756 - val_loss: 15128.0869 - val_accuracy: 0.6365\n",
            "Epoch 4/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 12005.8281 - accuracy: 0.7174 - val_loss: 14422.5410 - val_accuracy: 0.6430\n",
            "Epoch 5/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 11147.2051 - accuracy: 0.7400 - val_loss: 14613.2373 - val_accuracy: 0.7147\n",
            "Epoch 6/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 10483.8330 - accuracy: 0.7598 - val_loss: 14407.8662 - val_accuracy: 0.7207\n",
            "Epoch 7/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 9853.8350 - accuracy: 0.7814 - val_loss: 14211.7832 - val_accuracy: 0.7222\n",
            "Epoch 8/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 9454.4570 - accuracy: 0.7871 - val_loss: 14039.9658 - val_accuracy: 0.7804\n",
            "Epoch 9/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 8931.9795 - accuracy: 0.7975 - val_loss: 14119.0713 - val_accuracy: 0.7813\n",
            "Epoch 10/1000\n",
            "131/136 [===========================>..] - ETA: 0s - loss: 8605.9590 - accuracy: 0.8038roc-auc_val: 0.8129\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 8575.4346 - accuracy: 0.8037 - val_loss: 14155.6660 - val_accuracy: 0.7730\n",
            "Epoch 11/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 8282.7207 - accuracy: 0.8014 - val_loss: 14087.4092 - val_accuracy: 0.7805\n",
            "Epoch 12/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 7983.7666 - accuracy: 0.8131 - val_loss: 14173.3096 - val_accuracy: 0.7920\n",
            "Epoch 13/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 7622.1265 - accuracy: 0.8147 - val_loss: 13981.2607 - val_accuracy: 0.7910\n",
            "Epoch 14/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 7410.3062 - accuracy: 0.8158 - val_loss: 14126.1562 - val_accuracy: 0.8032\n",
            "Epoch 15/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 7203.7451 - accuracy: 0.8237 - val_loss: 14227.9014 - val_accuracy: 0.7782\n",
            "Epoch 16/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 7036.4629 - accuracy: 0.8232 - val_loss: 14009.8369 - val_accuracy: 0.7877\n",
            "Epoch 17/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 6944.9878 - accuracy: 0.8274 - val_loss: 14279.4883 - val_accuracy: 0.7905\n",
            "Epoch 18/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 6811.4888 - accuracy: 0.8278 - val_loss: 14045.0596 - val_accuracy: 0.7870\n",
            "Epoch 19/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 6389.5581 - accuracy: 0.8314 - val_loss: 14179.9580 - val_accuracy: 0.8022\n",
            "Epoch 20/1000\n",
            "133/136 [============================>.] - ETA: 0s - loss: 6312.2686 - accuracy: 0.8317roc-auc_val: 0.8122\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 6325.7944 - accuracy: 0.8317 - val_loss: 14190.7871 - val_accuracy: 0.8232\n",
            "Epoch 21/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 6362.7163 - accuracy: 0.8374 - val_loss: 14126.1768 - val_accuracy: 0.8180\n",
            "Epoch 22/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 6119.2461 - accuracy: 0.8358 - val_loss: 14274.8232 - val_accuracy: 0.8080\n",
            "Epoch 23/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 6027.2388 - accuracy: 0.8412 - val_loss: 14357.4561 - val_accuracy: 0.8198\n",
            "Epoch 24/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 5813.4346 - accuracy: 0.8393 - val_loss: 14260.2891 - val_accuracy: 0.8235\n",
            "Epoch 25/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 5796.9175 - accuracy: 0.8418 - val_loss: 14502.9463 - val_accuracy: 0.8189\n",
            "Epoch 26/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 5700.4346 - accuracy: 0.8438 - val_loss: 14564.8691 - val_accuracy: 0.8241\n",
            "Epoch 27/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 5701.8530 - accuracy: 0.8443 - val_loss: 14454.0791 - val_accuracy: 0.8330\n",
            "Epoch 28/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 5485.2344 - accuracy: 0.8454 - val_loss: 14423.0488 - val_accuracy: 0.8375\n",
            "Epoch 29/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 5503.9785 - accuracy: 0.8498 - val_loss: 14456.1826 - val_accuracy: 0.8421\n",
            "Epoch 30/1000\n",
            "131/136 [===========================>..] - ETA: 0s - loss: 5354.9766 - accuracy: 0.8495roc-auc_val: 0.8073\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 5363.9497 - accuracy: 0.8495 - val_loss: 14468.9805 - val_accuracy: 0.8265\n",
            "Epoch 31/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 5422.0605 - accuracy: 0.8503 - val_loss: 14476.1514 - val_accuracy: 0.8442\n",
            "Epoch 32/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 5204.9155 - accuracy: 0.8541 - val_loss: 14504.1387 - val_accuracy: 0.8469\n",
            "Epoch 33/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 5162.9297 - accuracy: 0.8523 - val_loss: 14472.2520 - val_accuracy: 0.8498\n",
            "Epoch 34/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 5078.5723 - accuracy: 0.8553 - val_loss: 14619.2090 - val_accuracy: 0.8396\n",
            "Epoch 35/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 5043.5166 - accuracy: 0.8538 - val_loss: 14728.4707 - val_accuracy: 0.8607\n",
            "Epoch 36/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4921.4326 - accuracy: 0.8572 - val_loss: 14564.9795 - val_accuracy: 0.8541\n",
            "Epoch 37/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4892.7529 - accuracy: 0.8604 - val_loss: 14565.7266 - val_accuracy: 0.8373\n",
            "Epoch 38/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 4855.8721 - accuracy: 0.8591 - val_loss: 14540.7021 - val_accuracy: 0.8522\n",
            "Epoch 39/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4795.5464 - accuracy: 0.8633 - val_loss: 14664.0283 - val_accuracy: 0.8546\n",
            "Epoch 40/1000\n",
            "134/136 [============================>.] - ETA: 0s - loss: 4709.0068 - accuracy: 0.8614roc-auc_val: 0.8087\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 4706.2656 - accuracy: 0.8612 - val_loss: 14476.4189 - val_accuracy: 0.8565\n",
            "Epoch 41/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4752.2578 - accuracy: 0.8628 - val_loss: 14604.3770 - val_accuracy: 0.8443\n",
            "Epoch 42/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4593.3574 - accuracy: 0.8595 - val_loss: 14588.0986 - val_accuracy: 0.8530\n",
            "Epoch 43/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4529.4902 - accuracy: 0.8626 - val_loss: 14745.2686 - val_accuracy: 0.8602\n",
            "Epoch 44/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4498.7773 - accuracy: 0.8657 - val_loss: 14731.9316 - val_accuracy: 0.8725\n",
            "Epoch 45/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4573.8359 - accuracy: 0.8660 - val_loss: 14649.1943 - val_accuracy: 0.8608\n",
            "Epoch 46/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4384.0698 - accuracy: 0.8626 - val_loss: 14650.6064 - val_accuracy: 0.8603\n",
            "Epoch 47/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4385.6162 - accuracy: 0.8667 - val_loss: 14748.7393 - val_accuracy: 0.8598\n",
            "Epoch 48/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4317.5430 - accuracy: 0.8679 - val_loss: 14698.4033 - val_accuracy: 0.8599\n",
            "Epoch 49/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4404.6987 - accuracy: 0.8670 - val_loss: 14774.2373 - val_accuracy: 0.8662\n",
            "Epoch 50/1000\n",
            "136/136 [==============================] - ETA: 0s - loss: 4308.5142 - accuracy: 0.8725roc-auc_val: 0.8054\n",
            "136/136 [==============================] - 12s 85ms/step - loss: 4308.5142 - accuracy: 0.8725 - val_loss: 14761.7148 - val_accuracy: 0.8720\n",
            "Epoch 51/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4328.5918 - accuracy: 0.8688 - val_loss: 14811.3262 - val_accuracy: 0.8647\n",
            "Epoch 52/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 4220.3608 - accuracy: 0.8690 - val_loss: 14765.8867 - val_accuracy: 0.8643\n",
            "Epoch 53/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 4277.2827 - accuracy: 0.8691 - val_loss: 14792.4170 - val_accuracy: 0.8717\n",
            "Epoch 54/1000\n",
            "136/136 [==============================] - 1s 11ms/step - loss: 4178.4648 - accuracy: 0.8693 - val_loss: 14877.3682 - val_accuracy: 0.8686\n",
            "Epoch 55/1000\n",
            "136/136 [==============================] - 1s 11ms/step - loss: 4079.1338 - accuracy: 0.8724 - val_loss: 14806.5303 - val_accuracy: 0.8774\n",
            "Epoch 56/1000\n",
            "136/136 [==============================] - 1s 11ms/step - loss: 4082.9397 - accuracy: 0.8729 - val_loss: 14939.5518 - val_accuracy: 0.8787\n",
            "Epoch 57/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 4031.2048 - accuracy: 0.8739 - val_loss: 14841.8965 - val_accuracy: 0.8850\n",
            "Epoch 58/1000\n",
            "136/136 [==============================] - 1s 11ms/step - loss: 4071.9446 - accuracy: 0.8760 - val_loss: 14855.8545 - val_accuracy: 0.8753\n",
            "Epoch 59/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 4073.3840 - accuracy: 0.8736 - val_loss: 14901.2764 - val_accuracy: 0.8704\n",
            "Epoch 60/1000\n",
            "129/136 [===========================>..] - ETA: 0s - loss: 3968.7346 - accuracy: 0.8737roc-auc_val: 0.8033\n",
            "136/136 [==============================] - 12s 86ms/step - loss: 3948.6213 - accuracy: 0.8736 - val_loss: 14981.0488 - val_accuracy: 0.8689\n",
            "Epoch 61/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 3940.3071 - accuracy: 0.8759 - val_loss: 15010.3955 - val_accuracy: 0.8821\n",
            "Epoch 62/1000\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 3901.7681 - accuracy: 0.8776 - val_loss: 15032.3389 - val_accuracy: 0.8703\n",
            "Epoch 63/1000\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 4051.3853 - accuracy: 0.8732 - val_loss: 15126.1182 - val_accuracy: 0.8798\n",
            "Epoch 1/1000\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 19189.2715 - accuracy: 0.5767 - val_loss: 17362.6074 - val_accuracy: 0.5374\n",
            "Epoch 2/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 14905.6611 - accuracy: 0.6324 - val_loss: 16767.7969 - val_accuracy: 0.6932\n",
            "Epoch 3/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 12783.6943 - accuracy: 0.6820 - val_loss: 16482.1445 - val_accuracy: 0.7042\n",
            "Epoch 4/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 11720.3213 - accuracy: 0.6947 - val_loss: 16264.5596 - val_accuracy: 0.6998\n",
            "Epoch 5/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 10922.6328 - accuracy: 0.7219 - val_loss: 15553.0371 - val_accuracy: 0.7203\n",
            "Epoch 6/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 10009.5791 - accuracy: 0.7406 - val_loss: 15459.6602 - val_accuracy: 0.7302\n",
            "Epoch 7/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 9466.6475 - accuracy: 0.7514 - val_loss: 15359.5693 - val_accuracy: 0.7248\n",
            "Epoch 8/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 8880.3105 - accuracy: 0.7629 - val_loss: 15404.6787 - val_accuracy: 0.7317\n",
            "Epoch 9/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 8483.7256 - accuracy: 0.7815 - val_loss: 15013.6416 - val_accuracy: 0.7794\n",
            "Epoch 10/1000\n",
            "81/88 [==========================>...] - ETA: 0s - loss: 8050.9297 - accuracy: 0.7908roc-auc_val: 0.8107\n",
            "88/88 [==============================] - 15s 166ms/step - loss: 8124.0952 - accuracy: 0.7912 - val_loss: 15041.6895 - val_accuracy: 0.7922\n",
            "Epoch 11/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 7657.9609 - accuracy: 0.7955 - val_loss: 15221.1602 - val_accuracy: 0.7664\n",
            "Epoch 12/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 7340.9409 - accuracy: 0.8043 - val_loss: 15225.5039 - val_accuracy: 0.7883\n",
            "Epoch 13/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 7091.3008 - accuracy: 0.8131 - val_loss: 15284.5742 - val_accuracy: 0.7996\n",
            "Epoch 14/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 6725.9507 - accuracy: 0.8163 - val_loss: 15403.8076 - val_accuracy: 0.8007\n",
            "Epoch 15/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 6589.4395 - accuracy: 0.8197 - val_loss: 15411.1260 - val_accuracy: 0.8087\n",
            "Epoch 16/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 6434.7246 - accuracy: 0.8254 - val_loss: 15466.4072 - val_accuracy: 0.8201\n",
            "Epoch 17/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 6258.8320 - accuracy: 0.8270 - val_loss: 15260.3594 - val_accuracy: 0.8175\n",
            "Epoch 18/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 5929.6313 - accuracy: 0.8288 - val_loss: 15402.2646 - val_accuracy: 0.8282\n",
            "Epoch 19/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 5809.6680 - accuracy: 0.8346 - val_loss: 15197.0879 - val_accuracy: 0.8270\n",
            "Epoch 20/1000\n",
            "87/88 [============================>.] - ETA: 0s - loss: 5768.6948 - accuracy: 0.8366roc-auc_val: 0.8087\n",
            "88/88 [==============================] - 15s 167ms/step - loss: 5758.9751 - accuracy: 0.8368 - val_loss: 15229.2070 - val_accuracy: 0.8164\n",
            "Epoch 21/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 5681.2148 - accuracy: 0.8364 - val_loss: 15420.3047 - val_accuracy: 0.8261\n",
            "Epoch 22/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 5343.4077 - accuracy: 0.8432 - val_loss: 15388.9023 - val_accuracy: 0.8353\n",
            "Epoch 23/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 5293.5488 - accuracy: 0.8465 - val_loss: 15468.8740 - val_accuracy: 0.8274\n",
            "Epoch 24/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 5219.3008 - accuracy: 0.8448 - val_loss: 15459.6885 - val_accuracy: 0.8294\n",
            "Epoch 25/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 5062.7573 - accuracy: 0.8500 - val_loss: 15555.6045 - val_accuracy: 0.8342\n",
            "Epoch 26/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4990.0259 - accuracy: 0.8519 - val_loss: 15639.4346 - val_accuracy: 0.8326\n",
            "Epoch 27/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4876.3164 - accuracy: 0.8557 - val_loss: 15517.6309 - val_accuracy: 0.8311\n",
            "Epoch 28/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4613.5967 - accuracy: 0.8541 - val_loss: 15645.7676 - val_accuracy: 0.8484\n",
            "Epoch 29/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4732.6133 - accuracy: 0.8595 - val_loss: 15826.4883 - val_accuracy: 0.8474\n",
            "Epoch 30/1000\n",
            "81/88 [==========================>...] - ETA: 0s - loss: 4526.9238 - accuracy: 0.8581roc-auc_val: 0.8001\n",
            "88/88 [==============================] - 15s 167ms/step - loss: 4518.5532 - accuracy: 0.8587 - val_loss: 15872.2783 - val_accuracy: 0.8540\n",
            "Epoch 31/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4472.1362 - accuracy: 0.8602 - val_loss: 16112.0459 - val_accuracy: 0.8582\n",
            "Epoch 32/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4375.6191 - accuracy: 0.8625 - val_loss: 16389.7227 - val_accuracy: 0.8672\n",
            "Epoch 33/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4261.2676 - accuracy: 0.8650 - val_loss: 15931.5566 - val_accuracy: 0.8599\n",
            "Epoch 34/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4252.5845 - accuracy: 0.8638 - val_loss: 16133.4863 - val_accuracy: 0.8505\n",
            "Epoch 35/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4229.7612 - accuracy: 0.8664 - val_loss: 16096.9941 - val_accuracy: 0.8439\n",
            "Epoch 36/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4068.2388 - accuracy: 0.8642 - val_loss: 16272.0693 - val_accuracy: 0.8600\n",
            "Epoch 37/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3998.0059 - accuracy: 0.8726 - val_loss: 16359.1807 - val_accuracy: 0.8679\n",
            "Epoch 38/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 4023.2051 - accuracy: 0.8707 - val_loss: 16275.3633 - val_accuracy: 0.8486\n",
            "Epoch 39/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3945.4607 - accuracy: 0.8724 - val_loss: 16537.6250 - val_accuracy: 0.8557\n",
            "Epoch 40/1000\n",
            "87/88 [============================>.] - ETA: 0s - loss: 3916.4041 - accuracy: 0.8717roc-auc_val: 0.7931\n",
            "88/88 [==============================] - 15s 167ms/step - loss: 3898.1997 - accuracy: 0.8719 - val_loss: 16381.6484 - val_accuracy: 0.8591\n",
            "Epoch 41/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3782.7405 - accuracy: 0.8729 - val_loss: 16445.8594 - val_accuracy: 0.8672\n",
            "Epoch 42/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3801.9849 - accuracy: 0.8736 - val_loss: 16308.7988 - val_accuracy: 0.8597\n",
            "Epoch 43/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3703.7192 - accuracy: 0.8761 - val_loss: 16402.5566 - val_accuracy: 0.8640\n",
            "Epoch 44/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3700.5913 - accuracy: 0.8786 - val_loss: 16401.5215 - val_accuracy: 0.8695\n",
            "Epoch 45/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3709.8230 - accuracy: 0.8794 - val_loss: 16306.8984 - val_accuracy: 0.8681\n",
            "Epoch 46/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3646.5557 - accuracy: 0.8782 - val_loss: 16380.5996 - val_accuracy: 0.8764\n",
            "Epoch 47/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3509.9849 - accuracy: 0.8806 - val_loss: 16539.0605 - val_accuracy: 0.8736\n",
            "Epoch 48/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3458.6936 - accuracy: 0.8825 - val_loss: 16438.6816 - val_accuracy: 0.8711\n",
            "Epoch 49/1000\n",
            "88/88 [==============================] - 1s 14ms/step - loss: 3536.0388 - accuracy: 0.8811 - val_loss: 16548.0625 - val_accuracy: 0.8690\n",
            "Epoch 50/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 3350.7849 - accuracy: 0.8828roc-auc_val: 0.796\n",
            "88/88 [==============================] - 15s 171ms/step - loss: 3350.7849 - accuracy: 0.8828 - val_loss: 16397.5430 - val_accuracy: 0.8784\n",
            "Epoch 51/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3378.7954 - accuracy: 0.8845 - val_loss: 16514.1230 - val_accuracy: 0.8820\n",
            "Epoch 52/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3354.2012 - accuracy: 0.8838 - val_loss: 16445.7754 - val_accuracy: 0.8764\n",
            "Epoch 53/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3302.3726 - accuracy: 0.8820 - val_loss: 16577.5098 - val_accuracy: 0.8893\n",
            "Epoch 54/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3309.2637 - accuracy: 0.8863 - val_loss: 16712.9141 - val_accuracy: 0.8848\n",
            "Epoch 55/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3218.8010 - accuracy: 0.8860 - val_loss: 16798.7598 - val_accuracy: 0.8880\n",
            "Epoch 56/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3236.8789 - accuracy: 0.8855 - val_loss: 16641.7246 - val_accuracy: 0.8795\n",
            "Epoch 57/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3170.7769 - accuracy: 0.8879 - val_loss: 16684.6777 - val_accuracy: 0.8845\n",
            "Epoch 58/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3164.7251 - accuracy: 0.8871 - val_loss: 16745.5488 - val_accuracy: 0.8851\n",
            "Epoch 59/1000\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 3127.8030 - accuracy: 0.8898 - val_loss: 16751.3164 - val_accuracy: 0.8847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw5PePWLxWIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e80dcb57-ff58-4368-afe2-1128d90fb633"
      },
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "for i in dk.keys():\n",
        "  sns.distplot(dk[i])\n",
        "  plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNDmjro-2ndD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}