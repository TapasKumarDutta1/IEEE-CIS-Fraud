{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_focal_loss_2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_focal_loss_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "70c693f5-0978-40c9-97c5-83c8847de5eb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXDyhihenRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "5100a666-8a15-4dd7-b3a2-63b65597b1be"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 96% 50.0M/52.2M [00:01<00:00, 27.9MB/s]\n",
            "100% 52.2M/52.2M [00:01<00:00, 37.3MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 107MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 160MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 98% 57.0M/58.3M [00:00<00:00, 79.9MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 91.9MB/s]\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 224MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_0F8Zfep7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_fold=5\n",
        "lr=0.001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train.csv')\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test.csv')\n",
        "ls=list(trn.filter(regex='V'))\n",
        "trn=trn.drop(ls,1)\n",
        "tst=tst.drop(ls,1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2yCpAINM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9D7_Mt01Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDrCIAqHzl6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ffcb89a6-316f-489f-d3ab-79f26270cfce"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols=list(trn.select_dtypes(include=object))\n",
        "for col in cols:\n",
        "  le=LabelEncoderExt()\n",
        "  le.fit(trn[col].astype(str))\n",
        "  trn[col]=le.transform(trn[col].astype(str))\n",
        "  tst[col] = tst[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "  tst[col]=le.transform(tst[col].astype(str))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EWJ-hzcznam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "ss=StandardScaler()\n",
        "frd=trn['isFraud']\n",
        "ls=list(trn)\n",
        "trn=ss.fit_transform(trn.drop(['isFraud'],1))\n",
        "trn=pd.DataFrame(trn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF5OQjb1zo6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls.remove('isFraud')\n",
        "trn.columns=ls\n",
        "trn['isFraud']=frd\n",
        "\n",
        "ls=list(tst)\n",
        "tst=ss.fit_transform(tst)\n",
        "tst=pd.DataFrame(tst)\n",
        "tst.columns=ls"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "478553f4-7a0a-4d16-b6db-b5430334eaf7"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 860.54 MB\n",
            "Memory usage after optimization is: 215.14 MB\n",
            "Decreased by 75.0%\n",
            "Memory usage of dataframe is 734.49 MB\n",
            "Memory usage after optimization is: 183.62 MB\n",
            "Decreased by 75.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArRiZ5lS0F9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d2d8099-f205-403e-8988-5dd2bffa865d"
      },
      "source": [
        "trn_n=pd.read_csv('train_transaction.csv.zip')\n",
        "tst_n=pd.read_csv('test_transaction.csv.zip')\n",
        "trn['month']=trn_n['TransactionDT']//(86400*30)\n",
        "trn_n.head()\n",
        "trn_ls=list(trn_n)\n",
        "tst_ls=list(tst_n)\n",
        "for col in trn:\n",
        "  if col in trn_ls:\n",
        "    trn[col+'_isna']=trn_n[col].isna().astype('uint8')\n",
        "for col in tst:\n",
        "  if col in tst_ls:\n",
        "    tst[col+'_isna']=tst_n[col].isna().astype('uint8')\n",
        "import gc\n",
        "del([trn_n,tst_n])\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f0r3SuH1K97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn=trn.drop(['isFraud_isna'],1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HQ20JqWATak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        if self.ep%10==0:\n",
        "          y_pred_val = self.model.predict(self.x_val)\n",
        "          roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "          print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnQIVOLKBFIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "153cdc32-a7c6-430a-8424-d08fdcc3ef56"
      },
      "source": [
        "1-0.036"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq6gnpm4CjDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9c273b0-1d90-41db-a6eb-c6231b547c9f"
      },
      "source": [
        "def fl():\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        gamma=0.3\n",
        "        alpha=1-0.036\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\n",
        "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
        "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
        "\n",
        "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
        "    return focal_loss\n",
        "dk={}\n",
        "def load_model():\n",
        "  K.clear_session()\n",
        "  inp=Input((233,))\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=inp,outputs=x)\n",
        "  return mod\n",
        "for en,month in enumerate([(4,5),(3,4),(3,5)]):\n",
        "  train=trn.loc[trn['month']>=month[1]]\n",
        "  test=trn.loc[trn['month']<=month[0]]\n",
        "  train=train.drop(['month'],1)\n",
        "  test=test.drop(['month'],1)\n",
        "  mod=load_model()\n",
        "  mod.compile(optimizer=Adam(0.0001,decay=1e-3),loss=fl())\n",
        "  roc = RocCallback(\n",
        "                  validation_data=(test.drop(['isFraud'],1), test['isFraud']))\n",
        "  es=EarlyStopping(monitor='val_loss',min_delta=0.0001,mode='min',restore_best_weights=True,patience=50)\n",
        "  mod.fit(train.drop(['isFraud'],1),train['isFraud'],validation_data=(test.drop(['isFraud'],1),test['isFraud']),batch_size=2048,epochs=1000,callbacks=[es,roc])\n",
        "  del([train,test])\n",
        "  gc.collect()\n",
        "  df=trn.loc[trn['month']==6].reset_index(drop=True).drop(['month'],1)\n",
        "  pre=mod.predict(df.drop(['isFraud'],1))\n",
        "  scr=roc_auc_score(df['isFraud'],pre)\n",
        "  dk[str(scr)]=mod.predict(tst)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "47/47 [==============================] - 1s 25ms/step - loss: 92.5732 - val_loss: 72.2690\n",
            "Epoch 2/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 81.9041 - val_loss: 69.7984\n",
            "Epoch 3/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 78.4321 - val_loss: 68.6832\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 74.5996 - val_loss: 67.9505\n",
            "Epoch 5/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 72.8760 - val_loss: 67.5111\n",
            "Epoch 6/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 70.8984 - val_loss: 67.0985\n",
            "Epoch 7/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 69.7395 - val_loss: 67.2605\n",
            "Epoch 8/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 68.8653 - val_loss: 66.9667\n",
            "Epoch 9/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 67.5753 - val_loss: 66.8725\n",
            "Epoch 10/1000\n",
            "43/47 [==========================>...] - ETA: 0s - loss: 67.6555roc-auc_val: 0.779\n",
            "47/47 [==============================] - 14s 289ms/step - loss: 67.5013 - val_loss: 66.7521\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 67.1016 - val_loss: 66.4811\n",
            "Epoch 12/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 64.9499 - val_loss: 66.2747\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 64.6849 - val_loss: 65.9324\n",
            "Epoch 14/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 64.3433 - val_loss: 65.9203\n",
            "Epoch 15/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 63.0870 - val_loss: 65.9760\n",
            "Epoch 16/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 63.0239 - val_loss: 65.6022\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 62.1815 - val_loss: 65.5616\n",
            "Epoch 18/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 61.8903 - val_loss: 65.6299\n",
            "Epoch 19/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 61.5048 - val_loss: 65.4780\n",
            "Epoch 20/1000\n",
            "38/47 [=======================>......] - ETA: 0s - loss: 62.4733roc-auc_val: 0.791\n",
            "47/47 [==============================] - 13s 282ms/step - loss: 61.6054 - val_loss: 65.3677\n",
            "Epoch 21/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 60.4664 - val_loss: 65.2649\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 59.4792 - val_loss: 65.1826\n",
            "Epoch 23/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 59.9426 - val_loss: 65.0962\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 59.5826 - val_loss: 65.1060\n",
            "Epoch 25/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 58.8550 - val_loss: 65.0772\n",
            "Epoch 26/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 58.5023 - val_loss: 65.2271\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 58.5990 - val_loss: 64.9662\n",
            "Epoch 28/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 58.1322 - val_loss: 65.0227\n",
            "Epoch 29/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 57.1672 - val_loss: 64.8630\n",
            "Epoch 30/1000\n",
            "41/47 [=========================>....] - ETA: 0s - loss: 57.6802roc-auc_val: 0.7969\n",
            "47/47 [==============================] - 13s 284ms/step - loss: 57.3893 - val_loss: 64.8352\n",
            "Epoch 31/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 57.2904 - val_loss: 64.8428\n",
            "Epoch 32/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 57.5127 - val_loss: 64.8980\n",
            "Epoch 33/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 57.1924 - val_loss: 64.9740\n",
            "Epoch 34/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 57.0967 - val_loss: 64.8861\n",
            "Epoch 35/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 56.7752 - val_loss: 64.7551\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 56.6949 - val_loss: 64.7323\n",
            "Epoch 37/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 56.0836 - val_loss: 64.6981\n",
            "Epoch 38/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 56.3049 - val_loss: 64.7199\n",
            "Epoch 39/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 55.8586 - val_loss: 64.6965\n",
            "Epoch 40/1000\n",
            "41/47 [=========================>....] - ETA: 0s - loss: 55.4188roc-auc_val: 0.7998\n",
            "47/47 [==============================] - 13s 279ms/step - loss: 55.5763 - val_loss: 64.8286\n",
            "Epoch 41/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 55.3046 - val_loss: 64.7675\n",
            "Epoch 42/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 54.8546 - val_loss: 64.8248\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 55.7594 - val_loss: 64.7711\n",
            "Epoch 44/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 55.1432 - val_loss: 64.8458\n",
            "Epoch 45/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 54.4767 - val_loss: 64.7837\n",
            "Epoch 46/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 53.8920 - val_loss: 64.8203\n",
            "Epoch 47/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 54.3443 - val_loss: 64.9067\n",
            "Epoch 48/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 53.7436 - val_loss: 64.8305\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 54.1676 - val_loss: 64.8426\n",
            "Epoch 50/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 53.2455roc-auc_val: 0.8015\n",
            "47/47 [==============================] - 13s 281ms/step - loss: 53.2348 - val_loss: 64.7293\n",
            "Epoch 51/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 54.2026 - val_loss: 64.7087\n",
            "Epoch 52/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 53.8145 - val_loss: 64.7509\n",
            "Epoch 53/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 52.9109 - val_loss: 64.6906\n",
            "Epoch 54/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 53.1227 - val_loss: 64.7731\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 52.9275 - val_loss: 64.7090\n",
            "Epoch 56/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 52.9942 - val_loss: 64.7761\n",
            "Epoch 57/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 53.1077 - val_loss: 64.7509\n",
            "Epoch 58/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 53.1725 - val_loss: 64.7883\n",
            "Epoch 59/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.9170 - val_loss: 64.6964\n",
            "Epoch 60/1000\n",
            "43/47 [==========================>...] - ETA: 0s - loss: 52.2428roc-auc_val: 0.8033\n",
            "47/47 [==============================] - 13s 280ms/step - loss: 51.7261 - val_loss: 64.7156\n",
            "Epoch 61/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 52.2188 - val_loss: 64.7208\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 52.2223 - val_loss: 64.7840\n",
            "Epoch 63/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 52.4025 - val_loss: 64.7673\n",
            "Epoch 64/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.1741 - val_loss: 64.7675\n",
            "Epoch 65/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.4566 - val_loss: 64.7665\n",
            "Epoch 66/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.5888 - val_loss: 64.7717\n",
            "Epoch 67/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 52.0586 - val_loss: 64.8009\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.6310 - val_loss: 64.8037\n",
            "Epoch 69/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 50.7475 - val_loss: 64.9317\n",
            "Epoch 70/1000\n",
            "42/47 [=========================>....] - ETA: 0s - loss: 50.5231roc-auc_val: 0.8044\n",
            "47/47 [==============================] - 13s 282ms/step - loss: 50.2804 - val_loss: 64.8773\n",
            "Epoch 71/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.6516 - val_loss: 64.9520\n",
            "Epoch 72/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 51.2831 - val_loss: 64.9396\n",
            "Epoch 73/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 51.5579 - val_loss: 64.9485\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 51.1238 - val_loss: 64.9178\n",
            "Epoch 75/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 51.0865 - val_loss: 64.8909\n",
            "Epoch 76/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.1668 - val_loss: 64.8623\n",
            "Epoch 77/1000\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 50.8321 - val_loss: 64.9693\n",
            "Epoch 78/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 50.4233 - val_loss: 64.9516\n",
            "Epoch 79/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.6524 - val_loss: 65.0465\n",
            "Epoch 80/1000\n",
            "42/47 [=========================>....] - ETA: 0s - loss: 50.4454roc-auc_val: 0.8054\n",
            "47/47 [==============================] - 13s 277ms/step - loss: 50.6287 - val_loss: 65.1085\n",
            "Epoch 81/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 50.6357 - val_loss: 64.9983\n",
            "Epoch 82/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 50.8245 - val_loss: 65.0003\n",
            "Epoch 83/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 50.2290 - val_loss: 64.9306\n",
            "Epoch 84/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.6552 - val_loss: 64.9593\n",
            "Epoch 85/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.8687 - val_loss: 65.0227\n",
            "Epoch 86/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 50.1098 - val_loss: 65.0375\n",
            "Epoch 87/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.1634 - val_loss: 65.0498\n",
            "Epoch 88/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.6232 - val_loss: 65.0739\n",
            "Epoch 89/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.6461 - val_loss: 65.0906\n",
            "Epoch 90/1000\n",
            "41/47 [=========================>....] - ETA: 0s - loss: 50.1973roc-auc_val: 0.8062\n",
            "47/47 [==============================] - 13s 278ms/step - loss: 49.9378 - val_loss: 65.1494\n",
            "Epoch 91/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.9704 - val_loss: 65.1979\n",
            "Epoch 92/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.5551 - val_loss: 65.2729\n",
            "Epoch 93/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.7318 - val_loss: 65.2965\n",
            "Epoch 94/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.3910 - val_loss: 65.2933\n",
            "Epoch 95/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.1278 - val_loss: 65.2731\n",
            "Epoch 96/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.8737 - val_loss: 65.2581\n",
            "Epoch 97/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.0635 - val_loss: 65.2668\n",
            "Epoch 98/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.1821 - val_loss: 65.2604\n",
            "Epoch 99/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.3382 - val_loss: 65.3109\n",
            "Epoch 100/1000\n",
            "37/47 [======================>.......] - ETA: 0s - loss: 49.0262roc-auc_val: 0.8065\n",
            "47/47 [==============================] - 13s 278ms/step - loss: 48.9905 - val_loss: 65.3405\n",
            "Epoch 101/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 48.8817 - val_loss: 65.4227\n",
            "Epoch 102/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.2775 - val_loss: 65.4048\n",
            "Epoch 103/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 49.0398 - val_loss: 65.4094\n",
            "Epoch 1/1000\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 88.4460 - val_loss: 69.8639\n",
            "Epoch 2/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 78.5110 - val_loss: 67.6898\n",
            "Epoch 3/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 75.1855 - val_loss: 67.2255\n",
            "Epoch 4/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 71.9486 - val_loss: 66.4631\n",
            "Epoch 5/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 70.7619 - val_loss: 66.2107\n",
            "Epoch 6/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 68.5919 - val_loss: 65.8296\n",
            "Epoch 7/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 66.7532 - val_loss: 65.1666\n",
            "Epoch 8/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 66.1145 - val_loss: 64.7037\n",
            "Epoch 9/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 65.4118 - val_loss: 64.4377\n",
            "Epoch 10/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 64.3319roc-auc_val: 0.7965\n",
            "88/88 [==============================] - 11s 127ms/step - loss: 64.6366 - val_loss: 64.5081\n",
            "Epoch 11/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 64.0246 - val_loss: 64.1642\n",
            "Epoch 12/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 63.2085 - val_loss: 63.7816\n",
            "Epoch 13/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 62.4958 - val_loss: 63.8657\n",
            "Epoch 14/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 62.2278 - val_loss: 63.7411\n",
            "Epoch 15/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 60.8833 - val_loss: 63.5359\n",
            "Epoch 16/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 61.1659 - val_loss: 63.3448\n",
            "Epoch 17/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 60.8345 - val_loss: 63.2355\n",
            "Epoch 18/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 59.5100 - val_loss: 63.2243\n",
            "Epoch 19/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 59.6328 - val_loss: 63.0677\n",
            "Epoch 20/1000\n",
            "83/88 [===========================>..] - ETA: 0s - loss: 59.5384roc-auc_val: 0.8059\n",
            "88/88 [==============================] - 11s 126ms/step - loss: 59.7352 - val_loss: 63.0226\n",
            "Epoch 21/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 58.9689 - val_loss: 62.9404\n",
            "Epoch 22/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 59.0096 - val_loss: 62.8594\n",
            "Epoch 23/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 59.0483 - val_loss: 62.8028\n",
            "Epoch 24/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 58.3611 - val_loss: 62.7454\n",
            "Epoch 25/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 57.8805 - val_loss: 62.6722\n",
            "Epoch 26/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 58.3748 - val_loss: 62.6020\n",
            "Epoch 27/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 57.5029 - val_loss: 62.5341\n",
            "Epoch 28/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 57.0566 - val_loss: 62.3647\n",
            "Epoch 29/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 57.5316 - val_loss: 62.3852\n",
            "Epoch 30/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 56.7807roc-auc_val: 0.8106\n",
            "88/88 [==============================] - 11s 127ms/step - loss: 56.7585 - val_loss: 62.3355\n",
            "Epoch 31/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 56.7155 - val_loss: 62.3418\n",
            "Epoch 32/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 57.2298 - val_loss: 62.3495\n",
            "Epoch 33/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 56.2687 - val_loss: 62.2756\n",
            "Epoch 34/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 56.0149 - val_loss: 62.2398\n",
            "Epoch 35/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 56.0692 - val_loss: 62.1719\n",
            "Epoch 36/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 56.0760 - val_loss: 62.1815\n",
            "Epoch 37/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.5444 - val_loss: 62.1352\n",
            "Epoch 38/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.3084 - val_loss: 62.0559\n",
            "Epoch 39/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.6816 - val_loss: 62.0136\n",
            "Epoch 40/1000\n",
            "82/88 [==========================>...] - ETA: 0s - loss: 55.6356roc-auc_val: 0.8131\n",
            "88/88 [==============================] - 11s 126ms/step - loss: 55.4755 - val_loss: 61.9459\n",
            "Epoch 41/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.6032 - val_loss: 61.9388\n",
            "Epoch 42/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.1304 - val_loss: 61.8872\n",
            "Epoch 43/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 54.9489 - val_loss: 61.8664\n",
            "Epoch 44/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 54.5842 - val_loss: 61.8579\n",
            "Epoch 45/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 54.7318 - val_loss: 61.8241\n",
            "Epoch 46/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 55.0233 - val_loss: 61.8676\n",
            "Epoch 47/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 54.3985 - val_loss: 61.8633\n",
            "Epoch 48/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 54.2645 - val_loss: 61.8400\n",
            "Epoch 49/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.7565 - val_loss: 61.8134\n",
            "Epoch 50/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 54.2142roc-auc_val: 0.8145\n",
            "88/88 [==============================] - 11s 130ms/step - loss: 54.1290 - val_loss: 61.7881\n",
            "Epoch 51/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 54.1244 - val_loss: 61.7811\n",
            "Epoch 52/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 54.0746 - val_loss: 61.7363\n",
            "Epoch 53/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.5261 - val_loss: 61.7209\n",
            "Epoch 54/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.8278 - val_loss: 61.6745\n",
            "Epoch 55/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.3131 - val_loss: 61.6444\n",
            "Epoch 56/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.9872 - val_loss: 61.6293\n",
            "Epoch 57/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.2650 - val_loss: 61.6381\n",
            "Epoch 58/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.7822 - val_loss: 61.6033\n",
            "Epoch 59/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.1454 - val_loss: 61.5868\n",
            "Epoch 60/1000\n",
            "78/88 [=========================>....] - ETA: 0s - loss: 53.0791roc-auc_val: 0.8162\n",
            "88/88 [==============================] - 11s 126ms/step - loss: 53.0517 - val_loss: 61.5537\n",
            "Epoch 61/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.8320 - val_loss: 61.5585\n",
            "Epoch 62/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.4927 - val_loss: 61.5353\n",
            "Epoch 63/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.4966 - val_loss: 61.5348\n",
            "Epoch 64/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.0336 - val_loss: 61.4905\n",
            "Epoch 65/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 53.4623 - val_loss: 61.5019\n",
            "Epoch 66/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.9391 - val_loss: 61.4887\n",
            "Epoch 67/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.2503 - val_loss: 61.4674\n",
            "Epoch 68/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.7089 - val_loss: 61.4778\n",
            "Epoch 69/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.2287 - val_loss: 61.4869\n",
            "Epoch 70/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 51.8410roc-auc_val: 0.8174\n",
            "88/88 [==============================] - 12s 134ms/step - loss: 51.9848 - val_loss: 61.4734\n",
            "Epoch 71/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 52.4130 - val_loss: 61.4201\n",
            "Epoch 72/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 51.9291 - val_loss: 61.3923\n",
            "Epoch 73/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 52.0114 - val_loss: 61.3621\n",
            "Epoch 74/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 51.5507 - val_loss: 61.3449\n",
            "Epoch 75/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 51.8369 - val_loss: 61.3395\n",
            "Epoch 76/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.0934 - val_loss: 61.3654\n",
            "Epoch 77/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 52.0377 - val_loss: 61.3618\n",
            "Epoch 78/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.4265 - val_loss: 61.3776\n",
            "Epoch 79/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.3923 - val_loss: 61.3385\n",
            "Epoch 80/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 51.3004roc-auc_val: 0.8185\n",
            "88/88 [==============================] - 11s 126ms/step - loss: 51.2364 - val_loss: 61.3339\n",
            "Epoch 81/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.9834 - val_loss: 61.3159\n",
            "Epoch 82/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.2695 - val_loss: 61.3085\n",
            "Epoch 83/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.2400 - val_loss: 61.3296\n",
            "Epoch 84/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.2571 - val_loss: 61.2943\n",
            "Epoch 85/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.1997 - val_loss: 61.3113\n",
            "Epoch 86/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.4475 - val_loss: 61.3089\n",
            "Epoch 87/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.2882 - val_loss: 61.2858\n",
            "Epoch 88/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.8878 - val_loss: 61.2784\n",
            "Epoch 89/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.9502 - val_loss: 61.2813\n",
            "Epoch 90/1000\n",
            "85/88 [===========================>..] - ETA: 0s - loss: 50.7283roc-auc_val: 0.8193\n",
            "88/88 [==============================] - 11s 127ms/step - loss: 50.8009 - val_loss: 61.2746\n",
            "Epoch 91/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.8215 - val_loss: 61.2372\n",
            "Epoch 92/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.7808 - val_loss: 61.2309\n",
            "Epoch 93/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.9924 - val_loss: 61.2349\n",
            "Epoch 94/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.6872 - val_loss: 61.2331\n",
            "Epoch 95/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.4171 - val_loss: 61.2573\n",
            "Epoch 96/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 51.0475 - val_loss: 61.2594\n",
            "Epoch 97/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.4822 - val_loss: 61.2354\n",
            "Epoch 98/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.6376 - val_loss: 61.2344\n",
            "Epoch 99/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.5647 - val_loss: 61.2382\n",
            "Epoch 100/1000\n",
            "84/88 [===========================>..] - ETA: 0s - loss: 50.7820roc-auc_val: 0.8198\n",
            "88/88 [==============================] - 11s 130ms/step - loss: 50.6353 - val_loss: 61.2296\n",
            "Epoch 101/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.4510 - val_loss: 61.2239\n",
            "Epoch 102/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.1256 - val_loss: 61.2200\n",
            "Epoch 103/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.8590 - val_loss: 61.2178\n",
            "Epoch 104/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.0401 - val_loss: 61.2100\n",
            "Epoch 105/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.8756 - val_loss: 61.1935\n",
            "Epoch 106/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.9194 - val_loss: 61.1772\n",
            "Epoch 107/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.5345 - val_loss: 61.1928\n",
            "Epoch 108/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 50.0085 - val_loss: 61.1671\n",
            "Epoch 109/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.9404 - val_loss: 61.1598\n",
            "Epoch 110/1000\n",
            "81/88 [==========================>...] - ETA: 0s - loss: 49.7776roc-auc_val: 0.8204\n",
            "88/88 [==============================] - 11s 127ms/step - loss: 49.8778 - val_loss: 61.1641\n",
            "Epoch 111/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.6402 - val_loss: 61.1483\n",
            "Epoch 112/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.9283 - val_loss: 61.1651\n",
            "Epoch 113/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.7326 - val_loss: 61.1766\n",
            "Epoch 114/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.3942 - val_loss: 61.1764\n",
            "Epoch 115/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.8436 - val_loss: 61.1767\n",
            "Epoch 116/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.7934 - val_loss: 61.1583\n",
            "Epoch 117/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.8962 - val_loss: 61.1748\n",
            "Epoch 118/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.5811 - val_loss: 61.1600\n",
            "Epoch 119/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.5009 - val_loss: 61.1725\n",
            "Epoch 120/1000\n",
            "82/88 [==========================>...] - ETA: 0s - loss: 49.1163roc-auc_val: 0.8209\n",
            "88/88 [==============================] - 11s 126ms/step - loss: 49.0472 - val_loss: 61.1575\n",
            "Epoch 121/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.5610 - val_loss: 61.1392\n",
            "Epoch 122/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.9697 - val_loss: 61.1488\n",
            "Epoch 123/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.2900 - val_loss: 61.1418\n",
            "Epoch 124/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.1799 - val_loss: 61.1433\n",
            "Epoch 125/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.0871 - val_loss: 61.1628\n",
            "Epoch 126/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.7410 - val_loss: 61.1537\n",
            "Epoch 127/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.1366 - val_loss: 61.1529\n",
            "Epoch 128/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.8114 - val_loss: 61.1343\n",
            "Epoch 129/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.1164 - val_loss: 61.1320\n",
            "Epoch 130/1000\n",
            "80/88 [==========================>...] - ETA: 0s - loss: 49.3170roc-auc_val: 0.8213\n",
            "88/88 [==============================] - 11s 128ms/step - loss: 49.1108 - val_loss: 61.1265\n",
            "Epoch 131/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 49.3937 - val_loss: 61.1172\n",
            "Epoch 132/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.6733 - val_loss: 61.1338\n",
            "Epoch 133/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 49.1133 - val_loss: 61.1283\n",
            "Epoch 134/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.5632 - val_loss: 61.1116\n",
            "Epoch 135/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.9072 - val_loss: 61.1109\n",
            "Epoch 136/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.9320 - val_loss: 61.1187\n",
            "Epoch 137/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.9739 - val_loss: 61.1340\n",
            "Epoch 138/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.9583 - val_loss: 61.1544\n",
            "Epoch 139/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.7747 - val_loss: 61.1504\n",
            "Epoch 140/1000\n",
            "81/88 [==========================>...] - ETA: 0s - loss: 48.9945roc-auc_val: 0.8216\n",
            "88/88 [==============================] - 12s 131ms/step - loss: 48.7822 - val_loss: 61.1440\n",
            "Epoch 141/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 48.4135 - val_loss: 61.1379\n",
            "Epoch 142/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 48.3685 - val_loss: 61.1344\n",
            "Epoch 143/1000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 48.5789 - val_loss: 61.1271\n",
            "Epoch 144/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.3991 - val_loss: 61.1173\n",
            "Epoch 145/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.8623 - val_loss: 61.1364\n",
            "Epoch 146/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1755 - val_loss: 61.1268\n",
            "Epoch 147/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1761 - val_loss: 61.1313\n",
            "Epoch 148/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.8108 - val_loss: 61.1556\n",
            "Epoch 149/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.7133 - val_loss: 61.1283\n",
            "Epoch 150/1000\n",
            "83/88 [===========================>..] - ETA: 0s - loss: 48.3947roc-auc_val: 0.822\n",
            "88/88 [==============================] - 11s 130ms/step - loss: 48.3486 - val_loss: 61.1347\n",
            "Epoch 151/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.0014 - val_loss: 61.1474\n",
            "Epoch 152/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1756 - val_loss: 61.1350\n",
            "Epoch 153/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1709 - val_loss: 61.1463\n",
            "Epoch 154/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.9892 - val_loss: 61.1477\n",
            "Epoch 155/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.4250 - val_loss: 61.1335\n",
            "Epoch 156/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1798 - val_loss: 61.1724\n",
            "Epoch 157/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1733 - val_loss: 61.1660\n",
            "Epoch 158/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.2879 - val_loss: 61.1647\n",
            "Epoch 159/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.4633 - val_loss: 61.1778\n",
            "Epoch 160/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 48.0515roc-auc_val: 0.8222\n",
            "88/88 [==============================] - 11s 127ms/step - loss: 48.1166 - val_loss: 61.1887\n",
            "Epoch 161/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.3356 - val_loss: 61.1967\n",
            "Epoch 162/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.4732 - val_loss: 61.1988\n",
            "Epoch 163/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.6899 - val_loss: 61.1985\n",
            "Epoch 164/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1100 - val_loss: 61.2145\n",
            "Epoch 165/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.7668 - val_loss: 61.2066\n",
            "Epoch 166/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.6321 - val_loss: 61.1876\n",
            "Epoch 167/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.7096 - val_loss: 61.2241\n",
            "Epoch 168/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1367 - val_loss: 61.2288\n",
            "Epoch 169/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.8423 - val_loss: 61.2052\n",
            "Epoch 170/1000\n",
            "88/88 [==============================] - ETA: 0s - loss: 47.9916roc-auc_val: 0.8225\n",
            "88/88 [==============================] - 11s 126ms/step - loss: 47.9916 - val_loss: 61.2054\n",
            "Epoch 171/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.7604 - val_loss: 61.1968\n",
            "Epoch 172/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.6434 - val_loss: 61.2135\n",
            "Epoch 173/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.7964 - val_loss: 61.2181\n",
            "Epoch 174/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 48.1503 - val_loss: 61.2217\n",
            "Epoch 175/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.6692 - val_loss: 61.2328\n",
            "Epoch 176/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.7353 - val_loss: 61.2134\n",
            "Epoch 177/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.3940 - val_loss: 61.1960\n",
            "Epoch 178/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.8092 - val_loss: 61.1875\n",
            "Epoch 179/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.6776 - val_loss: 61.1901\n",
            "Epoch 180/1000\n",
            "79/88 [=========================>....] - ETA: 0s - loss: 47.9331roc-auc_val: 0.8227\n",
            "88/88 [==============================] - 11s 127ms/step - loss: 47.5634 - val_loss: 61.2152\n",
            "Epoch 181/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.8450 - val_loss: 61.1938\n",
            "Epoch 182/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.6623 - val_loss: 61.1870\n",
            "Epoch 183/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.7174 - val_loss: 61.2119\n",
            "Epoch 184/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.6674 - val_loss: 61.2221\n",
            "Epoch 185/1000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 47.7321 - val_loss: 61.1985\n",
            "Epoch 1/1000\n",
            "47/47 [==============================] - 1s 24ms/step - loss: 91.5321 - val_loss: 76.0078\n",
            "Epoch 2/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 82.3490 - val_loss: 72.4146\n",
            "Epoch 3/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 76.7275 - val_loss: 70.5057\n",
            "Epoch 4/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 74.0642 - val_loss: 69.4175\n",
            "Epoch 5/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 72.8193 - val_loss: 68.7858\n",
            "Epoch 6/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 70.8206 - val_loss: 68.1438\n",
            "Epoch 7/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 70.3850 - val_loss: 67.8607\n",
            "Epoch 8/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 69.7798 - val_loss: 67.5605\n",
            "Epoch 9/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 67.3519 - val_loss: 67.4075\n",
            "Epoch 10/1000\n",
            "41/47 [=========================>....] - ETA: 0s - loss: 66.5185roc-auc_val: 0.7742\n",
            "47/47 [==============================] - 11s 234ms/step - loss: 66.6333 - val_loss: 67.2146\n",
            "Epoch 11/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 66.0545 - val_loss: 66.7676\n",
            "Epoch 12/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 64.8256 - val_loss: 66.6298\n",
            "Epoch 13/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 63.5771 - val_loss: 66.2566\n",
            "Epoch 14/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 63.9446 - val_loss: 66.2363\n",
            "Epoch 15/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 63.1063 - val_loss: 66.0578\n",
            "Epoch 16/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 62.1734 - val_loss: 65.8626\n",
            "Epoch 17/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 62.2286 - val_loss: 65.6844\n",
            "Epoch 18/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 61.1676 - val_loss: 65.6529\n",
            "Epoch 19/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 59.9361 - val_loss: 65.5572\n",
            "Epoch 20/1000\n",
            "42/47 [=========================>....] - ETA: 0s - loss: 60.8797roc-auc_val: 0.7859\n",
            "47/47 [==============================] - 11s 235ms/step - loss: 60.3647 - val_loss: 65.5868\n",
            "Epoch 21/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 59.8266 - val_loss: 65.5143\n",
            "Epoch 22/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 59.9763 - val_loss: 65.5146\n",
            "Epoch 23/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 60.0320 - val_loss: 65.4324\n",
            "Epoch 24/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 59.2005 - val_loss: 65.4171\n",
            "Epoch 25/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 58.2015 - val_loss: 65.3479\n",
            "Epoch 26/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 58.4210 - val_loss: 65.4828\n",
            "Epoch 27/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 57.7698 - val_loss: 65.2043\n",
            "Epoch 28/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 58.1843 - val_loss: 65.1842\n",
            "Epoch 29/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 57.8985 - val_loss: 65.2112\n",
            "Epoch 30/1000\n",
            "42/47 [=========================>....] - ETA: 0s - loss: 57.3615roc-auc_val: 0.7907\n",
            "47/47 [==============================] - 11s 235ms/step - loss: 57.2165 - val_loss: 65.2076\n",
            "Epoch 31/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 56.4995 - val_loss: 65.1625\n",
            "Epoch 32/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 56.8123 - val_loss: 65.1727\n",
            "Epoch 33/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 56.0575 - val_loss: 65.2329\n",
            "Epoch 34/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 56.3129 - val_loss: 65.2686\n",
            "Epoch 35/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 55.5336 - val_loss: 65.3590\n",
            "Epoch 36/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 55.7688 - val_loss: 65.3099\n",
            "Epoch 37/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 55.3087 - val_loss: 65.2359\n",
            "Epoch 38/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 55.3838 - val_loss: 65.2562\n",
            "Epoch 39/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 54.7322 - val_loss: 65.2516\n",
            "Epoch 40/1000\n",
            "42/47 [=========================>....] - ETA: 0s - loss: 55.0716roc-auc_val: 0.793\n",
            "47/47 [==============================] - 11s 234ms/step - loss: 54.7642 - val_loss: 65.2414\n",
            "Epoch 41/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 55.4368 - val_loss: 65.2256\n",
            "Epoch 42/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 54.8446 - val_loss: 65.1813\n",
            "Epoch 43/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 53.5618 - val_loss: 65.2209\n",
            "Epoch 44/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 54.3156 - val_loss: 65.2379\n",
            "Epoch 45/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 54.1769 - val_loss: 65.2699\n",
            "Epoch 46/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 53.7311 - val_loss: 65.2776\n",
            "Epoch 47/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 53.7564 - val_loss: 65.3647\n",
            "Epoch 48/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 53.0594 - val_loss: 65.3689\n",
            "Epoch 49/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 53.9962 - val_loss: 65.3934\n",
            "Epoch 50/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 53.5085roc-auc_val: 0.7942\n",
            "47/47 [==============================] - 11s 242ms/step - loss: 53.3517 - val_loss: 65.4438\n",
            "Epoch 51/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 53.1507 - val_loss: 65.4430\n",
            "Epoch 52/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 53.3457 - val_loss: 65.4640\n",
            "Epoch 53/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 52.8552 - val_loss: 65.5244\n",
            "Epoch 54/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 51.9752 - val_loss: 65.5427\n",
            "Epoch 55/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 52.7143 - val_loss: 65.6022\n",
            "Epoch 56/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 52.3295 - val_loss: 65.6915\n",
            "Epoch 57/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 52.1729 - val_loss: 65.6958\n",
            "Epoch 58/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 52.0240 - val_loss: 65.7010\n",
            "Epoch 59/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 52.0070 - val_loss: 65.7661\n",
            "Epoch 60/1000\n",
            "39/47 [=======================>......] - ETA: 0s - loss: 51.8119roc-auc_val: 0.7953\n",
            "47/47 [==============================] - 12s 247ms/step - loss: 51.7918 - val_loss: 65.7408\n",
            "Epoch 61/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.7292 - val_loss: 65.8080\n",
            "Epoch 62/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.4185 - val_loss: 65.8648\n",
            "Epoch 63/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.5537 - val_loss: 65.8895\n",
            "Epoch 64/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.5190 - val_loss: 65.9207\n",
            "Epoch 65/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 50.9921 - val_loss: 65.9515\n",
            "Epoch 66/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.3218 - val_loss: 65.9836\n",
            "Epoch 67/1000\n",
            "47/47 [==============================] - 1s 13ms/step - loss: 51.0490 - val_loss: 65.9861\n",
            "Epoch 68/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 50.7315 - val_loss: 66.0332\n",
            "Epoch 69/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 50.9919 - val_loss: 66.0319\n",
            "Epoch 70/1000\n",
            "41/47 [=========================>....] - ETA: 0s - loss: 50.8367roc-auc_val: 0.7951\n",
            "47/47 [==============================] - 11s 233ms/step - loss: 50.6426 - val_loss: 66.1015\n",
            "Epoch 71/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 50.4651 - val_loss: 66.1286\n",
            "Epoch 72/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 50.2759 - val_loss: 66.2039\n",
            "Epoch 73/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 50.2556 - val_loss: 66.2669\n",
            "Epoch 74/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 50.4674 - val_loss: 66.2523\n",
            "Epoch 75/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 49.7396 - val_loss: 66.2618\n",
            "Epoch 76/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 50.2655 - val_loss: 66.3184\n",
            "Epoch 77/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 50.1685 - val_loss: 66.3699\n",
            "Epoch 78/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 50.6849 - val_loss: 66.3893\n",
            "Epoch 79/1000\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 49.9352 - val_loss: 66.4297\n",
            "Epoch 80/1000\n",
            "40/47 [========================>.....] - ETA: 0s - loss: 49.7678roc-auc_val: 0.7951\n",
            "47/47 [==============================] - 11s 235ms/step - loss: 49.7754 - val_loss: 66.4907\n",
            "Epoch 81/1000\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 49.8610 - val_loss: 66.5010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnpeTPNLkiCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "outputId": "11dac4b8-e7dc-4b70-cfdb-5772c12dc556"
      },
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "for i in dk.keys():\n",
        "  sns.distplot(dk[i])\n",
        "  plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn6S7Pv_rc-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}