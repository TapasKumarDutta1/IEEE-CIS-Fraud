{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_trans=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n",
    "trn=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n",
    "tst_trans=pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\n",
    "tst=pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n",
    "fnl_trn=trn.merge(trn_trans,on='TransactionID',how='left')\n",
    "fnl_tst=tst.merge(tst_trans,on='TransactionID',how='left')\n",
    "fnl_trn=fnl_trn.drop(list(fnl_trn.filter(regex='V')),1)\n",
    "fnl_tst=fnl_tst.drop(list(fnl_tst.filter(regex='V')),1)\n",
    "import gc\n",
    "dk={}\n",
    "for i in range(1,39):\n",
    "    if i<10:\n",
    "        dk['id-0'+str(i)]='id_0'+str(i)\n",
    "    else:\n",
    "        dk['id-'+str(i)]='id_'+str(i)\n",
    "fnl_tst=fnl_tst.rename(columns=dk)\n",
    "del([trn,tst,trn_trans,tst_trans])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl_trn['is_train']=1\n",
    "fnl_tst['is_train']=0\n",
    "fnl=pd.concat([fnl_trn,fnl_tst],0)\n",
    "fnl=fnl.reset_index(drop=True)\n",
    "gc.collect()\n",
    "numerical = [\"TransactionAmt\", \"dist1\", \"dist2\"] + [\"C\" + str(i) for i in range(1, 15)] + \\\n",
    "            [\"D\" + str(i) for i in range(1, 16)] \n",
    "categorical = [\"ProductCD\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\",\n",
    "               \"P_emaildomain\", \"R_emaildomain\",\n",
    "              \"DeviceInfo\", \"DeviceType\"] + [\"id_0\" + str(i) for i in range(1, 10)] +\\\n",
    "                [\"id_\" + str(i) for i in range(10, 39)] + \\\n",
    "                 [\"M\" + str(i) for i in range(1, 10)]\n",
    "for col in numerical:\n",
    "    fnl[col]=fnl[col].fillna(fnl[col].mean())\n",
    "for col in categorical:\n",
    "    fnl[col]=fnl[col].fillna('nan')\n",
    "\n",
    "fnl['days']=fnl['TransactionDT']//86400\n",
    "fnl['id']=fnl['days']-fnl['D1']\n",
    "fnl['id']=fnl['id'].astype(str)+fnl['id'].astype(str)+fnl['card1'].astype(str)+fnl['addr1'].astype(str)+fnl['ProductCD'].astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "fnl['id']=le.fit_transform(fnl['id'])\n",
    "from tqdm import tqdm\n",
    "for col in tqdm(numerical):\n",
    "    try:\n",
    "        fnl[col+'_mean']=fnl.groupby(['id'])[col].transform('mean')\n",
    "        fnl[col+'_std']=fnl.groupby(['id'])[col].transform('std')\n",
    "    except:\n",
    "        continue\n",
    "fnl=fnl.drop(['id'],1)\n",
    "from tqdm import tqdm\n",
    "for col in tqdm(categorical):\n",
    "        print('before '+str(fnl[col].nunique()))\n",
    "        fnl.loc[~fnl[col].isin(list(fnl[col].value_counts().index[:5])),col]='other'\n",
    "        print('before '+str(fnl[col].nunique()))\n",
    "        if col!='card1' or col !='id_02':\n",
    "            fnl_dum=pd.get_dummies(fnl[col]).astype('uint8')\n",
    "            fnl_dum.columns=list(np.char.add(col,np.asarray(list(fnl_dum)).astype(str)))\n",
    "            fnl_dum.columns=fnl_dum.columns+'_dum'\n",
    "            \n",
    "            #fnl=fnl.drop([col],1)\n",
    "            fnl=pd.concat([fnl,fnl_dum],1)\n",
    "fnl['day']=fnl['TransactionDT']//86400\n",
    "fnl['month']=fnl['day']//30\n",
    "fnl['week']=fnl['day']//7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "fnl.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in fnl.columns]\n",
    "fnl=fnl.drop(['TransactionID','TransactionDT'],1)\n",
    "fnl=fnl.reset_index(drop=True)\n",
    "gc.collect()\n",
    "fnl=fnl.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col]=df[col].fillna(-1)\n",
    "        df[col]=df[col].replace([np.inf,-np.inf],-1)\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=set(list(fnl))\n",
    "tot=['ProductCD','card1','card2','DeviceType','DeviceInfo','card3','card4','card5','card6','P_emaildomain','R_emaildomain','day','month','week','is_train','isFraud']\n",
    "ls=list(fnl.filter(regex='dum'))\n",
    "tot+=ls\n",
    "ls=list(fnl.select_dtypes(include=object))\n",
    "tot+=ls\n",
    "tot=fnl[tot]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "ls=list(fnl.drop(tot,1))\n",
    "fnl=pd.DataFrame(ss.fit_transform(fnl.drop(tot,1)))\n",
    "fnl.columns=ls\n",
    "fnl=reduce_mem_usage(fnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst=pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv',usecols=['TransactionDT'])\n",
    "trn=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv',usecols=['TransactionDT'])\n",
    "sdo1=pd.concat([trn,tst],0)\n",
    "sdo1['day']=sdo1['TransactionDT']//86400\n",
    "sdo1['week']=sdo1['day']//7\n",
    "sdo1['month']=sdo1['day']//30\n",
    "sdo1=sdo1.reset_index(drop=True)\n",
    "fnl=pd.concat([fnl,sdo1.drop(['TransactionDT'],1),tot],1)\n",
    "del([sdo1,trn,tst,tot])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "/kaggle/input/ieee-fraud-detection/test_identity.csv\n",
    "/kaggle/input/ieee-fraud-detection/train_identity.csv\n",
    "/kaggle/input/ieee-fraud-detection/test_transaction.csv\n",
    "/kaggle/input/ieee-fraud-detection/sample_submission.csv\n",
    "/kaggle/input/ieee-fraud-detection/train_transaction.csv\n",
    "trn_trans=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n",
    "trn=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n",
    "tst_trans=pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\n",
    "tst=pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n",
    "fnl_trn=trn.merge(trn_trans,on='TransactionID',how='left')\n",
    "fnl_tst=tst.merge(tst_trans,on='TransactionID',how='left')\n",
    "fnl_trn=fnl_trn.drop(list(fnl_trn.filter(regex='V')),1)\n",
    "fnl_tst=fnl_tst.drop(list(fnl_tst.filter(regex='V')),1)\n",
    "import gc\n",
    "dk={}\n",
    "for i in range(1,39):\n",
    "    if i<10:\n",
    "        dk['id-0'+str(i)]='id_0'+str(i)\n",
    "    else:\n",
    "        dk['id-'+str(i)]='id_'+str(i)\n",
    "fnl_tst=fnl_tst.rename(columns=dk)\n",
    "del([trn,tst,trn_trans,tst_trans])\n",
    "gc.collect()\n",
    "0\n",
    "fnl_trn['is_train']=1\n",
    "fnl_tst['is_train']=0\n",
    "fnl=pd.concat([fnl_trn,fnl_tst],0)\n",
    "fnl=fnl.reset_index(drop=True)\n",
    "gc.collect()\n",
    "numerical = [\"TransactionAmt\", \"dist1\", \"dist2\"] + [\"C\" + str(i) for i in range(1, 15)] + \\\n",
    "            [\"D\" + str(i) for i in range(1, 16)] \n",
    "categorical = [\"ProductCD\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\",\n",
    "               \"P_emaildomain\", \"R_emaildomain\",\n",
    "              \"DeviceInfo\", \"DeviceType\"] + [\"id_0\" + str(i) for i in range(1, 10)] +\\\n",
    "                [\"id_\" + str(i) for i in range(10, 39)] + \\\n",
    "                 [\"M\" + str(i) for i in range(1, 10)]\n",
    "for col in numerical:\n",
    "    fnl[col]=fnl[col].fillna(fnl[col].mean())\n",
    "for col in categorical:\n",
    "    fnl[col]=fnl[col].fillna('nan')\n",
    "\n",
    "fnl['days']=fnl['TransactionDT']//86400\n",
    "fnl['id']=fnl['days']-fnl['D1']\n",
    "fnl['id']=fnl['id'].astype(str)+fnl['id'].astype(str)+fnl['card1'].astype(str)+fnl['addr1'].astype(str)+fnl['ProductCD'].astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "fnl['id']=le.fit_transform(fnl['id'])\n",
    "from tqdm import tqdm\n",
    "for col in tqdm(numerical):\n",
    "    try:\n",
    "        fnl[col+'_mean']=fnl.groupby(['id'])[col].transform('mean')\n",
    "        fnl[col+'_std']=fnl.groupby(['id'])[col].transform('std')\n",
    "    except:\n",
    "        continue\n",
    "fnl=fnl.drop(['id'],1)\n",
    "from tqdm import tqdm\n",
    "for col in tqdm(categorical):\n",
    "        print('before '+str(fnl[col].nunique()))\n",
    "        fnl.loc[~fnl[col].isin(list(fnl[col].value_counts().index[:5])),col]='other'\n",
    "        print('before '+str(fnl[col].nunique()))\n",
    "        if col!='card1' or col !='id_02':\n",
    "            fnl_dum=pd.get_dummies(fnl[col]).astype('uint8')\n",
    "            fnl_dum.columns=list(np.char.add(col,np.asarray(list(fnl_dum)).astype(str)))\n",
    "            fnl_dum.columns=fnl_dum.columns+'_dum'\n",
    "            \n",
    "            #fnl=fnl.drop([col],1)\n",
    "            fnl=pd.concat([fnl,fnl_dum],1)\n",
    "fnl['day']=fnl['TransactionDT']//86400\n",
    "fnl['month']=fnl['day']//30\n",
    "fnl['week']=fnl['day']//7\n",
    "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
    "of pandas will change to not sort by default.\n",
    "\n",
    "To accept the future behavior, pass 'sort=False'.\n",
    "\n",
    "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
    "\n",
    "  This is separate from the ipykernel package so we can avoid doing imports until\n",
    "100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n",
    "  0%|          | 0/60 [00:00<?, ?it/s]\n",
    "before 5\n",
    "before 5\n",
    "  2%|▏         | 1/60 [00:02<02:33,  2.60s/it]\n",
    "before 17091\n",
    "before 6\n",
    "  3%|▎         | 2/60 [00:10<04:01,  4.16s/it]\n",
    "before 502\n",
    "before 6\n",
    "  5%|▌         | 3/60 [00:16<04:30,  4.75s/it]\n",
    "before 134\n",
    "before 6\n",
    "  7%|▋         | 4/60 [00:22<04:47,  5.13s/it]\n",
    "before 5\n",
    "before 5\n",
    "  8%|▊         | 5/60 [00:28<04:50,  5.28s/it]\n",
    "before 139\n",
    "before 6\n",
    " 10%|█         | 6/60 [00:34<04:54,  5.45s/it]\n",
    "before 5\n",
    "before 5\n",
    " 12%|█▏        | 7/60 [00:39<04:49,  5.46s/it]\n",
    "before 442\n",
    "before 6\n",
    " 13%|█▎        | 8/60 [00:45<04:50,  5.59s/it]\n",
    "before 94\n",
    "before 6\n",
    " 15%|█▌        | 9/60 [00:51<04:53,  5.76s/it]\n",
    "before 61\n",
    "before 6\n",
    " 17%|█▋        | 10/60 [00:57<04:46,  5.74s/it]\n",
    "before 61\n",
    "before 6\n",
    " 18%|█▊        | 11/60 [01:02<04:38,  5.67s/it]\n",
    "before 2800\n",
    "before 6\n",
    " 20%|██        | 12/60 [01:08<04:29,  5.61s/it]\n",
    "before 3\n",
    "before 3\n",
    " 22%|██▏       | 13/60 [01:13<04:21,  5.57s/it]\n",
    "before 90\n",
    "before 6\n",
    " 23%|██▎       | 14/60 [01:19<04:19,  5.63s/it]\n",
    "before 198052\n",
    "before 6\n",
    " 25%|██▌       | 15/60 [01:25<04:18,  5.74s/it]\n",
    "before 26\n",
    "before 6\n",
    " 27%|██▋       | 16/60 [01:31<04:12,  5.75s/it]\n",
    "before 17\n",
    "before 6\n",
    " 28%|██▊       | 17/60 [01:36<04:07,  5.75s/it]\n",
    "before 98\n",
    "before 6\n",
    " 30%|███       | 18/60 [01:42<04:02,  5.77s/it]\n",
    "before 102\n",
    "before 6\n",
    " 32%|███▏      | 19/60 [01:48<03:57,  5.78s/it]\n",
    "before 93\n",
    "before 6\n",
    " 33%|███▎      | 20/60 [01:54<03:49,  5.74s/it]\n",
    "before 98\n",
    "before 6\n",
    " 35%|███▌      | 21/60 [01:59<03:43,  5.74s/it]\n",
    "before 52\n",
    "before 6\n",
    " 37%|███▋      | 22/60 [02:05<03:40,  5.79s/it]\n",
    "before 68\n",
    "before 6\n",
    " 38%|███▊      | 23/60 [02:11<03:34,  5.79s/it]\n",
    "before 413\n",
    "before 6\n",
    " 40%|████      | 24/60 [02:17<03:30,  5.84s/it]\n",
    "before 3\n",
    "before 3\n",
    " 42%|████▏     | 25/60 [02:23<03:21,  5.75s/it]\n",
    "before 56\n",
    "before 6\n",
    " 43%|████▎     | 26/60 [02:29<03:17,  5.82s/it]\n",
    "before 29\n",
    "before 6\n",
    " 45%|████▌     | 27/60 [02:34<03:12,  5.83s/it]\n",
    "before 4\n",
    "before 4\n",
    " 47%|████▋     | 28/60 [02:40<03:04,  5.76s/it]\n",
    "before 3\n",
    "before 3\n",
    " 48%|████▊     | 29/60 [02:46<02:57,  5.72s/it]\n",
    "before 128\n",
    "before 6\n",
    " 50%|█████     | 30/60 [02:52<02:54,  5.80s/it]\n",
    "before 20\n",
    "before 6\n",
    " 52%|█████▏    | 31/60 [02:58<02:48,  5.83s/it]\n",
    "before 569\n",
    "before 6\n",
    " 53%|█████▎    | 32/60 [03:04<02:44,  5.87s/it]\n",
    "before 548\n",
    "before 6\n",
    " 55%|█████▌    | 33/60 [03:09<02:38,  5.87s/it]\n",
    "before 735\n",
    "before 6\n",
    " 57%|█████▋    | 34/60 [03:15<02:32,  5.85s/it]\n",
    "before 36\n",
    "before 6\n",
    " 58%|█████▊    | 35/60 [03:21<02:25,  5.81s/it]\n",
    "before 4\n",
    "before 4\n",
    " 60%|██████    | 36/60 [03:27<02:18,  5.75s/it]\n",
    "before 18\n",
    "before 6\n",
    " 62%|██████▏   | 37/60 [03:32<02:12,  5.76s/it]\n",
    "before 441\n",
    "before 6\n",
    " 63%|██████▎   | 38/60 [03:38<02:06,  5.76s/it]\n",
    "before 116\n",
    "before 6\n",
    " 65%|██████▌   | 39/60 [03:44<02:01,  5.77s/it]\n",
    "before 3\n",
    "before 3\n",
    " 67%|██████▋   | 40/60 [03:50<01:54,  5.73s/it]\n",
    "before 3\n",
    "before 3\n",
    " 68%|██████▊   | 41/60 [03:55<01:48,  5.70s/it]\n",
    "before 3\n",
    "before 3\n",
    " 70%|███████   | 42/60 [04:01<01:42,  5.71s/it]\n",
    "before 88\n",
    "before 6\n",
    " 72%|███████▏  | 43/60 [04:07<01:37,  5.72s/it]\n",
    "before 173\n",
    "before 6\n",
    " 73%|███████▎  | 44/60 [04:12<01:31,  5.71s/it]\n",
    "before 7\n",
    "before 6\n",
    " 75%|███████▌  | 45/60 [04:18<01:26,  5.79s/it]\n",
    "before 462\n",
    "before 6\n",
    " 77%|███████▋  | 46/60 [04:24<01:20,  5.77s/it]\n",
    "before 5\n",
    "before 5\n",
    " 78%|███████▊  | 47/60 [04:30<01:14,  5.76s/it]\n",
    "before 3\n",
    "before 3\n",
    " 80%|████████  | 48/60 [04:35<01:08,  5.73s/it]\n",
    "before 3\n",
    "before 3\n",
    " 82%|████████▏ | 49/60 [04:41<01:02,  5.72s/it]\n",
    "before 3\n",
    "before 3\n",
    " 83%|████████▎ | 50/60 [04:47<00:57,  5.72s/it]\n",
    "before 3\n",
    "before 3\n",
    " 85%|████████▌ | 51/60 [04:53<00:51,  5.73s/it]\n",
    "before 3\n",
    "before 3\n",
    " 87%|████████▋ | 52/60 [04:58<00:45,  5.74s/it]\n",
    "before 3\n",
    "before 3\n",
    " 88%|████████▊ | 53/60 [05:04<00:40,  5.73s/it]\n",
    "before 3\n",
    "before 3\n",
    " 90%|█████████ | 54/60 [05:10<00:34,  5.70s/it]\n",
    "before 4\n",
    "before 4\n",
    " 92%|█████████▏| 55/60 [05:16<00:28,  5.74s/it]\n",
    "before 3\n",
    "before 3\n",
    " 93%|█████████▎| 56/60 [05:21<00:23,  5.77s/it]\n",
    "before 3\n",
    "before 3\n",
    " 95%|█████████▌| 57/60 [05:27<00:17,  5.78s/it]\n",
    "before 3\n",
    "before 3\n",
    " 97%|█████████▋| 58/60 [05:33<00:11,  5.76s/it]\n",
    "before 3\n",
    "before 3\n",
    " 98%|█████████▊| 59/60 [05:39<00:05,  5.74s/it]\n",
    "before 3\n",
    "before 3\n",
    "100%|██████████| 60/60 [05:44<00:00,  5.75s/it]\n",
    "z=fnl.isna().sum()\n",
    "z[z>0]\n",
    "isFraud               506691\n",
    "TransactionAmt_std    245596\n",
    "dist1_std             245596\n",
    "dist2_std             245596\n",
    "C1_std                245596\n",
    "C2_std                245596\n",
    "C3_std                245596\n",
    "C4_std                245596\n",
    "C5_std                245596\n",
    "C6_std                245596\n",
    "C7_std                245596\n",
    "C8_std                245596\n",
    "C9_std                245596\n",
    "C10_std               245596\n",
    "C11_std               245596\n",
    "C12_std               245596\n",
    "C13_std               245596\n",
    "C14_std               245596\n",
    "D1_std                245596\n",
    "D2_std                245596\n",
    "D3_std                245596\n",
    "D4_std                245596\n",
    "D5_std                245596\n",
    "D6_std                245596\n",
    "D7_std                245596\n",
    "D8_std                245596\n",
    "D9_std                245596\n",
    "D10_std               245596\n",
    "D11_std               245596\n",
    "D12_std               245596\n",
    "D13_std               245596\n",
    "D14_std               245596\n",
    "D15_std               245596\n",
    "dtype: int64\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "fnl.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in fnl.columns]\n",
    "fnl=fnl.drop(['TransactionID','TransactionDT'],1)\n",
    "fnl=fnl.reset_index(drop=True)\n",
    "gc.collect()\n",
    "fnl=fnl.fillna(-1)\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col]=df[col].fillna(-1)\n",
    "        df[col]=df[col].replace([np.inf,-np.inf],-1)\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "kps=['id_20nan',\n",
    " 'id_31nan',\n",
    " 'id_17nan',\n",
    " 'id_19nan',\n",
    " 'D8_mean',\n",
    " 'D5',\n",
    " 'id_06nan',\n",
    " 'id_05nan',\n",
    " 'D9_mean',\n",
    " 'id_02nan',\n",
    " 'R_emaildomainnan',\n",
    " 'id_01nan',\n",
    " 'id_12nan',\n",
    " 'id_11100_0',\n",
    " 'id_10nan',\n",
    " 'id_09nan',\n",
    " 'D11_mean',\n",
    " 'C9',\n",
    " 'id_03nan',\n",
    " 'id_04nan',\n",
    " 'C5_mean',\n",
    " 'M1nan',\n",
    " 'M3nan',\n",
    " 'M2nan',\n",
    " 'D6_mean',\n",
    " 'D8_std',\n",
    " 'C12',\n",
    " 'C8',\n",
    " 'D8',\n",
    " 'C10_mean',\n",
    " 'D14',\n",
    " 'D7_mean',\n",
    " 'C12_mean',\n",
    " 'D9_std',\n",
    " 'D2_mean',\n",
    " 'D13_mean',\n",
    " 'C8_mean',\n",
    " 'D9',\n",
    " 'C4_mean',\n",
    " 'C9_mean',\n",
    " 'C5_std',\n",
    " 'D3',\n",
    " 'id_17225_0',\n",
    " 'C2',\n",
    " 'DeviceTypenan',\n",
    " 'C7',\n",
    " 'D11_std',\n",
    " 'id_37T',\n",
    " 'id_02other',\n",
    " 'id_35F',\n",
    " 'dist2_mean',\n",
    " 'id_090_0',\n",
    " 'card3185_0',\n",
    " 'dist1_mean',\n",
    " 'id_38nan',\n",
    " 'id_15nan',\n",
    " 'id_35nan',\n",
    " 'id_36nan',\n",
    " 'id_37nan',\n",
    " 'D1_std',\n",
    " 'D7',\n",
    " 'card3150_0',\n",
    " 'D1_mean',\n",
    " 'dist2_std',\n",
    " 'D10_std',\n",
    " 'C7_mean',\n",
    " 'C4',\n",
    " 'ProductCDW',\n",
    " 'C12_std',\n",
    " 'C8_std',\n",
    " 'D2',\n",
    " 'D12_std',\n",
    " 'C10_std',\n",
    " 'addr287_0',\n",
    " 'id_11nan',\n",
    " 'id_29nan',\n",
    " 'id_28nan',\n",
    " 'C4_std',\n",
    " 'D12_mean',\n",
    " 'M3T',\n",
    " 'M6nan',\n",
    " 'M8nan',\n",
    " 'M9nan',\n",
    " 'C7_std',\n",
    " 'C1',\n",
    " 'id_36F',\n",
    " 'C10',\n",
    " 'M4nan',\n",
    " 'C11_mean',\n",
    " 'ProductCDC',\n",
    " 'D14_mean',\n",
    " 'D15_mean',\n",
    " 'D7_std',\n",
    " 'D6_std',\n",
    " 'id_20other',\n",
    " 'D14_std',\n",
    " 'D12',\n",
    " 'D10_mean',\n",
    " 'dist1',\n",
    " 'M1T',\n",
    " 'DeviceInfonan',\n",
    " 'id_28Found',\n",
    " 'dist1_std',\n",
    " 'id_29Found',\n",
    " 'M7nan',\n",
    " 'C1_mean',\n",
    " 'id_31other',\n",
    " 'C2_mean',\n",
    " 'C5','day','month','week',\n",
    " 'id_13nan',\n",
    " 'D13_std',\n",
    " 'D15',\n",
    " 'M2T',\n",
    " 'R_emaildomaingmail_com',\n",
    " 'M9T',\n",
    " 'D13',\n",
    " 'id_15Found',\n",
    " 'id_030_0',\n",
    " 'TransactionAmt',\n",
    " 'C13_mean',\n",
    " 'D4_mean',\n",
    " 'addr1nan',\n",
    " 'addr2nan',\n",
    " 'id_040_0',\n",
    " 'M6T',\n",
    " 'DeviceTypemobile',\n",
    " 'M4M2',\n",
    " 'D1',\n",
    " 'C13_std',\n",
    " 'D6',\n",
    " 'id_19other',\n",
    " 'C13',\n",
    " 'M7F',\n",
    " 'C11_std',\n",
    " 'card6credit',\n",
    " 'D15_std',\n",
    " 'C1_std',\n",
    " 'C14_mean',\n",
    " 'C6',\n",
    " 'D4_std',\n",
    " 'M6F',\n",
    " 'D11',\n",
    " 'D5_std',\n",
    " 'card5other',\n",
    " 'D4',\n",
    " 'id_18nan',\n",
    " 'C2_std',\n",
    " 'card6debit',\n",
    " 'addr1other',\n",
    " 'C11',\n",
    " 'id_38F',\n",
    " 'D10',\n",
    " 'id_1352_0',\n",
    " 'id_16Found',\n",
    " 'id_100_0',\n",
    " 'C14_std',\n",
    " 'id_20507_0',\n",
    " 'D5_mean',\n",
    " 'DeviceInfoother',\n",
    " 'id_28New',\n",
    " 'C9_std',\n",
    " 'D3_mean',\n",
    " 'id_16nan',\n",
    " 'id_38T',\n",
    " 'M8F',\n",
    " 'TransactionAmt_mean',\n",
    " 'id_01other',\n",
    " 'M7_dsct',\n",
    " 'C14',\n",
    " 'id_29NotFound',\n",
    " 'card1_std',\n",
    " 'C6_std',\n",
    " 'M8_dsct',\n",
    " 'card2other',\n",
    " 'M8T',\n",
    " 'id_19266_0',\n",
    " 'id_10_dsct',\n",
    " 'id_01_5_0',\n",
    " 'card5166_0',\n",
    " 'id_12NotFound',\n",
    " 'id_050_0',\n",
    " 'id_08nan',\n",
    " 'id_07nan',\n",
    " 'id_23nan',\n",
    " 'id_27nan',\n",
    " 'id_22nan',\n",
    " 'M3_dsct',\n",
    " 'id_26nan',\n",
    " 'M6_dsct',\n",
    " 'id_16_dsct',\n",
    "'is_train'\n",
    " 'card17919',\n",
    " 'M5_dsct',\n",
    " 'D3_std',\n",
    " 'id_37_dsct',\n",
    " 'id_03_dsct',\n",
    " 'id_04_dsct',\n",
    " 'id_010_0',\n",
    " 'card2111_0',\n",
    " 'id_15New',\n",
    " 'id_29_dsct',\n",
    " 'id_20_dsct',\n",
    " 'id_37F',\n",
    " 'id_30other',\n",
    " 'id_16NotFound',\n",
    " 'id_1364_0',\n",
    " 'M1_dsct',\n",
    " 'D2_std',\n",
    " 'id_09_dsct',\n",
    " 'card5102_0',\n",
    " 'id_051_0',\n",
    " 'dist2',\n",
    " 'P_emaildomaingmail_com',\n",
    " 'id_24_dsct',\n",
    " 'id_21nan',\n",
    " 'id_13other',\n",
    " 'DeviceInfoWindows',\n",
    " 'id_1815_0',\n",
    " 'R_emaildomainhotmail_com',\n",
    " 'id_32_dsct',\n",
    " 'addr287.0',\n",
    " 'card3150.0',\n",
    " 'card2583_0',\n",
    " 'id_14_300_0',\n",
    " 'R_emaildomainother',\n",
    " 'card5226.0',\n",
    " 'id_28_dsct',\n",
    " 'P_emaildomaingmail.com',\n",
    " 'P_emaildomainanonymous_com',\n",
    " 'id_33nan',\n",
    " 'id_06_dsct',\n",
    " 'id_30nan',\n",
    " 'id_031.0',\n",
    " 'id_091.0',\n",
    " 'id_2241.0',\n",
    " 'id_06-1.0',\n",
    " 'R_emaildomainyahoo.com',\n",
    " 'id_11100.0',\n",
    " 'id_05_dsct',\n",
    " 'addr1264.0',\n",
    " 'P_emaildomainanonymous.com',\n",
    " 'card2555.0',\n",
    " 'card2111.0',\n",
    " 'addr1299.0',\n",
    " 'card19500',\n",
    " 'card2583.0',\n",
    " 'id_19529.0',\n",
    " 'id_14-480.0',\n",
    " 'id_17166.0',\n",
    " 'R_emaildomainanonymous.com',\n",
    " 'addr1204.0',\n",
    " 'addr1325.0',\n",
    " 'id_1352.0',\n",
    " 'id_100.0',\n",
    " 'id_1327.0',\n",
    " 'id_090.0',\n",
    " 'id_14-360.0',\n",
    " 'card3185.0',\n",
    " 'id_08-33.0',\n",
    " 'card6charge card',\n",
    " 'id_08-100.0',\n",
    " 'id_0716.0',\n",
    " 'id_0714.0',\n",
    " 'id_08-34.0',\n",
    " 'id_092.0',\n",
    " 'id_1364.0',\n",
    " 'id_0712.0',\n",
    " 'id_093.0',\n",
    " 'id_10-1.0',\n",
    " 'id_10-5.0',\n",
    " 'id_10-6.0',\n",
    " 'id_1349.0',\n",
    " 'addr296.0',\n",
    " 'id_20325.0',\n",
    " 'addr260.0',\n",
    " 'id_1195.08000183105469',\n",
    " 'id_1195.16000366210938',\n",
    " 'id_080.0',\n",
    " 'id_070.0',\n",
    " 'card4american express',\n",
    " 'id_04-9.0',\n",
    " 'id_1812.0',\n",
    " 'card3117.0',\n",
    " 'id_21252.0',\n",
    " 'id_032.0',\n",
    " 'id_033.0',\n",
    " 'card3106.0',\n",
    " 'id_021102.0',\n",
    " 'id_04-6.0',\n",
    " 'id_2243.0',\n",
    " 'id_2214.0',\n",
    " 'id_02696.0',\n",
    " 'id_021083.0',\n",
    " 'id_2233.0','isFraud'\n",
    " 'id_051.0',\n",
    " 'addr232.0',\n",
    " 'id_052.0',\n",
    " 'id_17159.0',\n",
    " 'DeviceInfoTrident/7.0','day','month','week',\n",
    " 'id_14-420.0',\n",
    " 'id_19427.0','ProductCD','card1','card2','card3','card4','card5','card6','P_emaildomain','R_emaildomain','is_train']\n",
    "fnl.shape\n",
    "(1097231, 458)\n",
    "ls=set(list(fnl))\n",
    "kps=set(kps).intersection(ls)\n",
    "# fnl=fnl[kps]\n",
    "tot=['ProductCD','card1','card2','DeviceType','DeviceInfo','card3','card4','card5','card6','P_emaildomain','R_emaildomain','day','month','week','is_train','isFraud']\n",
    "ls=list(fnl.filter(regex='dum'))\n",
    "tot+=ls\n",
    "ls=list(fnl.select_dtypes(include=object))\n",
    "tot+=ls\n",
    "tot=fnl[tot]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "ls=list(fnl.drop(tot,1))\n",
    "fnl=pd.DataFrame(ss.fit_transform(fnl.drop(tot,1)))\n",
    "fnl.columns=ls\n",
    "fnl=reduce_mem_usage(fnl)\n",
    "Memory usage of dataframe is 812.01 MB\n",
    "Memory usage after optimization is: 203.00 MB\n",
    "Decreased by 75.0%\n",
    "fnl.shape\n",
    "(1097231, 97)\n",
    "tst=pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv',usecols=['TransactionDT'])\n",
    "trn=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv',usecols=['TransactionDT'])\n",
    "sdo1=pd.concat([trn,tst],0)\n",
    "sdo1['day']=sdo1['TransactionDT']//86400\n",
    "sdo1['week']=sdo1['day']//7\n",
    "sdo1['month']=sdo1['day']//30\n",
    "sdo1=sdo1.reset_index(drop=True)\n",
    "fnl=pd.concat([fnl,sdo1.drop(['TransactionDT'],1),tot],1)\n",
    "del([sdo1,trn,tst,tot])\n",
    "gc.collect()\n",
    "0\n",
    "#fnl=fnl.drop(['isFraud'],1)\n",
    "trn=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv',usecols=['isFraud'])\n",
    "fnl['isFraud']=trn['isFraud']\n",
    "#fnl=pd.concat([fnl,tot],1)\n",
    "fnl=fnl.loc[:,~(fnl.columns.duplicated())]\n",
    "fnl.to_csv('final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
