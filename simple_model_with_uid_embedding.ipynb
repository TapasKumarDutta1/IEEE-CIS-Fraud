{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_model_with_uid_embedding",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/IEEE-CIS-Fraud/blob/master/simple_model_with_uid_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAeHxBw8EEt"
      },
      "source": [
        "Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstQrkXM8Bz9"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "import gc"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IonOu6819IW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e1ee16-f7da-4a55-db7e-c36f0a32138f"
      },
      "source": [
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"tapaskd123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"aba8dc1f085221111d925003fe5a88ed\" # key from the json file\n",
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading train_identity.csv.zip to /content\n",
            "  0% 0.00/3.26M [00:00<?, ?B/s]\n",
            "100% 3.26M/3.26M [00:00<00:00, 110MB/s]\n",
            "Downloading test_transaction.csv.zip to /content\n",
            " 79% 41.0M/52.2M [00:00<00:00, 88.7MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 96.8MB/s]\n",
            "Downloading train_transaction.csv.zip to /content\n",
            " 84% 49.0M/58.3M [00:00<00:00, 150MB/s]\n",
            "100% 58.3M/58.3M [00:00<00:00, 168MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.14M [00:00<?, ?B/s]\n",
            "100% 1.14M/1.14M [00:00<00:00, 163MB/s]\n",
            "Downloading test_identity.csv.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 53.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvhOLFro71iv"
      },
      "source": [
        "loading drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqlrXIJej1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5c82d2-f999-41ca-9056-56cc60f1afde"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZi5I0Va7-Af"
      },
      "source": [
        "Loading dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauHZNZMerDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "ffd136ff-6cd7-4f8a-8b43-bbc3cd621457"
      },
      "source": [
        "trn=pd.read_csv('/content/gdrive/My Drive/fraud/train_id.csv',index_col=[0])\n",
        "tst=pd.read_csv('/content/gdrive/My Drive/fraud/test_id.csv',index_col=[0])\n",
        "trn.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>C9_std_isna</th>\n",
              "      <th>C10_std_isna</th>\n",
              "      <th>C11_std_isna</th>\n",
              "      <th>C12_std_isna</th>\n",
              "      <th>C13_std_isna</th>\n",
              "      <th>C14_std_isna</th>\n",
              "      <th>D1_mean_isna</th>\n",
              "      <th>D1_std_isna</th>\n",
              "      <th>D2_mean_isna</th>\n",
              "      <th>D2_std_isna</th>\n",
              "      <th>D3_mean_isna</th>\n",
              "      <th>D3_std_isna</th>\n",
              "      <th>D4_mean_isna</th>\n",
              "      <th>D4_std_isna</th>\n",
              "      <th>D5_mean_isna</th>\n",
              "      <th>D5_std_isna</th>\n",
              "      <th>D6_mean_isna</th>\n",
              "      <th>D6_std_isna</th>\n",
              "      <th>D7_mean_isna</th>\n",
              "      <th>D7_std_isna</th>\n",
              "      <th>D8_mean_isna</th>\n",
              "      <th>D8_std_isna</th>\n",
              "      <th>D9_mean_isna</th>\n",
              "      <th>D9_std_isna</th>\n",
              "      <th>D10_mean_isna</th>\n",
              "      <th>D10_std_isna</th>\n",
              "      <th>D11_mean_isna</th>\n",
              "      <th>D11_std_isna</th>\n",
              "      <th>D12_mean_isna</th>\n",
              "      <th>D12_std_isna</th>\n",
              "      <th>D13_mean_isna</th>\n",
              "      <th>D13_std_isna</th>\n",
              "      <th>D14_mean_isna</th>\n",
              "      <th>D14_std_isna</th>\n",
              "      <th>D15_mean_isna</th>\n",
              "      <th>D15_std_isna</th>\n",
              "      <th>V1_mean_isna</th>\n",
              "      <th>V1_std_isna</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wnan315.013926-13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wgmail.com325.027551.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Woutlook.com330.046631.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Wyahoo.com476.018132-111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Hgmail.com420.044971.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 619 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2  ...  V1_std_isna  isFraud                          id\n",
              "0  1.0  0.0  0.0  ...            1        0         Wnan315.013926-13.0\n",
              "1  1.0  0.0  0.0  ...            1        0      Wgmail.com325.027551.0\n",
              "2  1.0  0.0  0.0  ...            0        0    Woutlook.com330.046631.0\n",
              "3  1.0  0.0  0.0  ...            1        0  Wyahoo.com476.018132-111.0\n",
              "4  0.0  0.0  0.0  ...            1        0      Hgmail.com420.044971.0\n",
              "\n",
              "[5 rows x 619 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LEIUFVW8iAC"
      },
      "source": [
        "Reduce memory useage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4W36q1Kz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6ca16a-ac5d-47af-9284-7dc7dbd8b4b5"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "trn=reduce_mem_usage(trn)\n",
        "tst=reduce_mem_usage(tst)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2793.39 MB\n",
            "Memory usage after optimization is: 678.37 MB\n",
            "Decreased by 75.7%\n",
            "Memory usage of dataframe is 2392.90 MB\n",
            "Memory usage after optimization is: 580.09 MB\n",
            "Decreased by 75.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZjn9ePhArDJ"
      },
      "source": [
        "trn=trn.replace([np.inf,-np.inf],np.nan)\n",
        "tst=tst.replace([np.inf,-np.inf],np.nan)\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=trn.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(trn[col].mean())\n",
        "  tst[col]=tst[col].fillna(tst[col].mean())\n",
        "a=tst.isna().sum()\n",
        "ls=a[a>0].index\n",
        "for col in ls:\n",
        "  trn[col]=trn[col].fillna(0)\n",
        "  tst[col]=tst[col].fillna(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRqrD6vz8ol6"
      },
      "source": [
        "Making the callbacks and loading model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVzhwjpjEsW"
      },
      "source": [
        "dk={}\n",
        "class RocCallback(Callback):\n",
        "    def __init__(self,validation_data,epochs):\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.ep=0\n",
        "        self.epochs=epochs\n",
        "        self.val=0\n",
        "        self.wts=[]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.ep+=1\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "        if roc_val>self.val:\n",
        "          self.val=roc_val\n",
        "          self.epoch=10\n",
        "          self.wts=self.model.get_weights()\n",
        "        else:\n",
        "          self.epoch-=1\n",
        "        if self.epoch==0:\n",
        "          self.model.set_weights(self.wts)\n",
        "          self.model.stop_training = True\n",
        "        print('roc-auc_val: %s' % str(round(roc_val,4)))\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "def load_model(dim):\n",
        "  K.clear_session()\n",
        "\n",
        "\n",
        "  uid=Input((1,))\n",
        "  inp=Input((873,))\n",
        "  emb=Embedding(input_dim=dim,output_dim=4)(uid)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(inp)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  emb=Flatten()(emb)\n",
        "  x=Concatenate()([emb,x])\n",
        "  x=Dense(1,activation='sigmoid')(x)\n",
        "  mod=Model(inputs=[inp,uid],outputs=x)\n",
        "  return mod\n",
        "\n",
        "def custom_gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZH6xEokzPfj"
      },
      "source": [
        "Adding all datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZw0LXIzPG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3bd13c-96a6-4096-f4cc-b4334996d8ff"
      },
      "source": [
        "trn_s=trn.shape[0]\n",
        "df=pd.concat([trn,tst],0).reset_index(drop=True)\n",
        "del([trn,tst])\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "autoenc=pd.read_csv('/content/gdrive/My Drive/fraud/without_id.csv',index_col=[0])\n",
        "autoenc=reduce_mem_usage(autoenc)\n",
        "\n",
        "autoenc.columns=[i for i in range(444,444+autoenc.shape[1])]\n",
        "\n",
        "\n",
        "df=pd.concat([df,autoenc],1)\n",
        "del([autoenc])\n",
        "gc.collect()\n",
        "\n",
        "trn=df.loc[:trn_s-1]\n",
        "tst=df.loc[trn_s:].reset_index(drop=True)\n",
        "del([df])\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2151.40 MB\n",
            "Memory usage after optimization is: 544.13 MB\n",
            "Decreased by 74.7%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxmq8JSOz6Hk"
      },
      "source": [
        "categorical=[str(i) for i in range(444)]\n",
        "trn[categorical]=trn[categorical].astype('uint8')\n",
        "tst[categorical]=tst[categorical].astype('uint8')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oor5OujA6Bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42261750-f5b5-4b7a-fd0a-9a05f87b5981"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "splits=KFold(n_splits=5)\n",
        "gc.collect()\n",
        "pre=np.zeros((506691,1))\n",
        "tst=tst.drop(['isFraud'],1)\n",
        "for train_index,test_index in tqdm(splits.split(trn)):\n",
        "  X_train, X_test = trn.loc[train_index], trn.loc[test_index]\n",
        "  y_train, y_test = X_train['isFraud'], X_test['isFraud']\n",
        "  ids={}\n",
        "  for en,id in enumerate(X_train['id'].unique()):\n",
        "    ids[id]=en+2\n",
        "  X_train['id']=X_train['id'].map(lambda x: ids.get(x,1))\n",
        "  X_test['id']=X_test['id'].map(lambda x: ids.get(x,1))\n",
        "  dim=X_train['id'].nunique()+2\n",
        "  gc.collect()\n",
        "  trn_id,tst_id=X_train['id'],X_test['id']\n",
        "  X_train=X_train.drop(['isFraud','id'],1)\n",
        "  X_test=X_test.drop(['isFraud','id'],1)\n",
        "  mod=load_model(dim)\n",
        "  roc = RocCallback(validation_data=([X_test,tst_id], y_test),epochs=10)\n",
        "  mod.compile(optimizer=Nadam(),loss='binary_crossentropy')\n",
        "  es=EarlyStopping(monitor='acu_val',min_delta=0.0001,mode='min',restore_best_weights=True,patience=10)\n",
        "  mod.fit([X_train,trn_id],y_train,validation_data=([X_test,tst_id],y_test),batch_size=2048,epochs=50,callbacks=[roc])\n",
        "  \n",
        "  del[(X_train,y_train)]\n",
        "  gc.collect()\n",
        "\n",
        "  mod.fit([X_test,tst_id],y_test,epochs=2,batch_size=2048)\n",
        "  pre+=mod.predict([tst.drop(['id'],1),tst['id'].map(lambda x: ids.get(x,1))])/5\n",
        "  \n",
        "  del([X_test,y_test,mod])\n",
        "  gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "231/231 [==============================] - 7s 17ms/step - loss: 0.1466 - val_loss: 0.0845\n",
            "roc-auc_val: 0.8866\n",
            "Epoch 2/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0903 - val_loss: 0.0785\n",
            "roc-auc_val: 0.9028\n",
            "Epoch 3/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0758 - val_loss: 0.0847\n",
            "roc-auc_val: 0.8996\n",
            "Epoch 4/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0677 - val_loss: 0.0943\n",
            "roc-auc_val: 0.9073\n",
            "Epoch 5/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0567 - val_loss: 0.0779\n",
            "roc-auc_val: 0.9026\n",
            "Epoch 6/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0502 - val_loss: 0.0863\n",
            "roc-auc_val: 0.9106\n",
            "Epoch 7/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0429 - val_loss: 0.0748\n",
            "roc-auc_val: 0.9169\n",
            "Epoch 8/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0375 - val_loss: 0.0915\n",
            "roc-auc_val: 0.9029\n",
            "Epoch 9/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0329 - val_loss: 0.0847\n",
            "roc-auc_val: 0.8993\n",
            "Epoch 10/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0287 - val_loss: 0.0938\n",
            "roc-auc_val: 0.9071\n",
            "Epoch 11/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0254 - val_loss: 0.0921\n",
            "roc-auc_val: 0.9099\n",
            "Epoch 12/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0221 - val_loss: 0.0741\n",
            "roc-auc_val: 0.9145\n",
            "Epoch 13/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0198 - val_loss: 0.0981\n",
            "roc-auc_val: 0.9103\n",
            "Epoch 14/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0182 - val_loss: 0.0990\n",
            "roc-auc_val: 0.9094\n",
            "Epoch 15/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0163 - val_loss: 0.0981\n",
            "roc-auc_val: 0.903\n",
            "Epoch 16/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0147 - val_loss: 0.0952\n",
            "roc-auc_val: 0.9079\n",
            "Epoch 17/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0132 - val_loss: 0.0872\n",
            "roc-auc_val: 0.9047\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0619\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [02:41, 161.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "231/231 [==============================] - 5s 16ms/step - loss: 0.1400 - val_loss: 0.1004\n",
            "roc-auc_val: 0.9083\n",
            "Epoch 2/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0852 - val_loss: 0.0978\n",
            "roc-auc_val: 0.9125\n",
            "Epoch 3/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0743 - val_loss: 0.0883\n",
            "roc-auc_val: 0.9259\n",
            "Epoch 4/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0638 - val_loss: 0.0860\n",
            "roc-auc_val: 0.9349\n",
            "Epoch 5/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0552 - val_loss: 0.0831\n",
            "roc-auc_val: 0.9383\n",
            "Epoch 6/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0475 - val_loss: 0.0826\n",
            "roc-auc_val: 0.9394\n",
            "Epoch 7/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0418 - val_loss: 0.0797\n",
            "roc-auc_val: 0.9437\n",
            "Epoch 8/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0371 - val_loss: 0.0807\n",
            "roc-auc_val: 0.9374\n",
            "Epoch 9/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0321 - val_loss: 0.0769\n",
            "roc-auc_val: 0.9453\n",
            "Epoch 10/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0278 - val_loss: 0.0825\n",
            "roc-auc_val: 0.9313\n",
            "Epoch 11/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0248 - val_loss: 0.0781\n",
            "roc-auc_val: 0.9429\n",
            "Epoch 12/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0219 - val_loss: 0.0779\n",
            "roc-auc_val: 0.9442\n",
            "Epoch 13/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0195 - val_loss: 0.0785\n",
            "roc-auc_val: 0.9412\n",
            "Epoch 14/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0177 - val_loss: 0.0792\n",
            "roc-auc_val: 0.9437\n",
            "Epoch 15/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0159 - val_loss: 0.0784\n",
            "roc-auc_val: 0.9427\n",
            "Epoch 16/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0146 - val_loss: 0.0832\n",
            "roc-auc_val: 0.9394\n",
            "Epoch 17/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0127 - val_loss: 0.0819\n",
            "roc-auc_val: 0.9417\n",
            "Epoch 18/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0122 - val_loss: 0.0846\n",
            "roc-auc_val: 0.9348\n",
            "Epoch 19/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0111 - val_loss: 0.0809\n",
            "roc-auc_val: 0.9418\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0726\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r2it [05:23, 161.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "231/231 [==============================] - 5s 16ms/step - loss: 0.1316 - val_loss: 0.1008\n",
            "roc-auc_val: 0.8934\n",
            "Epoch 2/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0852 - val_loss: 0.0930\n",
            "roc-auc_val: 0.9092\n",
            "Epoch 3/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0737 - val_loss: 0.0874\n",
            "roc-auc_val: 0.9217\n",
            "Epoch 4/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0646 - val_loss: 0.0849\n",
            "roc-auc_val: 0.9267\n",
            "Epoch 5/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0564 - val_loss: 0.0806\n",
            "roc-auc_val: 0.9344\n",
            "Epoch 6/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0486 - val_loss: 0.0807\n",
            "roc-auc_val: 0.9338\n",
            "Epoch 7/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0430 - val_loss: 0.0791\n",
            "roc-auc_val: 0.9357\n",
            "Epoch 8/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0368 - val_loss: 0.0793\n",
            "roc-auc_val: 0.9313\n",
            "Epoch 9/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0324 - val_loss: 0.0824\n",
            "roc-auc_val: 0.9275\n",
            "Epoch 10/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0285 - val_loss: 0.0785\n",
            "roc-auc_val: 0.9363\n",
            "Epoch 11/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0255 - val_loss: 0.0760\n",
            "roc-auc_val: 0.9425\n",
            "Epoch 12/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.0772\n",
            "roc-auc_val: 0.9403\n",
            "Epoch 13/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0201 - val_loss: 0.0798\n",
            "roc-auc_val: 0.9372\n",
            "Epoch 14/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0181 - val_loss: 0.0779\n",
            "roc-auc_val: 0.9376\n",
            "Epoch 15/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0161 - val_loss: 0.0791\n",
            "roc-auc_val: 0.9387\n",
            "Epoch 16/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0148 - val_loss: 0.0824\n",
            "roc-auc_val: 0.9371\n",
            "Epoch 17/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0129 - val_loss: 0.0846\n",
            "roc-auc_val: 0.9306\n",
            "Epoch 18/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0121 - val_loss: 0.0840\n",
            "roc-auc_val: 0.9347\n",
            "Epoch 19/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0108 - val_loss: 0.0853\n",
            "roc-auc_val: 0.9311\n",
            "Epoch 20/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0100 - val_loss: 0.0854\n",
            "roc-auc_val: 0.9304\n",
            "Epoch 21/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0090 - val_loss: 0.0825\n",
            "roc-auc_val: 0.9311\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0676\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r3it [08:20, 166.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "231/231 [==============================] - 5s 16ms/step - loss: 0.1769 - val_loss: 0.0986\n",
            "roc-auc_val: 0.9088\n",
            "Epoch 2/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0885 - val_loss: 0.0892\n",
            "roc-auc_val: 0.9273\n",
            "Epoch 3/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0758 - val_loss: 0.0880\n",
            "roc-auc_val: 0.9326\n",
            "Epoch 4/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0667 - val_loss: 0.0797\n",
            "roc-auc_val: 0.9447\n",
            "Epoch 5/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0569 - val_loss: 0.0765\n",
            "roc-auc_val: 0.9505\n",
            "Epoch 6/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0500 - val_loss: 0.0762\n",
            "roc-auc_val: 0.9517\n",
            "Epoch 7/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0438 - val_loss: 0.0752\n",
            "roc-auc_val: 0.9533\n",
            "Epoch 8/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0374 - val_loss: 0.0730\n",
            "roc-auc_val: 0.9552\n",
            "Epoch 9/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0333 - val_loss: 0.0725\n",
            "roc-auc_val: 0.9543\n",
            "Epoch 10/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0289 - val_loss: 0.0741\n",
            "roc-auc_val: 0.9554\n",
            "Epoch 11/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0261 - val_loss: 0.0709\n",
            "roc-auc_val: 0.957\n",
            "Epoch 12/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0231 - val_loss: 0.0716\n",
            "roc-auc_val: 0.9572\n",
            "Epoch 13/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0201 - val_loss: 0.0717\n",
            "roc-auc_val: 0.9561\n",
            "Epoch 14/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0184 - val_loss: 0.0699\n",
            "roc-auc_val: 0.9583\n",
            "Epoch 15/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0165 - val_loss: 0.0746\n",
            "roc-auc_val: 0.9566\n",
            "Epoch 16/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0144 - val_loss: 0.0721\n",
            "roc-auc_val: 0.9549\n",
            "Epoch 17/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0133 - val_loss: 0.0746\n",
            "roc-auc_val: 0.9537\n",
            "Epoch 18/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0123 - val_loss: 0.0740\n",
            "roc-auc_val: 0.955\n",
            "Epoch 19/50\n",
            "231/231 [==============================] - 3s 14ms/step - loss: 0.0109 - val_loss: 0.0754\n",
            "roc-auc_val: 0.952\n",
            "Epoch 20/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0098 - val_loss: 0.0721\n",
            "roc-auc_val: 0.9548\n",
            "Epoch 21/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0091 - val_loss: 0.0752\n",
            "roc-auc_val: 0.9511\n",
            "Epoch 22/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0086 - val_loss: 0.0751\n",
            "roc-auc_val: 0.9557\n",
            "Epoch 23/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0079 - val_loss: 0.0771\n",
            "roc-auc_val: 0.9544\n",
            "Epoch 24/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0075 - val_loss: 0.0734\n",
            "roc-auc_val: 0.9561\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0647\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r4it [11:40, 176.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "231/231 [==============================] - 5s 16ms/step - loss: 0.1838 - val_loss: 0.1049\n",
            "roc-auc_val: 0.8751\n",
            "Epoch 2/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0867 - val_loss: 0.0954\n",
            "roc-auc_val: 0.8992\n",
            "Epoch 3/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0765 - val_loss: 0.0987\n",
            "roc-auc_val: 0.9011\n",
            "Epoch 4/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0658 - val_loss: 0.0908\n",
            "roc-auc_val: 0.9158\n",
            "Epoch 5/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0569 - val_loss: 0.0884\n",
            "roc-auc_val: 0.917\n",
            "Epoch 6/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0496 - val_loss: 0.0908\n",
            "roc-auc_val: 0.9195\n",
            "Epoch 7/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0431 - val_loss: 0.0861\n",
            "roc-auc_val: 0.9234\n",
            "Epoch 8/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0378 - val_loss: 0.0886\n",
            "roc-auc_val: 0.9227\n",
            "Epoch 9/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0334 - val_loss: 0.0863\n",
            "roc-auc_val: 0.9259\n",
            "Epoch 10/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0290 - val_loss: 0.0927\n",
            "roc-auc_val: 0.9165\n",
            "Epoch 11/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0256 - val_loss: 0.1027\n",
            "roc-auc_val: 0.9209\n",
            "Epoch 12/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0229 - val_loss: 0.0956\n",
            "roc-auc_val: 0.9236\n",
            "Epoch 13/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0206 - val_loss: 0.0861\n",
            "roc-auc_val: 0.9253\n",
            "Epoch 14/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0184 - val_loss: 0.0875\n",
            "roc-auc_val: 0.9232\n",
            "Epoch 15/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0163 - val_loss: 0.0882\n",
            "roc-auc_val: 0.9267\n",
            "Epoch 16/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0149 - val_loss: 0.0864\n",
            "roc-auc_val: 0.928\n",
            "Epoch 17/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0132 - val_loss: 0.0970\n",
            "roc-auc_val: 0.9213\n",
            "Epoch 18/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0123 - val_loss: 0.1009\n",
            "roc-auc_val: 0.9241\n",
            "Epoch 19/50\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.0115 - val_loss: 0.0890\n",
            "roc-auc_val: 0.924\n",
            "Epoch 20/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0102 - val_loss: 0.0931\n",
            "roc-auc_val: 0.9226\n",
            "Epoch 21/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0916\n",
            "roc-auc_val: 0.9242\n",
            "Epoch 22/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0089 - val_loss: 0.0915\n",
            "roc-auc_val: 0.9273\n",
            "Epoch 23/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0082 - val_loss: 0.0912\n",
            "roc-auc_val: 0.927\n",
            "Epoch 24/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0076 - val_loss: 0.0879\n",
            "roc-auc_val: 0.9279\n",
            "Epoch 25/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0070 - val_loss: 0.0893\n",
            "roc-auc_val: 0.9269\n",
            "Epoch 26/50\n",
            "231/231 [==============================] - 3s 12ms/step - loss: 0.0068 - val_loss: 0.0958\n",
            "roc-auc_val: 0.9226\n",
            "Epoch 1/2\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0700\n",
            "Epoch 2/2\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5it [15:12, 182.54s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVYgkVd5_NVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e831fba5-b2be-4204-dbd4-d0d48754ec3c"
      },
      "source": [
        "sub=pd.read_csv('sample_submission.csv.zip')\n",
        "sub['isFraud']=pre.ravel()\n",
        "sub=sub.set_index('TransactionID')\n",
        "sub.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3663549</th>\n",
              "      <td>0.000009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663550</th>\n",
              "      <td>0.000008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663551</th>\n",
              "      <td>0.005768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663552</th>\n",
              "      <td>0.000307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663553</th>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                isFraud\n",
              "TransactionID          \n",
              "3663549        0.000009\n",
              "3663550        0.000008\n",
              "3663551        0.005768\n",
              "3663552        0.000307\n",
              "3663553        0.000028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VZlw01oHayo"
      },
      "source": [
        "sub.to_csv('sub.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FeqwiR2HcSI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "47b80aaf-32a3-4d5a-d18e-c427e4f71864"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(pre)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff8a816bba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAeWMkwJIWng"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}